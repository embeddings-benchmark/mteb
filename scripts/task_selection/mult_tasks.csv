,Name,Type,Languages,Domains,License,Description
0,BornholmBitextMining,BitextMining,{'dan'},"['Web', 'Social', 'Fiction', 'Written']",CC-BY-4.0,"Danish Bornholmsk Parallel Corpus. Bornholmsk is a Danish dialect spoken on the island of Bornholm, Denmark. Historically it is a part of east Danish which was also spoken in Scania and Halland, Sweden."
1,BibleNLPBitextMining,BitextMining,"{'aoj', 'ncl', 'imo', 'acu', 'eko', 'urb', 'bvd', 'cab', 'bsp', 'mam', 'amf', 'ikk', 'mqj', 'esk', 'tur', 'cpb', 'azb', 'myy', 'nld', 'mcr', 'tgk', 'cbu', 'rwo', 'wmw', 'xbi', 'mdy', 'sri', 'ziw', 'zpu', 'xtm', 'mlp', 'yad', 'cuk', 'tpt', 'shj', 'bch', 'msk', 'taj', 'lat', 'awk', 'azz', 'san', 'mca', 'kpx', 'pes', 'kqw', 'kpg', 'cek', 'cop', 'cnl', 'zai', 'agt', 'kaq', 'cjo', 'dan', 'enq', 'gnw', 'luo', 'kqc', 'kgk', 'tbz', 'mig', 'snc', 'acr', 'kpr', 'mwf', 'nhe', 'beo', 'mxt', 'rmy', 'wal', 'otn', 'sps', 'tcz', 'aak', 'bgs', 'kan', 'zsr', 'bmr', 'gun', 'kpw', 'amm', 'gmv', 'wos', 'cao', 'mkn', 'mek', 'aey', 'nhu', 'mcd', 'mgh', 'kiw', 'lgl', 'ycn', 'nna', 'apz', 'ndg', 'xon', 'ptu', 'glk', 'cmn', 'mwp', 'sab', 'qvw', 'chz', 'far', 'msy', 'ots', 'agr', 'apw', 'ebk', 'agu', 'ind', 'amx', 'jid', 'mhl', 'myk', 'pio', 'tnn', 'yaa', 'kto', 'cap', 'msc', 'ron', 'mkj', 'tam', 'naf', 'tuf', 'ppo', 'zpo', 'bao', 'meu', 'ubr', 'amn', 'zos', 'mzz', 'hin', 'wim', 'bhl', 'npi', 'bpr', 'quf', 'hmo', 'mle', 'tca', 'bjz', 'tof', 'maj', 'tod', 'uvh', 'yut', 'pol', 'zav', 'piu', 'opm', 'csy', 'ken', 'tee', 'mie', 'snn', 'pad', 'cbv', 'mya', 'xsi', 'faa', 'rgu', 'gwi', 'lin', 'reg', 'vid', 'chd', 'mto', 'nca', 'agm', 'soy', 'knf', 'kwd', 'tew', 'maq', 'cco', 'blz', 'swe', 'med', 'tbf', 'taw', 'avt', 'urt', 'ben', 'iou', 'poy', 'pjt', 'are', 'kup', 'amr', 'met', 'spm', 'tbg', 'tfr', 'hus', 'txu', 'cbs', 'buk', 'ncu', 'zpz', 'poe', 'sll', 'atd', 'hla', 'row', 'mxp', 'zpm', 'awb', 'shp', 'nsn', 'mop', 'mcb', 'mal', 'mpj', 'bus', 'hat', 'bre', 'kyf', 'qup', 'kmu', 'jac', 'jic', 'kjs', 'dgr', 'pls', 'ood', 'myw', 'rop', 'hau', 'knj', 'cha', 'ino', 'mbh', 'poi', 'tue', 'epo', 'ake', 'clu', 'mbs', 'bbb', 'zga', 'llg', 'usp', 'cbi', 'ilo', 'mir', 'gvs', 'hns', 'mib', 'agd', 'tpz', 'tel', 'mar', 'aii', 'kyq', 'dgz', 'mjc', 'cle', 'acf', 'gfk', 'ksr', 'trc', 'aia', 'atb', 'lif', 'top', 'gym', 'ngu', 'toc', 'mcp', 'hui', 'agg', 'tav', 'yon', 'awx', 'pab', 'kos', 'byr', 'hix', 'ewe', 'srq', 'nab', 'msm', 'sey', 'mpp', 'ctp', 'nko', 'sja', 'ffm', 'mph', 'ory', 'srp', 'kde', 'ktm', 'wiu', 'mgw', 'mpm', 'kze', 'haw', 'qvz', 'mvn', 'noa', 'zaj', 'mih', 'dik', 'sbs', 'ura', 'gul', 'obo', 'dji', 'ssd', 'tke', 'aon', 'mpt', 'uvl', 'nif', 'jae', 'mks', 'qul', 'xed', 'ame', 'aer', 'usa', 'zlm', 'djk', 'apn', 'pma', 'tiy', 'zpv', 'bzj', 'sxb', 'not', 'srn', 'grc', 'anv', 'guj', 'mit', 'kmg', 'pon', 'seh', 'gyr', 'kqf', 'apu', 'kvn', 'pao', 'mxq', 'adz', 'ong', 'kbh', 'bqc', 'dad', 'ipi', 'gum', 'spy', 'yva', 'wrs', 'rmc', 'snp', 'ese', 'tsw', 'zas', 'zpl', 'heb', 'tuo', 'bvr', 'upv', 'emi', 'yka', 'cux', 'crx', 'als', 'tet', 'mmx', 'alp', 'dop', 'geb', 'deu', 'waj', 'xtd', 'gam', 'kyc', 'ptp', 'ces', 'hbo', 'hub', 'mbt', 'pwg', 'toj', 'dww', 'zty', 'hrv', 'nii', 'tim', 'msb', 'kdc', 'zao', 'blw', 'qvn', 'kbq', 'tos', 'chq', 'gvn', 'tpa', 'myu', 'kmk', 'nhr', 'omw', 'kud', 'kmo', 'cbr', 'kkl', 'wed', 'otq', 'sim', 'caa', 'jao', 'uig', 'ssx', 'nnq', 'ghs', 'lbk', 'bps', 'tzj', 'aaz', 'bmk', 'kyz', 'tmd', 'ntu', 'bjk', 'tvk', 'dgc', 'cof', 'ulk', 'bzd', 'quc', 'abx', 'amo', 'nhg', 'sua', 'swp', 'vie', 'tif', 'nfa', 'tgo', 'dah', 'boa', 'apr', 'sus', 'zpc', 'cac', 'nwi', 'pri', 'otm', 'qwh', 'bba', 'aka', 'cbc', 'mav', 'cak', 'gdn', 'yre', 'wol', 'aau', 'snx', 'sgb', 'gnn', 'hun', 'wnc', 'meq', 'npl', 'kyg', 'bdd', 'inb', 'nuy', 'wat', 'gvc', 'tnc', 'mqb', 'chk', 'wuv', 'amk', 'isn', 'xav', 'bss', 'qvm', 'yaq', 'wap', 'yal', 'bjp', 'kue', 'abt', 'bea', 'qxn', 'ctu', 'bki', 'yrb', 'fai', 'sbk', 'guh', 'fuh', 'maz', 'apb', 'gdr', 'kwj', 'mgc', 'zam', 'bqp', 'ngp', 'rro', 'beu', 'bsn', 'lbb', 'kdl', 'lac', 'srm', 'ded', 'hch', 'cbt', 'sny', 'mcf', 'mio', 'auc', 'cpy', 'aai', 'cpu', 'zab', 'ntp', 'agn', 'qvh', 'arb', 'eri', 'cso', 'kbc', 'amp', 'ndj', 'bmh', 'ata', 'guo', 'hot', 'mna', 'cot', 'ter', 'too', 'prf', 'wbi', 'bkx', 'yuw', 'bzh', 'cme', 'zar', 'kgf', 'mil', 'bbr', 'smk', 'big', 'jiv', 'wiv', 'wro', 'urd', 'dwr', 'kmh', 'kqa', 'kkc', 'nch', 'ukr', 'zap', 'bon', 'gux', 'ian', 'ceb', 'kpf', 'bsj', 'nou', 'aom', 'caf', 'knv', 'lww', 'aly', 'miz', 'zca', 'cya', 'bkq', 'cnt', 'kms', 'nss', 'nhw', 'cuc', 'ape', 'klv', 'plu', 'cax', 'gai', 'bnp', 'box', 'spl', 'pan', 'spp', 'mbc', 'khs', 'wrk', 'tdt', 'cpc', 'lex', 'nhi', 'tuc', 'cth', 'pib', 'amu', 'azg', 'ztq', 'yor', 'arl', 'tnk', 'ckb', 'ncj', 'leu', 'kje', 'bco', 'vmy', 'cgc', 'yle', 'soq', 'uli', 'cta', 'muy', 'arp', 'ita', 'tac', 'kek', 'nhy', 'hop', 'con', 'udu', 'nlg', 'dov', 'mic', 'bmu', 'ubu', 'swh', 'cwe', 'kew', 'auy', 'bel', 'crn', 'nbq', 'sbe', 'yuj', 'hvn', 'jni', 'zia', 'ksj', 'gup', 'klt', 'huv', 'tgl', 'dhg', 'jvn', 'mwe', 'zad', 'kiz', 'rkb', 'mox', 'mwc', 'quh', 'cav', 'uri', 'tbo', 'eng', 'wnu', 'mbb', 'ton', 'tte', 'poh', 'mmo', 'tiw', 'iws', 'tcs', 'ikw', 'rus', 'pir', 'mxb', 'zaa', 'etr', 'aby', 'rai', 'byx', 'zac', 'gaw', 'yss', 'khz', 'mti', 'lid', 'rug', 'fra', 'aso', 'emp', 'dwy', 'stp', 'tlf', 'mva', 'tpi', 'yby', 'ote', 'bef', 'sgz', 'tnp', 'nin', 'cjv', 'ixl', 'mbl', 'tbc', 'ntj', 'daa', 'zat', 'zyp', 'urw', 'lcm', 'gui', 'heg', 'hto', 'qvc', 'wmt', 'gvf', 'mlh', 'huu', 'kwf', 'suz', 'lug', 'chf', 'gub', 'nas', 'cut', 'mau', 'aoi', 'hlt', 'twi', 'mux', 'anh', 'ttc', 'kql', 'cub', 'mcq', 'ruf', 'car', 'viv', 'nvm', 'wbp', 'for', 'bjr', 'nyu', 'qxo', 'yap', 'djr', 'yml', 'asm', 'kvg', 'wsk', 'cbk', 'arn', 'dif', 'tna', 'nho', 'ons', 'alq', 'fue', 'sue', 'mkl', 'dob', 'fuf', 'qvs', 'por', 'tgp', 'bkd', 'kik', 'nak', 'okv', 'bgt', 'mee', 'mps', 'bhg', 'mco', 'roo', 'zaw', 'zpq', 'txq', 'att', 'kbm', 'pah', 'lit', 'nop', 'spa', 'ssg', 'xnn', 'tzo', 'boj', 'aui', 'cni', 'wer', 'mpx', 'bjv', 'atg', 'maa', 'kgp', 'kpj', 'cpa', 'kne', 'nya', 'qve', 'gah', 'qxh', 'nys', 'ign', 'som', 'kwi', 'jpn', 'cui', 'ksd', 'mbj', 'tha', 'tku', 'gng', 'gof', 'qub', 'xla', 'bxh'}","['Religious', 'Written']",CC-BY-SA-4.0,"Partial Bible translations in 829 languages, aligned by verse."
2,BUCC.v2,BitextMining,"{'deu', 'cmn', 'fra', 'rus', 'eng'}",['Written'],Unknown,BUCC bitext mining dataset
3,DiaBlaBitextMining,BitextMining,"{'fra', 'eng'}","['Social', 'Written']",CC BY-NC-SA 4.0,"English-French Parallel Corpus. DiaBLa is an English-French dataset for the evaluation of Machine Translation (MT) for informal, written bilingual dialogue."
4,FloresBitextMining,BitextMining,"{'kin', 'ita', 'zul', 'sin', 'kbp', 'khk', 'ast', 'ell', 'shn', 'slk', 'lim', 'uig', 'hne', 'bho', 'tzm', 'scn', 'mal', 'mlt', 'fon', 'swh', 'hat', 'ajp', 'azj', 'tur', 'bel', 'uzn', 'azb', 'nld', 'tso', 'szl', 'vie', 'hau', 'tgk', 'bos', 'kaz', 'epo', 'tgl', 'pag', 'srd', 'isl', 'kmb', 'grn', 'ilo', 'ace', 'bod', 'aka', 'tel', 'mar', 'nob', 'quy', 'eng', 'ban', 'wol', 'mkd', 'ssw', 'san', 'kea', 'prs', 'pes', 'ary', 'zho', 'hun', 'rus', 'dan', 'jav', 'umb', 'xho', 'plt', 'luo', 'gaz', 'bem', 'kab', 'fra', 'smo', 'tpi', 'ewe', 'sna', 'mag', 'crh', 'hye', 'gla', 'bug', 'amh', 'kan', 'gle', 'bul', 'ory', 'srp', 'bam', 'bjn', 'kor', 'tum', 'nus', 'lug', 'ydd', 'est', 'twi', 'afr', 'kas', 'pbt', 'fij', 'fuv', 'dik', 'min', 'sat', 'glg', 'yue', 'apc', 'lua', 'ayr', 'tir', 'arz', 'kir', 'fao', 'ind', 'fur', 'ibo', 'kmr', 'pap', 'arb', 'asm', 'lmo', 'ron', 'tsn', 'vec', 'zsm', 'awa', 'tam', 'mri', 'snd', 'sot', 'slv', 'cjk', 'nno', 'dyu', 'guj', 'lvs', 'por', 'hin', 'khm', 'cat', 'kik', 'eus', 'npi', 'aeb', 'nso', 'kat', 'urd', 'tuk', 'ukr', 'taq', 'mni', 'pol', 'run', 'kam', 'cym', 'ceb', 'lit', 'mya', 'knc', 'kon', 'lij', 'spa', 'lin', 'heb', 'oci', 'ars', 'tat', 'sag', 'mos', 'acm', 'ltg', 'acq', 'als', 'pan', 'lus', 'fin', 'bak', 'deu', 'nya', 'swe', 'ces', 'som', 'jpn', 'ltz', 'ben', 'hrv', 'mai', 'kac', 'yor', 'tha', 'ckb', 'dzo', 'war', 'lao', 'sun'}","['Non-fiction', 'Encyclopaedic', 'Written']",CC BY-SA 4.0,FLORES is a benchmark dataset for machine translation between English and low-resource languages.
5,IN22GenBitextMining,BitextMining,"{'san', 'kas', 'mni', 'sat', 'mal', 'brx', 'pan', 'asm', 'tam', 'snd', 'kan', 'mai', 'ben', 'ory', 'guj', 'doi', 'hin', 'tel', 'mar', 'gom', 'eng', 'npi', 'urd'}","['Web', 'Legal', 'Government', 'News', 'Religious', 'Non-fiction', 'Written']",CC-BY-4.0,IN22-Gen is a n-way parallel general-purpose multi-domain benchmark dataset for machine translation spanning English and 22 Indic languages.
6,IndicGenBenchFloresBitextMining,BitextMining,"{'san', 'mup', 'mni', 'sat', 'bgc', 'hne', 'bho', 'nep', 'mal', 'pan', 'asm', 'awa', 'tam', 'boy', 'kan', 'raj', 'mwr', 'mai', 'ben', 'pus', 'ory', 'guj', 'urd', 'bod', 'hin', 'tel', 'mar', 'gom', 'eng', 'gbm'}","['Web', 'News', 'Written']",CC-BY-SA-4.0,Flores-IN dataset is an extension of Flores dataset released as a part of the IndicGenBench by Google
7,NollySentiBitextMining,BitextMining,"{'yor', 'pcm', 'hau', 'ibo', 'eng'}","['Social', 'Reviews', 'Written']",CC BY-SA 4.0,"NollySenti is Nollywood movie reviews for five languages widely spoken in Nigeria (English, Hausa, Igbo, Nigerian-Pidgin, and Yoruba."
8,NorwegianCourtsBitextMining,BitextMining,"{'nob', 'nno'}","['Legal', 'Written']",CC BY 4.0,"Nynorsk and Bokmål parallel corpus from Norwegian courts. Norwegian courts have two standardised written languages. Bokmål is a variant closer to Danish, while Nynorsk was created to resemble regional dialects of Norwegian."
9,NTREXBitextMining,BitextMining,"{'kin', 'ita', 'zul', 'sin', 'swa', 'ell', 'slk', 'uig', 'mal', 'mlt', 'tur', 'bel', 'nld', 'lav', 'vie', 'hau', 'fuc', 'tgk', 'bos', 'kaz', 'isl', 'div', 'bod', 'tel', 'mar', 'nob', 'eng', 'ton', 'wol', 'mkd', 'ssw', 'tah', 'prs', 'zho', 'hun', 'rus', 'dan', 'xho', 'nep', 'bem', 'sqi', 'fra', 'smo', 'hmn', 'ewe', 'sna', 'hye', 'amh', 'kan', 'gle', 'bul', 'pus', 'srp', 'kor', 'afr', 'fij', 'glg', 'yue', 'tir', 'kir', 'fao', 'ind', 'ibo', 'kmr', 'arb', 'ron', 'fil', 'orm', 'tsn', 'tam', 'mri', 'snd', 'slv', 'nno', 'guj', 'por', 'hin', 'khm', 'cat', 'eus', 'nso', 'kat', 'urd', 'tuk', 'ukr', 'pol', 'cym', 'lit', 'mya', 'spa', 'mey', 'heb', 'tat', 'mlg', 'pan', 'fin', 'bak', 'deu', 'nya', 'shi', 'swe', 'ces', 'som', 'jpn', 'aze', 'ltz', 'ben', 'hrv', 'mon', 'yor', 'tha', 'ckb', 'fas', 'dzo', 'ven', 'uzb', 'msa', 'nde', 'lao'}","['News', 'Written']",CC-BY-SA-4.0,"NTREX is a News Test References dataset for Machine Translation Evaluation, covering translation from English into 128 languages. We select language pairs according to the M2M-100 language grouping strategy, resulting in 1916 directions."
10,NusaTranslationBitextMining,BitextMining,"{'bew', 'bbc', 'mad', 'sun', 'ind', 'min', 'bhp', 'jav', 'mak', 'abs', 'rej', 'mui'}","['Social', 'Written']",CC BY-SA 4.0,NusaTranslation is a parallel dataset for machine translation on 11 Indonesia languages and English.
11,NusaXBitextMining,BitextMining,"{'bjn', 'bbc', 'mad', 'nij', 'ace', 'ind', 'min', 'bug', 'jav', 'eng', 'ban', 'sun'}","['Reviews', 'Written']",CC BY-SA 4.0,NusaX is a parallel dataset for machine translation and sentiment analysis on 11 Indonesia languages and English.
12,Tatoeba,BitextMining,"{'ita', 'max', 'ast', 'ell', 'slk', 'nov', 'uig', 'mal', 'swh', 'bre', 'mhr', 'tur', 'bel', 'kur', 'nld', 'vie', 'cha', 'kaz', 'bos', 'epo', 'tgl', 'ber', 'isl', 'tel', 'mar', 'nob', 'eng', 'lat', 'mkd', 'csb', 'pes', 'yid', 'hun', 'rus', 'dan', 'jav', 'xho', 'kab', 'sqi', 'fra', 'ido', 'hye', 'dtp', 'gla', 'arq', 'amh', 'swg', 'gle', 'bul', 'srp', 'kor', 'ina', 'est', 'afr', 'cmn', 'glg', 'yue', 'kzj', 'arz', 'fao', 'ind', 'orv', 'ron', 'cor', 'cbk', 'wuu', 'awa', 'zsm', 'tam', 'lfn', 'nds', 'slv', 'nno', 'lvs', 'por', 'hin', 'khm', 'cat', 'eus', 'pam', 'kat', 'ang', 'urd', 'ile', 'tuk', 'ara', 'ukr', 'pol', 'gsw', 'cym', 'ceb', 'lit', 'spa', 'tzl', 'heb', 'oci', 'tat', 'fin', 'deu', 'swe', 'ces', 'hsb', 'aze', 'jpn', 'ben', 'hrv', 'mon', 'pms', 'tha', 'dsb', 'fry', 'war', 'uzb'}",['Written'],CC BY 2.0,"1,000 English-aligned sentence pairs for each language based on the Tatoeba corpus"
13,BulgarianStoreReviewSentimentClassfication,Classification,{'bul'},"['Reviews', 'Written']",cc-by-4.0,Bulgarian online store review dataset for sentiment classification.
14,CzechProductReviewSentimentClassification,Classification,{'ces'},"['Reviews', 'Written']",CC BY-NC-SA 4.0,"User reviews of products on Czech e-shop Mall.cz with 3 sentiment classes (positive, neutral, negative)"
15,GreekLegalCodeClassification,Classification,{'ell'},"['Legal', 'Written']",cc-by-4.0,Greek Legal Code Dataset for Classification. (subset = chapter)
16,DBpediaClassification,Classification,{'eng'},"['Encyclopaedic', 'Written']",cc-by-sa-3.0,"DBpedia14 is a dataset of English texts from Wikipedia articles, categorized into 14 non-overlapping classes based on their DBpedia ontology."
17,FinancialPhrasebankClassification,Classification,{'eng'},"['News', 'Written']",cc-by-nc-sa-3.0,"Polar sentiment dataset of sentences from financial news, categorized by sentiment into positive, negative, or neutral."
18,PoemSentimentClassification,Classification,{'eng'},"['Reviews', 'Written']",CC-BY-4.0,Poem Sentiment is a sentiment dataset of poem verses from Project Gutenberg.
19,ToxicConversationsClassification,Classification,{'eng'},"['Social', 'Written']",CC BY 4.0,Collection of comments from the Civil Comments platform together with annotations if the comment is toxic or not.
20,TweetTopicSingleClassification,Classification,{'eng'},"['Social', 'News', 'Written']",Other,"Topic classification dataset on Twitter with 6 labels. Each instance of
        TweetTopic comes with a timestamp which distributes from September 2019 to August 2021.
        Tweets were preprocessed before the annotation to normalize some artifacts, converting
        URLs into a special token {{URL}} and non-verified usernames into {{USERNAME}}. For verified
        usernames, we replace its display name (or account name) with symbols {@}.
        "
21,EstonianValenceClassification,Classification,{'est'},"['News', 'Written']",CC BY 4.0,Dataset containing annotated Estonian news data from the Postimees and Õhtuleht newspapers.
22,FilipinoShopeeReviewsClassification,Classification,{'fil'},"['Social', 'Written']",MPL-2.0,"The Shopee reviews tl 15 dataset is constructed by randomly taking 2100 training samples and 450 samples for testing and validation for each review star from 1 to 5. In total, there are 10500 training samples and 2250 each in validation and testing samples."
23,GujaratiNewsClassification,Classification,{'guj'},"['News', 'Written']",MIT,A Gujarati dataset for 3-class classification of Gujarati news articles
24,SentimentAnalysisHindi,Classification,{'hin'},"['Reviews', 'Written']",CC BY-NC-SA 4.0,Hindi Sentiment Analysis Dataset
25,IndonesianIdClickbaitClassification,Classification,{'ind'},"['News', 'Written']",cc-by-4.0,The CLICK-ID dataset is a collection of Indonesian news headlines that was collected from 12 local online news publishers.
26,ItaCaseholdClassification,Classification,{'ita'},"['Legal', 'Government', 'Written']",Apache 2.0,An Italian Dataset consisting of 1101 pairs of judgments and their official holdings between the years 2019 and 2022 from the archives of Italian Administrative Justice categorized with 64 subjects.
27,KorSarcasmClassification,Classification,{'kor'},"['Social', 'Written']",MIT,"
        The Korean Sarcasm Dataset was created to detect sarcasm in text, which can significantly alter the original
        meaning of a sentence. 9319 tweets were collected from Twitter and labeled for sarcasm or not_sarcasm. These
        tweets were gathered by querying for: irony sarcastic, and
        sarcasm. 
        The dataset was created by gathering HTML data from Twitter. Queries for hashtags that include sarcasm
        and variants of it were used to return tweets. It was preprocessed by removing the keyword
        hashtag, urls and mentions of the user to preserve anonymity.
        "
28,KurdishSentimentClassification,Classification,{'kur'},"['Web', 'Written']",CC BY 4.0,Kurdish Sentiment Dataset
29,MacedonianTweetSentimentClassification,Classification,{'mkd'},"['Social', 'Written']",CC BY-NC-SA 3.0,An Macedonian dataset for tweet sentiment classification.
30,AfriSentiClassification,Classification,"{'yor', 'kin', 'pcm', 'twi', 'ary', 'por', 'tso', 'arq', 'hau', 'amh', 'ibo', 'swa'}","['Social', 'Written']",Creative Commons Attribution 4.0 International License,AfriSenti is the largest sentiment analysis dataset for under-represented African languages.
31,AmazonCounterfactualClassification,Classification,"{'deu', 'eng', 'jpn'}","['Reviews', 'Written']",CC BY 4.0,A collection of Amazon customer reviews annotated for counterfactual detection pair classification.
32,CataloniaTweetClassification,Classification,"{'spa', 'cat'}","['Social', 'Government', 'Written']",cc-by-sa-4.0,"This dataset contains two corpora in Spanish and Catalan that consist of annotated Twitter
        messages for automatic stance detection. The data was collected over 12 days during February and March
        of 2019 from tweets posted in Barcelona, and during September of 2018 from tweets posted in the town of Terrassa, Catalonia.
        Each corpus is annotated with three classes: AGAINST, FAVOR and NEUTRAL, which express the stance
        towards the target - independence of Catalonia.
        "
33,CyrillicTurkicLangClassification,Classification,"{'kir', 'bak', 'sah', 'chv', 'tat', 'rus', 'kaz', 'krc', 'tyv'}","['Web', 'Written']",CC BY-NC 4.0 DEED,Cyrillic dataset of 8 Turkic languages spoken in Russia and former USSR
34,IndicLangClassification,Classification,"{'san', 'kas', 'mni', 'sat', 'mal', 'brx', 'pan', 'asm', 'tam', 'snd', 'kan', 'mai', 'ben', 'ory', 'guj', 'doi', 'hin', 'tel', 'mar', 'gom', 'npi', 'urd'}","['Web', 'Non-fiction', 'Written']",CC0,A language identification test set for native-script as well as Romanized text which spans 22 Indic languages.
35,MasakhaNEWSClassification,Classification,"{'yor', 'pcm', 'lin', 'run', 'fra', 'hau', 'ibo', 'amh', 'som', 'eng', 'swa', 'xho', 'tir', 'lug', 'sna', 'orm'}","['News', 'Written']",cc-by-nc-4.0,MasakhaNEWS is the largest publicly available dataset for news topic classification in 16 languages widely spoken in Africa. The train/validation/test sets are available for all the 16 languages.
36,MassiveIntentClassification,Classification,"{'afr', 'ara', 'ita', 'pol', 'hun', 'rus', 'cym', 'dan', 'jav', 'swa', 'ell', 'mya', 'spa', 'sqi', 'mal', 'heb', 'cmo', 'fra', 'ind', 'tur', 'ron', 'fin', 'deu', 'tam', 'nld', 'hye', 'swe', 'lav', 'vie', 'amh', 'kan', 'slv', 'jpn', 'aze', 'tgl', 'ben', 'mon', 'isl', 'tha', 'kor', 'por', 'fas', 'hin', 'khm', 'tel', 'nob', 'eng', 'msa', 'kat', 'urd'}",['Spoken'],Apache 2.0,MASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages
37,MultiHateClassification,Classification,"{'ara', 'deu', 'nld', 'por', 'cmn', 'ita', 'pol', 'fra', 'hin', 'eng', 'spa'}","['Constructed', 'Written']",cc-by-4.0,"Hate speech detection dataset with binary
                       (hateful vs non-hateful) labels. Includes 25+ distinct types of hate
                       and challenging non-hate, and 11 languages.
                     "
38,NordicLangClassification,Classification,"{'isl', 'swe', 'fao', 'nob', 'dan', 'nno'}",['Encyclopaedic'],cc-by-sa-3.0,A dataset for Nordic language identification.
39,NusaParagraphEmotionClassification,Classification,"{'bew', 'mad', 'bbc', 'sun', 'min', 'bug', 'jav', 'mak', 'rej', 'mui'}","['Non-fiction', 'Fiction', 'Written']",Apache 2.0,NusaParagraphEmotionClassification is a multi-class emotion classification on 10 Indonesian languages from the NusaParagraph dataset.
40,NusaX-senti,Classification,"{'bjn', 'bbc', 'mad', 'nij', 'ace', 'ind', 'min', 'bug', 'jav', 'eng', 'ban', 'sun'}","['Reviews', 'Web', 'Social', 'Constructed', 'Written']",CC-BY-SA 4.0,"NusaX is a high-quality multilingual parallel corpus that covers 12 languages, Indonesian, English, and 10 Indonesian local languages, namely Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Ngaju, Sundanese, and Toba Batak. NusaX-Senti is a 3-labels (positive, neutral, negative) sentiment analysis dataset for 10 Indonesian local languages + Indonesian and English."
41,ScalaClassification,Classification,"{'swe', 'nob', 'dan', 'nno'}","['Fiction', 'News', 'Non-fiction', 'Blog', 'Spoken', 'Web', 'Written']",CC BY-SA 4.0,"ScaLa a linguistic acceptability dataset for the mainland Scandinavian languages automatically constructed from dependency annotations in Universal Dependencies Treebanks. 
        Published as part of 'ScandEval: A Benchmark for Scandinavian Natural Language Processing'"
42,SwissJudgementClassification,Classification,"{'ita', 'deu', 'fra'}","['Legal', 'Written']",CC-BY-4.0,"Multilingual, diachronic dataset of Swiss Federal Supreme Court cases annotated with the respective binarized judgment outcome (approval/dismissal)"
43,NepaliNewsClassification,Classification,{'nep'},"['News', 'Written']",CC BY-SA 4.0,A Nepali dataset for 7500 news articles 
44,OdiaNewsClassification,Classification,{'ory'},"['News', 'Written']",MIT,A Odia dataset for 3-class classification of Odia news articles
45,PunjabiNewsClassification,Classification,{'pan'},"['News', 'Written']",MIT,A Punjabi dataset for 2-class classification of Punjabi news articles
46,PolEmo2.0-OUT,Classification,{'pol'},"['Written', 'Social']",cc-by-sa-4.0,"A collection of Polish online reviews from four domains: medicine, hotels, products and school. The PolEmo2.0-OUT task is to predict the sentiment of out-of-domain (products and school) reviews using models train on reviews from medicine and hotels domains."
47,PAC,Classification,{'pol'},"['Legal', 'Written']",cc-by-nc-sa-4.0,Polish Paraphrase Corpus
48,SinhalaNewsClassification,Classification,{'sin'},"['News', 'Written']",mit,"This file contains news texts (sentences) belonging to 5 different news categories (political, business, technology, sports and Entertainment). The original dataset was released by Nisansa de Silva (Sinhala Text Classification: Observations from the Perspective of a Resource Poor Language, 2015)."
49,CSFDSKMovieReviewSentimentClassification,Classification,{'slk'},"['Reviews', 'Written']",CC-BY-SA-4.0,The dataset contains 30k user reviews from csfd.cz in Slovak.
50,SiswatiNewsClassification,Classification,{'ssw'},"['News', 'Written']",CC-BY-SA-4.0,Siswati News Classification Dataset
51,SlovakMovieReviewSentimentClassification,Classification,{'svk'},"['Reviews', 'Written']",CC BY-NC-SA 4.0,"User reviews of movies on the CSFD movie database, with 2 sentiment classes (positive, negative)"
52,SwahiliNewsClassification,Classification,{'swa'},"['News', 'Written']",CC BY-NC-SA 4.0,"Dataset for Swahili News Classification, categorized with 6 domains (Local News (Kitaifa), International News (Kimataifa), Finance News (Uchumi), Health News (Afya), Sports News (Michezo), and Entertainment News (Burudani)). Building and Optimizing Swahili Language Models: Techniques, Embeddings, and Datasets"
53,DalajClassification,Classification,{'swe'},"['Non-fiction', 'Written']",CC-BY-4.0,A Swedish dataset for linguistic acceptability. Available as a part of Superlim.
54,TswanaNewsClassification,Classification,{'tsn'},"['News', 'Written']",CC-BY-SA-4.0,Tswana News Classification Dataset
55,IsiZuluNewsClassification,Classification,{'zul'},"['News', 'Written']",CC-BY-SA-4.0,isiZulu News Classification Dataset
56,WikiCitiesClustering,Clustering,{'eng'},"['Encyclopaedic', 'Written']",cc-by-sa-4.0,"Clustering of Wikipedia articles of cities by country from https://huggingface.co/datasets/wikipedia. Test set includes 126 countries, and a total of 3531 cities."
57,MasakhaNEWSClusteringS2S,Clustering,"{'yor', 'pcm', 'lin', 'run', 'fra', 'hau', 'ibo', 'amh', 'som', 'eng', 'swa', 'xho', 'tir', 'lug', 'sna', 'orm'}",,,Clustering of news article headlines from MasakhaNEWS dataset. Clustering of 10 sets on the news article label.
58,RomaniBibleClustering,Clustering,{'rom'},"['Religious', 'Written']",MIT,Clustering verses from the Bible in Kalderash Romani by book.
59,ArXivHierarchicalClusteringP2P,Clustering,{'eng'},"['Academic', 'Written']",CC0,"Clustering of titles+abstract from arxiv. Clustering of 30 sets, either on the main or secondary category"
60,ArXivHierarchicalClusteringS2S,Clustering,{'eng'},"['Academic', 'Written']",CC0,"Clustering of titles from arxiv. Clustering of 30 sets, either on the main or secondary category"
61,BigPatentClustering.v2,Clustering,{'eng'},"['Legal', 'Written']",cc-by-4.0,"Clustering of documents from the Big Patent dataset. Test set only includes documentsbelonging to a single category, with a total of 9 categories."
62,BiorxivClusteringP2P.v2,Clustering,{'eng'},"['Academic', 'Written']",https://www.biorxiv.org/content/about-biorxiv,Clustering of titles+abstract from biorxiv across 26 categories.
63,MedrxivClusteringP2P.v2,Clustering,{'eng'},"['Academic', 'Medical', 'Written']",https://www.medrxiv.org/content/about-medrxiv,Clustering of titles+abstract from medrxiv across 51 categories.
64,StackExchangeClustering.v2,Clustering,{'eng'},"['Web', 'Written']",Not specified,"Clustering of titles from 121 stackexchanges. Clustering of 25 sets, each with 10-50 classes, and each class with 100 - 1000 sentences."
65,AlloProfClusteringS2S.v2,Clustering,{'fra'},"['Encyclopaedic', 'Written']",mit,Clustering of document titles from Allo Prof dataset. Clustering of 10 sets on the document topic.
66,HALClusteringS2S.v2,Clustering,{'fra'},"['Academic', 'Written']",Apache-2.0,Clustering of titles from HAL (https://huggingface.co/datasets/lyon-nlp/clustering-hal-s2s)
67,SIB200ClusteringS2S,Clustering,"{'kin', 'ita', 'zul', 'sin', 'kbp', 'khk', 'ast', 'ell', 'shn', 'slk', 'lim', 'uig', 'hne', 'bho', 'tzm', 'scn', 'mal', 'mlt', 'fon', 'swh', 'hat', 'ajp', 'azj', 'tur', 'bel', 'uzn', 'azb', 'nld', 'tso', 'szl', 'vie', 'hau', 'tgk', 'bos', 'kaz', 'epo', 'tgl', 'pag', 'srd', 'isl', 'kmb', 'grn', 'ilo', 'ace', 'bod', 'aka', 'tel', 'mar', 'nob', 'quy', 'eng', 'ban', 'wol', 'mkd', 'ssw', 'san', 'kea', 'prs', 'pes', 'ary', 'zho', 'hun', 'rus', 'dan', 'jav', 'umb', 'xho', 'plt', 'luo', 'gaz', 'bem', 'kab', 'fra', 'smo', 'tpi', 'ewe', 'sna', 'mag', 'crh', 'hye', 'gla', 'bug', 'amh', 'kan', 'gle', 'bul', 'ory', 'srp', 'bam', 'bjn', 'kor', 'tum', 'nus', 'lug', 'ydd', 'est', 'twi', 'afr', 'kas', 'pbt', 'fij', 'fuv', 'dik', 'min', 'sat', 'glg', 'yue', 'apc', 'lua', 'ayr', 'tir', 'arz', 'kir', 'fao', 'ind', 'fur', 'ibo', 'kmr', 'pap', 'arb', 'asm', 'lmo', 'ron', 'tsn', 'vec', 'zsm', 'awa', 'tam', 'mri', 'snd', 'sot', 'slv', 'cjk', 'nno', 'dyu', 'guj', 'lvs', 'por', 'hin', 'khm', 'cat', 'kik', 'eus', 'npi', 'aeb', 'nso', 'kat', 'urd', 'tuk', 'ukr', 'taq', 'mni', 'pol', 'run', 'kam', 'cym', 'ceb', 'lit', 'mya', 'knc', 'kon', 'lij', 'spa', 'lin', 'heb', 'oci', 'ars', 'tat', 'sag', 'mos', 'acm', 'ltg', 'acq', 'als', 'pan', 'lus', 'fin', 'bak', 'deu', 'nya', 'swe', 'ces', 'som', 'jpn', 'ltz', 'ben', 'hrv', 'mai', 'kac', 'yor', 'tha', 'ckb', 'dzo', 'nqo', 'war', 'lao', 'sun'}","['News', 'Written']",cc-by-sa-4.0,"SIB-200 is the largest publicly available topic classification
        dataset based on Flores-200 covering 205 languages and dialects annotated. The dataset is
        annotated in English for the topics,  science/technology, travel, politics, sports,
        health, entertainment, and geography. The labels are then transferred to the other languages
        in Flores-200 which are machine-translated.
        "
68,WikiClusteringP2P.v2,Clustering,"{'sqi', 'wln', 'mlt', 'ilo', 'lav', 'min', 'cat', 'ces', 'dan', 'eus', 'bos', 'glv', 'sco', 'kur'}","['Encyclopaedic', 'Written']",cc-by-sa-3.0,"Clustering of wikipedia articles inspired by BlubrbsClusteringP2P. Labels are taken from top-level categories of the respective languages (e.g., https://lv.wikipedia.org/wiki/Kategorija:Pamatkategorijas)."
69,SNLHierarchicalClusteringP2P,Clustering,{'nob'},"['Encyclopaedic', 'Non-fiction', 'Written']",CC-BY-NC,Webscrabed articles from the Norwegian lexicon 'Det Store Norske Leksikon'. Uses articles categories as clusters.
70,PlscClusteringP2P.v2,Clustering,{'pol'},"['Academic', 'Written']",cc0-1.0,"Clustering of Polish article titles+abstracts from Library of Science (https://bibliotekanauki.pl/), either on the scientific field or discipline."
71,SwednClusteringP2P,Clustering,{'swe'},"['News', 'Non-fiction', 'Written']",cc-by-4.0,"The SWE-DN corpus is based on 1,963,576 news articles from the Swedish newspaper Dagens Nyheter (DN) during the years 2000--2020. The articles are filtered to resemble the CNN/DailyMail dataset both regarding textual structure. This dataset uses the category labels as clusters."
72,CLSClusteringP2P.v2,Clustering,{'cmn'},"['Academic', 'Written']",Apache-2.0,Clustering of titles + abstract from CLS dataset. Clustering of 13 sets on the main category.
73,StackOverflowQA,Retrieval,{'eng'},"['Programming', 'Written']",MIT,The dataset is a collection of natural language queries and their corresponding response which may include some text mixed with code snippets. The task is to retrieve the most relevant response for a given query.
74,TwitterHjerneRetrieval,Retrieval,{'dan'},"['Social', 'Written']",CC BY 4.0,Danish question asked on Twitter with the Hashtag #Twitterhjerne ('Twitter brain') and their corresponding answer.
75,AILAStatutes,Retrieval,{'eng'},"['Legal', 'Written']",CC BY 4.0,This dataset is structured for the task of identifying the most relevant statutes for a given situation.
76,ArguAna,Retrieval,{'eng'},"['Medical', 'Written']",cc-by-sa-4.0,NFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval
77,HagridRetrieval,Retrieval,{'eng'},"['Encyclopaedic', 'Written']",apache-2.0,HAGRID (Human-in-the-loop Attributable Generative Retrieval for Information-seeking Dataset)is a dataset for generative information-seeking scenarios. It consists of queriesalong with a set of manually labelled relevant passages
78,LegalBenchCorporateLobbying,Retrieval,{'eng'},"['Legal', 'Written']",CC BY 4.0,The dataset includes bill titles and bill summaries related to corporate lobbying.
79,LEMBPasskeyRetrieval,Retrieval,{'eng'},"['Fiction', 'Written']",Not specified,passkey subset of dwzhu/LongEmbed dataset.
80,SCIDOCS,Retrieval,{'eng'},"['Academic', 'Written', 'Non-fiction']",cc-by-sa-4.0,"SciDocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation."
81,SpartQA,Retrieval,{'eng'},"['Encyclopaedic', 'Written']",MIT,Measuring the ability to retrieve the groundtruth answers to reasoning task queries on SpartQA.
82,TempReasonL1,Retrieval,{'eng'},"['Encyclopaedic', 'Written']",CC BY-SA 3.0,Measuring the ability to retrieve the groundtruth answers to reasoning task queries on TempReason l1.
83,TRECCOVID,Retrieval,{'eng'},,,TRECCOVID is an ad-hoc search challenge based on the COVID-19 dataset containing scientific articles related to the COVID-19 pandemic.
84,WinoGrande,Retrieval,{'eng'},"['Encyclopaedic', 'Written']",CC BY,Measuring the ability to retrieve the groundtruth answers to reasoning task queries on winogrande.
85,BelebeleRetrieval,Retrieval,"{'kin', 'ita', 'zul', 'sin', 'khk', 'ell', 'shn', 'slk', 'mal', 'mlt', 'swh', 'hat', 'azj', 'tur', 'uzn', 'nld', 'tso', 'vie', 'hau', 'tgk', 'kaz', 'tgl', 'isl', 'grn', 'ilo', 'bod', 'tel', 'mar', 'nob', 'eng', 'wol', 'mkd', 'ssw', 'kea', 'pes', 'ary', 'zho', 'hun', 'rus', 'dan', 'jav', 'xho', 'plt', 'luo', 'gaz', 'fra', 'sna', 'hye', 'amh', 'kan', 'bul', 'ory', 'srp', 'bam', 'kor', 'lug', 'est', 'afr', 'pbt', 'fuv', 'apc', 'tir', 'arz', 'kir', 'ind', 'ibo', 'arb', 'asm', 'ron', 'tsn', 'zsm', 'tam', 'mri', 'snd', 'sot', 'slv', 'guj', 'lvs', 'por', 'hin', 'khm', 'cat', 'eus', 'npi', 'nso', 'kat', 'urd', 'ukr', 'pol', 'ceb', 'lit', 'mya', 'spa', 'lin', 'heb', 'ars', 'acm', 'pan', 'als', 'fin', 'deu', 'nya', 'swe', 'ces', 'som', 'jpn', 'ben', 'hrv', 'kac', 'yor', 'tha', 'ckb', 'war', 'lao', 'sun'}","['Web', 'News', 'Written']",CC-BY-SA-4.0,Belebele is a multiple-choice machine reading comprehension (MRC) dataset spanning 122 language variants (including 115 distinct languages and their scripts)
86,MLQARetrieval,Retrieval,"{'ara', 'deu', 'vie', 'hin', 'zho', 'eng', 'spa'}","['Encyclopaedic', 'Written']",cc-by-sa-3.0,"MLQA (MultiLingual Question Answering) is a benchmark dataset for evaluating cross-lingual question answering performance.
        MLQA consists of over 5K extractive QA instances (12K in English) in SQuAD format in seven languages - English, Arabic,
        German, Spanish, Hindi, Vietnamese and Simplified Chinese. MLQA is highly parallel, with QA instances parallel between
        4 different languages on average."
87,StatcanDialogueDatasetRetrieval,Retrieval,"{'fra', 'eng'}","['Government', 'Web', 'Written']",https://huggingface.co/datasets/McGill-NLP/statcan-dialogue-dataset-retrieval/blob/main/LICENSE.md,"A Dataset for Retrieving Data Tables through Conversations with Genuine Intents, available in English and French."
88,WikipediaRetrievalMultilingual,Retrieval,"{'srp', 'deu', 'nor', 'nld', 'por', 'swe', 'fas', 'ita', 'hin', 'ben', 'ces', 'dan', 'eng', 'bul', 'ron', 'fin'}","['Encyclopaedic', 'Written']",cc-by-sa-3.0,The dataset is derived from Cohere's wikipedia-2023-11 dataset and contains synthetically generated queries.
89,CovidRetrieval,Retrieval,{'cmn'},,,COVID-19 news articles
90,Core17InstructionRetrieval,InstructionRetrieval,{'eng'},"['News', 'Written']",MIT,Measuring retrieval instruction following ability on Core17 narratives.
91,News21InstructionRetrieval,InstructionRetrieval,{'eng'},"['News', 'Written']",MIT,Measuring retrieval instruction following ability on News21 narratives.
92,Robust04InstructionRetrieval,InstructionRetrieval,{'eng'},"['News', 'Written']",MIT,Measuring retrieval instruction following ability on Robust04 narratives.
93,KorHateSpeechMLClassification,MultilabelClassification,{'kor'},"['Social', 'Written']",cc-by-sa-4.0,"
        The Korean Multi-label Hate Speech Dataset, K-MHaS, consists of 109,692 utterances from Korean online news comments,
        labelled with 8 fine-grained hate speech classes (labels: Politics, Origin, Physical, Age, Gender, Religion, Race, Profanity)
        or Not Hate Speech class. Each utterance provides from a single to four labels that can handles Korean language patterns effectively.
        For more details, please refer to the paper about K-MHaS, published at COLING 2022.
        This dataset is based on the Korean online news comments available on Kaggle and Github.
        The unlabeled raw data was collected between January 2018 and June 2020.
        The language producers are users who left the comments on the Korean online news platform between 2018 and 2020. 
        "
94,MalteseNewsClassification,MultilabelClassification,{'mlt'},"['Constructed', 'Written']",cc-by-nc-sa-4.0,"A multi-label topic classification dataset for Maltese News
        Articles. The data was collected from the press_mt subset from Korpus
        Malti v4.0. Article contents were cleaned to filter out JavaScript, CSS,
        & repeated non-Maltese sub-headings. The labels are based on the category
        field from this corpus. 
        "
95,MultiEURLEXMultilabelClassification,MultilabelClassification,"{'est', 'ita', 'pol', 'hun', 'dan', 'lit', 'ell', 'slk', 'spa', 'mlt', 'fra', 'ron', 'fin', 'deu', 'nld', 'swe', 'lav', 'ces', 'slv', 'hrv', 'bul', 'por', 'eng'}","['Legal', 'Government', 'Written']",CC BY-SA 4.0,EU laws in 23 EU languages containing gold labels.
96,BrazilianToxicTweetsClassification,MultilabelClassification,{'por'},"['Constructed', 'Written']",CC BY-SA 4.0,"
        ToLD-Br is the biggest dataset for toxic tweets in Brazilian Portuguese, crowdsourced by 42 annotators selected from
        a pool of 129 volunteers. Annotators were selected aiming to create a plural group in terms of demographics (ethnicity,
        sexual orientation, age, gender). Each tweet was labeled by three annotators in 6 possible categories: LGBTQ+phobia,
        Xenophobia, Obscene, Insult, Misogyny and Racism.
        "
97,CEDRClassification,MultilabelClassification,{'rus'},"['Web', 'Social', 'Blog', 'Written']",apache-2.0,"Classification of sentences by emotions, labeled into 5 categories (joy, sadness, surprise, fear, and anger)."
98,CTKFactsNLI,PairClassification,{'ces'},"['News', 'Written']",CC-BY-SA-3.0,"Czech Natural Language Inference dataset of around 3K evidence-claim pairs labelled with SUPPORTS, REFUTES or NOT ENOUGH INFO veracity labels. Extracted from a round of fact-checking experiments."
99,SprintDuplicateQuestions,PairClassification,{'eng'},"['Programming', 'Written']",Not specified,Duplicate questions from the Sprint community.
100,TwitterURLCorpus,PairClassification,{'eng'},,,Paraphrase-Pairs of Tweets.
101,ArmenianParaphrasePC,PairClassification,{'hye'},"['News', 'Written']",Apache-2.0,asparius/Armenian-Paraphrase-PC
102,indonli,PairClassification,{'ind'},"['Encyclopaedic', 'Web', 'News', 'Written']",CC-BY-SA 4.0,IndoNLI is the first human-elicited Natural Language Inference (NLI) dataset for Indonesian. IndoNLI is annotated by both crowd workers and experts.
103,OpusparcusPC,PairClassification,"{'deu', 'swe', 'fra', 'rus', 'eng', 'fin'}","['Spoken', 'Spoken']",cc-by-nc-4.0,"Opusparcus is a paraphrase corpus for six European language: German, English, Finnish, French, Russian, and Swedish. The paraphrases consist of subtitles from movies and TV shows."
104,PawsXPairClassification,PairClassification,"{'deu', 'kor', 'cmn', 'fra', 'eng', 'jpn', 'spa'}","['Web', 'Encyclopaedic', 'Written']",Custom (commercial),{PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification
105,RTE3,PairClassification,"{'fra', 'deu', 'eng', 'ita'}","['News', 'Web', 'Encyclopaedic', 'Written']",cc-by-4.0,Recognising Textual Entailment Challenge (RTE-3) aim to provide the NLP community with a benchmark to test progress in recognizing textual entailment
106,XNLI,PairClassification,"{'tha', 'ara', 'deu', 'vie', 'fra', 'hin', 'rus', 'zho', 'swa', 'eng', 'tur', 'ell', 'spa', 'bul'}","['Non-fiction', 'Fiction', 'Government', 'Written']",Not specified,
107,PpcPC,PairClassification,{'pol'},"['Fiction', 'Non-fiction', 'Web', 'Written', 'Spoken', 'Social', 'News']",GPL-3.0,Polish Paraphrase Corpus
108,TERRa,PairClassification,{'rus'},"['News', 'Web', 'Written']",mit,"Textual Entailment Recognition for Russian. This task requires to recognize, given two text fragments, whether the meaning of one text is entailed (can be inferred) from the other text."
109,WebLINXCandidatesReranking,Reranking,{'eng'},"['Academic', 'Web', 'Written']",CC BY-NC-SA 4.0,WebLINX is a large-scale benchmark of 100K interactions across 2300 expert demonstrations of conversational web navigation. The reranking task focuses on finding relevant elements at every given step in the trajectory.
110,AlloprofReranking,Reranking,{'fra'},"['Web', 'Academic', 'Written']",CC BY-NC-SA 4.0,"This dataset was provided by AlloProf, an organisation in Quebec, Canada offering resources and a help forum curated by a large number of teachers to students on all subjects taught from in primary and secondary school"
111,VoyageMMarcoReranking,Reranking,{'jpn'},"['Academic', 'Non-fiction', 'Written']",CC BY 4.0,a hard-negative augmented version of the Japanese MMARCO dataset as used in Voyage AI Evaluation Suite
112,WikipediaRerankingMultilingual,Reranking,"{'srp', 'deu', 'nor', 'nld', 'por', 'swe', 'fas', 'ita', 'hin', 'ben', 'ces', 'dan', 'eng', 'bul', 'ron', 'fin'}","['Encyclopaedic', 'Written']",cc-by-sa-3.0,The dataset is derived from Cohere's wikipedia-2023-11 dataset and contains synthetically generated queries.
113,RuBQReranking,Reranking,{'rus'},"['Encyclopaedic', 'Written']",cc-by-sa-4.0,Paragraph reranking based on RuBQ 2.0. Give paragraphs that answer the question higher scores.
114,T2Reranking,Reranking,{'cmn'},,,T2Ranking: A large-scale Chinese Benchmark for Passage Ranking
115,GermanSTSBenchmark,STS,{'deu'},,,Semantic Textual Similarity Benchmark (STSbenchmark) dataset translated into German. Translations were originally done by T-Systems on site services GmbH.
116,SICK-R,STS,{'eng'},,,Semantic Textual Similarity SICK-R dataset as described here:
117,STS12,STS,{'eng'},"['Encyclopaedic', 'News', 'Written']",Not specified,SemEval-2012 Task 6.
118,STS13,STS,{'eng'},"['Web', 'News', 'Non-fiction', 'Written']",Not specified,SemEval STS 2013 dataset.
119,STS14,STS,{'eng'},"['Blog', 'Web', 'Spoken']",Not specified,SemEval STS 2014 dataset. Currently only the English dataset
120,STS15,STS,{'eng'},"['Blog', 'News', 'Web', 'Written', 'Spoken']",Not specified,SemEval STS 2015 dataset
121,STSBenchmark,STS,{'eng'},,,Semantic Textual Similarity Benchmark (STSbenchmark) dataset.
122,FaroeseSTS,STS,{'fao'},"['News', 'Web', 'Written']",cc-by-4.0,Semantic Text Similarity (STS) corpus for Faroese.
123,FinParaSTS,STS,{'fin'},"['News', 'Subtitles', 'Written']",cc-by-sa-4.0,Finnish paraphrase-based semantic similarity corpus
124,JSICK,STS,{'jpn'},"['Web', 'Written']",cc-by-4.0,"JSICK is the Japanese NLI and STS dataset by manually translating the English dataset SICK (Marelli et al., 2014) into Japanese."
125,IndicCrosslingualSTS,STS,"{'ory', 'tam', 'mal', 'guj', 'hin', 'tel', 'mar', 'kan', 'eng', 'pan', 'ben', 'asm', 'urd'}","['News', 'Non-fiction', 'Web', 'Spoken', 'Government', 'Written', 'Spoken']",CC0,This is a Semantic Textual Similarity testset between English and 12 high-resource Indic languages.
126,SemRel24STS,STS,"{'kin', 'afr', 'ary', 'arq', 'hau', 'hin', 'ind', 'tel', 'amh', 'mar', 'eng', 'arb'}","['Spoken', 'Written']",Not specified,"SemRel2024 is a collection of Semantic Textual Relatedness (STR) datasets for 14 languages, including African and Asian languages. The datasets are composed of sentence pairs, each assigned a relatedness score between 0 (completely) unrelated and 1 (maximally related) with a large range of expected relatedness values."
127,STS17,STS,"{'ara', 'deu', 'kor', 'nld', 'ita', 'fra', 'eng', 'tur', 'spa'}","['News', 'Web', 'Written']",Not specified,Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation
128,STS22.v2,STS,"{'ara', 'deu', 'cmn', 'ita', 'pol', 'fra', 'rus', 'eng', 'tur', 'spa'}","['News', 'Written']",Not specified,SemEval 2022 Task 8: Multilingual News Article Similarity. Version 2 filters updated on STS22 by removing pairs where one of entries contain empty sentences.
129,STSES,STS,{'spa'},['Written'],cc-by-4.0,"Spanish test sets from SemEval-2014 (Agirre et al., 2014) and SemEval-2015 (Agirre et al., 2015)"
130,STSB,STS,{'cmn'},,,A Chinese dataset for textual relatedness
