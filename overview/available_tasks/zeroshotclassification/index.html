
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../visualsts%28multi%29/">
      
      
        <link rel="next" href="../../available_models/image/">
      
      
      <link rel="icon" href="../../../images/logos/mteb_logo/dots-icon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>ZeroShotClassification - Massive Text Embedding Benchmark</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="light-blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#zeroshotclassification" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Massive Text Embedding Benchmark" class="md-header__button md-logo" aria-label="Massive Text Embedding Benchmark" data-md-component="logo">
      
  <img src="../../../images/logos/mteb_logo/dots-icon.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Massive Text Embedding Benchmark
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              ZeroShotClassification
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="light-blue"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="light-blue"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/embeddings-benchmark/mteb" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../.." class="md-tabs__link">
          
  
  
    
  
  Get Started

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../contributing/adding_a_model/" class="md-tabs__link">
          
  
  
    
  
  Contributing

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
  
    
  
  Overview

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../api/" class="md-tabs__link">
          
  
  
    
  
  API

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="https://huggingface.co/spaces/mteb/leaderboard" class="md-tabs__link">
        
  
  
    
  
  Leaderboard

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Massive Text Embedding Benchmark" class="md-nav__button md-logo" aria-label="Massive Text Embedding Benchmark" data-md-component="logo">
      
  <img src="../../../images/logos/mteb_logo/dots-icon.png" alt="logo">

    </a>
    Massive Text Embedding Benchmark
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/embeddings-benchmark/mteb" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../.." class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Get Started
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_1" id="__nav_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Get Started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../whats_new/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    New in v2.0 🎉
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Installation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_4" >
        
          
          <label class="md-nav__link" for="__nav_1_4" id="__nav_1_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Usage
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_4">
            <span class="md-nav__icon md-icon"></span>
            Usage
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../usage/get_started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Get Started
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../usage/defining_the_model/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Defining the Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../usage/selecting_tasks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Selecting Tasks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../usage/running_the_evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Running the Evaluation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../usage/loading_results/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Loading Results
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../usage/cli/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Command Line Interface
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../usage/leaderboard/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Running the Leaderboard
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_5" >
        
          
          <label class="md-nav__link" for="__nav_1_5" id="__nav_1_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Advanced Usage
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_5">
            <span class="md-nav__icon md-icon"></span>
            Advanced Usage
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced_usage/two_stage_reranking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Two stage reranking
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../advanced_usage/cache_embeddings/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cache embeddings
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Contributing
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Contributing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../contributing/adding_a_model/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Adding a Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../contributing/adding_a_dataset/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Adding a Task
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../contributing/adding_a_benchmark/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Adding a Benchmark
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../CONTRIBUTING/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Guidelines
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Overview
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Benchmarks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Benchmarks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../available_benchmarks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Available Benchmarks
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Tasks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Tasks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3_1" checked>
        
          
          <label class="md-nav__link" for="__nav_3_3_1" id="__nav_3_3_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Available Tasks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_3_1">
            <span class="md-nav__icon md-icon"></span>
            Available Tasks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../any2anymultilingualretrieval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Any2AnyMultilingualRetrieval
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../any2anyretrieval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Any2AnyRetrieval
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bitextmining/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    BitextMining
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../classification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Classification
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../clustering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Clustering
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../compositionality/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Compositionality
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../documentunderstanding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DocumentUnderstanding
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../imageclassification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ImageClassification
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../imageclustering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ImageClustering
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../instructionreranking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    InstructionReranking
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../instructionretrieval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    InstructionRetrieval
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../multilabelclassification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MultilabelClassification
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pairclassification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    PairClassification
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../regression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Regression
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reranking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Reranking
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../retrieval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Retrieval
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    STS
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../summarization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Summarization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../visioncentricqa/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    VisionCentricQA
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../visualsts%28eng%29/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    VisualSTS(eng)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../visualsts%28multi%29/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    VisualSTS(multi)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    ZeroShotClassification
    
  </span>
  

      </a>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Models
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_1" >
        
          
          <label class="md-nav__link" for="__nav_3_4_1" id="__nav_3_4_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Available Models
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_1">
            <span class="md-nav__icon md-icon"></span>
            Available Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../available_models/image/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Image Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../available_models/image_text/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Image-text Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../available_models/text/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Text Model
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../api/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    API
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../api/evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Evaluation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../api/benchmark/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Benchmark
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../api/task/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Task
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../api/model/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../api/results/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Results
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../api/types/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Additional Types
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://huggingface.co/spaces/mteb/leaderboard" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Leaderboard
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/embeddings-benchmark/mteb/blob/main/docs/overview/available_tasks/zeroshotclassification.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/embeddings-benchmark/mteb/raw/main/docs/overview/available_tasks/zeroshotclassification.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="zeroshotclassification">ZeroShotClassification<a class="headerlink" href="#zeroshotclassification" title="Permanent link">&para;</a></h1>
<!-- This document is auto-generated. Changes will be overwritten. Please change the generating script. -->

<ul>
<li><strong>Number of tasks:</strong> 24</li>
</ul>
<h4 id="birdsnapzeroshot">BirdsnapZeroShot<a class="headerlink" href="#birdsnapzeroshot" title="Permanent link">&para;</a></h4>
<p>Classifying bird images from 500 species. </p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/isaacchung/birdsnap"><code>isaacchung/birdsnap</code></a> • <strong>License:</strong> not specified • <a href="https://openaccess.thecvf.com/content_cvpr_2014/html/Berg_Birdsnap_Large-scale_Fine-grained_2014_CVPR_paper.html">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Encyclopaedic</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Berg_2014_CVPR</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Berg, Thomas and Liu, Jiongxin and Woo Lee, Seung and Alexander, Michelle L. and Jacobs, David W. and Belhumeur, Peter N.}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}</span><span class="p">,</span>
<span class="w">  </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{June}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Birdsnap: Large-scale Fine-grained Visual Categorization of Birds}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2014}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="cifar100zeroshot">CIFAR100ZeroShot<a class="headerlink" href="#cifar100zeroshot" title="Permanent link">&para;</a></h4>
<p>Classifying images from 100 classes.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/uoft-cs/cifar100"><code>uoft-cs/cifar100</code></a> • <strong>License:</strong> not specified • <a href="https://huggingface.co/datasets/uoft-cs/cifar100">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Web</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@techreport</span><span class="p">{</span><span class="nl">Krizhevsky09learningmultiple</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Alex Krizhevsky}</span><span class="p">,</span>
<span class="w">  </span><span class="na">institution</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Learning multiple layers of features from tiny images}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2009}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="cifar10zeroshot">CIFAR10ZeroShot<a class="headerlink" href="#cifar10zeroshot" title="Permanent link">&para;</a></h4>
<p>Classifying images from 10 classes.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/uoft-cs/cifar10"><code>uoft-cs/cifar10</code></a> • <strong>License:</strong> not specified • <a href="https://huggingface.co/datasets/uoft-cs/cifar10">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Web</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@techreport</span><span class="p">{</span><span class="nl">Krizhevsky09learningmultiple</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Alex Krizhevsky}</span><span class="p">,</span>
<span class="w">  </span><span class="na">institution</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Learning multiple layers of features from tiny images}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2009}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="clevrcountzeroshot">CLEVRCountZeroShot<a class="headerlink" href="#clevrcountzeroshot" title="Permanent link">&para;</a></h4>
<p>CLEVR count objects task.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/clip-benchmark/wds_vtab-clevr_count_all"><code>clip-benchmark/wds_vtab-clevr_count_all</code></a> • <strong>License:</strong> not specified • <a href="https://openaccess.thecvf.com/content_cvpr_2017/html/Johnson_CLEVR_A_Diagnostic_CVPR_2017_paper.html">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Constructed</td>
<td>human-annotated</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Johnson_2017_CVPR</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C. and Girshick, Ross}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}</span><span class="p">,</span>
<span class="w">  </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{July}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="clevrzeroshot">CLEVRZeroShot<a class="headerlink" href="#clevrzeroshot" title="Permanent link">&para;</a></h4>
<p>CLEVR closest object distance identification task.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/clip-benchmark/wds_vtab-clevr_closest_object_distance"><code>clip-benchmark/wds_vtab-clevr_closest_object_distance</code></a> • <strong>License:</strong> cc-by-4.0 • <a href="https://openaccess.thecvf.com/content_cvpr_2017/html/Johnson_CLEVR_A_Diagnostic_CVPR_2017_paper.html">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Constructed</td>
<td>human-annotated</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Johnson_2017_CVPR</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C. and Girshick, Ross}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}</span><span class="p">,</span>
<span class="w">  </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{July}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="caltech101zeroshot">Caltech101ZeroShot<a class="headerlink" href="#caltech101zeroshot" title="Permanent link">&para;</a></h4>
<p>Classifying images of 101 widely varied objects.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/mteb/Caltech101"><code>mteb/Caltech101</code></a> • <strong>License:</strong> not specified • <a href="https://ieeexplore.ieee.org/document/1384978">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Encyclopaedic</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">1384978</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Li Fei-Fei and Fergus, R. and Perona, P.}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2004 Conference on Computer Vision and Pattern Recognition Workshop}</span><span class="p">,</span>
<span class="w">  </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{10.1109/CVPR.2004.383}</span><span class="p">,</span>
<span class="w">  </span><span class="na">keywords</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Bayesian methods;Testing;Humans;Maximum likelihood estimation;Assembly;Shape;Machine vision;Image recognition;Parameter estimation;Image databases}</span><span class="p">,</span>
<span class="w">  </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{178-178}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories}</span><span class="p">,</span>
<span class="w">  </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2004}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="country211zeroshot">Country211ZeroShot<a class="headerlink" href="#country211zeroshot" title="Permanent link">&para;</a></h4>
<p>Classifying images of 211 countries.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/clip-benchmark/wds_country211"><code>clip-benchmark/wds_country211</code></a> • <strong>License:</strong> cc-by-sa-4.0 • <a href="https://huggingface.co/datasets/clip-benchmark/wds_country211">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Scene</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">radford2021learning</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{arXiv preprint arXiv:2103.00020}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Learning Transferable Visual Models From Natural Language Supervision}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="dtdzeroshot">DTDZeroShot<a class="headerlink" href="#dtdzeroshot" title="Permanent link">&para;</a></h4>
<p>Describable Textures Dataset in 47 categories.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/tanganke/dtd"><code>tanganke/dtd</code></a> • <strong>License:</strong> not specified • <a href="https://www.robots.ox.ac.uk/~vgg/data/dtd/">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Encyclopaedic</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">cimpoi14describing</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{M. Cimpoi and S. Maji and I. Kokkinos and S. Mohamed and and A. Vedaldi}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Proceedings of the {IEEE} Conf. on Computer Vision and Pattern Recognition ({CVPR})}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Describing Textures in the Wild}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2014}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="eurosatzeroshot">EuroSATZeroShot<a class="headerlink" href="#eurosatzeroshot" title="Permanent link">&para;</a></h4>
<p>Classifying satellite images.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/timm/eurosat-rgb"><code>timm/eurosat-rgb</code></a> • <strong>License:</strong> not specified • <a href="https://ieeexplore.ieee.org/document/8736785">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Encyclopaedic</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">8736785</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian}</span><span class="p">,</span>
<span class="w">  </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{10.1109/JSTARS.2019.2918242}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}</span><span class="p">,</span>
<span class="w">  </span><span class="na">keywords</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Satellites;Earth;Remote sensing;Machine learning;Spatial resolution;Feature extraction;Benchmark testing;Dataset;deep convolutional neural network;deep learning;earth observation;land cover classification;land use classification;machine learning;remote sensing;satellite image classification;satellite images}</span><span class="p">,</span>
<span class="w">  </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{7}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2217-2226}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification}</span><span class="p">,</span>
<span class="w">  </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{12}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="fer2013zeroshot">FER2013ZeroShot<a class="headerlink" href="#fer2013zeroshot" title="Permanent link">&para;</a></h4>
<p>Classifying facial emotions.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/clip-benchmark/wds_fer2013"><code>clip-benchmark/wds_fer2013</code></a> • <strong>License:</strong> not specified • <a href="https://arxiv.org/abs/1412.6572">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Encyclopaedic</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">goodfellow2015explainingharnessingadversarialexamples</span><span class="p">,</span>
<span class="w">  </span><span class="na">archiveprefix</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{arXiv}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy}</span><span class="p">,</span>
<span class="w">  </span><span class="na">eprint</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{1412.6572}</span><span class="p">,</span>
<span class="w">  </span><span class="na">primaryclass</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{stat.ML}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Explaining and Harnessing Adversarial Examples}</span><span class="p">,</span>
<span class="w">  </span><span class="na">url</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{https://arxiv.org/abs/1412.6572}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2015}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="fgvcaircraftzeroshot">FGVCAircraftZeroShot<a class="headerlink" href="#fgvcaircraftzeroshot" title="Permanent link">&para;</a></h4>
<p>Classifying aircraft images from 41 manufacturers and 102 variants.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/mteb/FGVCAircraftZeroShot"><code>mteb/FGVCAircraftZeroShot</code></a> • <strong>License:</strong> not specified • <a href="https://arxiv.org/abs/1306.5151">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Encyclopaedic</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">maji2013finegrainedvisualclassificationaircraft</span><span class="p">,</span>
<span class="w">  </span><span class="na">archiveprefix</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{arXiv}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Subhransu Maji and Esa Rahtu and Juho Kannala and Matthew Blaschko and Andrea Vedaldi}</span><span class="p">,</span>
<span class="w">  </span><span class="na">eprint</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{1306.5151}</span><span class="p">,</span>
<span class="w">  </span><span class="na">primaryclass</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{cs.CV}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Fine-Grained Visual Classification of Aircraft}</span><span class="p">,</span>
<span class="w">  </span><span class="na">url</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{https://arxiv.org/abs/1306.5151}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2013}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="food101zeroshot">Food101ZeroShot<a class="headerlink" href="#food101zeroshot" title="Permanent link">&para;</a></h4>
<p>Classifying food.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/ethz/food101"><code>ethz/food101</code></a> • <strong>License:</strong> not specified • <a href="https://huggingface.co/datasets/ethz/food101">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Web</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">bossard14</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{European Conference on Computer Vision}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Food-101 -- Mining Discriminative Components with Random Forests}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2014}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="gtsrbzeroshot">GTSRBZeroShot<a class="headerlink" href="#gtsrbzeroshot" title="Permanent link">&para;</a></h4>
<p>The German Traffic Sign Recognition Benchmark (GTSRB) is a multi-class classification dataset for traffic signs. It consists of dataset of more than 50,000 traffic sign images. The dataset comprises 43 classes with unbalanced class frequencies.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/clip-benchmark/wds_gtsrb"><code>clip-benchmark/wds_gtsrb</code></a> • <strong>License:</strong> not specified • <a href="https://benchmark.ini.rub.de/">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Scene</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">6033395</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Stallkamp, Johannes and Schlipsing, Marc and Salmen, Jan and Igel, Christian}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{The 2011 International Joint Conference on Neural Networks}</span><span class="p">,</span>
<span class="w">  </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{10.1109/IJCNN.2011.6033395}</span><span class="p">,</span>
<span class="w">  </span><span class="na">keywords</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Humans;Training;Image color analysis;Benchmark testing;Lead;Histograms;Image resolution}</span><span class="p">,</span>
<span class="w">  </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{1453-1460}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{The German Traffic Sign Recognition Benchmark: A multi-class classification competition}</span><span class="p">,</span>
<span class="w">  </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2011}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="imagenet1kzeroshot">Imagenet1kZeroShot<a class="headerlink" href="#imagenet1kzeroshot" title="Permanent link">&para;</a></h4>
<p>ImageNet, a large-scale ontology of images built upon the backbone of the WordNet structure.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/clip-benchmark/wds_imagenet1k"><code>clip-benchmark/wds_imagenet1k</code></a> • <strong>License:</strong> not specified • <a href="https://ieeexplore.ieee.org/document/5206848">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Scene</td>
<td>human-annotated</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">deng2009imagenet</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2009 IEEE Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
<span class="w">  </span><span class="na">organization</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Ieee}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{248--255}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{ImageNet: A large-scale hierarchical image database}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2009}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="mnistzeroshot">MNISTZeroShot<a class="headerlink" href="#mnistzeroshot" title="Permanent link">&para;</a></h4>
<p>Classifying handwritten digits.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/ylecun/mnist"><code>ylecun/mnist</code></a> • <strong>License:</strong> not specified • <a href="https://en.wikipedia.org/wiki/MNIST_database">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Encyclopaedic</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">lecun2010mnist</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{LeCun, Yann and Cortes, Corinna and Burges, CJ}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{MNIST handwritten digit database}</span><span class="p">,</span>
<span class="w">  </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2010}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="oxfordpetszeroshot">OxfordPetsZeroShot<a class="headerlink" href="#oxfordpetszeroshot" title="Permanent link">&para;</a></h4>
<p>Classifying animal images.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/isaacchung/OxfordPets"><code>isaacchung/OxfordPets</code></a> • <strong>License:</strong> not specified • <a href="https://arxiv.org/abs/1306.5151">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Encyclopaedic</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">maji2013finegrainedvisualclassificationaircraft</span><span class="p">,</span>
<span class="w">  </span><span class="na">archiveprefix</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{arXiv}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Subhransu Maji and Esa Rahtu and Juho Kannala and Matthew Blaschko and Andrea Vedaldi}</span><span class="p">,</span>
<span class="w">  </span><span class="na">eprint</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{1306.5151}</span><span class="p">,</span>
<span class="w">  </span><span class="na">primaryclass</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{cs.CV}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Fine-Grained Visual Classification of Aircraft}</span><span class="p">,</span>
<span class="w">  </span><span class="na">url</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{https://arxiv.org/abs/1306.5151}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2013}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="patchcamelyonzeroshot">PatchCamelyonZeroShot<a class="headerlink" href="#patchcamelyonzeroshot" title="Permanent link">&para;</a></h4>
<p>Histopathology diagnosis classification dataset.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/clip-benchmark/wds_vtab-pcam"><code>clip-benchmark/wds_vtab-pcam</code></a> • <strong>License:</strong> not specified • <a href="https://link.springer.com/chapter/10.1007/978-3-030-00934-2_24">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Medical</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1007/978-3-030-00934-2_24</span><span class="p">,</span>
<span class="w">  </span><span class="na">address</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Cham}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Veeling, Bastiaan S.</span>
<span class="s">and Linmans, Jasper</span>
<span class="s">and Winkens, Jim</span>
<span class="s">and Cohen, Taco</span>
<span class="s">and Welling, Max}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Medical Image Computing and Computer Assisted Intervention -- MICCAI 2018}</span><span class="p">,</span>
<span class="w">  </span><span class="na">editor</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Frangi, Alejandro F.</span>
<span class="s">and Schnabel, Julia A.</span>
<span class="s">and Davatzikos, Christos</span>
<span class="s">and Alberola-L{\&#39;o}pez, Carlos</span>
<span class="s">and Fichtinger, Gabor}</span><span class="p">,</span>
<span class="w">  </span><span class="na">isbn</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{978-3-030-00934-2}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{210--218}</span><span class="p">,</span>
<span class="w">  </span><span class="na">publisher</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Springer International Publishing}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Rotation Equivariant CNNs for Digital Pathology}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2018}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="resisc45zeroshot">RESISC45ZeroShot<a class="headerlink" href="#resisc45zeroshot" title="Permanent link">&para;</a></h4>
<p>Remote Sensing Image Scene Classification by Northwestern Polytechnical University (NWPU).</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/timm/resisc45"><code>timm/resisc45</code></a> • <strong>License:</strong> not specified • <a href="https://ieeexplore.ieee.org/abstract/document/7891544">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Encyclopaedic</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@article</span><span class="p">{</span><span class="nl">7891544</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Cheng, Gong and Han, Junwei and Lu, Xiaoqiang}</span><span class="p">,</span>
<span class="w">  </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{10.1109/JPROC.2017.2675998}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Proceedings of the IEEE}</span><span class="p">,</span>
<span class="w">  </span><span class="na">keywords</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Remote sensing;Benchmark testing;Spatial resolution;Social network services;Satellites;Image analysis;Machine learning;Unsupervised learning;Classification;Benchmark data set;deep learning;handcrafted features;remote sensing image;scene classification;unsupervised feature learning}</span><span class="p">,</span>
<span class="w">  </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{10}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{1865-1883}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Remote Sensing Image Scene Classification: Benchmark and State of the Art}</span><span class="p">,</span>
<span class="w">  </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{105}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="renderedsst2">RenderedSST2<a class="headerlink" href="#renderedsst2" title="Permanent link">&para;</a></h4>
<p>RenderedSST2.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/clip-benchmark/wds_renderedsst2"><code>clip-benchmark/wds_renderedsst2</code></a> • <strong>License:</strong> mit • <a href="https://huggingface.co/datasets/clip-benchmark/wds_renderedsst2">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Reviews</td>
<td>human-annotated</td>
<td>created</td>
</tr>
</tbody>
</table>
<h4 id="stl10zeroshot">STL10ZeroShot<a class="headerlink" href="#stl10zeroshot" title="Permanent link">&para;</a></h4>
<p>Classifying 96x96 images from 10 classes.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/tanganke/stl10"><code>tanganke/stl10</code></a> • <strong>License:</strong> not specified • <a href="https://cs.stanford.edu/~acoates/stl10/">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Encyclopaedic</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pmlr-v15-coates11a</span><span class="p">,</span>
<span class="w">  </span><span class="na">address</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Fort Lauderdale, FL, USA}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Coates, Adam and Ng, Andrew and Lee, Honglak}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics}</span><span class="p">,</span>
<span class="w">  </span><span class="na">editor</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Gordon, Geoffrey and Dunson, David and Dudík, Miroslav}</span><span class="p">,</span>
<span class="w">  </span><span class="na">month</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{11--13 Apr}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{215--223}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pdf</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{http://proceedings.mlr.press/v15/coates11a/coates11a.pdf}</span><span class="p">,</span>
<span class="w">  </span><span class="na">publisher</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{PMLR}</span><span class="p">,</span>
<span class="w">  </span><span class="na">series</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{An Analysis of Single-Layer Networks in Unsupervised Feature Learning}</span><span class="p">,</span>
<span class="w">  </span><span class="na">url</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{https://proceedings.mlr.press/v15/coates11a.html}</span><span class="p">,</span>
<span class="w">  </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{15}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2011}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="sun397zeroshot">SUN397ZeroShot<a class="headerlink" href="#sun397zeroshot" title="Permanent link">&para;</a></h4>
<p>Large scale scene recognition in 397 categories.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/dpdl-benchmark/sun397"><code>dpdl-benchmark/sun397</code></a> • <strong>License:</strong> not specified • <a href="https://ieeexplore.ieee.org/abstract/document/5539970">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Encyclopaedic</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">5539970</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Xiao, Jianxiong and Hays, James and Ehinger, Krista A. and Oliva, Aude and Torralba, Antonio}</span><span class="p">,</span>
<span class="w">  </span><span class="na">booktitle</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
<span class="w">  </span><span class="na">doi</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{10.1109/CVPR.2010.5539970}</span><span class="p">,</span>
<span class="w">  </span><span class="na">number</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{3485-3492}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{SUN database: Large-scale scene recognition from abbey to zoo}</span><span class="p">,</span>
<span class="w">  </span><span class="na">volume</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2010}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="scimmir">SciMMIR<a class="headerlink" href="#scimmir" title="Permanent link">&para;</a></h4>
<p>SciMMIR.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/m-a-p/SciMMIR"><code>m-a-p/SciMMIR</code></a> • <strong>License:</strong> not specified • <a href="https://huggingface.co/datasets/m-a-p/SciMMIR">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Academic</td>
<td>human-annotated</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">wu2024scimmirbenchmarkingscientificmultimodal</span><span class="p">,</span>
<span class="w">  </span><span class="na">archiveprefix</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{arXiv}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Siwei Wu and Yizhi Li and Kang Zhu and Ge Zhang and Yiming Liang and Kaijing Ma and Chenghao Xiao and Haoran Zhang and Bohao Yang and Wenhu Chen and Wenhao Huang and Noura Al Moubayed and Jie Fu and Chenghua Lin}</span><span class="p">,</span>
<span class="w">  </span><span class="na">eprint</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2401.13478}</span><span class="p">,</span>
<span class="w">  </span><span class="na">primaryclass</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{cs.IR}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval}</span><span class="p">,</span>
<span class="w">  </span><span class="na">url</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{https://arxiv.org/abs/2401.13478}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="stanfordcarszeroshot">StanfordCarsZeroShot<a class="headerlink" href="#stanfordcarszeroshot" title="Permanent link">&para;</a></h4>
<p>Classifying car images from 96 makes.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/isaacchung/StanfordCars"><code>isaacchung/StanfordCars</code></a> • <strong>License:</strong> not specified • <a href="https://pure.mpg.de/rest/items/item_2029263/component/file_2029262/content">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Scene</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Krause2013CollectingAL</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Jonathan Krause and Jia Deng and Michael Stark and Li Fei-Fei}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Collecting a Large-scale Dataset of Fine-grained Cars}</span><span class="p">,</span>
<span class="w">  </span><span class="na">url</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{https://api.semanticscholar.org/CorpusID:16632981}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2013}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>
<h4 id="ucf101zeroshot">UCF101ZeroShot<a class="headerlink" href="#ucf101zeroshot" title="Permanent link">&para;</a></h4>
<p>UCF101 is an action recognition data set of realistic
action videos collected from YouTube, having 101 action categories. This
version of the dataset does not contain images but images saved frame by
frame. Train and test splits are generated based on the authors' first
version train/test list.</p>
<p><strong>Dataset:</strong> <a href="https://huggingface.co/datasets/flwrlabs/ucf101"><code>flwrlabs/ucf101</code></a> • <strong>License:</strong> not specified • <a href="https://huggingface.co/datasets/flwrlabs/ucf101">Learn more →</a></p>
<table>
<thead>
<tr>
<th>Task category</th>
<th>Score</th>
<th>Languages</th>
<th>Domains</th>
<th>Annotations Creators</th>
<th>Sample Creation</th>
</tr>
</thead>
<tbody>
<tr>
<td>image to text (i2t)</td>
<td>accuracy</td>
<td>eng</td>
<td>Scene</td>
<td>derived</td>
<td>created</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Citation</summary>
<div class="highlight"><pre><span></span><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">soomro2012ucf101dataset101human</span><span class="p">,</span>
<span class="w">  </span><span class="na">archiveprefix</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{arXiv}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Khurram Soomro and Amir Roshan Zamir and Mubarak Shah}</span><span class="p">,</span>
<span class="w">  </span><span class="na">eprint</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{1212.0402}</span><span class="p">,</span>
<span class="w">  </span><span class="na">primaryclass</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{cs.CV}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild}</span><span class="p">,</span>
<span class="w">  </span><span class="na">url</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{https://arxiv.org/abs/1212.0402}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2012}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
</details>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../visualsts%28multi%29/" class="md-footer__link md-footer__link--prev" aria-label="Previous: VisualSTS(multi)">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                VisualSTS(multi)
              </div>
            </div>
          </a>
        
        
          
          <a href="../../available_models/image/" class="md-footer__link md-footer__link--next" aria-label="Next: Image Model">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Image Model
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      This text is freely available under a Creative Commons Attribution 4.0 license
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/embeddings-benchmark/mteb" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tracking", "navigation.instant", "navigation.tabs", "navigation.sections", "navigation.top", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy", "content.action.edit", "content.action.view", "content.code.annotate", "content.tooltips", "navigation.footer", "navigation.indexes", "toc.follow"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>