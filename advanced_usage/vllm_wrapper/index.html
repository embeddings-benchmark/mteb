
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../retrieval_backend/">
      
      
        <link rel="next" href="../../contributing/adding_a_model/">
      
      
        
      
      
      <link rel="icon" href="../../images/logos/mteb_logo/dots-icon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>vLLM Wrapper - Massive Text Embedding Benchmark</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="light-blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#vllm" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Massive Text Embedding Benchmark" class="md-header__button md-logo" aria-label="Massive Text Embedding Benchmark" data-md-component="logo">
      
  <img src="../../images/logos/mteb_logo/dots-icon.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Massive Text Embedding Benchmark
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              vLLM Wrapper
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="light-blue"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="light-blue"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/embeddings-benchmark/mteb" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../.." class="md-tabs__link">
          
  
  
    
  
  Get Started

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../contributing/adding_a_model/" class="md-tabs__link">
          
  
  
    
  
  Contributing

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../overview/" class="md-tabs__link">
          
  
  
    
  
  Overview

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../api/" class="md-tabs__link">
          
  
  
    
  
  API

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="https://huggingface.co/spaces/mteb/leaderboard" class="md-tabs__link">
        
  
  
    
  
  Leaderboard

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Massive Text Embedding Benchmark" class="md-nav__button md-logo" aria-label="Massive Text Embedding Benchmark" data-md-component="logo">
      
  <img src="../../images/logos/mteb_logo/dots-icon.png" alt="logo">

    </a>
    Massive Text Embedding Benchmark
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/embeddings-benchmark/mteb" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../.." class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Get Started
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_1" id="__nav_1_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Get Started
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Installation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../whats_new/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    What's New
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_4" >
        
          
          <label class="md-nav__link" for="__nav_1_4" id="__nav_1_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Usage
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Usage
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/get_started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Get Started
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/defining_the_model/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Defining the Model
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/selecting_tasks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Selecting Tasks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/running_the_evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Running the Evaluation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/loading_results/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Loading Results
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/cli/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Command Line Interface
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/leaderboard/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Running the Leaderboard
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_5" checked>
        
          
          <label class="md-nav__link" for="__nav_1_5" id="__nav_1_5_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Advanced Usage
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Advanced Usage
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../two_stage_reranking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Two stage reranking
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cache_embeddings/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Cache embeddings
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../retrieval_backend/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Retrieval backend
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    vLLM Wrapper
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    vLLM Wrapper
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#vllm" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Installation
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#usage" class="md-nav__link">
    <span class="md-ellipsis">
      
        Usage
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#why-is-vllm-fast" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why is vLLM fast?
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Why is vLLM fast?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#half-precision-inference" class="md-nav__link">
    <span class="md-ellipsis">
      
        Half-Precision Inference
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unpadding" class="md-nav__link">
    <span class="md-ellipsis">
      
        Unpadding
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#others" class="md-nav__link">
    <span class="md-ellipsis">
      
        Others
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#api-reference" class="md-nav__link">
    <span class="md-ellipsis">
      
        API Reference
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="API Reference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mteb.models.vllm_wrapper.VllmWrapperBase" class="md-nav__link">
    <span class="md-ellipsis">
      
        VllmWrapperBase
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mteb.models.vllm_wrapper.VllmEncoderWrapper" class="md-nav__link">
    <span class="md-ellipsis">
      
        VllmEncoderWrapper
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mteb.models.vllm_wrapper.VllmCrossEncoderWrapper" class="md-nav__link">
    <span class="md-ellipsis">
      
        VllmCrossEncoderWrapper
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Contributing
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Contributing
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contributing/adding_a_model/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Adding a Model
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contributing/adding_a_dataset/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Adding a Task
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contributing/adding_a_benchmark/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Adding a Benchmark
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../CONTRIBUTING/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Contributing to mteb
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../overview/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Overview
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Benchmarks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Benchmarks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_benchmarks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Available Benchmarks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Tasks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Tasks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_3_1" id="__nav_3_3_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Available Tasks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Available Tasks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/any2anymultilingualretrieval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Any2AnyMultilingualRetrieval
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/any2anyretrieval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Any2AnyRetrieval
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/audioclassification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AudioClassification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/audioclustering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AudioClustering
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/audiomultilabelclassification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AudioMultilabelClassification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/audiopairclassification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AudioPairClassification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/audioreranking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AudioReranking
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/audiozeroshotclassification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AudioZeroshotClassification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/bitextmining/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    BitextMining
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/classification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Classification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/clustering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Clustering
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/compositionality/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Compositionality
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/documentunderstanding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    DocumentUnderstanding
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/imageclassification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ImageClassification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/imageclustering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ImageClustering
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/instructionreranking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    InstructionReranking
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/instructionretrieval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    InstructionRetrieval
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/multilabelclassification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MultilabelClassification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/pairclassification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PairClassification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/regression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Regression
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/reranking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Reranking
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/retrieval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Retrieval
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/sts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    STS
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/summarization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Summarization
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/visioncentricqa/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    VisionCentricQA
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/visualsts%28eng%29/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    VisualSTS(eng)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/visualsts%28multi%29/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    VisualSTS(multi)
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_tasks/zeroshotclassification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ZeroShotClassification
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Models
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4_1" >
        
          
          <label class="md-nav__link" for="__nav_3_4_1" id="__nav_3_4_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Available Models
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Available Models
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_models/audio/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Audio Model
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_models/audio_image_text/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Audio-image-text Model
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_models/audio_text/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Audio-text Model
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_models/image/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Image Model
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_models/image_text/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Image-text Model
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/available_models/text/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Text Model
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../api/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    API
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    API
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/evaluation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Evaluation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/benchmark/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Benchmark
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/task/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Task
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/model/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Model
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/results/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Results
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/types/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Additional Types
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://huggingface.co/spaces/mteb/leaderboard" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Leaderboard
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#vllm" class="md-nav__link">
    <span class="md-ellipsis">
      
        vLLM
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Installation
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#usage" class="md-nav__link">
    <span class="md-ellipsis">
      
        Usage
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#why-is-vllm-fast" class="md-nav__link">
    <span class="md-ellipsis">
      
        Why is vLLM fast?
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Why is vLLM fast?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#half-precision-inference" class="md-nav__link">
    <span class="md-ellipsis">
      
        Half-Precision Inference
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unpadding" class="md-nav__link">
    <span class="md-ellipsis">
      
        Unpadding
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#others" class="md-nav__link">
    <span class="md-ellipsis">
      
        Others
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#api-reference" class="md-nav__link">
    <span class="md-ellipsis">
      
        API Reference
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="API Reference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mteb.models.vllm_wrapper.VllmWrapperBase" class="md-nav__link">
    <span class="md-ellipsis">
      
        VllmWrapperBase
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mteb.models.vllm_wrapper.VllmEncoderWrapper" class="md-nav__link">
    <span class="md-ellipsis">
      
        VllmEncoderWrapper
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mteb.models.vllm_wrapper.VllmCrossEncoderWrapper" class="md-nav__link">
    <span class="md-ellipsis">
      
        VllmCrossEncoderWrapper
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/embeddings-benchmark/mteb/blob/main/docs/advanced_usage/vllm_wrapper.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/embeddings-benchmark/mteb/raw/main/docs/advanced_usage/vllm_wrapper.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


  <h1>vLLM Wrapper</h1>

<h2 id="vllm">vLLM<a class="headerlink" href="#vllm" title="Permanent link">&para;</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>vLLM currently supports only a limited number of models, and many implementations have subtle differences compared to the default implementations in mteb. For the full list of supported models, refer to the <a href="https://docs.vllm.ai/en/stable/models/supported_models/#pooling-models">vllm documentation</a>.</p>
</div>
<h2 id="installation">Installation<a class="headerlink" href="#installation" title="Permanent link">&para;</a></h2>
<p>If you're using cuda you can run</p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">pip</label><label for="__tabbed_1_2">uv</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;mteb[vllm]&quot;</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code>uv<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;mteb[vllm]&quot;</span>
</code></pre></div>
</div>
</div>
</div>
<p>For other architectures, please refer to the <a href="https://docs.vllm.ai/en/latest/getting_started/installation/">vllm installation guide</a>.</p>
<h2 id="usage">Usage<a class="headerlink" href="#usage" title="Permanent link">&para;</a></h2>
<p>To use vLLM with MTEB you have to wrap the model with its respective wrapper.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>you must update your Python code to guard usage of vllm behind a if <strong>name</strong> == '<strong>main</strong>': block. For example, instead of this:</p>
<p><div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">vllm</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">vllm</span><span class="o">.</span><span class="n">LLM</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</code></pre></div>
try this instead:
<div class="highlight"><pre><span></span><code><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">vllm</span>

    <span class="n">llm</span> <span class="o">=</span> <span class="n">vllm</span><span class="o">.</span><span class="n">LLM</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</code></pre></div></p>
<p>See more <a href="https://docs.vllm.ai/en/latest/usage/troubleshooting/#python-multiprocessing">troubleshooting</a></p>
</div>
<div class="tabbed-set tabbed-alternate" data-tabs="2:2"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio" /><input id="__tabbed_2_2" name="__tabbed_2" type="radio" /><div class="tabbed-labels"><label for="__tabbed_2_1">Embedding models</label><label for="__tabbed_2_2">Reranking models</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">mteb</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mteb.models.vllm_wrapper</span><span class="w"> </span><span class="kn">import</span> <span class="n">VllmEncoderWrapper</span>

<span class="k">def</span><span class="w"> </span><span class="nf">run_vllm_encoder</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate a model on specified MTEB tasks using vLLM for inference.&quot;&quot;&quot;</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">VllmEncoderWrapper</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;intfloat/e5-small&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mteb</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
        <span class="n">encoder</span><span class="p">,</span>
        <span class="n">mteb</span><span class="o">.</span><span class="n">get_task</span><span class="p">(</span><span class="s2">&quot;STS12&quot;</span><span class="p">),</span>
    <span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">run_vllm_encoder</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">mteb</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mteb.models.vllm_wrapper</span><span class="w"> </span><span class="kn">import</span> <span class="n">VllmCrossEncoderWrapper</span>

<span class="k">def</span><span class="w"> </span><span class="nf">run_vllm_crossencoder</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate a model on specified MTEB tasks using vLLM for inference.&quot;&quot;&quot;</span>
    <span class="n">cross_encoder</span> <span class="o">=</span> <span class="n">VllmCrossEncoderWrapper</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;cross-encoder/ms-marco-MiniLM-L-6-v2&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mteb</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
        <span class="n">cross_encoder</span><span class="p">,</span>
        <span class="n">mteb</span><span class="o">.</span><span class="n">get_task</span><span class="p">(</span><span class="s2">&quot;AskUbuntuDupQuestions&quot;</span><span class="p">),</span>
    <span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">run_vllm_crossencoder</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div>
</div>
</div>
</div>
<h2 id="why-is-vllm-fast">Why is vLLM fast?<a class="headerlink" href="#why-is-vllm-fast" title="Permanent link">&para;</a></h2>
<h3 id="half-precision-inference">Half-Precision Inference<a class="headerlink" href="#half-precision-inference" title="Permanent link">&para;</a></h3>
<p>By default, vLLM uses Flash Attention, which only supports float16 and bfloat16 but not float32. vLLM does not optimize inference performance for float32.</p>
<figure>
    <img alt="" src="../../images/visualizations/half_precision_inference.png" />
    <figcaption>The throughput using float16 is approximately four times that of float32.
ST: using sentence transformers backend
vLLM: using vLLM backend
X-axis: Throughput (request/s)
Y-axis: Latency, Time needed for one step (ms) &lt;- logarithmic scale
The curve lower right is better 
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<table>
<thead>
<tr>
<th>Format</th>
<th>Bits</th>
<th>Exponent</th>
<th>Fraction</th>
</tr>
</thead>
<tbody>
<tr>
<td>float32</td>
<td>32</td>
<td>8</td>
<td>23</td>
</tr>
<tr>
<td>float16</td>
<td>16</td>
<td>5</td>
<td>10</td>
</tr>
<tr>
<td>bfloat16</td>
<td>16</td>
<td>8</td>
<td>7</td>
</tr>
</tbody>
</table>
<p>If the model weights are stored in float32:</p>
<ul>
<li>VLLM uses float16 for inference by default to inference a float32 model, it will keep numerical precision in most cases, for it have retains relatively more Fraction bits. However, due to the smaller Exponent part (only 5 bits), some models (e.g., the Gemma family) may risk producing NaN. VLLM maintains a list models that may cause NaN values and uses bfloat16 for inference by default.</li>
<li>Using bfloat16 for inference avoids NaN risks because its Exponent part matches float32 with 8 bits. However, with only 7 Fraction bits, numerical precision decreases noticeably.</li>
<li>Using float32 for inference incurs no precision loss but is about four times slower than float16/bfloat16.</li>
</ul>
<p>If model weights are stored in float16 or bfloat16, vLLM defaults to using the original dtype for inference.</p>
<p>Quantization: With the advancement of open-source large models, fine-tuning of larger models for tasks like embedding and reranking is increasing. Exploring quantization methods to accelerate inference and reduce GPU memory usage may become necessary.</p>
</div>
<h3 id="unpadding">Unpadding<a class="headerlink" href="#unpadding" title="Permanent link">&para;</a></h3>
<p>By default, Sentence Transformers (st) pads all inputs in a batch to the length of the longest one, which is undoubtedly very inefficient. VLLM avoids padding entirely during inference.</p>
<figure>
    <img alt="" src="../../images/visualizations/unpadding.png" />
    <figcaption>X-axis: Throughput (request/s)
ST: using sentence transformers
vLLM: using vLLM
Y-axis: Latency, Time needed for one step (ms) &lt;- logarithmic scale
The curve lower right is better 
</figcaption>
</figure>
<p>Sentence Transformers (st) suffers a noticeable drop in speed when handling requests with varied input lengths, whereas vLLM does not.</p>
<h3 id="others">Others<a class="headerlink" href="#others" title="Permanent link">&para;</a></h3>
<p>For models using bidirectional attention, such as BERT, VLLM offers a range of performance optimizations:</p>
<ul>
<li>Optimized CUDA kernels, including FlashAttention and FlashInfer integration</li>
<li>CUDA Graphs and <code>torch.compile</code> support to reduce overhead and accelerate execution</li>
<li>Support for tensor, pipeline, data, and expert parallelism for distributed inference</li>
<li>Multiple quantization schemesGPTQ, AWQ, AutoRound, INT4, INT8, and FP8for efficient deployment</li>
<li>Continuous batching of incoming requests to maximize throughput</li>
</ul>
<p>For causal attention models, such as the Qwen3 reranker, the following optimizations are also applicable:</p>
<ul>
<li>Efficient KV cache memory management via PagedAttention</li>
<li>Chunked prefill for improved memory handling during long-context processing</li>
<li>Prefix caching to accelerate repeated prompt processing</li>
</ul>
<p>vLLMs optimizations are primarily designed for and most effective with causal language models (generative models). For the full list of features, refer to the <a href="https://docs.vllm.ai/en/latest/features/">vllm documentation</a>.</p>
<h2 id="api-reference">API Reference<a class="headerlink" href="#api-reference" title="Permanent link">&para;</a></h2>


<div class="doc doc-object doc-class">



<h3 id="mteb.models.vllm_wrapper.VllmWrapperBase" class="doc doc-heading">
            <code>mteb.models.vllm_wrapper.VllmWrapperBase</code>


<a href="#mteb.models.vllm_wrapper.VllmWrapperBase" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents first">



        <p>Wrapper for vllm serving engine.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>mteb/models/vllm_wrapper.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">VllmWrapperBase</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrapper for vllm serving engine.&quot;&quot;&quot;</span>

    <span class="n">convert</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span>
    <span class="n">mteb_model_meta</span><span class="p">:</span> <span class="n">ModelMeta</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">ModelMeta</span><span class="p">,</span>
        <span class="n">revision</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">trust_remote_code</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">Dtype</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">head_dtype</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="n">Dtype</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_model_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_num_batched_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_num_seqs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">tensor_parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">enable_prefix_caching</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">gpu_memory_utilization</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
        <span class="n">hf_overrides</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pooler_config</span><span class="p">:</span> <span class="n">PoolerConfig</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">enforce_eager</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Wrapper for vllm serving engine.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: model name string.</span>
<span class="sd">            revision: The revision of the model to use.</span>
<span class="sd">            trust_remote_code: Whether to trust remote code execution when loading the model.</span>
<span class="sd">                Should be True for models with custom code.</span>
<span class="sd">            dtype: Data type for model weights. &quot;auto&quot; will automatically select appropriate</span>
<span class="sd">                dtype based on hardware and model capabilities. vllm uses flash attention by</span>
<span class="sd">                default, which does not support fp32. Therefore, it defaults to using fp16 for</span>
<span class="sd">                inference on fp32 models. Testing has shown a relatively small drop in accuracy.</span>
<span class="sd">                You can manually opt for fp32, but inference speed will be very slow.</span>
<span class="sd">            head_dtype: &quot;head&quot; refers to the last Linear layer(s) of an LLMs, such as the score</span>
<span class="sd">                or classifier in a classification model. Uses fp32 for the head by default to</span>
<span class="sd">                gain extra precision.</span>
<span class="sd">            max_model_len: Maximum sequence length (context window) supported by the model.</span>
<span class="sd">                If None, uses the model&#39;s default maximum length.</span>
<span class="sd">            max_num_batched_tokens: Maximum number of tokens to process in a single batch.</span>
<span class="sd">                If None, automatically determined.</span>
<span class="sd">            max_num_seqs: Maximum number of sequences to process concurrently.</span>
<span class="sd">            tensor_parallel_size: Number of GPUs for tensor parallelism.</span>
<span class="sd">            enable_prefix_caching: Whether to enable KV cache sharing for common prompt prefixes.</span>
<span class="sd">                If None, uses the model&#39;s default setting.</span>
<span class="sd">            gpu_memory_utilization: Target GPU memory utilization ratio (0.0 to 1.0).</span>
<span class="sd">            hf_overrides: Dictionary mapping Hugging Face configuration keys to override values.</span>
<span class="sd">            pooler_config: Controls the behavior of output pooling in pooling models.</span>
<span class="sd">            enforce_eager: Whether to disable CUDA graph optimization and use eager execution.</span>
<span class="sd">            **kwargs: Additional arguments to pass to the vllm serving engine model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">requires_package</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="s2">&quot;vllm&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Wrapper for vllm serving engine&quot;</span><span class="p">,</span>
            <span class="n">install_instruction</span><span class="o">=</span><span class="s2">&quot;pip install mteb[vllm]&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;VLLM_WORKER_MULTIPROC_METHOD&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;spawn&quot;</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">EngineArgs</span>

        <span class="n">hf_overrides</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">hf_overrides</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">hf_overrides</span>

        <span class="k">if</span> <span class="n">head_dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">hf_overrides</span><span class="p">[</span><span class="s2">&quot;head_dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">head_dtype</span>

        <span class="n">model_name</span> <span class="o">=</span> <span class="n">model</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">model</span><span class="o">.</span><span class="n">name</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ModelMeta</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Using revision from model meta. Passed revision will be ignored&quot;</span>
            <span class="p">)</span>
            <span class="n">revision</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">revision</span>

        <span class="n">args</span> <span class="o">=</span> <span class="n">EngineArgs</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">,</span>
            <span class="n">runner</span><span class="o">=</span><span class="s2">&quot;pooling&quot;</span><span class="p">,</span>
            <span class="n">convert</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">convert</span><span class="p">,</span>  <span class="c1"># type: ignore[arg-type]</span>
            <span class="n">max_model_len</span><span class="o">=</span><span class="n">max_model_len</span><span class="p">,</span>
            <span class="n">max_num_batched_tokens</span><span class="o">=</span><span class="n">max_num_batched_tokens</span><span class="p">,</span>
            <span class="n">max_num_seqs</span><span class="o">=</span><span class="n">max_num_seqs</span><span class="p">,</span>
            <span class="n">tensor_parallel_size</span><span class="o">=</span><span class="n">tensor_parallel_size</span><span class="p">,</span>
            <span class="n">enable_prefix_caching</span><span class="o">=</span><span class="n">enable_prefix_caching</span><span class="p">,</span>
            <span class="n">gpu_memory_utilization</span><span class="o">=</span><span class="n">gpu_memory_utilization</span><span class="p">,</span>
            <span class="n">hf_overrides</span><span class="o">=</span><span class="n">hf_overrides</span><span class="p">,</span>
            <span class="n">pooler_config</span><span class="o">=</span><span class="n">pooler_config</span><span class="p">,</span>
            <span class="n">enforce_eager</span><span class="o">=</span><span class="n">enforce_eager</span><span class="p">,</span>
            <span class="n">trust_remote_code</span><span class="o">=</span><span class="n">trust_remote_code</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">llm</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="o">**</span><span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mteb_model_meta</span> <span class="o">=</span> <span class="n">ModelMeta</span><span class="o">.</span><span class="n">from_hub</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mteb_model_meta</span> <span class="o">=</span> <span class="n">model</span>

        <span class="n">atexit</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cleanup</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clean up the VLLM distributed runtime environment and release GPU resources.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="kn">from</span><span class="w"> </span><span class="nn">vllm.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>  <span class="c1"># type: ignore[import-not-found]</span>
            <span class="n">cleanup_dist_env_and_memory</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">llm</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
        <span class="n">cleanup_dist_env_and_memory</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cleanup</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="mteb.models.vllm_wrapper.VllmWrapperBase.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">revision</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">head_dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_model_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_num_batched_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_num_seqs</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">tensor_parallel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">enable_prefix_caching</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">gpu_memory_utilization</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">hf_overrides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pooler_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">enforce_eager</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mteb.models.vllm_wrapper.VllmWrapperBase.__init__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Wrapper for vllm serving engine.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code><span title="str">str</span> | <a class="autorefs autorefs-internal" title="&lt;code&gt;mteb.models.model_meta.ModelMeta&lt;/code&gt; (&lt;code&gt;mteb.models.ModelMeta&lt;/code&gt;)" href="../../api/model/#mteb.models.model_meta.ModelMeta">ModelMeta</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>model name string.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>revision</code>
            </td>
            <td>
                  <code><span title="str">str</span> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The revision of the model to use.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>trust_remote_code</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to trust remote code execution when loading the model.
Should be True for models with custom code.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
                  <code><span title="mteb.models.vllm_wrapper.Dtype">Dtype</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Data type for model weights. "auto" will automatically select appropriate
dtype based on hardware and model capabilities. vllm uses flash attention by
default, which does not support fp32. Therefore, it defaults to using fp16 for
inference on fp32 models. Testing has shown a relatively small drop in accuracy.
You can manually opt for fp32, but inference speed will be very slow.</p>
              </div>
            </td>
            <td>
                  <code>&#39;auto&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>head_dtype</code>
            </td>
            <td>
                  <code><span title="typing.Literal">Literal</span>[&#39;model&#39;] | <span title="mteb.models.vllm_wrapper.Dtype">Dtype</span> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>"head" refers to the last Linear layer(s) of an LLMs, such as the score
or classifier in a classification model. Uses fp32 for the head by default to
gain extra precision.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_model_len</code>
            </td>
            <td>
                  <code><span title="int">int</span> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum sequence length (context window) supported by the model.
If None, uses the model's default maximum length.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_num_batched_tokens</code>
            </td>
            <td>
                  <code><span title="int">int</span> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of tokens to process in a single batch.
If None, automatically determined.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_num_seqs</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of sequences to process concurrently.</p>
              </div>
            </td>
            <td>
                  <code>128</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tensor_parallel_size</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of GPUs for tensor parallelism.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>enable_prefix_caching</code>
            </td>
            <td>
                  <code><span title="bool">bool</span> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to enable KV cache sharing for common prompt prefixes.
If None, uses the model's default setting.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>gpu_memory_utilization</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Target GPU memory utilization ratio (0.0 to 1.0).</p>
              </div>
            </td>
            <td>
                  <code>0.9</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hf_overrides</code>
            </td>
            <td>
                  <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>] | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dictionary mapping Hugging Face configuration keys to override values.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pooler_config</code>
            </td>
            <td>
                  <code><span title="vllm.config.PoolerConfig">PoolerConfig</span> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Controls the behavior of output pooling in pooling models.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>enforce_eager</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to disable CUDA graph optimization and use eager execution.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional arguments to pass to the vllm serving engine model.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>mteb/models/vllm_wrapper.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">ModelMeta</span><span class="p">,</span>
    <span class="n">revision</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">trust_remote_code</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Dtype</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="n">head_dtype</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span> <span class="o">|</span> <span class="n">Dtype</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_model_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_num_batched_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_num_seqs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
    <span class="n">tensor_parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">enable_prefix_caching</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">gpu_memory_utilization</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="n">hf_overrides</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">pooler_config</span><span class="p">:</span> <span class="n">PoolerConfig</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">enforce_eager</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrapper for vllm serving engine.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: model name string.</span>
<span class="sd">        revision: The revision of the model to use.</span>
<span class="sd">        trust_remote_code: Whether to trust remote code execution when loading the model.</span>
<span class="sd">            Should be True for models with custom code.</span>
<span class="sd">        dtype: Data type for model weights. &quot;auto&quot; will automatically select appropriate</span>
<span class="sd">            dtype based on hardware and model capabilities. vllm uses flash attention by</span>
<span class="sd">            default, which does not support fp32. Therefore, it defaults to using fp16 for</span>
<span class="sd">            inference on fp32 models. Testing has shown a relatively small drop in accuracy.</span>
<span class="sd">            You can manually opt for fp32, but inference speed will be very slow.</span>
<span class="sd">        head_dtype: &quot;head&quot; refers to the last Linear layer(s) of an LLMs, such as the score</span>
<span class="sd">            or classifier in a classification model. Uses fp32 for the head by default to</span>
<span class="sd">            gain extra precision.</span>
<span class="sd">        max_model_len: Maximum sequence length (context window) supported by the model.</span>
<span class="sd">            If None, uses the model&#39;s default maximum length.</span>
<span class="sd">        max_num_batched_tokens: Maximum number of tokens to process in a single batch.</span>
<span class="sd">            If None, automatically determined.</span>
<span class="sd">        max_num_seqs: Maximum number of sequences to process concurrently.</span>
<span class="sd">        tensor_parallel_size: Number of GPUs for tensor parallelism.</span>
<span class="sd">        enable_prefix_caching: Whether to enable KV cache sharing for common prompt prefixes.</span>
<span class="sd">            If None, uses the model&#39;s default setting.</span>
<span class="sd">        gpu_memory_utilization: Target GPU memory utilization ratio (0.0 to 1.0).</span>
<span class="sd">        hf_overrides: Dictionary mapping Hugging Face configuration keys to override values.</span>
<span class="sd">        pooler_config: Controls the behavior of output pooling in pooling models.</span>
<span class="sd">        enforce_eager: Whether to disable CUDA graph optimization and use eager execution.</span>
<span class="sd">        **kwargs: Additional arguments to pass to the vllm serving engine model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">requires_package</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="s2">&quot;vllm&quot;</span><span class="p">,</span>
        <span class="s2">&quot;Wrapper for vllm serving engine&quot;</span><span class="p">,</span>
        <span class="n">install_instruction</span><span class="o">=</span><span class="s2">&quot;pip install mteb[vllm]&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;VLLM_WORKER_MULTIPROC_METHOD&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;spawn&quot;</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">EngineArgs</span>

    <span class="n">hf_overrides</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">hf_overrides</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">hf_overrides</span>

    <span class="k">if</span> <span class="n">head_dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">hf_overrides</span><span class="p">[</span><span class="s2">&quot;head_dtype&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">head_dtype</span>

    <span class="n">model_name</span> <span class="o">=</span> <span class="n">model</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">model</span><span class="o">.</span><span class="n">name</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ModelMeta</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Using revision from model meta. Passed revision will be ignored&quot;</span>
        <span class="p">)</span>
        <span class="n">revision</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">revision</span>

    <span class="n">args</span> <span class="o">=</span> <span class="n">EngineArgs</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
        <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">,</span>
        <span class="n">runner</span><span class="o">=</span><span class="s2">&quot;pooling&quot;</span><span class="p">,</span>
        <span class="n">convert</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">convert</span><span class="p">,</span>  <span class="c1"># type: ignore[arg-type]</span>
        <span class="n">max_model_len</span><span class="o">=</span><span class="n">max_model_len</span><span class="p">,</span>
        <span class="n">max_num_batched_tokens</span><span class="o">=</span><span class="n">max_num_batched_tokens</span><span class="p">,</span>
        <span class="n">max_num_seqs</span><span class="o">=</span><span class="n">max_num_seqs</span><span class="p">,</span>
        <span class="n">tensor_parallel_size</span><span class="o">=</span><span class="n">tensor_parallel_size</span><span class="p">,</span>
        <span class="n">enable_prefix_caching</span><span class="o">=</span><span class="n">enable_prefix_caching</span><span class="p">,</span>
        <span class="n">gpu_memory_utilization</span><span class="o">=</span><span class="n">gpu_memory_utilization</span><span class="p">,</span>
        <span class="n">hf_overrides</span><span class="o">=</span><span class="n">hf_overrides</span><span class="p">,</span>
        <span class="n">pooler_config</span><span class="o">=</span><span class="n">pooler_config</span><span class="p">,</span>
        <span class="n">enforce_eager</span><span class="o">=</span><span class="n">enforce_eager</span><span class="p">,</span>
        <span class="n">trust_remote_code</span><span class="o">=</span><span class="n">trust_remote_code</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">llm</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="o">**</span><span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mteb_model_meta</span> <span class="o">=</span> <span class="n">ModelMeta</span><span class="o">.</span><span class="n">from_hub</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mteb_model_meta</span> <span class="o">=</span> <span class="n">model</span>

    <span class="n">atexit</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cleanup</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mteb.models.vllm_wrapper.VllmWrapperBase.cleanup" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">cleanup</span><span class="p">()</span></code>

<a href="#mteb.models.vllm_wrapper.VllmWrapperBase.cleanup" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Clean up the VLLM distributed runtime environment and release GPU resources.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>mteb/models/vllm_wrapper.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Clean up the VLLM distributed runtime environment and release GPU resources.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">vllm.distributed</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>  <span class="c1"># type: ignore[import-not-found]</span>
        <span class="n">cleanup_dist_env_and_memory</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">llm</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
    <span class="n">cleanup_dist_env_and_memory</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><div class="admonition info">
<p class="admonition-title">Info</p>
<p>For all vLLM parameters, please refer to https://docs.vllm.ai/en/latest/configuration/engine_args/.</p>
</div>


<div class="doc doc-object doc-class">



<h3 id="mteb.models.vllm_wrapper.VllmEncoderWrapper" class="doc doc-heading">
            <code>mteb.models.vllm_wrapper.VllmEncoderWrapper</code>


<a href="#mteb.models.vllm_wrapper.VllmEncoderWrapper" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mteb.models.abs_encoder.AbsEncoder">AbsEncoder</span></code>, <code><a class="autorefs autorefs-internal" title="&lt;code&gt;mteb.models.vllm_wrapper.VllmWrapperBase&lt;/code&gt;" href="#mteb.models.vllm_wrapper.VllmWrapperBase">VllmWrapperBase</a></code></p>



        <p>vLLM wrapper for Encoder models.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code><span title="str">str</span> | <a class="autorefs autorefs-internal" title="&lt;code&gt;mteb.models.model_meta.ModelMeta&lt;/code&gt; (&lt;code&gt;mteb.models.ModelMeta&lt;/code&gt;)" href="../../api/model/#mteb.models.model_meta.ModelMeta">ModelMeta</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>model name string or ModelMeta.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>revision</code>
            </td>
            <td>
                  <code><span title="str">str</span> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The revision of the model to use.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt_dict</code>
            </td>
            <td>
                  <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="str">str</span>] | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary mapping task names to prompt strings.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_instructions</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to use instructions from the prompt_dict.
When False, values from prompt_dict are used as static prompts (prefixes).
When True, values from prompt_dict are used as instructions to be formatted
using the instruction_template.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>instruction_template</code>
            </td>
            <td>
                  <code><span title="str">str</span> | <span title="collections.abc.Callable">Callable</span>[[<span title="str">str</span>, <a class="autorefs autorefs-internal" title="&lt;code&gt;PromptType&lt;/code&gt; (&lt;code&gt;mteb.types.PromptType&lt;/code&gt;)" href="../../api/types/#mteb.types._encoder_io.PromptType">PromptType</a> | None], <span title="str">str</span>] | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A template or callable to format instructions.
Can be a string with '{instruction}' placeholder or a callable that takes
the instruction and prompt type and returns a formatted string.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>apply_instruction_to_documents</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to apply instructions to documents prompts.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional arguments to pass to the vllm serving engine model.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>mteb/models/vllm_wrapper.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">VllmEncoderWrapper</span><span class="p">(</span><span class="n">AbsEncoder</span><span class="p">,</span> <span class="n">VllmWrapperBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;vLLM wrapper for Encoder models.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: model name string or ModelMeta.</span>
<span class="sd">        revision: The revision of the model to use.</span>
<span class="sd">        prompt_dict: A dictionary mapping task names to prompt strings.</span>
<span class="sd">        use_instructions: Whether to use instructions from the prompt_dict.</span>
<span class="sd">            When False, values from prompt_dict are used as static prompts (prefixes).</span>
<span class="sd">            When True, values from prompt_dict are used as instructions to be formatted</span>
<span class="sd">            using the instruction_template.</span>
<span class="sd">        instruction_template: A template or callable to format instructions.</span>
<span class="sd">            Can be a string with &#39;{instruction}&#39; placeholder or a callable that takes</span>
<span class="sd">            the instruction and prompt type and returns a formatted string.</span>
<span class="sd">        apply_instruction_to_documents: Whether to apply instructions to documents prompts.</span>
<span class="sd">        **kwargs: Additional arguments to pass to the vllm serving engine model.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">convert</span> <span class="o">=</span> <span class="s2">&quot;embed&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">ModelMeta</span><span class="p">,</span>
        <span class="n">revision</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prompt_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_instructions</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">instruction_template</span><span class="p">:</span> <span class="p">(</span>
            <span class="nb">str</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">str</span><span class="p">,</span> <span class="n">PromptType</span> <span class="o">|</span> <span class="kc">None</span><span class="p">],</span> <span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span>
        <span class="p">)</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">apply_instruction_to_documents</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">use_instructions</span> <span class="ow">and</span> <span class="n">instruction_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;To use instructions, an instruction_template must be provided. &quot;</span>
                <span class="s2">&quot;For example, `Instruction: </span><span class="si">{instruction}</span><span class="s2">`&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">instruction_template</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="ow">and</span> <span class="s2">&quot;</span><span class="si">{instruction}</span><span class="s2">&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instruction_template</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Instruction template must contain the string &#39;</span><span class="si">{instruction}</span><span class="s2">&#39;.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">prompts_dict</span> <span class="o">=</span> <span class="n">prompt_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_instructions</span> <span class="o">=</span> <span class="n">use_instructions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">instruction_template</span> <span class="o">=</span> <span class="n">instruction_template</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply_instruction_to_passages</span> <span class="o">=</span> <span class="n">apply_instruction_to_documents</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span>
            <span class="n">revision</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">[</span><span class="n">BatchedInput</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">task_metadata</span><span class="p">:</span> <span class="n">TaskMetadata</span><span class="p">,</span>
        <span class="n">hf_split</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">hf_subset</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">prompt_type</span><span class="p">:</span> <span class="n">PromptType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Array</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Encodes the given sentences using the encoder.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: The sentences to encode.</span>
<span class="sd">            task_metadata: The metadata of the task. Sentence-transformers uses this to</span>
<span class="sd">                determine which prompt to use from a specified dictionary.</span>
<span class="sd">            prompt_type: The name type of prompt. (query or passage)</span>
<span class="sd">            hf_split: Split of current task</span>
<span class="sd">            hf_subset: Subset of current task</span>
<span class="sd">            **kwargs: Additional arguments to pass to the encoder.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The encoded sentences.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_instructions</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_task_instruction</span><span class="p">(</span><span class="n">task_metadata</span><span class="p">,</span> <span class="n">prompt_type</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prompt_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_prompt_name</span><span class="p">(</span><span class="n">task_metadata</span><span class="p">,</span> <span class="n">prompt_type</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">prompt_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">prompt_name</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_instructions</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_instruction_to_passages</span> <span class="ow">is</span> <span class="kc">False</span>
            <span class="ow">and</span> <span class="n">prompt_type</span> <span class="o">==</span> <span class="n">PromptType</span><span class="o">.</span><span class="n">document</span>
        <span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;No instruction used, because prompt type = </span><span class="si">{</span><span class="n">prompt_type</span><span class="o">.</span><span class="n">document</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Using instruction: &#39;</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2">&#39; for task: &#39;</span><span class="si">{</span><span class="n">task_metadata</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; prompt type: &#39;</span><span class="si">{</span><span class="n">prompt_type</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
            <span class="p">)</span>

        <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">prompt</span> <span class="o">+</span> <span class="n">text</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">inputs</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]]</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
            <span class="n">prompts</span><span class="p">,</span> <span class="n">pooling_task</span><span class="o">=</span><span class="s2">&quot;embed&quot;</span><span class="p">,</span> <span class="n">truncate_prompt_tokens</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">output</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">embeddings</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="mteb.models.vllm_wrapper.VllmEncoderWrapper.encode" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">encode</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">task_metadata</span><span class="p">,</span> <span class="n">hf_split</span><span class="p">,</span> <span class="n">hf_subset</span><span class="p">,</span> <span class="n">prompt_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mteb.models.vllm_wrapper.VllmEncoderWrapper.encode" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Encodes the given sentences using the encoder.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs</code>
            </td>
            <td>
                  <code><span title="torch.utils.data.DataLoader">DataLoader</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;BatchedInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TextInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CorpusInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;QueryInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AudioInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultimodalInput&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;mteb.types.BatchedInput&lt;/code&gt;)" href="../../api/types/#mteb.types._encoder_io.BatchedInput">BatchedInput</a>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The sentences to encode.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>task_metadata</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="&lt;code&gt;mteb.TaskMetadata&lt;/code&gt; (&lt;code&gt;mteb.abstasks.task_metadata.TaskMetadata&lt;/code&gt;)" href="../../api/task/#mteb.TaskMetadata">TaskMetadata</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The metadata of the task. Sentence-transformers uses this to
determine which prompt to use from a specified dictionary.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt_type</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="&lt;code&gt;PromptType&lt;/code&gt; (&lt;code&gt;mteb.types.PromptType&lt;/code&gt;)" href="../../api/types/#mteb.types._encoder_io.PromptType">PromptType</a> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name type of prompt. (query or passage)</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hf_split</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Split of current task</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hf_subset</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Subset of current task</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional arguments to pass to the encoder.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;Array&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NDArray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floating&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;integer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bool_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;mteb.types.Array&lt;/code&gt;)" href="../../api/types/#mteb.types._encoder_io.Array">Array</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The encoded sentences.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>mteb/models/vllm_wrapper.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">encode</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">[</span><span class="n">BatchedInput</span><span class="p">],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">task_metadata</span><span class="p">:</span> <span class="n">TaskMetadata</span><span class="p">,</span>
    <span class="n">hf_split</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">hf_subset</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">prompt_type</span><span class="p">:</span> <span class="n">PromptType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Array</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Encodes the given sentences using the encoder.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs: The sentences to encode.</span>
<span class="sd">        task_metadata: The metadata of the task. Sentence-transformers uses this to</span>
<span class="sd">            determine which prompt to use from a specified dictionary.</span>
<span class="sd">        prompt_type: The name type of prompt. (query or passage)</span>
<span class="sd">        hf_split: Split of current task</span>
<span class="sd">        hf_subset: Subset of current task</span>
<span class="sd">        **kwargs: Additional arguments to pass to the encoder.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The encoded sentences.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_instructions</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_task_instruction</span><span class="p">(</span><span class="n">task_metadata</span><span class="p">,</span> <span class="n">prompt_type</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">prompt_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_prompt_name</span><span class="p">(</span><span class="n">task_metadata</span><span class="p">,</span> <span class="n">prompt_type</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">prompt_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompts_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">prompt_name</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_instructions</span>
        <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_instruction_to_passages</span> <span class="ow">is</span> <span class="kc">False</span>
        <span class="ow">and</span> <span class="n">prompt_type</span> <span class="o">==</span> <span class="n">PromptType</span><span class="o">.</span><span class="n">document</span>
    <span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;No instruction used, because prompt type = </span><span class="si">{</span><span class="n">prompt_type</span><span class="o">.</span><span class="n">document</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Using instruction: &#39;</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2">&#39; for task: &#39;</span><span class="si">{</span><span class="n">task_metadata</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; prompt type: &#39;</span><span class="si">{</span><span class="n">prompt_type</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
        <span class="p">)</span>

    <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">prompt</span> <span class="o">+</span> <span class="n">text</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">inputs</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]]</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
        <span class="n">prompts</span><span class="p">,</span> <span class="n">pooling_task</span><span class="o">=</span><span class="s2">&quot;embed&quot;</span><span class="p">,</span> <span class="n">truncate_prompt_tokens</span><span class="o">=-</span><span class="mi">1</span>
    <span class="p">)</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">output</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">embeddings</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mteb.models.vllm_wrapper.VllmCrossEncoderWrapper" class="doc doc-heading">
            <code>mteb.models.vllm_wrapper.VllmCrossEncoderWrapper</code>


<a href="#mteb.models.vllm_wrapper.VllmCrossEncoderWrapper" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="&lt;code&gt;mteb.models.vllm_wrapper.VllmWrapperBase&lt;/code&gt;" href="#mteb.models.vllm_wrapper.VllmWrapperBase">VllmWrapperBase</a></code></p>



        <p>vLLM wrapper for CrossEncoder models.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>mteb/models/vllm_wrapper.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">VllmCrossEncoderWrapper</span><span class="p">(</span><span class="n">VllmWrapperBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;vLLM wrapper for CrossEncoder models.&quot;&quot;&quot;</span>

    <span class="n">convert</span> <span class="o">=</span> <span class="s2">&quot;classify&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">ModelMeta</span><span class="p">,</span>
        <span class="n">revision</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">query_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">document_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span>
            <span class="n">revision</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query_prefix</span> <span class="o">=</span> <span class="n">query_prefix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">document_prefix</span> <span class="o">=</span> <span class="n">document_prefix</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs1</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">[</span><span class="n">BatchedInput</span><span class="p">],</span>
        <span class="n">inputs2</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">[</span><span class="n">BatchedInput</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">task_metadata</span><span class="p">:</span> <span class="n">TaskMetadata</span><span class="p">,</span>
        <span class="n">hf_split</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">hf_subset</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">prompt_type</span><span class="p">:</span> <span class="n">PromptType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Array</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Predicts relevance scores for pairs of inputs. Note that, unlike the encoder, the cross-encoder can compare across inputs.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs1: First Dataloader of inputs to encode. For reranking tasks, these are queries (for text only tasks `QueryDatasetType`).</span>
<span class="sd">            inputs2: Second Dataloader of inputs to encode. For reranking, these are documents (for text only tasks `RetrievalOutputType`).</span>
<span class="sd">            task_metadata: Metadata of the current task.</span>
<span class="sd">            hf_split: Split of current task, allows to know some additional information about current split.</span>
<span class="sd">                E.g. Current language</span>
<span class="sd">            hf_subset: Subset of current task. Similar to `hf_split` to get more information</span>
<span class="sd">            prompt_type: The name type of prompt. (query or passage)</span>
<span class="sd">            **kwargs: Additional arguments to pass to the cross-encoder.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The predicted relevance scores for each inputs pair.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">queries</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">query_prefix</span> <span class="o">+</span> <span class="n">text</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">inputs1</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>
        <span class="p">]</span>
        <span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">document_prefix</span> <span class="o">+</span> <span class="n">text</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">inputs2</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>
        <span class="p">]</span>
        <span class="c1"># TODO: support score prompt</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">score</span><span class="p">(</span>
            <span class="n">queries</span><span class="p">,</span>
            <span class="n">corpus</span><span class="p">,</span>
            <span class="n">truncate_prompt_tokens</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">use_tqdm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">output</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">score</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">scores</span>
</code></pre></div></td></tr></table></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="mteb.models.vllm_wrapper.VllmCrossEncoderWrapper.predict" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="n">inputs1</span><span class="p">,</span> <span class="n">inputs2</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">task_metadata</span><span class="p">,</span> <span class="n">hf_split</span><span class="p">,</span> <span class="n">hf_subset</span><span class="p">,</span> <span class="n">prompt_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mteb.models.vllm_wrapper.VllmCrossEncoderWrapper.predict" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Predicts relevance scores for pairs of inputs. Note that, unlike the encoder, the cross-encoder can compare across inputs.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>inputs1</code>
            </td>
            <td>
                  <code><span title="torch.utils.data.DataLoader">DataLoader</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;BatchedInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TextInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CorpusInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;QueryInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AudioInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultimodalInput&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;mteb.types.BatchedInput&lt;/code&gt;)" href="../../api/types/#mteb.types._encoder_io.BatchedInput">BatchedInput</a>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>First Dataloader of inputs to encode. For reranking tasks, these are queries (for text only tasks <code>QueryDatasetType</code>).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>inputs2</code>
            </td>
            <td>
                  <code><span title="torch.utils.data.DataLoader">DataLoader</span>[<a class="autorefs autorefs-internal" title="&lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;BatchedInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TextInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CorpusInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;QueryInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ImageInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AudioInput&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MultimodalInput&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;mteb.types.BatchedInput&lt;/code&gt;)" href="../../api/types/#mteb.types._encoder_io.BatchedInput">BatchedInput</a>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Second Dataloader of inputs to encode. For reranking, these are documents (for text only tasks <code>RetrievalOutputType</code>).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>task_metadata</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="&lt;code&gt;mteb.TaskMetadata&lt;/code&gt; (&lt;code&gt;mteb.abstasks.task_metadata.TaskMetadata&lt;/code&gt;)" href="../../api/task/#mteb.TaskMetadata">TaskMetadata</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Metadata of the current task.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hf_split</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Split of current task, allows to know some additional information about current split.
E.g. Current language</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hf_subset</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Subset of current task. Similar to <code>hf_split</code> to get more information</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt_type</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="&lt;code&gt;PromptType&lt;/code&gt; (&lt;code&gt;mteb.types.PromptType&lt;/code&gt;)" href="../../api/types/#mteb.types._encoder_io.PromptType">PromptType</a> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name type of prompt. (query or passage)</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
                  <code><span title="typing.Any">Any</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional arguments to pass to the cross-encoder.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" title="&lt;code class=&quot;highlight language-python&quot;&gt;&lt;span class=&quot;n&quot;&gt;Array&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NDArray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floating&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;integer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bool_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;/code&gt;

  &lt;span class=&quot;doc doc-labels&quot;&gt;
      &lt;small class=&quot;doc doc-label doc-label-module-attribute&quot;&gt;&lt;code&gt;module-attribute&lt;/code&gt;&lt;/small&gt;
  &lt;/span&gt; (&lt;code&gt;mteb.types.Array&lt;/code&gt;)" href="../../api/types/#mteb.types._encoder_io.Array">Array</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The predicted relevance scores for each inputs pair.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>mteb/models/vllm_wrapper.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs1</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">[</span><span class="n">BatchedInput</span><span class="p">],</span>
    <span class="n">inputs2</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">[</span><span class="n">BatchedInput</span><span class="p">],</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">task_metadata</span><span class="p">:</span> <span class="n">TaskMetadata</span><span class="p">,</span>
    <span class="n">hf_split</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">hf_subset</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">prompt_type</span><span class="p">:</span> <span class="n">PromptType</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Array</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Predicts relevance scores for pairs of inputs. Note that, unlike the encoder, the cross-encoder can compare across inputs.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs1: First Dataloader of inputs to encode. For reranking tasks, these are queries (for text only tasks `QueryDatasetType`).</span>
<span class="sd">        inputs2: Second Dataloader of inputs to encode. For reranking, these are documents (for text only tasks `RetrievalOutputType`).</span>
<span class="sd">        task_metadata: Metadata of the current task.</span>
<span class="sd">        hf_split: Split of current task, allows to know some additional information about current split.</span>
<span class="sd">            E.g. Current language</span>
<span class="sd">        hf_subset: Subset of current task. Similar to `hf_split` to get more information</span>
<span class="sd">        prompt_type: The name type of prompt. (query or passage)</span>
<span class="sd">        **kwargs: Additional arguments to pass to the cross-encoder.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The predicted relevance scores for each inputs pair.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">queries</span> <span class="o">=</span> <span class="p">[</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">query_prefix</span> <span class="o">+</span> <span class="n">text</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">inputs1</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>
    <span class="p">]</span>
    <span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">document_prefix</span> <span class="o">+</span> <span class="n">text</span> <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">inputs2</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>
    <span class="p">]</span>
    <span class="c1"># TODO: support score prompt</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">llm</span><span class="o">.</span><span class="n">score</span><span class="p">(</span>
        <span class="n">queries</span><span class="p">,</span>
        <span class="n">corpus</span><span class="p">,</span>
        <span class="n">truncate_prompt_tokens</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">use_tqdm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">output</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">score</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">scores</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../retrieval_backend/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Retrieval backend">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Retrieval backend
              </div>
            </div>
          </a>
        
        
          
          <a href="../../contributing/adding_a_model/" class="md-footer__link md-footer__link--next" aria-label="Next: Adding a Model">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Adding a Model
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      This text is freely available under a Creative Commons Attribution 4.0 license
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/embeddings-benchmark/mteb" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.tracking", "navigation.instant", "navigation.tabs", "navigation.sections", "navigation.top", "search.suggest", "search.highlight", "content.action.edit", "content.action.view", "content.code.copy", "content.code.annotate", "content.code.annotation", "content.tabs.link", "content.tooltips", "navigation.footer", "navigation.indexes", "toc.follow"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
  </body>
</html>