# CHANGELOG

## v2.7.22 (2026-02-03)

### Documentation

* docs: Added changelog (#3741)

* docs: Added changelog

- Clean up docs to prepare for adding the changelog. By adding missing links and removing references to documentation that does not exist
- Added whats new section
- Added changes from 2.0 upwards. I might be missing some

I think going forward we can just update this as well go.

* minor fix

* added autogenerated changelog

* rename

* add autogenerated workflows

* updates

* update

* update ([`2082d3e`](https://github.com/embeddings-benchmark/mteb/commit/2082d3e44d9ca7fd610deee199e5f01949264680))

### Fix

* fix: backfilling historic tasks (#4034)

* fix: backfilling historic tasks

- [x] Backfilled task metadata
- [x] extended test to ensure that backfilled tasks are removed from the historic list

addresses #2502

* back citation, date and task subtypes where only those are missing

* Update mteb/tasks/pair_classification/pol/polish_pc.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* add famteb citation

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`e542519`](https://github.com/embeddings-benchmark/mteb/commit/e5425190b152174a626b3491e709b66dce1a4ae4))

## v2.7.21 (2026-02-03)

### Fix

* fix: Add Optional dependencies for NemotronColEmbed models as extras (#4036)

* fix: Move nemotron-colembed models to separate module

Signed-off-by: Oliver Holworthy &lt;1216955+oliverholworthy@users.noreply.github.com&gt;

* fix: Add optional extra section for nemotron-colembed-vl-v2

Signed-off-by: Oliver Holworthy &lt;1216955+oliverholworthy@users.noreply.github.com&gt;

* fix: add requires_package to init method of Llama nemotron class

Signed-off-by: Oliver Holworthy &lt;1216955+oliverholworthy@users.noreply.github.com&gt;

* fix: consolidate and rename nemotron colembed classes

Signed-off-by: Oliver Holworthy &lt;1216955+oliverholworthy@users.noreply.github.com&gt;

* fix: Update transformers version check to reference extra name

Signed-off-by: Oliver Holworthy &lt;1216955+oliverholworthy@users.noreply.github.com&gt;

* fix: revert change to llama-embed-nemotron extra

Signed-off-by: Oliver Holworthy &lt;1216955+oliverholworthy@users.noreply.github.com&gt;

* fix: restore transformers_version_constraint in ModelMeta definitions

Signed-off-by: Oliver Holworthy &lt;1216955+oliverholworthy@users.noreply.github.com&gt;

* fix: set citation to None for llama-nemotron-colembed-vl-3b-v2

Signed-off-by: Oliver Holworthy &lt;1216955+oliverholworthy@users.noreply.github.com&gt;

* fix: revert unrelated citation change

Signed-off-by: Oliver Holworthy &lt;1216955+oliverholworthy@users.noreply.github.com&gt;

* fix: change version typo for 4b model

Signed-off-by: Oliver Holworthy &lt;1216955+oliverholworthy@users.noreply.github.com&gt;

* fix: cleanup now unused transformers_version_constraint kwarg

Signed-off-by: Oliver Holworthy &lt;1216955+oliverholworthy@users.noreply.github.com&gt;

* fix: revert change to revision and transformers version

Signed-off-by: Oliver Holworthy &lt;1216955+oliverholworthy@users.noreply.github.com&gt;

* fix: rename extra for llama nemotron models to llama-nemotron-colembed-vl

Signed-off-by: Oliver Holworthy &lt;1216955+oliverholworthy@users.noreply.github.com&gt;

* Update nemotron extras with accelerate for clarify

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Signed-off-by: Oliver Holworthy &lt;1216955+oliverholworthy@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`2cc8dc2`](https://github.com/embeddings-benchmark/mteb/commit/2cc8dc21889b1a9eb47f9e80d43f38c704e9a12b))

## v2.7.20 (2026-02-03)

### Fix

* fix: avoid supplying trust_remote_code twice to `OpenSearch-AI/Ops-Coâ€¦ (#4042)

fix: avoid supplying trust_remote_code twice to `OpenSearch-AI/Ops-Colqwen3-4B`

related to: #4040 ([`9aa5ae5`](https://github.com/embeddings-benchmark/mteb/commit/9aa5ae593a276061a7ff4ed380c8f41c9a37e7ef))

## v2.7.19 (2026-02-03)

### Fix

* fix: change `np.bool` to `np.bool_` (#4041)

change np.bool ([`53de8c1`](https://github.com/embeddings-benchmark/mteb/commit/53de8c137b430547a8341097f044fcd8e65d98de))

### Unknown

* model: add the model of boom (#4022)

* add the model of boom

* add the model of boom

* rename the file from boom_models.py to ict_time_and_querit_models.py, match MTEB task names, and remove the #

* rename the file from boom_models.py to ict_time_and_querit_models.py, match MTEB task names, and remove the #

* lint

* dirctly use the InstructSentenceTransformerModel class

* Remove unused boom_4b_v1_loader function

Removed commented-out loader function for BOOM_4B_v1 model.

* Removed the commented code

* lint again

* Removed the commented code

* lint again

* Remove the description comment at the beginning

* Remove the description comment at the beginning and update the n_parameters

* Add adapted_from field to model metadata

* add the description of some instruction templates

* reformatted the ict_time_and_querit_models.py

* update the model revision

---------

Co-authored-by: zhanghengran &lt;zhanghengran@baidu.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`62d354a`](https://github.com/embeddings-benchmark/mteb/commit/62d354a49f8d77c160ac93ed8e7fc40a37292523))

## v2.7.18 (2026-02-02)

### Fix

* fix: set num proc to `None` by default (#4038)

set num proc to none by default ([`b3a51c6`](https://github.com/embeddings-benchmark/mteb/commit/b3a51c6620e2711b0693bf07a59e9ab7f332effa))

## v2.7.17 (2026-02-02)

### Fix

* fix: Improve array typing by also specifying dtype (#4018)

* Correct array typing

* Added arrat typing in docs

* fix typechecking

* Address comments

* fix typechecking

* simplify typechecking

* fix typecheck

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`3a40adc`](https://github.com/embeddings-benchmark/mteb/commit/3a40adc781a5bd2e9cf40e1f113f91ae27d72952))

* fix: Update ViDoRe3 to rank based on the mean (#4033)

* Update ViDoRe3 benchmark and leaderboard

* revert uv.lock ([`b616950`](https://github.com/embeddings-benchmark/mteb/commit/b616950553197d67548d6fa999ae4b8202d6b154))

## v2.7.16 (2026-02-01)

### Fix

* fix: remove undocumented models or models with no model card (#4030)

* fix: don&#39;t fill-missing metedata by default

This include two changes:
1) rename `compute_missing` to `fill_missing`, it seems like this change was only applied to `get_model_meta`, but not throughout the stack. This is technically breaking so I added a deprecation.
2) passed fill_missing to `from_hub`, I believe this was unintentionally missed

fixes #4027

* set `fill_missing=False` for `from_{model}`

* propegate deprecation

* add framework default

* fix: remove undocumented models or models with no model card

Also removed `scripts/generate_metadata.py`

fixes #3746

* compute_missing &gt; compute_metadata

* clean up tests to match new functionality

* format

* lint ([`dbc7334`](https://github.com/embeddings-benchmark/mteb/commit/dbc73346ccaca6f7a7f1cb05c43895032b1f9c76))

## v2.7.15 (2026-01-31)

### Ci

* ci: Pre-commit should not be forced (#4024)

We want to support people using pre-commit, but we don&#39;t want to force it. ([`b45ac3a`](https://github.com/embeddings-benchmark/mteb/commit/b45ac3a901ee22e0b35b82b97ebee943f69abb2f))

### Fix

* fix: don&#39;t fill-missing metedata by default (#4029)

* fix: don&#39;t fill-missing metedata by default

This include two changes:
1) rename `compute_missing` to `fill_missing`, it seems like this change was only applied to `get_model_meta`, but not throughout the stack. This is technically breaking so I added a deprecation.
2) passed fill_missing to `from_hub`, I believe this was unintentionally missed

fixes #4027

* set `fill_missing=False` for `from_{model}`

* propegate deprecation

* add framework default ([`d06184f`](https://github.com/embeddings-benchmark/mteb/commit/d06184fe48ead6652f83c5642a1faceac0cf6105))

## v2.7.14 (2026-01-30)

### Fix

* fix: Make `mteb.get_model` compatible with `CrossEncoders` (#3988)

* Made mteg.get_model compatible with CrossEncoders and SparseEncoders

* update loader for sparseEncoder

* fix import

* Simplify structure

* Add model_type to sparseEncoder models

* remove detection logic of sparsencoder

* Add tests and documentation

* simplified tests

* updated docs

* fix docs

* fix

* fix grammar

* Update docs/usage/defining_the_model.md

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* Update docs/advanced_usage/two_stage_reranking.md

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* Update docs/index.md

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* address comments

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt; ([`8cacef7`](https://github.com/embeddings-benchmark/mteb/commit/8cacef77c230d17efd8815a5047c63a45d085479))

### Unknown

* Add to_disk and from_disk to ModelResults (#3973)

* Add to_disk and from_disk to ModelResults

* fix signature

* change import to high-level

* Changed model_validate to model_validate_json

* fix tests

* remove duplicate path ([`4a33277`](https://github.com/embeddings-benchmark/mteb/commit/4a33277b7addedc76c499b9ef0d5d2686fbd3b24))

* Fix support for datsets 4.5 with pandas 3 (#3983)

* fix test

* fix: sanitize type for label during array conversion

* lint

* revert typo fix

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`8876169`](https://github.com/embeddings-benchmark/mteb/commit/887616960ea3ebba8a73ea83074e93a6e278ed93))

* rename bm25s to baseline/bm25s (#4007)

* rename bm25s to baseline/bm25s

* Update mteb/models/get_model_meta.py

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* remove logger message

* rename Human to baseline/Human

---------

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt; ([`3bab8d9`](https://github.com/embeddings-benchmark/mteb/commit/3bab8d9397ad48090559b86c45559e7de5fc6aee))

## v2.7.13 (2026-01-30)

### Fix

* fix: simplify dependencies (#4017) ([`7f07463`](https://github.com/embeddings-benchmark/mteb/commit/7f07463bcdf8cdd127e2ec36346d5f5e9e1be363))

### Unknown

* Build image on leaderboard refresh (#4015)

build image on leaderboard refresh ([`b9ff905`](https://github.com/embeddings-benchmark/mteb/commit/b9ff9056ad20d07bfdd3ef47dd92493bf509b48c))

* model: added Querit/Querit (#3996)

* querit_models_add

* Querit_Models_Change

* Update

* format revise

* add future

* format revise

* format revise

* last format revison

* last last revise

* last last last revison

* revise

* revise

* change the instruction

* last revison

* revise

* revise

* revise

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`5ca3387`](https://github.com/embeddings-benchmark/mteb/commit/5ca338787d79e0c0bd1f1b7ee1317520682c818c))

* Adding nvidia/nemotron-colembed models (#3941)

* Adding nvidia/nemotron-colembed models

* add colembed 4b, 8b model meta

* fix colembed-3b-v2 model name

* update revision for colembed 3b

* update revisions

* Update mteb/models/model_implementations/nvidia_llama_nemoretriever_colemb.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* lint

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`47d59ad`](https://github.com/embeddings-benchmark/mteb/commit/47d59ad56b36b6b4be2a6cdc8b0a092161e33ea3))

* model: added nomic-ai/nomic-embed-code (#4006)

* Add model metadata for nomic-embed-code

Added new model metadata for &#39;nomic-embed-code&#39;

* fix nomic_embed_code

* lint

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`88e72c6`](https://github.com/embeddings-benchmark/mteb/commit/88e72c6bbcf7c1e3f1e0a565ae668a24bc664312))

* model: Adding Ops-Colqwen3 models (#3987)

* Create ops_colqwen3_models.py

* Refactor OpsColQwen3 model and processor classes

* Update model revision in ops_colqwen3_models.py

* Remove calculate_probs method and fix model name

Removed the calculate_probs method and updated model name.

* format

* fix ds name

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`7c9bab2`](https://github.com/embeddings-benchmark/mteb/commit/7c9bab2f8ed4f3992c681098c232524eb6043621))

## v2.7.12 (2026-01-25)

### Fix

* fix: all dataset transform (#4002)

fix dataset transform ([`78687f7`](https://github.com/embeddings-benchmark/mteb/commit/78687f7518d4c8cf9d60126f02031e24a19a4773))

* fix: `dataset_transform` signature in PubChemWikiPairClassification (#4001)

fix: add num_proc arg to PubChemWikiPairClassification dataset_transform ([`4faaf36`](https://github.com/embeddings-benchmark/mteb/commit/4faaf362b0e2b22ef67597a90a85e838ab1b44ec))

## v2.7.11 (2026-01-25)

### Fix

* fix: `BedrockModel` initialization arguments (#3999)

fix: add model_name arg to BedrockModel init to prevent multiple values for model_id ([`0b9de9b`](https://github.com/embeddings-benchmark/mteb/commit/0b9de9b8572cb4b988c7e9c1278d03ec3c1b9db8))

## v2.7.10 (2026-01-25)

### Fix

* fix: NomicWrapper `get_prompt_name` call (#3995)

fix(models): correct get_prompt_name call in NomicWrapper ([`74dc105`](https://github.com/embeddings-benchmark/mteb/commit/74dc105f2a9743a6e0840b9230cc88a9bcea6544))

* fix: `BAAI/bge-small-en` model revision (#3993)

fix(models): update invalid bge-small-en revision ([`8c6a4d6`](https://github.com/embeddings-benchmark/mteb/commit/8c6a4d6bfa20e3e6735029698378292cc7082945))

## v2.7.9 (2026-01-24)

### Fix

* fix: add kwargs to pub chem load data (#3990)

add kwargs to pub chem load data ([`aeb22cd`](https://github.com/embeddings-benchmark/mteb/commit/aeb22cdff8577400c0dccbc3ae093beb5f785df3))

## v2.7.8 (2026-01-20)

### Fix

* fix: Filled active_parameter_overiride for GritLM/GritLM-8x7B nomic-ai/nomic-embed-text-v2-moe (#3967)

* Filled active_parameter_overiride for ritLM/GritLM-8x7B and nomic-ai/nomic-embed-text-v2-moe

* add correct parameters for nomic-ai/nomic-embed-text-v2-moe ([`dbd4287`](https://github.com/embeddings-benchmark/mteb/commit/dbd4287d1adaaf5dbda2efa26dc9c916dbda5b68))

## v2.7.7 (2026-01-20)

### Fix

* fix: leaderboard Nan handling (#3965)

* fix leaderboard

* fix loading aggregated tasks

* Update mteb/results/task_result.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`a369c26`](https://github.com/embeddings-benchmark/mteb/commit/a369c26a012c44eff229a79741796ba0045fa680))

* fix: Add `fill_missing` parameter in `get_model_meta` (#3801)

* Add compute missing parameter in get_model_meta

* fix logs

* fix

* fix from comments

* apply suggestion

* fix method

* add test and fix logic

* address comments

* rename compute_missing to fill_missing

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`90536d4`](https://github.com/embeddings-benchmark/mteb/commit/90536d420d0acdb911bb23ee822fcea6f2339fc2))

* fix: Ensure that retrieval tasks only evaluate on specified subsets instead of all (#3946)

* fix dataset loading

* update logging

* add test ([`8186392`](https://github.com/embeddings-benchmark/mteb/commit/8186392763f9b81d0064b66ae444646cea5d3426))

### Unknown

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`523b5bc`](https://github.com/embeddings-benchmark/mteb/commit/523b5bc0be917f4f1f4d58b230cbaa9be7be6078))

* model: Adding voyage-4-large (2048d) model configs (#3970)

* Adding voyage-4-large (2048d) model configs

* Adding voyage-4-large 2048d model configs

* Adding voyage-4-large 2048d model configs ([`961a43b`](https://github.com/embeddings-benchmark/mteb/commit/961a43b2ef63a77bd809aac5b65288c750f1166b))

## v2.7.6 (2026-01-20)

### Fix

* fix: saving aggregated tasks (#3915)

fix saving ([`ced5f71`](https://github.com/embeddings-benchmark/mteb/commit/ced5f710fd0e0b263c3bdcbfbca13cbbaf71ddba))

## v2.7.5 (2026-01-19)

### Fix

* fix: use `num_proc` for dataset processing (#3832)

* add typehint for encode kwargs

* remove num_proc

* start adding num_proc

* remove all num proc

* fix import

* add num proc to transform

* add to push to hub

* use num proc in vidore v2

* move num proc to evaluate

* pass num proc everywhere

* fix tests

* fix pylate

* fix image text pair

* fix num workers

* add kwargs to `load_data` ([`daf2b6f`](https://github.com/embeddings-benchmark/mteb/commit/daf2b6f27e89c32f2c7b84330313fd27d2175f59))

## v2.7.4 (2026-01-19)

### Fix

* fix: Update metadata to include active number of parameter to `ModelMeta` (#3837)

* Add active parameter column on LB

* update ModelMeta with parameters

* update ModelMeta of models

* Delete parameter_update_results.csv

* fix test

* fix tests

* delete script

* rename for consistency

* convert active_parameter to property

* rename and fix property

* update embedding parameters for model2vec models

* remove duplicate loading of models

* fix

* lintter

* fix

* remove separate method for embedding parameter calculation

* fix embedding calculation to pass typecheck

* lintter

* fix checking

* rename active parameters

* upd docstring

* fix tests

* remove n_active_parameters_override from ModelMeta of all models

* lintter

* rename file instead of merging main

* fix tests

* correct tests

* Delete model total and active parameters - model_parameters.csv

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`a45359e`](https://github.com/embeddings-benchmark/mteb/commit/a45359e6b2f1122c25c44829b4642b981c903539))

### Refactor

* refactor: split `BRIGHT` benchmark into individual subset tasks (#3285)

* refactor: split BRIGHT benchmark into individual subset tasks

* readd bright

* readd bright subset tasks

* feat: add descriptive stats for BRIGHT subsets retrieval tasks

* feat: add top_ranked for excluded_ids handling

* change main score to recall@1 for long version

* improve BRIGHT task descriptions

* add prompts to BRIGHT retrieval tasks

* refactor: BRIGHT(v1.1)

* calculate descriptive stats for BRIGHTLongRetrieval

* update prompts

* normalize names in prompts

* don&#39;t filter tasks

* remove filter_queries_without_positives and update revision

* don&#39;t create top ranked if not necessary

* get back naucs

* fix instructions

* add warning

* fix import

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`2c9b9e9`](https://github.com/embeddings-benchmark/mteb/commit/2c9b9e9371a730bdffdcf0382605d2898309e760))

## v2.7.3 (2026-01-19)

### Fix

* fix: temporarily remove private column from RTEB (#3932)

* fix: temporarily remove private column from RTEB

Link is still missing the note as I am waiting for @isaac-chung and @Samoed to confirm the write-up.

fixes #3902

* added issue link

* fix remove mean (Task)

* lint

* merge in fixes to remove_private (#3940)

fix: exclude private tasks from Borda rank calculation in RTEB

Co-authored-by: bflhc &lt;kunka.xgw@gmail.com&gt;

---------

Co-authored-by: bflhc &lt;kunka.xgw@gmail.com&gt; ([`b968433`](https://github.com/embeddings-benchmark/mteb/commit/b9684339fa34e4e74e16d94d76d231b806cd6f79))

* fix: correct inverted unload_data condition in evaluate (#3929)

Add tests verifying preloaded data is preserved.

Co-authored-by: Daniel Svonava &lt;daniel@superlinked.com&gt; ([`1c5d9c6`](https://github.com/embeddings-benchmark/mteb/commit/1c5d9c614d8d377cec073733e3ead4dcbda3d852))

* fix: temporarily remove private column from RTEB

Link is still missing the note as I am waiting for @isaac-chung and @Samoed to confirm the write-up.

fixes #3902 ([`5ca2559`](https://github.com/embeddings-benchmark/mteb/commit/5ca2559361816cdb05fd7896fd2f3049de752650))

### Refactor

* refactor: Activate `TC` (#3800)

* activate tc

* activate `TC`

* small import fix

* fix imports

* fix imports

* fix pil import

* fix benchmark result validation

* full benchmark fix

* update

* fix unpack imports

* upd vllm type ([`16e0211`](https://github.com/embeddings-benchmark/mteb/commit/16e0211ae67ce8cf95dd2378a5c8a49831229c8a))

### Unknown

* dedup colnomic_7b and fix loader (#3957)

* dedup colnomic_7b and fix loader

* remove flash_attention_2 ([`8c96b79`](https://github.com/embeddings-benchmark/mteb/commit/8c96b79985a038924dd89eb7d982f01ee9d8967d))

* fix colSmol-256M revision (#3956) ([`b3c2718`](https://github.com/embeddings-benchmark/mteb/commit/b3c2718544b021fbb13d02c02b79f44a2994071d))

* fix typo (#3954) ([`d7acd57`](https://github.com/embeddings-benchmark/mteb/commit/d7acd573e5bd98248eec18759f903be5f57e40fa))

* Merge branches &#39;main&#39; and &#39;remove-private&#39; of https://github.com/embeddings-benchmark/mteb ([`8a4663d`](https://github.com/embeddings-benchmark/mteb/commit/8a4663d1ee4864be5bb5896aa71f67b6f3c514e3))

* merge in fixes to remove_private (#3940)

fix: exclude private tasks from Borda rank calculation in RTEB

Co-authored-by: bflhc &lt;kunka.xgw@gmail.com&gt; ([`2279071`](https://github.com/embeddings-benchmark/mteb/commit/2279071d1e0514bcdbc6a24bdc7ecc54db441cc1))

* lint ([`a8acae7`](https://github.com/embeddings-benchmark/mteb/commit/a8acae75d14c93653fe36849331edf7a46d41233))

* fix remove mean (Task) ([`52731ff`](https://github.com/embeddings-benchmark/mteb/commit/52731ff1054cb4c39d9d551f7ab5c550c8116523))

* added issue link ([`b432896`](https://github.com/embeddings-benchmark/mteb/commit/b43289638ea7901e380101ecd6f70c9df5db511d))

## v2.7.2 (2026-01-15)

### Documentation

* docs: fix vllm broken link (#3936)

fix vllm link ([`d045d53`](https://github.com/embeddings-benchmark/mteb/commit/d045d53bab167956a78b9fd2f15e0651c37644eb))

### Fix

* fix: expose `ResultCache` directly as `mteb.ResultCache` (#3912)

* fix: expose `ResultCache` directly as `mteb.ResultCache`

fixes #3910

* docs: Update docs usage of `ResultCache` ([`3103f97`](https://github.com/embeddings-benchmark/mteb/commit/3103f97c0f5ec6bd5120046f14e196c368fdad56))

* fix: computation of results with missing scores (#3874)

* fix computation of results with missing scores

* fix test

* change 0 to nan

* change 0 to nan

* remove `fill_missing_scores` ([`d60e916`](https://github.com/embeddings-benchmark/mteb/commit/d60e91659e14c316ea121090e2adfa5af89c095f))

### Unknown

* model: add pixie_models (#3938)

* model: add pixie_models

* Apply lint formatting ([`8b54f0e`](https://github.com/embeddings-benchmark/mteb/commit/8b54f0e6261bcd9cabaec19fac76af8b14711728))

* model: mixedbread-ai/mxbai-edge-colbert-v0-32m and mixedbread-ai/mxbai-edge-colbert-v0-17m (#3931)

* Add model: mixedbread-ai/mxbai-edge-colbert-v0-32m and mixedbread-ai/mxbai-edge-colbert-v0-17m

* Lintter

* Add quotes

* Update dataset name

* Apply suggestions from code review

* Update mixedbread_ai_models.py

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`5de2194`](https://github.com/embeddings-benchmark/mteb/commit/5de219438283195c47f36bae42db76523737725e))

## v2.7.1 (2026-01-14)

### Fix

* fix: Minor logging fixes by activate `LOG` rule (#3820)

activate logger rule ([`65313c9`](https://github.com/embeddings-benchmark/mteb/commit/65313c9b7c407b9b695f4fb48429838118cc7233))

### Unknown

* model: Adding voyage-4 model (#3927)

* Adding voyage-4 model

* Adding voyage-4 model configs ([`b80da30`](https://github.com/embeddings-benchmark/mteb/commit/b80da30b77c669773a1855cb82ecca8719c7b636))

* Update references and citations for ViDoRe V3 benchmark (#3930)

* fix: Update references and citations for ViDoRe V3 benchmark

* foramat citation

* format again

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`e7d077e`](https://github.com/embeddings-benchmark/mteb/commit/e7d077e41d0cf1db559febe2078fdf39236d371d))

* model: add nemotron rerank (#3750)

* add nemotron rerank

* move to nvidia models

* removed extra params

* Apply suggestions from code review

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* remove or

* add docstring

* Update mteb/models/model_implementations/nvidia_models.py

Co-authored-by: Yauhen Babakhin &lt;ybabakhin@nvidia.com&gt;

* update

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Yauhen Babakhin &lt;ybabakhin@nvidia.com&gt; ([`330a601`](https://github.com/embeddings-benchmark/mteb/commit/330a60103edaa21e40f266726e4381227e6c1719))

* dataset: Add EuroPIRQRetrieval dataset (#3924)

* dataset: Add EuroPIRQRetrieval dataset

* Removed unnecessary load dataset functions ([`7966e06`](https://github.com/embeddings-benchmark/mteb/commit/7966e06b2c435b60428b36cc26a698f8ddef3222))

* dataset: add ChemRxivRetrieval task to ChemTEB benchmark (#3923)

* dataset: add ChemRxivRetrieval task to ChemTEB benchmark

* fix: add descriptive statistics

* feat: add ChemTEB v1.1 with ChemRxivRetrieval task

* fix: chemteb v1.1 alias ([`86359fd`](https://github.com/embeddings-benchmark/mteb/commit/86359fd5f6f00167147cf35441b2408ed6e88bad))

## v2.7.0 (2026-01-13)

### Documentation

* docs: Resolve problems with missing documentation links (#3834)

* resolve problems with missing documentation links

* split into files ([`0d277cd`](https://github.com/embeddings-benchmark/mteb/commit/0d277cde1502f57c8f0ce7d4189bf064e74be8b0))

### Feature

* feat: Add vLLM support (#3794)

* init

* init

Signed-off-by: wang.yuqi &lt;noooop@126.com&gt;

* ruff

Signed-off-by: wang.yuqi &lt;noooop@126.com&gt;

* - vllm_loader

Signed-off-by: wang.yuqi &lt;noooop@126.com&gt;

* + TYPE_CHECKING

Signed-off-by: wang.yuqi &lt;noooop@126.com&gt;

* Make vLLM exit properly.

Signed-off-by: wang.yuqi &lt;noooop@126.com&gt;

* rename

Signed-off-by: wang.yuqi &lt;noooop@126.com&gt;

* support rerank

Signed-off-by: wang.yuqi &lt;yuqi.wang@daocloud.io&gt;

* refine

Signed-off-by: wang.yuqi &lt;noooop@126.com&gt;

* refine

Signed-off-by: wang.yuqi &lt;noooop@126.com&gt;

* Update mteb/models/vllm_wrapper.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* refine

Signed-off-by: wang.yuqi &lt;yuqi.wang@daocloud.io&gt;

* + docs

Signed-off-by: wang.yuqi &lt;yuqi.wang@daocloud.io&gt;

* + benchmark

Signed-off-by: wang.yuqi &lt;yuqi.wang@daocloud.io&gt;

* + more benchmark

Signed-off-by: wang.yuqi &lt;yuqi.wang@daocloud.io&gt;

* Update docs/advanced_usage/vllm_wrapper.md

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update docs/advanced_usage/vllm_wrapper.md

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* refine docs

Signed-off-by: wang.yuqi &lt;yuqi.wang@daocloud.io&gt;

* refine docs

Signed-off-by: wang.yuqi &lt;yuqi.wang@daocloud.io&gt;

* fix typing

* move type ignore

* doc upd

* add test

* Update Makefile

* add support for prompts

* add support for prompts

* - demo

Signed-off-by: wang.yuqi &lt;yuqi.wang@daocloud.io&gt;

* make mypy happy

Signed-off-by: wang.yuqi &lt;yuqi.wang@daocloud.io&gt;

* fix typehints

* update pyproject

* update pyproject

* update pyproject

* The pooling + dp fails to run.

* fix uv lock

* fix docs

* simplify conflicts

* upd lock

* upd lock

* Update docs/advanced_usage/vllm_wrapper.md

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update docs/advanced_usage/vllm_wrapper.md

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update docs/advanced_usage/vllm_wrapper.md

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update docs/advanced_usage/vllm_wrapper.md

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update docs/advanced_usage/vllm_wrapper.md

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Apply suggestion from @Samoed

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* update

Signed-off-by: wang.yuqi &lt;noooop@126.com&gt;

* update

Signed-off-by: wang.yuqi &lt;noooop@126.com&gt;

---------

Signed-off-by: wang.yuqi &lt;noooop@126.com&gt;
Signed-off-by: wang.yuqi &lt;yuqi.wang@daocloud.io&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`4d568a8`](https://github.com/embeddings-benchmark/mteb/commit/4d568a807de3d523439adb9989dfb71db633d54c))

### Unknown

* model: Update the nemo retriever reversions to avoid error when loading the model (#3925)

* Update the nemo retriever versions to fix the crash issue with visual_config

* Update mteb/models/model_implementations/nvidia_llama_nemoretriever_colemb.py

* Update mteb/models/model_implementations/nvidia_llama_nemoretriever_colemb.py

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`dcd31fa`](https://github.com/embeddings-benchmark/mteb/commit/dcd31fa01ee5b58292e088d2be796486fa9f4300))

* model: Adding voyage-4-large, voyage-4 and voyage-4-lite (#3885)

* Adding voyage-4-large and voyage-4-lite

* Adding voyage-4-large and voyage-4-lite

* Adding voyage-4

* Reverting voyage-4 (as the tokenizer is not yet available publicly)

* added superseeded_by

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`64ce6ba`](https://github.com/embeddings-benchmark/mteb/commit/64ce6baa25f9e04100954d035d6b6fc21e1b82f6))

## v2.6.9 (2026-01-12)

### Fix

* fix: model load test (#3914)

* fix model load test

* trigger on dependencies change ([`227ce95`](https://github.com/embeddings-benchmark/mteb/commit/227ce95dcc217606bb8b14152cc45d187fb211c5))

### Unknown

* Artifacts for llama-embed-nemotron-8b model (#3919)

add artifacts for llama-embed-nemotron-8b model ([`c38ed02`](https://github.com/embeddings-benchmark/mteb/commit/c38ed020b210e20bada95ba8f779d0137a3aa2f5))

## v2.6.8 (2026-01-11)

### Fix

* fix: KoVidore2EnergyRetrieval revision fix (#3913) ([`0221b94`](https://github.com/embeddings-benchmark/mteb/commit/0221b945fd08bc855bc6463c6f6f5425820d6a7a))

### Unknown

* add model: bflhc/Octen-Embedding-0.6B (#3906) ([`c5c481f`](https://github.com/embeddings-benchmark/mteb/commit/c5c481f41979fdb05b775ee4bf82c339cccb7120))

* model: mixedbread-ai/mxbai-rerank-large-v1 (#3905)

* Add model: mixedbread-ai/mxbai-rerank-large-v1

* apply suggestions

* Added xsmall and base version of reranker models

* lintter ([`cb29623`](https://github.com/embeddings-benchmark/mteb/commit/cb29623e109e80d95fcfc2e4af36133d61bda1de))

* Add typehint for encode kwargs (#3831)

* add typehint for encode kwargs

* remove num_proc

* remove all num proc

* fix import

* fix docstrings ([`a417426`](https://github.com/embeddings-benchmark/mteb/commit/a41742622354561550f6f44b2f378eff574bd402))

* add dataset: KoViDoRe(v2) (#3876)

* add dataset: KoViDoRe v2

* fix citation format

* add direct loading

* lint format

* delete benchmark language view

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`24f3f85`](https://github.com/embeddings-benchmark/mteb/commit/24f3f8549cf8c8ca3e3ca3c182990bb70df70cf2))

## v2.6.7 (2026-01-08)

### Fix

* fix: nv embed version (#3715)

* fix nv embed wrapper

* try to fix

* fix sbert version ([`d3020f3`](https://github.com/embeddings-benchmark/mteb/commit/d3020f32129b9b420fd6b4360ce805def9b26d12))

### Unknown

* Don&#39;t sync make lint (#3841)

* don&#39;t sync make lint

* don&#39;t sync make typecheck

* upd ci

* upd ci

* upd ci

* upd ci

* upd ci

* swap ([`cb26458`](https://github.com/embeddings-benchmark/mteb/commit/cb26458c9b34561f7021284021a316dee22e2e03))

* model: add missing sentence transformers and jina models (#3808)

* add sentence transformers models

* add jina v2

* fix modalities ([`27619d1`](https://github.com/embeddings-benchmark/mteb/commit/27619d1e1bac24dbcfd416de57009ec0a915a691))

## v2.6.6 (2026-01-07)

### Fix

* fix: Simplify conflicts (#3875)

* simplify conflicts

* add lock

* remove torch ([`1bc3fba`](https://github.com/embeddings-benchmark/mteb/commit/1bc3fba86a4f98609069a97ca3b832c684be660b))

### Test

* test: Add HF Space Dockerfile using pre-built leaderboard image (#3838)

* Add HF Space Dockerfile using pre-built leaderboard image

Adds a lightweight Dockerfile for HuggingFace Space deployment that uses
the pre-built ghcr.io/embeddings-benchmark/mteb/leaderboard image as base.
Also adds a workflow to test the Dockerfile.

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;

* Delete .github/workflows/hf_space_docker.yml

* test: Add CI workflow for HF Space Dockerfile validation

---------

Co-authored-by: Claude Opus 4.5 &lt;noreply@anthropic.com&gt;
Co-authored-by: MTEB Agent &lt;agent@example.com&gt; ([`b905e27`](https://github.com/embeddings-benchmark/mteb/commit/b905e27b69a1015f4345960faf4bf4885c9e8cd7))

### Unknown

* model: Update bflhc/Octen-Embedding-8B revision (#3869)

update bflhc/Octen-Embedding-8B revision ([`1e78793`](https://github.com/embeddings-benchmark/mteb/commit/1e7879300fd27e57973a01f31e171e2c29df4580))

* dataset: Vietnamese VN-MTEB TVPLRetrieval, NanoClimateFEVER-VN, NanoFEVER-VN, NanoDBPedia-VN, NanoNQ-VN, NanoHotpotQA-VN, NanoMSMARCO-VN (#3810)

* [ADD] Vietnamese VN-MTEB TVPLRetrieval, NanoClimateFEVER-VN, NanoFEVER-VN, NanoDBPedia-VN, NanoNQ-VN, NanoHotpotQA-VN, NanoMSMARCO-VN

* [UPDATE] descriptive stats

* [UPDATE] bibtext

* [UPDATE] dataset path

* [UPDATE] nano db pedia retrieval

* [UPDATE] size dataset from 1M corpus to 100k

* [ADD] add note about what&#39;s different in nano version

* [ADD] TVPLRetrieval description ([`adb5b42`](https://github.com/embeddings-benchmark/mteb/commit/adb5b421c130a3b424298b9e850eea9a8953ed50))

## v2.6.5 (2026-01-05)

### Documentation

* docs: Fix docs build strict mode errors (#3809)

* fix: resolve mkdocs strict mode errors

* fix: remove duplicate line in installation.md

* build: add --strict flag to mkdocs build

* fix: resolve invalid BibTeX keys in task citations

* feat: filter BibTeX warnings in strict docs build

* Update docs/usage/defining_the_model.md

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: dynamic mkdocs path discovery for CI

* fix: improve docs build script with clear warning counts

* fix: resolve 6 real docs build warnings

* fix: remove broken PylateSearchEncoder reference

* Remove unused build scripts

* docs: wrap multimodal example as code snippet

* fix: export SklearnModelProtocol for docs API

* docs: add API reference for SklearnModelProtocol

* fix: remove SklearnModelProtocol export to avoid circular import

* feat: add SklearnModelProtocol docs with lazy import

* fix: convert Sphinx cross-references to MkDocs syntax for proper linking

Convert :class: Sphinx syntax to [Text][module.path] MkDocs syntax to ensure
cross-references are properly clickable in the generated documentation.

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* chore: remove SklearnModelProtocol docs to avoid circular import

* chore: remove SklearnModelProtocol export from _evaluators

* style: fix indentation in _evaluators/__init__.py

* fix: enable mkdocs build --strict without warnings

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* fix: rename evaluator to multilabel_classifier to avoid type conflict

* fix: use evaluator_model instead of evaluator to avoid type conflict

- Change parameter name from multilabel_classifier to evaluator_model
- Maintains SklearnModelProtocol type hint as requested in PR review
- Resolves mypy type error by using parent class&#39;s evaluator_model field
- Keeps explicit protocol reference in docstring for clarity

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Claude Sonnet 4 &lt;noreply@anthropic.com&gt; ([`3723d27`](https://github.com/embeddings-benchmark/mteb/commit/3723d2700223824677efa4d43f0ee1a6e8063cb0))

### Fix

* fix: Extend framework annotations for `ModelMeta` (#3819)

* Update framework and filter based on them

* update ModelMeta of models

* update ModelMeta of models

* update ModelMeta of models

* update ModelMeta of models

* update ModelMeta of models

* update ModelMeta of models

* update ModelMeta

* add csv

* update ModelMeta

* added framework to ModelMeta

* update ModelMeta of models

* update ModelMeta of models

* update framework in ModelMeta of models

* update framework

* update framework

* update framework in ModelMeta

* fix tests

* Add models

* fix tests

* add tags extraction in from_hub()

* fix typecheck

* apply suggestions

* apply suggestions

* keep only static method

* delete csv and script ([`d033c24`](https://github.com/embeddings-benchmark/mteb/commit/d033c241ddb5c0ef1b9e7925607d2c69d55091a2))

### Unknown

* fix dataset generation tags (#3835) ([`bf2627a`](https://github.com/embeddings-benchmark/mteb/commit/bf2627a7efe78d0f618d0a11c8f993f31a0686b6))

* model: Add SauerkrautLM-ColPali visual document retrieval models (#3804)

* model: Add SauerkrautLM-ColPali visual document retrieval models

Add inference code and requirements for SauerkrautLM-ColPali visual document retrieval models.

These are multi-vector embedding models based on the ColPali architecture:
- ColQwen3 (Qwen3-VL backbone): 1.7B Turbo, 2B, 4B, 8B variants
- ColLFM2 (LFM2-VL backbone): 450M variant
- ColMinistral3 (Ministral3 backbone): 3B variant

All models produce 128-dimensional embeddings per text/image token and use MaxSim (late interaction) for retrieval scoring.

Model checkpoints:
- https://huggingface.co/VAGOsolutions/SauerkrautLM-ColQwen3-1.7b-Turbo-v0.1
- https://huggingface.co/VAGOsolutions/SauerkrautLM-ColQwen3-2b-v0.1
- https://huggingface.co/VAGOsolutions/SauerkrautLM-ColQwen3-4b-v0.1
- https://huggingface.co/VAGOsolutions/SauerkrautLM-ColQwen3-8b-v0.1
- https://huggingface.co/VAGOsolutions/SauerkrautLM-ColLFM2-450M-v0.1
- https://huggingface.co/VAGOsolutions/SauerkrautLM-ColMinistral3-3b-v0.1

* fix: Address review comments

- Remove loader functions, use classes directly in ModelMeta
- Remove unused get_fused_embeddings method
- Move model.to(device) and model.eval() to base class __init__
- Pass torch_dtype directly to ColMinistral3.from_pretrained

* Update mteb/models/model_implementations/slm_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/slm_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/slm_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/slm_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/slm_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/slm_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update pyproject.toml

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: Update release_date to 2025-12-20

* fix: address review comments - remove partial, add adapted_from and training_datasets

* Update mteb/models/model_implementations/slm_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: import COLPALI_CITATION from colpali_models and add model_type

* add training datasets

* fix: remove section headers and use PyPI package instead of Git URL

* fix: resolve merge conflicts and remove section headers

* fix: use COLPALI_TRAINING_DATA for training_datasets

* fix: use exact n_parameters and memory_usage_mb values from HuggingFace

* don&#39;t build 3.14

* lint

---------

Co-authored-by: David Golchinfar &lt;d.golchin@web.de&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`44e9b20`](https://github.com/embeddings-benchmark/mteb/commit/44e9b2038a26e131247e74242aa26438970d9377))

## v2.6.4 (2026-01-03)

### Fix

* fix: Add leaderboard docker workflow (#3828)

* Add GitHub workflow to test leaderboard Dockerfile

- Add .github/workflows/leaderboard_docker.yml workflow that:
  - Builds the Docker image
  - Tests container startup with 6-minute timeout
  - Monitors for container exit codes and failures
  - Shows progress updates during long initialization
  - Validates leaderboard dependencies are available
- Include Dockerfile for leaderboard containerization
- Fix missing typer dependency in leaderboard extras to resolve ModuleNotFoundError
- Update uv.lock with typer dependency

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* Optimize leaderboard Docker workflow with smart exit conditions

- Add intelligent startup progress detection instead of blind 5.5min wait
- Monitor key milestones: app startup, Step 1/7 completion
- Only exit early on actual completion signals (Gradio server ready, full initialization)
- Hard timeout failure at 5.5min regardless of progress
- Improved logging with 30s progress updates
- Tested with act: reduces wait time from 5.5min to ~2.5min when appropriate

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* Remove redundant Test container dependencies step

- Dependencies already verified during Docker build process
- Runtime verification handled by smart exit conditions
- Eliminates environment-specific import failures in act testing
- Streamlines workflow to focus on essential container startup validation

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* Fix Docker image availability and add GHCR caching

- Add load: true to ensure built image is available for docker run
- Add GHCR login and push for enhanced caching across workflow runs
- Include commit-specific and latest tags for better cache utilization

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* Fix Docker Hub push error by separating GHCR push from local testing

- Only push to GHCR to avoid Docker Hub authentication issues
- Pull GHCR image and tag locally for testing
- Maintains same local tag name for test step compatibility

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* Add free disk space step to prevent storage errors

- Remove unused software installations (~10GB)
- Clean Docker cache before build operations
- Prevents &#34;no space left on device&#34; errors during image pull

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* Fix duplicate detection messages and improve server response validation

- Add INIT_COMPLETE_DETECTED state tracking to prevent repeated &#34;initialization complete&#34; messages
- Remove Step 1/7 detection logic that was causing duplicate output
- Add server response test after initialization complete detection
- Clean up progress status display and exit conditions

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* fix: remove redundant typer dependency from leaderboard extras

* fix: only push Docker images from main branch

* fix: use COPY instead of git clone in Dockerfile

---------

Co-authored-by: Claude Sonnet 4 &lt;noreply@anthropic.com&gt; ([`c7c04e5`](https://github.com/embeddings-benchmark/mteb/commit/c7c04e5947ba823075c4165051daacb31c1d6d6b))

## v2.6.3 (2026-01-03)

### Fix

* fix: Allow passing device to model (#3812)

* Allow passing device to model

* revert incorrect modification and fix typeerror

* add device to get_model and address comments

* Correct CDEWrapper ([`17ef363`](https://github.com/embeddings-benchmark/mteb/commit/17ef363459425e50f92310149b9ec57fa4c020de))

## v2.6.2 (2026-01-02)

### Ci

* ci: Switch CI to use `uv` (#3702)

* use uv to all make commands

* read the docs a bit more...

* try out system flag

* fix: remove redundant pip install uv commands from Makefile

Removes duplicate uv installations that were conflicting with the
properly configured uv from astral-sh/setup-uv GitHub Action.
The GitHub Action already installs and configures uv correctly,
so the Makefile pip installs were overwriting this configuration
and causing &#34;No system Python installation found&#34; errors.

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* fix: remove --system flag from uv pip install commands

The astral-sh/setup-uv GitHub Action configures uv to manage its own
Python installations, not to use system Python. The --system flag
was causing &#34;No system Python installation found&#34; errors because
uv expects to use its managed Python environment.

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* fix: migrate Makefile to use correct uv workflow

- Replace &#39;uv pip install&#39; with &#39;uv sync&#39; for dependency management
- Add proper --extra flags for all optional dependencies
- Use &#39;uv run&#39; for all Python command executions
- Follow official uv GitHub Actions best practices

This aligns with uv&#39;s recommended project workflow and should resolve
the CI environment issues we were experiencing.

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* fix: update all GitHub Actions workflows to remove UV_SYSTEM_PYTHON

- Remove UV_SYSTEM_PYTHON: 1 from all workflow files
- Fix documentation.yml to use &#39;uv sync --group docs&#39; instead of &#39;uv pip install&#39;
- Fix leaderboard_build.yml to use &#39;uv sync --extra leaderboard --group dev&#39;
- Ensures consistent uv workflow across all CI jobs

Updated workflows:
- lint.yml
- documentation.yml
- model_loading.yml
- dataset_loading.yml
- leaderboard_build.yml

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* fix: lint workflow to use correct dependency group

- Change from &#39;make install&#39; to &#39;uv sync --group lint&#39; since pre-commit is in the lint group
- Add explicit pre-commit install step
- Use &#39;uv run&#39; for lint commands (ruff, typos) to ensure proper environment
- Fixes &#34;pre-commit: No such file or directory&#34; error in lint workflow

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* remove 3.14

* try out 3.14 again with python_full_version

* specify torch version for pylate dep

* try to skip colpali

* try split torch

* Add --no-sync flag and group/extra flags to uv run commands

Address review comments from PR #3702:

1. Add --no-sync to all uv run commands in Makefile for:
   - Faster execution (avoids re-syncing on each command)
   - pip compatibility (users can remove &#39;uv run&#39; prefix)

2. Add appropriate group/extra flags to uv run commands:
   - test commands: --group test
   - docs commands: --group docs
   - typecheck: --group typing
   - leaderboard: --extra leaderboard

3. Update CI workflows to use --no-sync and appropriate groups:
   - lint.yml: Add --no-sync --group lint to all uv run commands
   - documentation.yml: Add uv run --no-sync --group docs to mkdocs gh-deploy

These changes improve performance while maintaining compatibility for
contributors who prefer using pip directly.

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4.5 &lt;noreply@anthropic.com&gt;

* try removing install block

* add back install block

* remove install block in doc CI without --no-sync

* add uv lock file

* replace install-for-test with just install

* install pre-commit with uv

* fix doc workflow

* address review comments

* remove no-sync from run-leaderboard make command

* remove --no-sync from selected make commands

* update typechecking

* fix type checking

* sync to install

* fix tests

* test pre-commit setup

* remove test file

* fix: separate install and install-for-tests with uv commands

* fix: add leaderboard extra to typecheck command for gradio imports

* fix: add faiss-cpu extra to test targets

* fix: update CI workflows for uv dependency management

* docs: update all documentation for uv migration

- Add uv installation options alongside pip in README.md
- Update installation.md with comprehensive migration guide for contributors
- Add uv context to CONTRIBUTING.md for development setup
- Update all usage docs to include uv alternatives for extras:
  - openai, leaderboard, image, xet, faiss-cpu dependencies
- Fix incorrect extra name: faiss -&gt; faiss-cpu in retrieval_backend.md
- Ensure consistent dual-option approach (pip/uv) throughout documentation

This provides users and contributors with modern, fast uv tooling while
maintaining backward compatibility with existing pip workflows.

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

---------

Co-authored-by: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`75743f1`](https://github.com/embeddings-benchmark/mteb/commit/75743f1933cb32bf2841dd3f58eb72f31ed0d205))

### Fix

* fix: handle git lfs content for cached zip file (#3827) ([`043ea38`](https://github.com/embeddings-benchmark/mteb/commit/043ea3837b44a55d8dc5d9533749442cf4829a42))

## v2.6.1 (2025-12-30)

### Fix

* fix: Download cached results zip from cached-data branch (#3795)

* Optimize leaderboard startup by downloading cached results from cached-data branch

- Modify _load_results() to first try downloading __cached_results.json.gz from the cached-data branch
- Only fallback to full repository clone if the direct download fails
- Add gzip decompression to handle the compressed cache file
- This reduces startup time significantly by avoiding full repo cloning when possible
- Added comprehensive logging to track download progress and fallback behavior

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* make lint

* Fix leaderboard stability test with enhanced debugging

- Remove prevent_thread_lock=True to keep Gradio process alive
- Add comprehensive exception handling for HTTP, gzip, and file operations
- Optimize test completion with HTTP 200 health checking (300s â†’ ~140s)
- Add detailed logging and warning suppressions for better debugging

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* Update tests/test_leaderboard.py

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* Add comprehensive tests for leaderboard caching exception handling

- Add 46 unit tests covering HTTP downloads, gzip decompression, file I/O, and JSON validation
- Reorganize leaderboard tests into focused modules for better maintainability
- Update Makefile with improved leaderboard test commands

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* Increase cached results download size limit to 500MB

The cached results file has grown to ~92.7MB, exceeding the previous 50MB limit.
This change increases the limit to 500MB to accommodate current and future file sizes.

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* Fix leaderboard tests by adding missing dependency to install-for-tests

GitHub Actions were failing because cachetools was not installed during CI test runs.
The leaderboard extra was already defined with cachetools&gt;=5.2.0 but wasn&#39;t included
in the install-for-tests target used by CI.

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* Remove LogFlusher functionality from leaderboard app

Addresses PR comment feedback indicating the log flushing optimization
was unnecessary at this stage. Removes:
- LogFlusher class with batching logic
- Global _log_flusher instance
- _flush_logs() wrapper function
- All calls to _flush_logs() throughout the app
- Complete test file test_log_flushing.py

Leaderboard functionality remains unchanged and tests pass.

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* remove _validate_benchmark_json

* Refactor leaderboard caching to use ResultCache and consolidate tests

Move download_cached_results_from_branch to ResultCache class and reduce TestDownloadCachedResultsFromBranch from 23 to 13 test cases while maintaining full coverage.

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* Apply suggestions from code review

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* lint and remove unreachable code

* Move shared test fixtures to parent conftest.py

- Created tests/conftest.py with shared fixtures (mock_benchmark_json,
  mock_invalid_json, mock_gzipped_content) for use across all tests
- Removed duplicate fixtures from tests/test_leaderboard/conftest.py
- Kept leaderboard-specific fixtures in test_leaderboard/conftest.py
- Fixes TestDownloadCachedResultsFromBranch test failures by making
  fixtures accessible to test_result_cache.py

All 25 tests now passing (23 in test_result_cache.py, 2 in test_integration.py)

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4.5 &lt;noreply@anthropic.com&gt;

* make method private

* Fix content type validation test to match implementation behavior

The test_content_type_handling test was expecting warnings for unexpected
content types, but the actual implementation raises exceptions. Updated test
to use pytest.raises() for proper exception validation.

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* update cache based on review comments

* type check

* Remove unused leaderboard_test_config fixture

* fix: remove unused mock_invalid_json fixture

* rm AGENTS/,d

* reduce number of excepts in app.py

---------

Co-authored-by: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;
Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt; ([`3303087`](https://github.com/embeddings-benchmark/mteb/commit/33030877cfc69908844a21cc7e42e0a6ce1038ec))

### Unknown

* add model: bflhc/Octen-Embedding-4B (#3816) ([`6dcbf9f`](https://github.com/embeddings-benchmark/mteb/commit/6dcbf9f513a7fe46e6c92532edaaea4917f5282f))

* Add filter for model type (#3799)

* Add filter for model type

* fix literal issue

* fix

* remove white space

* remove logic in filter_tasks

* remove info in leaderboard

* add tests

* update tests

* add default in model types

* fix model filter

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`6f4627e`](https://github.com/embeddings-benchmark/mteb/commit/6f4627e46a8d255a155971c65759f9e2a31fa3fd))

## v2.6.0 (2025-12-30)

### Feature

* feat: Add leaderboard CLI command (#3802)

* feat: add leaderboard CLI command with cache-path option

* test: add comprehensive tests for leaderboard CLI command

* try to fix install

* fix: lazy-load leaderboard to avoid requiring deps for CLI

* Update mteb/cli/build_cli.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* make lint

* remove AGENTS.md

* move import to top of file

* log the default cache path

* Improve leaderboard tests to verify actual cache paths

Address PR feedback by modifying leaderboard tests to verify the actual
cache paths passed to get_leaderboard_app instead of mocking ResultCache.

- Updated test_leaderboard_custom_cache_path to create real ResultCache instances
  and verify the correct custom cache path is used
- Updated test_leaderboard_default_cache to verify the default cache path is used
- Removed ResultCache mocking in favor of testing actual cache behavior
- Used patch.dict to mock the leaderboard module import while preserving
  real cache functionality

This provides better test coverage by validating that the cache objects
passed to the leaderboard app have the correct paths, as suggested in
PR comment: https://github.com/embeddings-benchmark/mteb/pull/3802#discussion_r2650719614

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* Combine leaderboard cache tests using pytest parametrize

Address PR feedback by combining test_leaderboard_custom_cache_path and
test_leaderboard_default_cache into a single parametrized test.

- Created test_leaderboard_cache_paths with parametrize decorator
- Tests both custom cache path and default cache path scenarios
- Each test case covers different host, port, and share configurations
- Removed redundant test_leaderboard_args as functionality is now covered
  by the parametrized test
- Improved test maintainability by reducing code duplication

This addresses PR comment: https://github.com/embeddings-benchmark/mteb/pull/3802#discussion_r2650721879
&#34;Can be combined with the following test using a parametrize argument&#34;

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* Update make run-leaderboard to use new CLI and remove app.py main block

Address PR feedback by updating the project to use the new leaderboard CLI:

- Updated Makefile run-leaderboard target to use `python -m mteb leaderboard`
  instead of `python -m mteb.leaderboard.app`
- Removed the `if __name__ == &#34;__main__&#34;:` block from mteb/leaderboard/app.py
  as this functionality is now handled by the CLI command

This completes the integration of the new leaderboard CLI command into
the project&#39;s build system and removes deprecated direct module execution.

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* feat: add theme and head parameters to leaderboard CLI

* fix: suppress leaderboard warnings on CLI launch

* test: update leaderboard tests for theme and head params

* Revert &#34;Update make run-leaderboard to use new CLI and remove app.py main block&#34;

This reverts commit d4df501a4c5111b80899624620398c2e72a308a2.

* Update mteb/cli/build_cli.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* docs: update leaderboard CLI usage

* update docs to show defaults

* fix: apply ruff formatting

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`1a64ed6`](https://github.com/embeddings-benchmark/mteb/commit/1a64ed68689f1e7f163e12a5f46a783b65d334b8))

## v2.5.5 (2025-12-30)

### Documentation

* docs: add benchmark filtering examples (#3805)

* docs: add benchmark filtering examples

* Apply suggestion from @Samoed

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* docs: remove custom benchmarks subsection

* docs: expand filtering section with content tabs

* docs: fix code block indentation in content tabs

* build: include docs deps in dev group

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`b1aae79`](https://github.com/embeddings-benchmark/mteb/commit/b1aae795f8c8983fd02b14e4b34e313b5c515f55))

### Fix

* fix: repo exists check (#3813)

* fix repo exists check

* add test ([`6ebc5fd`](https://github.com/embeddings-benchmark/mteb/commit/6ebc5fd3108f05178c3dc830e0187a360a4aebd0))

### Unknown

* Update the API of Bytedance/Seed1.6-embedding-1215 (#3814)

* update reference website of Seed1.6-embedding-1215

* update Bytedance/Seed1.6-embedding-1215 model ([`ab2d494`](https://github.com/embeddings-benchmark/mteb/commit/ab2d4940d2ec4504cd099f046bd3aa7a87051099))

* update generate_model_card with get_benchmark_result() (#3796)

* update generate_model_card with get_benchmark_result()

* add support for list of benchmarks

* split parameters

* fix type

* generate card

* add tests

* add tests

* add tabulate to test dependencies

* correct tests

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`9e867f5`](https://github.com/embeddings-benchmark/mteb/commit/9e867f56346a80e6269bc30b6af83b5e5b32c720))

* Add function for creating mock images  (#3803)

* create function for creating mock tasks

* add annotations ([`48f137e`](https://github.com/embeddings-benchmark/mteb/commit/48f137e0d60f58b31768dd5e41294fc775da10ab))

* Add benchmark aliases (#3767)

* add benchmark aliases

* split to aliases

* move aliases

* create aliases in separate function

* simplify a bit

* add test

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* add default value

* add MTEB alias

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`480f1b9`](https://github.com/embeddings-benchmark/mteb/commit/480f1b99f54d193985dbb02ec2f8e8a55c5170a5))

## v2.5.4 (2025-12-27)

### Fix

* fix: add typecheck (#3550)

* add pytyped

* start typing

* finish evaluators

* add more types

* Update mteb/results/benchmark_results.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* apply comments

* continue typechecking

* fix typehint

* typechecking

* fix tests

* fix type errors again

* fix cache

* add more types

* fix method

* roll back pyproject

* activate PGH

* install more types

* almost finish

* fix search wrappers

* add ci

* fix tests

* fix 3.10 types

* rollback overload

* fixes after merge

* change to iterable

* add fixes

* remove summarization scores hint

* simplify deprecated_evaluator

* simplify model conversion

* add comment for typechecking

* remove casts

* remove duplicated function

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`a99557d`](https://github.com/embeddings-benchmark/mteb/commit/a99557d308b3d62868a9cef2a64947525311c4fd))

### Unknown

* save kwargs passed to get_model in model_meta (#3785)

* save kwargs passed to get_model in model_meta

* add save_kwargs to load_model

* removed copy of meta

* Update mteb/models/model_meta.py

* try to run with kwargs

* try to move kwargs

* add tests

* change model in tests

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`3ec1f63`](https://github.com/embeddings-benchmark/mteb/commit/3ec1f6343349e3c9de2ba741abf6d1a68eddb0c6))

## v2.5.3 (2025-12-26)

### Fix

* fix: Added warnings.warn when logging warnings (#3753)

* Added warnings.warn when logging warnings

* address comments

* Added depreciation warning

* made better

* address comments

* address comments

* address comments

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`10e6bc5`](https://github.com/embeddings-benchmark/mteb/commit/10e6bc5fad299f7271600efde11f28aa91afe857))

## v2.5.2 (2025-12-25)

### Documentation

* docs: update MIEB contributing guide for MTEB v2 AbsTask structure (#3787)

* docs: update MIEB contributing guide for MTEB v2 AbsTask structure

* Update docs/mieb/readme.md

* Update docs/mieb/readme.md ([`fb53f57`](https://github.com/embeddings-benchmark/mteb/commit/fb53f57053c6d2c596a812eacc6bbce4e1f60f05))

### Fix

* fix: Add model_type in model_meta for all models (#3751)

* Add model_type in model_meta for all models

* added literal for model_type

* update jina embedding model type

* Added model_type to from_cross_encoder() method

* update test

* change location in model_meta to pass test

* update late_interaction model and fix test

* update late_interaction for colnomic models

* update test

* Update mteb/models/model_meta.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix naming

* remove is_cross_encoder field and convert it into property

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`522eecc`](https://github.com/embeddings-benchmark/mteb/commit/522eecc34cd744fe3943b1653b4d9f2d3829ba61))

### Unknown

* Optimize validate filter scores only (#3792)

* feat: add detailed timing logs to leaderboard initialization

Add comprehensive timing information to track performance of each step
in the leaderboard building process:
- Loading benchmark results (from cache or remote)
- Fetching and processing benchmarks
- Filtering models and generating tables
- Creating Gradio components and interface
- Prerun phase for cache population

Each step logs start and completion times with elapsed duration to help
identify performance bottlenecks during leaderboard initialization.

* perf: optimize benchmark processing with caching and vectorized operations

Implemented 3 high-impact optimizations to reduce benchmark processing time:

1. Cache get_model_metas() calls using @functools.lru_cache
   - Eliminates 59 redundant calls (once per benchmark)
   - Now called once and cached for all benchmarks

2. Replace pandas groupby().apply() with vectorized operations
   - Replaced deprecated .apply(keep_best) pattern
   - Uses sort_values() + groupby().first() instead
   - Avoids nested function calls per group

3. Cache version string parsing with @functools.lru_cache
   - Eliminates redundant parsing of same version strings
   - Uses LRU cache with 10,000 entry limit

Performance improvements:
- Benchmark processing: 131.17s â†’ 44.73s (2.93x faster, 66% reduction)
- join_revisions(): 84.96s â†’ 1.73s (49x faster, 98% reduction)
- Leaderboard Step 3: 121.28s â†’ 48.23s (2.51x faster, 60% reduction)

This significantly improves leaderboard startup time by reducing the
benchmark processing bottleneck.

* perf: optimize validate_and_filter_scores filtering logic

* Update mteb/results/task_result.py

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

---------

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt; ([`d3bc4cc`](https://github.com/embeddings-benchmark/mteb/commit/d3bc4cc043ed184d151d59dbed3a945ca4bb26a5))

* Add leaderboard timing logs and join_revisions() speedups (#3790)

* feat: add detailed timing logs to leaderboard initialization

Add comprehensive timing information to track performance of each step
in the leaderboard building process:
- Loading benchmark results (from cache or remote)
- Fetching and processing benchmarks
- Filtering models and generating tables
- Creating Gradio components and interface
- Prerun phase for cache population

Each step logs start and completion times with elapsed duration to help
identify performance bottlenecks during leaderboard initialization.

* perf: optimize benchmark processing with caching and vectorized operations

Implemented 3 high-impact optimizations to reduce benchmark processing time:

1. Cache get_model_metas() calls using @functools.lru_cache
   - Eliminates 59 redundant calls (once per benchmark)
   - Now called once and cached for all benchmarks

2. Replace pandas groupby().apply() with vectorized operations
   - Replaced deprecated .apply(keep_best) pattern
   - Uses sort_values() + groupby().first() instead
   - Avoids nested function calls per group

3. Cache version string parsing with @functools.lru_cache
   - Eliminates redundant parsing of same version strings
   - Uses LRU cache with 10,000 entry limit

Performance improvements:
- Benchmark processing: 131.17s â†’ 44.73s (2.93x faster, 66% reduction)
- join_revisions(): 84.96s â†’ 1.73s (49x faster, 98% reduction)
- Leaderboard Step 3: 121.28s â†’ 48.23s (2.51x faster, 60% reduction)

This significantly improves leaderboard startup time by reducing the
benchmark processing bottleneck.

* Update mteb/leaderboard/app.py

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* fix: ensure deterministic revision grouping in join_revisions()

- Replace groupby(revision_clean) with groupby(revision)
- Remove non-deterministic iloc[0] access for revision selection
- Tasks with different original revisions (None vs external) now kept separate
- Each ModelResult has consistent revision across all its task_results

This resolves the issue where tasks with different original revisions that mapped
to the same cleaned value would be grouped together non-deterministically.

* refactor: use default lru_cache maxsize for _get_cached_model_metas

* refactor: remove optimization markers from comments

* Apply suggestion from @isaac-chung

---------

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt; ([`57a4b0c`](https://github.com/embeddings-benchmark/mteb/commit/57a4b0ce7bb0206737566b81e7a81ec0e44b0a09))

* model: add octen_models (#3789)

* model: add octen_models

* add issue link for document prompt ([`a2631dd`](https://github.com/embeddings-benchmark/mteb/commit/a2631dd38e3a9290f0149dac0866add10ca022ef))

* better clustering fix (#3793) ([`44555a7`](https://github.com/embeddings-benchmark/mteb/commit/44555a7c8df2610d9e5df48f5550084e272e57e3))

## v2.5.1 (2025-12-23)

### Fix

* fix: legacy clustering processing (#3791)

fix clustering processing ([`eee248a`](https://github.com/embeddings-benchmark/mteb/commit/eee248a80ab3a37accd1f440fcc098b64dc75347))

## v2.5.0 (2025-12-23)

### Feature

* feat: Added `get_benchmark_result()` to BenchmarkResults to obtain a benchmark table (#3771)

* Update BenchmarkResults to output results of benchmark

* added score column and correct TYPE_CHECKING

* address comments

* address comments

* fix import

* fix tests

* fix tests

* change BenchmarkResults to Pydantic dataclass

* change benchmark to pydantic dataclass

* fix tests

* fix model

* fix

* lint

* remove future

* fix after review

* add test

* reapply comments from review

* remove mock benchmark

* add documentation

* added actual results

* Update docs/usage/loading_results.md

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* add actual results

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`92fa705`](https://github.com/embeddings-benchmark/mteb/commit/92fa7057009638a3cd63db1095fd0c9075b35306))

### Unknown

* Updates on ColEmbed 3B and 1B model wrapper to support MTEB 2 image dataloader (#3783)

Renaming model forward_passages to forward_images ([`0a0e398`](https://github.com/embeddings-benchmark/mteb/commit/0a0e3983df15be0eb947ef1314fe451e4b0febde))

* dataset: Add Turkish Constitutional Court violation classification task (#3777)

* Add Turkish Constitutional Court violation classification task

* Format Turkish task files with ruff

* Update mteb/tasks/classification/tur/turkish_constitutional_court.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Fix dataset revision to pinned commit hash

* Remove results directory from task PR

* task dataset path updated

* load data deleted

* ruff formatted

* bibtex fix

* descriptive stats added

* descriptive stats file name fix

* Fix dataset duplicates/overlap and bibtex

* Fix dataset duplicates, remove validation, and clean BibTeX

* Format TurkishConstitutionalCourtViolation task with ruff

* upd statistics

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`d3ce3d5`](https://github.com/embeddings-benchmark/mteb/commit/d3ce3d5cfdc46c38f18c4afa625ef25661f69b02))

* model: add c2llm &amp; fix f2llm (#3782)

* add c2llm &amp; fix f2llm

* Update c2llm via sentence_transformer_wrapper

* add c2llm languages

* format

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`9b00964`](https://github.com/embeddings-benchmark/mteb/commit/9b0096409358d037e1f95527a3240828b5de95b8))

* dataset: add SQuADKorV1Retrieval task for Korean (#3779)

* dataset: add SQuADKorV1Retrieval task for Korean

Add Korean SQuAD v1.0 retrieval task based on the yjoonjang/squad_kor_v1 dataset.

This dataset provides:
- 5,777 queries
- 960 corpus documents
- Korean Wikipedia-based question answering pairs

* dataset: add descriptive statistics for SQuADKorV1Retrieval

Statistics:
- 6,734 total samples
- 960 unique documents (avg 545 chars)
- 5,764 unique queries (avg 34 chars) ([`fd339dd`](https://github.com/embeddings-benchmark/mteb/commit/fd339dd6d06c5fc83afce4b8b2c8db3f22abe2a8))

* Fix: update reference website of Seed1.6-embedding-1215 (#3780)

update reference website of Seed1.6-embedding-1215 ([`f5182fb`](https://github.com/embeddings-benchmark/mteb/commit/f5182fb65b8412763270ca2d7f8031f187cb0ce4))

* fix pre commit (#3775) ([`1a7b4cf`](https://github.com/embeddings-benchmark/mteb/commit/1a7b4cf0e7c6d6985d35857765a062ed094a95b6))

* fix_mod_embedding_oom (#3774) ([`02bdcd8`](https://github.com/embeddings-benchmark/mteb/commit/02bdcd84192168e3aa211cdad6089070f90174bc))

* model: added `Bytedance/Seed1.6-embedding-1215` (#3760)

* add model: Bytedance/Seed1.6-embedding-1215

* make lint

* fix typo

* remove get_text_embedding() and get_image_embedding(), only reserve get_fused

* move &#34;max_tokens&#34; and &#34;available_embed_dims&#34; into model implementations

* fix typo

* Apply suggestions from code review

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: fix bug when &#34;images&#34; or &#34;texts&#34; are none

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`0d73c3d`](https://github.com/embeddings-benchmark/mteb/commit/0d73c3d02a91d934dc4123b4202da6eeaef38509))

* Added revision parameter for results repo (#3764)

* Added revision parameter for results repo

* fix clone_cmd

* Added depth parameter in clone command ([`e8c02b1`](https://github.com/embeddings-benchmark/mteb/commit/e8c02b15641f337a311d4a66b7e4feb0ca926113))

## v2.4.2 (2025-12-17)

### Fix

* fix: Added missing model citations (#3762)

* Added model citations

* Apply suggestions from code review

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* fix syntax and remove citation of 1 model

* Delete scripts/model_citations_report.csv

* add missing &#34;@&#34; in citations

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt; ([`4f7016b`](https://github.com/embeddings-benchmark/mteb/commit/4f7016b0f17d31cc1bd6d9b9a8a3eaf4ffe30874))

### Unknown

* fix `bflhc/MoD-Embedding` loader (#3759)

* Rename prompt_dicts to prompts_dict in mod_models.py

* move to meta ([`1113e56`](https://github.com/embeddings-benchmark/mteb/commit/1113e56a24af02a1c4c6612beaae3c1a07790246))

## v2.4.1 (2025-12-17)

### Fix

* fix: instruction selection for `InstructSentenceTransformerModel` (#3758)

* fix doc

* fix `get_instruction` ([`b0f677c`](https://github.com/embeddings-benchmark/mteb/commit/b0f677c07b38bafbe68488eb49cf672b89d2e0c8))

### Unknown

* fix prompt_dict to prompt_dicts (#3756) ([`e9e7cd2`](https://github.com/embeddings-benchmark/mteb/commit/e9e7cd2e02d48b1f9b4fa45596855a4e70a786cf))

* model: mod_models.py (#3749)

* Add new model: mod_models.py

* Update mteb/models/model_implementations/mod_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/mod_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/mod_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/mod_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Remove duplicate Instruct and Query prefixes from PREDEFINED_PROMPTS

The instruction_template function already adds &#34;Instruct:&#34; and &#34;Query:&#34;
prefixes automatically, so these should not be duplicated in the
PREDEFINED_PROMPTS dictionary values.

* make lint

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`ad4a8b6`](https://github.com/embeddings-benchmark/mteb/commit/ad4a8b6ea7b3045d18a42d4162743ee9589fdb9b))

## v2.4.0 (2025-12-15)

### Feature

* feat: Add `.from_hf_hub()` and similar methods to `ModelMeta` (#3737)

* refactor `ModelMeta`

* add compute_metadata

* add reference

* reference if repo exists

* fix error

* fix revision

* fix mock model

* compute revision in `ModelMeta`

* simplify calculations

* simplify calculations

* fix tests

* fetch max tokens and embedding_dim

* add `from_hub_for_sentence_transformer`

* add doc

* add tests

* fix autoconfig load

* fix tests

* upd docstring

* use sentence transformer by default

* fix tests

* fix typehint

* fix doc

* fix doc ([`28e733e`](https://github.com/embeddings-benchmark/mteb/commit/28e733e9fedf65704140ffea4d090ee8ce9db774))

### Unknown

* model: Add bisectgroup/BiCA-base  (#3742)

* Create bica_model.py

* Update mteb/models/model_implementations/bica_model.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update bica_model.py

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`2cc2ca9`](https://github.com/embeddings-benchmark/mteb/commit/2cc2ca93b1d38c99bc6c1514f31f5bf0c5351cf8))

* model: Added nomic-ai/nomic-embed-text-v2-moe (#3740)

* model: Added nomic-ai/nomic-embed-text-v2-moe

fixes https://github.com/embeddings-benchmark/mteb/issues/3731

* format

* Update mteb/models/model_implementations/nomic_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`15652aa`](https://github.com/embeddings-benchmark/mteb/commit/15652aa5dd4cf388ad49cbc2c6b16ebed23bd0e8))

* Added feature to fetch release_date in model_meta (#3717)

* Added feature to fetch release_date in model_meta

* Fix

* make lint

* Added functionality in get_model_meta file

* Added repository not found error catch

* make lint

* made fetch_release_date() static method

* fix syntax error

* fix arguments of static function ([`e2e993f`](https://github.com/embeddings-benchmark/mteb/commit/e2e993f589b32de905be2700a6c81f7fdd22109c))

* dataset: Add JMTEB-lite(v1) benchmark (#3738)

* Add JMTEB-lite(v1) benchmark

* Switch to mteb&#39;s repo

* Switch to mteb&#39;s repo

* update description ([`2b98edf`](https://github.com/embeddings-benchmark/mteb/commit/2b98edf2742c2d74c89bb45c64a5e76cf51da7e5))

* ModelMeta to python (#3732)

* meta to python

* update test ([`fc219f1`](https://github.com/embeddings-benchmark/mteb/commit/fc219f1a6ca1688eb86bb8906031421c1e377d9b))

* Add citation for `google/embeddinggemma-300m` (#3733)

add citation ([`12281c7`](https://github.com/embeddings-benchmark/mteb/commit/12281c7fb21fa1209756e0d05c0d68017b24a22f))

* Modify summary table column&#39;s type (#3714)

* fix - modify summary_table column&#39;s type

* fix - modify summary_table column&#39;s type

* fix - remove _get_column_types ([`debab52`](https://github.com/embeddings-benchmark/mteb/commit/debab524930377ab5493e1812ef173d50f701586))

* dataset: Add JMTEB-lite datasets (#3716)

* Add JMTEB-lite datasets

* fix typo

* Reformat and reupload datasets

* Reformat and reupload datasets

* Add desc stats

* add adapted_from for datasets ([`9fec5f8`](https://github.com/embeddings-benchmark/mteb/commit/9fec5f8a2e5037d40a753902e831b48e62ad6d4e))

* Fix citation for freshstack (#3726)

fix citation ([`4e20591`](https://github.com/embeddings-benchmark/mteb/commit/4e205914754ec174a780ffff5cf1e29f8b563ca1))

## v2.3.11 (2025-12-12)

### Fix

* fix: Make `PIL` optional (#3713)

* make pil optional

* make pil optional

* update pyproject deps

* fix deps

* fix deps

* Update pyproject.toml

* change to future

* change to future

* remove transformers version ([`80fef47`](https://github.com/embeddings-benchmark/mteb/commit/80fef471f0bdb883a7578ca95406689a7ff6f03c))

### Unknown

* Remove padding after pylate encoding (#3711) ([`15fd5f9`](https://github.com/embeddings-benchmark/mteb/commit/15fd5f97acc919a31db1d33c75aa385d1eeedbd3))

## v2.3.10 (2025-12-10)

### Fix

* fix: Add optional &#34;per language table&#34; (#3617)

* fix: external links in hf space

* try to fix model name

* feat: Add per-language table creation

* refactor: Simplify per-language table creation by removing unnecessary comments and print statements

* feat: Enhance per-language table functionality

* feat: Enhance per-language table functionality with support flag and styling improvements

* feat: redo

* feat: refacto language filtering support

* feat: update per-language table to support &#39;all&#39; option and improve styling for wide tables

* feat: simplify per-language table styling by rounding values for wide tables

* Update mteb/benchmarks/benchmarks/benchmarks.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* feat: enhance language view condition to include &#39;all&#39; option in per-language table

* fix

* refactor: update button display options in per-language table styling

* fix: check emptiness before further analysis

* fix: set column width for task and language tables

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`46612af`](https://github.com/embeddings-benchmark/mteb/commit/46612af421721a3c21029fe6793a207077d28477))

### Unknown

* add PawanEmbd-68M model metadata (#3703)

* add PawanEmbd-68M model metadata

* add adapted_from &amp; lint file ([`05e8b79`](https://github.com/embeddings-benchmark/mteb/commit/05e8b79dfd8881f691686b5015e3750112d15350))

## v2.3.9 (2025-12-08)

### Fix

* fix: Add baseline encoders (#3701)

Adds baseline model for MTEB(Scandinavian) (XLM-R models are also relevant elsewhere)

closes #3679
closes #3678
closes #3677 ([`fd395fd`](https://github.com/embeddings-benchmark/mteb/commit/fd395fd80e3192b6c3ef4771c6c9b05ae477b3a4))

## v2.3.8 (2025-12-08)

### Fix

* fix: Add hamming score to multilabel classification (#3700)

* test: add mixed performance case for hamming_score

* add hamming score to multilabel classification metrics

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4 &lt;noreply@anthropic.com&gt;

* move to eval folder

* remove try except

---------

Co-authored-by: Claude Sonnet 4 &lt;noreply@anthropic.com&gt; ([`bc2e24e`](https://github.com/embeddings-benchmark/mteb/commit/bc2e24e09376cd5a21954da3681ac49a5919ff06))

### Unknown

* dataset: Replace JMTEB(v2) with MTEB(jpn,v1) for general-purpose Japanese evaluation (#3699)

* Replace JMTEB(v2) with MTEB(jpn,v1) for general-purpose Japanese evaluation

* fix get_benchmark as Japanese benchmark updated

* Replace MTEB(jpn, v1) with JMTEB(v2)

* Revert &#34;Replace MTEB(jpn, v1) with JMTEB(v2)&#34;

This reverts commit b49f67b4409becbc81e65318b5f79ea195e40304.

* keep MTEB(jpn, v1) as legacy

* revert class name

* revert change ([`11a2e9e`](https://github.com/embeddings-benchmark/mteb/commit/11a2e9e1cf0bdc626a1658190ebece897d1a2650))

* dataset: RuSciBenchBitextMining small dataset cleanup (#3690)

* RuSciBenchBitextMining small dataset cleanup

* RuSciBenchBitextMining new version

* Add RuSciBenchBitextMining.v2 stats ([`cb4b3ed`](https://github.com/embeddings-benchmark/mteb/commit/cb4b3edca9595f6d20ff0da8e9bafff0d01fb63d))

* model: add NbAiLab/nb-bert-large and NbAiLab/nb-bert-base (#3688)

* Initial plan

* Add NbAiLab/nb-bert-large model to MTEB

Co-authored-by: KennethEnevoldsen &lt;23721977+KennethEnevoldsen@users.noreply.github.com&gt;

* Apply suggestions from code review

* add models

* fix naming and linting

---------

Co-authored-by: copilot-swe-agent[bot] &lt;198982749+Copilot@users.noreply.github.com&gt;
Co-authored-by: KennethEnevoldsen &lt;23721977+KennethEnevoldsen@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`97834cb`](https://github.com/embeddings-benchmark/mteb/commit/97834cbd0e150f7348edd7f96ba86ec0c76a2c33))

* Add dataset task filter (#3685)

* init task filter

* fix typehint

* split filters and pipelines

* change filters logging ([`3afd6f8`](https://github.com/embeddings-benchmark/mteb/commit/3afd6f8b3d37c7935b743d6cb2e0f8bbf99a73f3))

## v2.3.7 (2025-12-08)

### Fix

* fix: Don&#39;t pass embed dim to `openai/text-embedding-ada-002` (#3689)

It does not support embed dim.

closes #3687

tested imp. with the below code to ensure that it works with both old and new models

```py
import mteb

mdl = mteb.get_model(&#34;openai/text-embedding-ada-002&#34;)
task = mteb.get_task(&#34;STSBenchmark&#34;, eval_splits=[&#34;test&#34;])
mteb.evaluate(mdl, task, cache=None)
mdl = mteb.get_model(&#34;openai/text-embedding-3-small&#34;)
mteb.evaluate(mdl, task, cache=None)
```

Co-authored-by: Kenneth &lt;kennethenevoldsen@gmail.com&gt; ([`25af7b9`](https://github.com/embeddings-benchmark/mteb/commit/25af7b9221af9ba319019cb785c1bb60dd55832a))

## v2.3.6 (2025-12-08)

### Unknown

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`c04effb`](https://github.com/embeddings-benchmark/mteb/commit/c04effb2c8f3369b5f69c48d36b053d0f8384f16))

* Fix: fix Performance per Model Size display issues (#3691)

fix - filtering Mean(Task)=0 ([`86e9235`](https://github.com/embeddings-benchmark/mteb/commit/86e92357263ca991c4ad58168b23b3739f7809c9))

* model: Kowshik24/bangla-sentence-transformer-ft-matryoshka-paraphâ€¦ (#3661)

* Add Model: Kowshik24/bangla-sentence-transformer-ft-matryoshka-paraphrase-multilingual-mpnet-base-v2

* Updated the memory usage and public training code

* fix: correct public_training_code syntax and initialize training_datasets as an empty set

* fix: update import path for ModelMeta in kowshik24_models.py ([`a39c011`](https://github.com/embeddings-benchmark/mteb/commit/a39c0119f99c7bd6f6de62180f253b7d5fdf3223))

* model: add two Japanese models sarashina-embedding-{v1, v2}-1b (#3683)

* Add sarashina embedding models

* fix public training data info

* fix prompt setting for v2 model

* Use InstructionSentenceTransformerModel wrapper for instruction model

* Update mteb/models/model_implementations/sarashina_embedding_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`db74fc5`](https://github.com/embeddings-benchmark/mteb/commit/db74fc5ee2ea0b1ccfe3f666f4580b05b4fb260e))

## v2.3.5 (2025-12-07)

### Fix

* fix: Change git clone results depth to 1 (#3682)

change git clone depth ([`874ddf2`](https://github.com/embeddings-benchmark/mteb/commit/874ddf2efd23b90016e9ef2e8f1756194998d6a1))

* fix: Resolve search wrapper warning (#3681)

resolve search wrapper warning ([`46fb44c`](https://github.com/embeddings-benchmark/mteb/commit/46fb44cab716aed701f6df60c6051ae49cecca35))

### Unknown

* model: add ruri-series Japanese embedding models (#3684)

* Add ruri models

* fix typo and add trust_remote_code when necessary ([`5de8d98`](https://github.com/embeddings-benchmark/mteb/commit/5de8d98bb4b089097ac970c90067e07d366f8811))

* dataset: Add hebrew v3 (#3607)

* add hebrew v3

* add to init

* add v4

* v4 -&gt; v3 ([`3982f33`](https://github.com/embeddings-benchmark/mteb/commit/3982f33bca73d21920922ed698dbb5870f723d20))

* dataset: Add new benchmark JMTEB(v2) (#3660)

* Add benchmark: JMTEB(v2)

* fix bibtex format

* Fix bibtex format, description and contacts for JMTEB v2

* Fix bib of JMTEB

* Fix dataset version ([`d14923c`](https://github.com/embeddings-benchmark/mteb/commit/d14923c7c63408c17222196ae05b70a16ac89cb2))

## v2.3.4 (2025-12-05)

### Fix

* fix: `get_model` now correctly assumed `SentenceTransformer` (#3673)

fix: `get_model` now correctly assumed `SentenceTransformer` if
unkown

fixes #3670 ([`21cf638`](https://github.com/embeddings-benchmark/mteb/commit/21cf6382dee64661bb2aee0b3c85fa9cf7591821))

### Unknown

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`e3a0181`](https://github.com/embeddings-benchmark/mteb/commit/e3a01813cdd6615c272a742c2f4b966e933372ac))

## v2.3.3 (2025-12-05)

### Ci

* ci: remove unnecessary items on disk (#3664)

* remove unnecessary items on disk

* don&#39;t remove on windows ([`2c51e3a`](https://github.com/embeddings-benchmark/mteb/commit/2c51e3a6122878547e63b5df781c2936f57fc3ea))

* ci: Update broken links in pull request template (#3656) ([`095803c`](https://github.com/embeddings-benchmark/mteb/commit/095803c5c4951d36959d0411ad548a84c2a367b0))

### Documentation

* docs: Add direct image links to the readme (#3667)

Updated image sources in README to use raw links. This ensures that the readme has images in pypi ([`8e2929d`](https://github.com/embeddings-benchmark/mteb/commit/8e2929d4194d7dd7d496618bea22da54f50099eb))

* docs: Minor grammar fixes (#3657) ([`663bb87`](https://github.com/embeddings-benchmark/mteb/commit/663bb87080215672ca88572cf962fdd959b69dfa))

### Fix

* fix: remove docker system prune command (#3671)

Removed unnecessary docker system prune command from the workflow.

Close https://github.com/embeddings-benchmark/mteb/issues/3669 ([`6d92cbc`](https://github.com/embeddings-benchmark/mteb/commit/6d92cbced52bbacffb707642b16895825d805266))

* fix: Reduce the number of decimals for the number of parameters (#3668) ([`397e0dd`](https://github.com/embeddings-benchmark/mteb/commit/397e0dd9b96dd382a8322c91c07baad65a3d0617))

* fix: cohere import error (#3665)

fix cohere ([`745ad84`](https://github.com/embeddings-benchmark/mteb/commit/745ad84755827737d0a804a3498d04ad1a95d431))

* fix: `get_model` now correctly assumed `SentenceTransformer` if
unkown

fixes #3670 ([`968e498`](https://github.com/embeddings-benchmark/mteb/commit/968e498b0d7ea4f96659757255d1eea7e477055c))

* fix: Remove &#34;Unknown&#34; for int on leaderboard causing them to be unsortable (#3653)

* fix: Remove &#34;Unknown&#34; for int on leaderboard causing them to be unsortable

Fixes #3579

* fix: Linq-Embed-Mistral loader does not take `instruction_template` as a kwargs (#3654)

I assume it is intended to use `instruct_wrapper`

* fix some formatting

* fixed

* update

* removed incorrect text

* fix: GoogleTextEmbeddingModel were given multiple `model_name` (#3658)

* fix: GoogleTextEmbeddingModel were given multiple `model_name`

* fix based on comments

* model: Added dfm-sentence-encoder models (#3655)

* fix: Linq-Embed-Mistral loader does not take `instruction_template` as a kwargs

I assume it is intended to use `instruct_wrapper`

* model: Added dfm-sentence-encoder models ([`94979ca`](https://github.com/embeddings-benchmark/mteb/commit/94979ca42284547c26426069279cceb191ec766a))

### Unknown

* Model: add e5-nl models (#3646)

* e5-nl models

* e5-nl moved to a new file ([`f3e5763`](https://github.com/embeddings-benchmark/mteb/commit/f3e5763d52488d274c6e43fa682d1f2a1231de18))

## v2.3.2 (2025-12-03)

### Fix

* fix: fix display for task information and improve UI for benchmark filtering (#3629)

* fix: bump gradio to v6

fixes #3601

* more fixes

* refactor themes (might need some more refactors)

* feat - issue #3569

* feat - issue #3569

* feat - issue #3569

* feat - issue #3616

* feat - CheckboxGroup

* feat - ruff check

* bump gradio

* fix - task options bug

* fix - fix task filter condition

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`a882295`](https://github.com/embeddings-benchmark/mteb/commit/a8822953bd6ccc95e27395e873cb8a63b35e04e5))

### Unknown

* dataset: ruMTEB v1.1 (#3631)

* ruMTEB_v1

* ruMTEB_v1

* ruMTEB_v1

* ruMTEB_v1

* ruMTEB_v1.1 description and contacts

* Update benchmarks.py

edited  MTEB(rus, v1) display name ([`c228707`](https://github.com/embeddings-benchmark/mteb/commit/c228707f87bfb878307532913835a02d41092781))

## v2.3.1 (2025-12-03)

### Fix

* fix: `colpali_training_set` &amp; updated `JinaVDR` and `ViDoRe` tasks annotation (#3636)

* add adapted annotation

* fix training set annotation

* update nemotriever datasets ([`1ce74c2`](https://github.com/embeddings-benchmark/mteb/commit/1ce74c22b89d1b48941258611862fb98d289c096))

* fix: add flag to run public only tasks (#3563)

* run public only tasks

* pass to evaluate

* add tests

* update cli

* add task error

* fix metadata name

* fix tests

* Update mteb/evaluate.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* remove from cli

* add tests

* fix exception

* fix renaming

* raise error if `public_only` False

* rollback co2

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* remove test

* fix test

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`f905b68`](https://github.com/embeddings-benchmark/mteb/commit/f905b68a79765ddb3ba2ce09895171a684ce7584))

### Unknown

* model: Add IEITYuan/Yuan-embedding-2.0-en model (#3630)

* add

* Update mteb/models/model_implementations/yuan_models_en.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/yuan_models_en.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/yuan_models_en.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/models/model_implementations/yuan_models_en.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Apply suggestions from code review

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`d31f1cd`](https://github.com/embeddings-benchmark/mteb/commit/d31f1cda1000e9af4cd95f30a71d45df81683ac7))

* model: Add tomoro-colqwen3-embed embedding models (#3627)

* feat(colqwen3): add wrapper and model metadata

* feat(colqwen3): update ColQwen3Wrapper to use bfloat16 and enhance similarity scoring

- Changed default dtype from float16 to bfloat16 for improved performance.
- Added max_num_visual_tokens parameter to AutoProcessor initialization.
- Refined embedding extraction logic to avoid boolean casting issues.
- Introduced support for score_multi_vector in similarity computation.
- Added new model metadata for colqwen3_4b with relevant attributes.

* fix(colqwen): require transformers&gt;=4.57 and refresh metadata, set revision

* refactor(colqwen): reorder wrappers and metadata definitions for clarity

* chore(colqwen): set release date for tomoro colqwen3 8b

* chore(colqwen): remove unused methods and fix lint errors

* feat(colqwen3): add fused image-text encoding path

* refactor(colqwen): unify encode method with get_fused_embeddings

* chore(colqwen): update encoding progress message

* chore(colqwen): update model revisions for colqwen models

* docs(colqwen): update train data annotation

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: tankm &lt;kyemin.tan@tomoro.ai&gt;
Co-authored-by: Huang Xin &lt;hxssg1124@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`71ac96c`](https://github.com/embeddings-benchmark/mteb/commit/71ac96ccef0ebdee06e71e621e55eb0845370bdc))

* model: euler legal embedding (#3640)

* add model implementation

* modify the correct model path

* Update mteb/models/model_implementations/euler_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/euler_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/euler_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/euler_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* lint

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`a1fbdb9`](https://github.com/embeddings-benchmark/mteb/commit/a1fbdb9f8529330c489be06d36da5ea2b013a4e4))

* model: jina-reranker-v3 (#3645)

* add: jina-reranker-v3

* Update mteb/models/model_implementations/jina_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: remove useless check

* fix: use only one class which inherits from CrossEncoderWrapper

* Update mteb/models/model_implementations/jina_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: remove unused import

* Update mteb/models/model_implementations/jina_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: ruff format

* add: cross_encoder label

* add: datasets

* Update mteb/models/model_implementations/jina_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`1ecd892`](https://github.com/embeddings-benchmark/mteb/commit/1ecd8921cb22035ab1e578ad8fa9f626837ea8b0))

* dataset: MultiLongDocReranking (#3642)

* Add MultiLongDocReranking dataset

* Add descriptive stats for MultiLongDocReranking

* Fix information

* reformat

* fix hash

* Update multi_long_doc_reranking.py

* lint

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`4f7774d`](https://github.com/embeddings-benchmark/mteb/commit/4f7774de68b850f8fae43d9af9ad7e650825df40))

## v2.3.0 (2025-11-28)

### Ci

* ci: Add HF_TOKEN to dataset loading and merge CI (#3622) ([`4ffef40`](https://github.com/embeddings-benchmark/mteb/commit/4ffef408b0990c9cf4ee7ed7ba74175e21426b08))

* ci: update action versions (#3623)

update action versions ([`bcf4e82`](https://github.com/embeddings-benchmark/mteb/commit/bcf4e82fed2eca1972d96850717600350b25fc04))

### Documentation

* docs: Update &#34;speeding up&#34;-section to include bumping version (#3634)

* Update &#34;speeding up&#34;-section to include bumping version 

Also corrected grammar and punctuation for clarity.

* Update docs/usage/running_the_evaluation.md

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`392186f`](https://github.com/embeddings-benchmark/mteb/commit/392186f574af609702897860a6fb6c0159dba7db))

### Feature

* feat: add search encoder backend (#3492)

* add search backend

* make faiss optional

* fix import

* use faiss in reranking

* add support for multiple similarities

* remove check

* update index check

* rename and move files

* add missing files

* fix import

* rename to add documents

* make index backend optional

* remove streaming backend

* fix test

* add doc

* add memory

* add API to docs ([`4ed7ef4`](https://github.com/embeddings-benchmark/mteb/commit/4ed7ef49ab0c36c79dcf8c658a47b0dac4595839))

### Fix

* fix: Updated metadata on model memory (#3624)

fix model memory ([`73168c6`](https://github.com/embeddings-benchmark/mteb/commit/73168c621ee859dbe23c40e12ddd6928d2f340f9))

### Unknown

* model: Add eager-embed embedding model (#3602)

* Add eagerembed model

* Address CR comments to make code cleaner

* Refactor code to remove unnecessary dataloader. Use prompt_type

* Update model revision. Move tokenizer config to file

* Add support for unified encoding

* Fix vidore2 retrieval language filter

* Remove unused methods. Fix vidore2 filtering

* Remove deprecated torch_dtype ([`7e2fa98`](https://github.com/embeddings-benchmark/mteb/commit/7e2fa988df697a86919cc96268ec1f2fcfb261bd))

## v2.2.2 (2025-11-25)

### Fix

* fix: vidore loading (#3618)

fix vidore loading ([`ca8e7c4`](https://github.com/embeddings-benchmark/mteb/commit/ca8e7c47110d5466604fb99e068ad7dc31288b49))

## v2.2.1 (2025-11-25)

### Fix

* fix: Avoiding stating warning if what is logged is not a warning (#3619)

Stating warning here might lead devs to think it should be considered a warning. It is just a info message.

Also changes to that &#34;...&#34; appears at the end ([`b0d6c7b`](https://github.com/embeddings-benchmark/mteb/commit/b0d6c7b5e840beb8bd0b3923cc0e56cf87b26248))

## v2.2.0 (2025-11-25)

### Feature

* feat: make STS and PairClassification asymmetric (#3568)

* make STS and PairClassification asymmetric

* update logging

* make terra v2

* fix

* fix tests ([`5010468`](https://github.com/embeddings-benchmark/mteb/commit/5010468f3c72ccd45b02d959eb9941ff9aa543c5))

## v2.1.19 (2025-11-25)

### Fix

* fix: Cache language filtering (#3612)

* fix cache filtering

* add test ([`f75bfc4`](https://github.com/embeddings-benchmark/mteb/commit/f75bfc46dab6445acfd405a6b95837a2d9e63b45))

### Unknown

* model: Add IEITYuan/Yuan-embedding-2.0-zh model (#3613)

* Add model Yuan-embedding-2.0 to MTEB

* add memory_usage_mb

---------

Co-authored-by: Jason Wang (çŽ‹æ–°æ™¯)-æµªæ½®ä¿¡æ¯ &lt;wangxinjing01@inspur.com&gt; ([`cfcedfc`](https://github.com/embeddings-benchmark/mteb/commit/cfcedfccca7217d22ddc678719b81a2cd092ceb6))

## v2.1.18 (2025-11-24)

### Fix

* fix: Correcting the cohere lstrip bug in `cohere` (#3610)

* Correcting the cohere lstrip bug

* Update mteb/models/model_implementations/cohere_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`398b31b`](https://github.com/embeddings-benchmark/mteb/commit/398b31b4c09fe2f328588a08f760af559be12812))

### Unknown

* add note for BUCC tasks about using train split (#3609)

add note for BUCC tasks about using train split; ([`3af54eb`](https://github.com/embeddings-benchmark/mteb/commit/3af54ebe80980947e68553c0c0a0cca266a91dc8))

* add missing citation for Vietnamese retrieval datasets (#3608)

* add missing citation

* Update mteb/tasks/retrieval/vie/green_node_table_markdown_retrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* remove editors for now

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`027bc17`](https://github.com/embeddings-benchmark/mteb/commit/027bc1719f6a294930435bfb5c299a3c42bede79))

* tests: Add tests for dataset quality (#3603)

* tests: Add test to prevent low-quality tasks

This tests ensures a minimum quality of task for future submissions

Currently it tests for:
- text duplicates
- train test leakage
- too short documents

I suspect we can likely add many more tests to this in future PRs

* collect all errors before raising

* Update tests/test_tasks/test_task_quality.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`9b898ea`](https://github.com/embeddings-benchmark/mteb/commit/9b898ea0724b5cebbe951c6bec4bd474a8f006f4))

* model: Add model2vecdk models (#3600)

* model: Add model2vecdk models

* Apply suggestions from code review ([`300418d`](https://github.com/embeddings-benchmark/mteb/commit/300418dbc675fc566907e996e746c82615648d74))

* model: Remove `flash_attn` for Tarka (#3599) ([`7f4bcbb`](https://github.com/embeddings-benchmark/mteb/commit/7f4bcbb2516b6ffa149c0cb4e3b55038010b4f98))

## v2.1.17 (2025-11-20)

### Fix

* fix: improve messages for running missing splits (#3596)

It now looks like:
```
INFO:mteb.evaluate:Found existing results for MassiveIntentClassification, only running missing splits (subset): {&#39;validation&#39;: [&#39;hy&#39;, &#39;jv&#39;, &#39;fr&#39;, &#39;hu&#39;, &#39;tl&#39;, &#39;az&#39;, &#39;zh-CN&#39;, &#39;ms&#39;, &#39;ar&#39;, &#39;pt&#39;, &#39;ja&#39;, &#39;tr&#39;, &#39;hi&#39;, &#39;lv&#39;, &#39;sw&#39;, &#39;nl&#39;, &#39;en&#39;, &#39;ko&#39;, &#39;mn&#39;, &#39;zh-TW&#39;, &#39;kn&#39;, &#39;am&#39;, &#39;he&#39;, &#39;my&#39;, &#39;sq&#39;, &#39;vi&#39;, &#39;fi&#39;, &#39;ru&#39;, &#39;cy&#39;, &#39;it&#39;, &#39;pl&#39;, &#39;el&#39;, &#39;de&#39;, &#39;te&#39;, &#39;af&#39;, &#39;ro&#39;, &#39;sl&#39;, &#39;fa&#39;, &#39;ur&#39;, &#39;ml&#39;, &#39;is&#39;, &#39;bn&#39;, &#39;es&#39;, &#39;km&#39;, &#39;ka&#39;, &#39;th&#39;, &#39;ta&#39;, &#39;id&#39;], &#39;test&#39;: [&#39;hy&#39;, &#39;jv&#39;, &#39;fr&#39;, &#39;hu&#39;, &#39;tl&#39;, &#39;az&#39;, &#39;zh-CN&#39;, &#39;ms&#39;, &#39;ar&#39;, &#39;pt&#39;, &#39;ja&#39;, &#39;tr&#39;, &#39;hi&#39;, &#39;lv&#39;, &#39;sw&#39;, &#39;nl&#39;, &#39;en&#39;, &#39;ko&#39;, &#39;mn&#39;, &#39;zh-TW&#39;, &#39;kn&#39;, &#39;am&#39;, &#39;he&#39;, &#39;my&#39;, &#39;sq&#39;, &#39;vi&#39;, &#39;fi&#39;, &#39;ru&#39;, &#39;cy&#39;, &#39;it&#39;, &#39;pl&#39;, &#39;el&#39;, &#39;de&#39;, &#39;te&#39;, &#39;af&#39;, &#39;ro&#39;, &#39;sl&#39;, &#39;fa&#39;, &#39;ur&#39;, &#39;ml&#39;, &#39;is&#39;, &#39;bn&#39;, &#39;es&#39;, &#39;km&#39;, &#39;ka&#39;, &#39;th&#39;, &#39;ta&#39;, &#39;id&#39;]}
``` ([`5d7b78b`](https://github.com/embeddings-benchmark/mteb/commit/5d7b78bd84437f14f01149d86e362b1016d4e88f))

## v2.1.16 (2025-11-20)

### Fix

* fix: issues on cache hits (#3558)

* fix: issues on cache hits

Found a couple of issue where the cache is not hit

- the condition `overwrite_strategy == &#34;only-missing&#34;
        and overwrite_strategy == OverwriteStrategy.ONLY_MISSING` would never be met as it is never both (so we always rerun all splits)
- Currently the remote cache path is not specified correctly (`remote` vs `remote/results`), which means that it is never hit.
- Added a check if a merge is required. E.g. it is often the case that you don&#39;t need to merge the new results (because the results include all the splits), however we still rerun them if the version does not match
-  Added better error messages to merge messages

* add test

* format

* fix: Overwrite / ignore existing results if not mergeable

* add fest from review

* fix match

---------

Co-authored-by: Kenneth &lt;kennethenevoldsen@gmail.com&gt; ([`9d7d4df`](https://github.com/embeddings-benchmark/mteb/commit/9d7d4dfbf128e754d12efc5cc71639766696e49c))

* fix: Bump gradio version to fix links on leaderboard (#3591)

update gradio ([`09021df`](https://github.com/embeddings-benchmark/mteb/commit/09021df642d3f526801dda26b95cff1741f304ef))

* fix: typo for attn_implementation kwargs in jasper models (#3592)

* add prompt dict for Jasper_Token_Compression_600M

* use sdpa for Jasper_Token_Compression_600M

* remove JasperTokenCompressionLoader

* fix typo for attn_implementation ([`0d33bd3`](https://github.com/embeddings-benchmark/mteb/commit/0d33bd38b06cc4d689426cd2cbd72280941dbb9a))

### Unknown

* add prompt dict for Jasper_Token_Compression_600M (#3587)

* add prompt dict for Jasper_Token_Compression_600M

* use sdpa for Jasper_Token_Compression_600M

* remove JasperTokenCompressionLoader ([`5bca292`](https://github.com/embeddings-benchmark/mteb/commit/5bca292ab3485f02f6b8d5f0408de1ac131d374d))

* tests: Added test for ensuring training datasets can be computed  (#3566)

* fix: Fix adapted from points to the models itself

We should probably add a test to prevent this in the future.

* Added test

* Update tests/test_models/test_model_meta.py ([`4636b24`](https://github.com/embeddings-benchmark/mteb/commit/4636b24c5450b0179589094429658e9d9dc386ac))

## v2.1.15 (2025-11-19)

### Fix

* fix: utilize `max_seq_length` (#3588)

utilize `max_seq_length` ([`f7b481e`](https://github.com/embeddings-benchmark/mteb/commit/f7b481e4e3c51cbb445c171ff4718b0a409afe1c))

### Unknown

* add training code and citation for Jasper_Token_Compression_600M (#3584) ([`76be959`](https://github.com/embeddings-benchmark/mteb/commit/76be9594308a4427fef461d30b499268fb14532a))

* model: Add spartan8806/atles-champion-embedding model (#3575)

* Add ATLES Champion Embedding model wrapper

* Move ATLES Champion embedding wrapper into mteb/models and export it

* Update spartan8806_atles_champion.py with current date and time

* Update the file __init__.py with new content

* Update spartan8806_atles_champion.py with the latest content

* fix: Use sentence_transformers_loader per MTEB guide

* fix: Move model to model_implementations and clean up per @Samoed feedback

* fix: Remove old files and revert __init__.py per @Samoed feedback

* fix: Remove old model file from wrong location

* fix: Remove stray root file

* fix: Restore proper line breaks in model file

* fix(lint): correct module docstring in model file

* feat: Add training dataset info to ModelMeta

* fix: Update revision to commit hash and add training datasets

* fix: Restore file with proper newlines (encoding fix)

* fix: Update training_datasets format per @Samoed feedback

* Update mteb/models/__init__.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/spartan8806_atles_champion.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/spartan8806_atles_champion.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/model_implementations/spartan8806_atles_champion.py

* fix: Add required metadata fields (memory_usage_mb, open_weights, public_training_code, public_training_data)

* fix: Correct release_date to November (2025-11-16)

* fix: Update release_date to 2025-11-15 (actual training date)

* fix: Add adapted_from and convert public_training_code/data to URLs

* Update mteb/models/model_implementations/spartan8806_atles_champion.py

---------

Co-authored-by: spartan8806 &lt;spartan8806@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`723fd98`](https://github.com/embeddings-benchmark/mteb/commit/723fd9808be2dce238f1ddef2af7b5d28adbcd3a))

## v2.1.14 (2025-11-16)

### Fix

* fix: benchmark references links (#3560)

* fix: external links in hf space

* try to fix model name

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`07f1e6e`](https://github.com/embeddings-benchmark/mteb/commit/07f1e6e67c52668558f29a3e3bb7e9583e8e280d))

## v2.1.13 (2025-11-15)

### Fix

* fix: Set default input_type for VoyageMultiModalModelWrapper (#3567)

* fix: Set default input_type for VoyageMultiModalModelWrapper

* Apply suggestions from code review

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`711e7cb`](https://github.com/embeddings-benchmark/mteb/commit/711e7cbfdd5625ddb70f5bc8a773b7fa8c740ef6))

## v2.1.12 (2025-11-15)

### Fix

* fix: Fix adapted from points to the models itself (#3565)

We should probably add a test to prevent this in the future. ([`08b8ec7`](https://github.com/embeddings-benchmark/mteb/commit/08b8ec7426a0dc442b923b626c65d2f941e82dbb))

## v2.1.11 (2025-11-14)

### Fix

* fix: MTEB-NL switches to v2 datasets with new prompts (#3555)

MTEB-NL swithes to v2 datasets with new prompts ([`26e36cd`](https://github.com/embeddings-benchmark/mteb/commit/26e36cda9d4c7c44d069d7c89a9e27b6fa62ec6e))

* fix: add jasper token compression model (#3557)

* add jasper token compression model

* add distillation dataset ([`64459d1`](https://github.com/embeddings-benchmark/mteb/commit/64459d127fd259d2a88254946204e8586ae809ab))

## v2.1.10 (2025-11-13)

### Fix

* fix: resolve hash randomization in retrieval task ID generation (#3553)

This commit fixes non-deterministic query ID assignment in three retrieval
tasks caused by Python hash randomization when using enumerate(set()).

Affected tasks:
- PublicHealthQARetrieval (8 languages including Korean)
- BelebeleRetrieval (122 language variants including Korean)
- GeorgianFAQRetrieval (Georgian) ([`0c4f099`](https://github.com/embeddings-benchmark/mteb/commit/0c4f099b2252e4cfa394d841a6c5207e20dfbd2e))

## v2.1.9 (2025-11-13)

### Fix

* fix: Added leaderboard Vidore V3 (#3542)

* feat:initial leaderboard proposal

* feat: update summary table for ViDoRe V3 to reflect Document Understanding tasks

* refactor: update leaderboard references

* fix: update VISUAL_DOCUMENT_RETRIEVAL to use VidoreBenchmark

* fix: update JinaVisualDocumentBenchmark summary table creation method

* fix: add VisualDocumentRetrieval to previous benchmark names

* fix: remove JinaVisualDocumentBenchmark

---------

Co-authored-by: Antoine Edy &lt;antoine.edy@illuin.tech&gt; ([`ab390ce`](https://github.com/embeddings-benchmark/mteb/commit/ab390cec5f05a5baf720b25b25b562057e6eccf8))

### Unknown

* model: Added emillykkes scandi models (#3521)

* model: Added EmbeddingGemma-Scandi-300m

```
from sentence_transformers import SentenceTransformer

# test that is loads with sentence transformers
model = SentenceTransformer(&#34;emillykkejensen/EmbeddingGemma-Scandi-300m&#34;)
# OSError: Can&#39;t load the model for &#39;emillykkejensen/EmbeddingGemma-Scandi-300m&#39;. If you were trying to load it from &#39;https://huggingface.co/models&#39;, make sure you don&#39;t have a local directory with the same name. Otherwise, make sure &#39;emillykkejensen/EmbeddingGemma-Scandi-300m&#39; is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.
```

Can&#39;t get the model to load

* added other models

* fix remaining metada issue ([`1ad433f`](https://github.com/embeddings-benchmark/mteb/commit/1ad433f9fa4376d7799af99f67bab10b9ce01ded))

## v2.1.8 (2025-11-13)

### Ci

* ci: fix false positive check in typos (#3540) ([`b2b9599`](https://github.com/embeddings-benchmark/mteb/commit/b2b959936afa2a658fcf4797f17715535a1d28ac))

### Documentation

* docs: Convert all descriptions to singe line (#3544)

make single line descriptions ([`fe83e27`](https://github.com/embeddings-benchmark/mteb/commit/fe83e27968adff648de9520e187164ea5f906935))

### Fix

* fix: Pass encode kwargs in all dataloaders (#3548)

* pass all encode kwargs in dataloaders

* fix tests

* fix tests ([`eaec6cb`](https://github.com/embeddings-benchmark/mteb/commit/eaec6cb0571783416c76a3475f6e21bc02869ea5))

### Unknown

* Model : Tarka Embedding 350M V1 (#3549)

* Add : Tarka Embedding 350M V1

* removing custom wrapper

* removing device map and minor changes

* minor fix ([`27c10e9`](https://github.com/embeddings-benchmark/mteb/commit/27c10e9024a5ebba1f4124dc398079f2479a76d3))

* Add concurrency to tests (#3543)

add concurrency to tests ([`57e179d`](https://github.com/embeddings-benchmark/mteb/commit/57e179d6390c267d0b5c9ab399e7538204723080))

* dataset: Benchmark/VidoreV3 (#3514)

* vidore_3_tasks

* update init

* add benchmark

* fix oopsies + linting

* add private tasks + apply some reco

* update private datasets path

* refactor: update Vidore3 retrieval classes and paths for improved organization

* update descriptions for public datasets

* fix loading error

* sort imports with updated names

* update: Vidore3 retrieval references and citations

* use batched image processing

* don&#39;t process if

* fix: update dataset revisions for Vidore3 retrieval classes + remove custom load_data methods

* add private datasets

* fix private test

* feat: added descriptive statistics for public ViDoRe V3 datasets

* format benhcmark citation

* feat: enhance ViDoRe V3 benchmark with detailed description and update task domains

* Update mteb/benchmarks/benchmarks/benchmarks.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* feat: better leaderboard

* fix:update description and sample creation

* Update mteb/leaderboard/benchmark_selector.py

---------

Co-authored-by: Antoine Edy &lt;antoine.edy@illuin.tech&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: antoineedy &lt;antoineedy@outlook.fr&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`1a02edb`](https://github.com/embeddings-benchmark/mteb/commit/1a02edbb7d50ec9f02c258267de299a731ea10ed))

* add citation to models (#3539) ([`d98a008`](https://github.com/embeddings-benchmark/mteb/commit/d98a008c1f1117e436802d673af543c0aad9d71b))

## v2.1.7 (2025-11-07)

### Fix

* fix: MTEB-NL prompts (#3516)

* adding prompts to MTEB-NL

* prompts for vabb_clustering fixed

* arguana-nl fixed

* update retrieval/nld/__init__

* descriptive stats for v2

* prompts in Dutch for MTEB-NL

* descriptions added to the Dutch prompts for MTEB-NL

* Update mteb/tasks/retrieval/nld/argu_ana_nl_retrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`8f3f806`](https://github.com/embeddings-benchmark/mteb/commit/8f3f8067734257ff082fb5ba4596dfc3fbc8fe6f))

## v2.1.6 (2025-11-06)

### Fix

* fix: Add support for python 3.14 (#3450) ([`632a83a`](https://github.com/embeddings-benchmark/mteb/commit/632a83a50dd6bb98b1e73035565230031d716937))

### Unknown

* model: add kalm_models.py ModelMeta (#3519)

* model: add kalm_models.py ModelMeta

* fix: model revision

* fix: recover ESCIReranking for train data

* fix: recover the original auto-generated kalm_training_data

* fix: restore docs logo files

---------

Co-authored-by: xinshuohu &lt;xinshuohu@tencent.com&gt; ([`28f9c54`](https://github.com/embeddings-benchmark/mteb/commit/28f9c54fdf046e80c17158698ee0fae6d4c885de))

* model: add EvoQwen2.5-VL-Retriever model (#3526)

model: add EvoQwen2.5-VL-Retriever ([`18ff6f3`](https://github.com/embeddings-benchmark/mteb/commit/18ff6f33940f9db06dfe2e272f1cb1fa9383c295))

* fix : Tarka V1 Model revision fix (#3525) ([`ba5bcb2`](https://github.com/embeddings-benchmark/mteb/commit/ba5bcb2141be1bb7965b1ca1f62658416ab1c829))

* model: Add `rasgaard/m2v-dfm-large` (#3523) ([`a7fb4a9`](https://github.com/embeddings-benchmark/mteb/commit/a7fb4a92d7fcf653bfaa7cd8b1cd1ed465a88b3a))

## v2.1.5 (2025-11-04)

### Fix

* fix: materialize corpus id to speed up evaluation (#3518)

materialize corpus id to speed up evaluation ([`08f76a6`](https://github.com/embeddings-benchmark/mteb/commit/08f76a6c183d231ed5a9ce903ae8a894a0373479))

### Unknown

* model: Tarka-Embedding-150M-V1 (#3520)

* adding tarka model

* addressing the comments ([`d5a8cbe`](https://github.com/embeddings-benchmark/mteb/commit/d5a8cbe7594388df4c922576ab4dcc7e2fa009d4))

## v2.1.4 (2025-10-30)

### Fix

* fix: reupload winogrande (#3513)

reupload winogrande ([`fe43f73`](https://github.com/embeddings-benchmark/mteb/commit/fe43f735f2ac51532a3e9a63a0ec132159171ca8))

### Unknown

* Correcting the VoyageAI model URLs and handling empty strings (#3511)

Correcting the VoyageAI model URLs
Handling the empty strings in requests ([`b45d37b`](https://github.com/embeddings-benchmark/mteb/commit/b45d37b6e7317a7d5764c3663e35bcbfccc61700))

## v2.1.3 (2025-10-29)

### Fix

* fix: aggregated task evaluation (#3510)

fix aggregated task evaluation ([`5eae04c`](https://github.com/embeddings-benchmark/mteb/commit/5eae04ce0746ea87b77f96ffd9cadcffceca1150))

## v2.1.2 (2025-10-29)

### Fix

* fix: remove `set_float32_matmul_precision` (#3509)

remove `set_float32_matmul_precision` ([`ce07dfd`](https://github.com/embeddings-benchmark/mteb/commit/ce07dfdb6c7c7425f12c1a074d672049c9a4da64))

### Unknown

* fix ReasonIR instruction (#3506) ([`8189108`](https://github.com/embeddings-benchmark/mteb/commit/8189108e49bf2dd8e7b0121f72106e7333fcbe6f))

* Update links in leaderboard description (#3503)

* Update links in leaderboard description

Resolve 404&#39;s for leaderboard contribution docs

* Update links in leaderboard description

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`976fadf`](https://github.com/embeddings-benchmark/mteb/commit/976fadf72919c463358f16e523998e8dd7689e5e))

* dataset: Add MTEB-NL to the leaderboard  (#3489)

* adding WebFAQRetrieval to  MTEB-NL

* adding  MTEB-NL to the leaderboard

* MTEB-NL renamed to Dutch in the leaderboard ([`da9feef`](https://github.com/embeddings-benchmark/mteb/commit/da9feef0188fa36d60fa958ad3c92e28e4575ed4))

## v2.1.1 (2025-10-27)

### Ci

* ci: New release workflow (#3448)

* add sematic release

* add main release

* fix: update action

* merge semantic with release

* run release after tests passed

* add benchmark to minor releases ([`b649e6f`](https://github.com/embeddings-benchmark/mteb/commit/b649e6f7207fcd8955b255af93e5e22ce20c65a3))

### Documentation

* docs: Update links in readme (#3484)

Update links in readme ([`b0b0e7d`](https://github.com/embeddings-benchmark/mteb/commit/b0b0e7d2744886e8ded4b3ca58e183c78995e133))

* docs: fix broken links (#3483)

* docs: fix broken links

* Update docs/usage/defining_the_model.md

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`dfd516a`](https://github.com/embeddings-benchmark/mteb/commit/dfd516aa33abfaca37b72b2c55eb29fbdc550242))

### Fix

* fix: Rollback to semantic release (#3502)

* rollback to semantic release

* update pyproject.toml ([`1325328`](https://github.com/embeddings-benchmark/mteb/commit/13253287ec7b2ea472afcb665bcabe0a10205f2a))

* fix: simplify release (#3494)

* fix release CI

* skip if None

* simplify workflow

* remove ifs

* make action condition as `and` instead `or` ([`4484112`](https://github.com/embeddings-benchmark/mteb/commit/4484112ceaade5326e4844926f8b5fa6e8cdd197))

* fix: add prompts to hardnegative tasks (#3469)

* add prompts to hardnegative tasks

* fix superseded_by

* add stats

* add more description ([`7b7bdd0`](https://github.com/embeddings-benchmark/mteb/commit/7b7bdd021dac853623dadc50136512ef85a16db8))

* fix: verify languages during filtering (#3472)

* verify lang code

* add support for language script code

* fix

* add check for language names

* update language check

* remove problematic tasks ([`799b869`](https://github.com/embeddings-benchmark/mteb/commit/799b869747c9dd45c37e6f9c0836d366336e3e84))

* fix: release CI (#3493)

* fix release CI

* skip if None ([`21223ed`](https://github.com/embeddings-benchmark/mteb/commit/21223edd870601105567a64803e9728af080ba03))

* fix: `top_k` document selection in two stage reranking (#3486)

* fix topk

* update test for correct top_k selection ([`16ae6ff`](https://github.com/embeddings-benchmark/mteb/commit/16ae6ff9cdc44cb1e2ce9dfa73155ec50cf77dd3))

* fix: task metadata was not passed in Jina implementation (#3485)

* Update jina_models.py

Add missing keyword argument

* Add prompt_type to embedding functions

Add missing keyword arguments ([`ea1bac1`](https://github.com/embeddings-benchmark/mteb/commit/ea1bac1a650e4f254537b87c2193217b93dd53eb))

* fix: qrels selection negative scores (#3479)

fix: qrels selection ([`31c8329`](https://github.com/embeddings-benchmark/mteb/commit/31c8329817e2c1f6e52a90166738d53c683d7ca5))

### Unknown

* Add spell checker (#3476)

* add spell checker

* remove arg ([`9e683fe`](https://github.com/embeddings-benchmark/mteb/commit/9e683feb0c3fb62e526c080a8e54ff6f9f3579e2))

* Correcting the VoyageAI multimodal code (#3491) ([`cf81dd1`](https://github.com/embeddings-benchmark/mteb/commit/cf81dd12b954cccbe7bc89609cd2199f98e647b7))

* Remove skip for tasks (#3475) ([`fcd3b71`](https://github.com/embeddings-benchmark/mteb/commit/fcd3b71a09bef1d141686ecf74e46fc285ae6509))

* Descriptive stats, MIRACLVisionRetrieval (#3473) ([`5b92f73`](https://github.com/embeddings-benchmark/mteb/commit/5b92f73c5fc975a26ac1284e42a537dc6c36711e))

* Update text_segments.py (#3474) ([`181490f`](https://github.com/embeddings-benchmark/mteb/commit/181490fdc6ad41e97dc696d2c51d09a60f713413))

* Almost final descriptive stats (#3463)

* fix tasks

* final statistics

* remove persiantexttone, was renamed to SynPerTextToneClassification

* remove duplicated tasks statistics

* fix category

* run test on all tasks

* remove `image/text: None`

* try to fix none in batch

* add vdr statistics ([`0ead029`](https://github.com/embeddings-benchmark/mteb/commit/0ead029894571fb40132084eee9ac7bf710ce358))

* fix miracl loading (#3466) ([`179702e`](https://github.com/embeddings-benchmark/mteb/commit/179702edb1df70fb3e0c068812ac84a4f47a1b9d))

## v2.1.0 (2025-10-21)

### Documentation

* docs: Ignore overview docs (#3456) ([`5e903b1`](https://github.com/embeddings-benchmark/mteb/commit/5e903b145316041056daad4598a0d94d573e8670))

### Feature

* feat: Add mteb nl (#3464)

* classification tasks for MTEB-NL

* clustering tasks for MTEB-NL

* ml classification tasks for MTEB-NL

* pair classification tasks for MTEB-NL

* sts tasks for MTEB-NL

* cherry-picked commits from MTEB-NL for tasks

* descriptive stats for MTEB-NL

* Update mteb/tasks/classification/nld/DutchColaClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/sts/nld/SICKNLSTS.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* imports fixed for MTEB-NL

* SICKNLPairClassification the HF location fixed

* DutchColaClassification the HF location fixed

* DutchGovernmentBiasClassification the HF location fixed

* XLWICNLPairClassification the HF location fixed

* BBSARDNLRetrieval the HF location fixed

* LegalQANLRetrieval the HF location fixed

* cls and mlcls deduplication for MTEB-NL

* SICK-NL deduplication for MTEB-NL

* pep 8 to MTEB-NL (2)

* bBSARDNLRetrieval deduplicated

* imports fixed for pair classification MTEB-NL

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`4f9f157`](https://github.com/embeddings-benchmark/mteb/commit/4f9f157df75d98dc4da95ac6615769564e6940f0))

### Fix

* fix: Add more impots to root `__init__` (#3458)

update root init ([`f8c07ff`](https://github.com/embeddings-benchmark/mteb/commit/f8c07ff43e42f79aa9a148b2921e43f0b2396e17))

* fix: license pyproject (#3457)

fix license ([`6fbe482`](https://github.com/embeddings-benchmark/mteb/commit/6fbe482fc1217f6083f09c0ed3d069b7ea18414e))

## v2.0.5 (2025-10-21)

### Fix

* fix: vdr category (#3465) ([`4b384bb`](https://github.com/embeddings-benchmark/mteb/commit/4b384bb4d27b6adf29f3c1dc4d1ca8e914190270))

### Unknown

* Add more statistics (#3462)

* add statistics

* add PatchCamelyonZeroShot stats ([`93d638d`](https://github.com/embeddings-benchmark/mteb/commit/93d638d62b4ebb7a88b81f4a7eb0a9cb2f22bec1))

* model: Kalm model (#3461)

readd ([`5c111ea`](https://github.com/embeddings-benchmark/mteb/commit/5c111ea3193ec4be5d9fc1a5e8ab055f88a842c4))

* Add stats from fzoll (#3460)

* Correcting the get_tasks filtering issue

* Correcting the get_tasks filtering issue

* Descriptive stats, last part

* Descriptive stats, last part

---------

Co-authored-by: fzoll &lt;fodizoltan@gmail.com&gt; ([`4ef51f2`](https://github.com/embeddings-benchmark/mteb/commit/4ef51f2a5e3ce4cc22cd39fdf9f8dd779cf5855f))

## v2.0.4 (2025-10-20)

### Documentation

* docs: Update readme header (#3443)

To avoid the text focus ([`0a6fe95`](https://github.com/embeddings-benchmark/mteb/commit/0a6fe957f4c9b8806fb6ddb2d48930ecc3df19ef))

* docs: Don&#39;t shorten embedding size (#3455)

Don&#39;t shorten embedding size ([`be20185`](https://github.com/embeddings-benchmark/mteb/commit/be20185035c0f9fb77b07041265eb50e010306c5))

### Fix

* fix: Roll back setting OMP_NUM_THREADS for clustering (#3444)

* test: disable flaky test

Added issue to readd #3441

* fix: Roll back setting OMP_NUM_THREADS for clustering

This rolls back #3400 as it didn&#39;t work (as shown in most recent CI on main) ([`38e7bc7`](https://github.com/embeddings-benchmark/mteb/commit/38e7bc776d2372b9de33128905d1f8aa737f709b))

### Unknown

* Update logo size and heading levels in README ([`6eab159`](https://github.com/embeddings-benchmark/mteb/commit/6eab1594517fb0a2275423d5fa62cc192d4a1e44))

## v2.0.3 (2025-10-20)

### Fix

* fix: speedup retrieval computation (#3454)

* speedup retrieval computation

* lint ([`01f3a19`](https://github.com/embeddings-benchmark/mteb/commit/01f3a19064aa800db3515d9959feed5478cdb91d))

## v2.0.2 (2025-10-20)

### Ci

* ci: Updating docs ci (#3445)

* feat!: Updating to v2

* 2.0.0

Automatically generated by python-semantic-release

* ci: Updating docs ci

- removed outdated CI for tables
- updated docs ci to also test mkdocs build
- updated docs deployment to build new overview on PRs
- remove old doc files

---------

Co-authored-by: semantic-release &lt;semantic-release&gt; ([`3af1aa0`](https://github.com/embeddings-benchmark/mteb/commit/3af1aa0af9f77e72b29cfe228ca2f8fe6157898d))

### Fix

* fix: add citations to models (#3435) (#3439)

add citations to models (#3435)

* fix: add citations to models

* Update mteb/models/model_implementations/salesforce_models.py

---------

Co-authored-by: Yongbin Choi &lt;whybe.choi@gmail.com&gt; ([`a04d78b`](https://github.com/embeddings-benchmark/mteb/commit/a04d78bf0e7cc859079d18376745dc1e5f02d935))

### Unknown

* Fix: Cache invalidation (#3393)

* feat - issue #3381

* feat - issue #3381

* feat - add task_select.change ([`9b08e8c`](https://github.com/embeddings-benchmark/mteb/commit/9b08e8caeb45c99c6cceca5f52b915f339ca7035))

* Merge statics (#3452)

* Recalculating desc. stats, part 6 (#3451)

* Correcting the get_tasks filtering issue

* Correcting the get_tasks filtering issue

* Descriptive stats, part 6

* merge statisrics

---------

Co-authored-by: fzoll &lt;5575946+fzoll@users.noreply.github.com&gt; ([`5e6542e`](https://github.com/embeddings-benchmark/mteb/commit/5e6542e4cc2d69ad93c38e2d565ada85ba27b107))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`48b11a7`](https://github.com/embeddings-benchmark/mteb/commit/48b11a717a28c60bddd8956c5c53b928788110cb))

## v2.0.1 (2025-10-20)

### Breaking

* feat!: Updating to v2 ([`c20226f`](https://github.com/embeddings-benchmark/mteb/commit/c20226f945749947913058c749956e266ff96f7d))

### Documentation

* docs: Update AbsTaskPairClassification to correct path (#3437)

This ensures that the documentation can be built

Reran make build docs (added changes). Also updated pyproject.toml given new PRs ([`a329381`](https://github.com/embeddings-benchmark/mteb/commit/a3293811f40629a20a71d2c6474099c344749629))

* docs: fix typos in `docs/adding_a_benchmark.md` (#3344) ([`721e8a3`](https://github.com/embeddings-benchmark/mteb/commit/721e8a34743c050179ee5e9093ed24ee7ab37fba))

### Test

* test: disable flaky test (#3442)

Added issue to readd #3441 ([`29e605f`](https://github.com/embeddings-benchmark/mteb/commit/29e605f7f022c47c96567cc9dfcf653d7d270088))

### Unknown

* bump version ([`838f25f`](https://github.com/embeddings-benchmark/mteb/commit/838f25fbfeb1a7afd54404a28b7b97681391784b))

* breaking: Updating to v2 ([`ba2a434`](https://github.com/embeddings-benchmark/mteb/commit/ba2a4342e957a08d336bfcfe295ce83ea2b44c90))

* BREAKING: v2.0.0 (#1433)

* [v2] Merge `MIEB` into v2 (#1973)

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* 1.31.6

Automatically generated by python-semantic-release

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* fix: remove SummaryRetrieval as a type (#1915)

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* fix: revert rename and add to description (#1918)

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* Update tasks table

* docs: Add sort to domains for task metadata (#1922)

Tests currently go into an infinite loop. This should prevent that.

* Update tasks table

* 1.31.7

Automatically generated by python-semantic-release

* docs: Updated citation for mteb(scandinavian) (#1914)

fix: Updated citation for mteb(scandinavian)

* fix: Add datasets in CodeRAG-Bench (#1595)

* add three out of four datasets in CodeRAG-Bench
* add verified CodeRAGStackoverflowPostsRetrieval dataset
* clean up code and make some comments
* fixed lint errors
* addressed comments about code-rag datasets: fixed grammar and remove unnessary code and loop
* roll back files which is not supposed to change
* fixed the comments in split_by_first_newline() and make the methods private by adding a underscore prefix
* refactor to use common args
* update task descriptions
* add entry in benchmarks
* correct the alphanumeric order for the dataset
* add  in tasks.md
* add  in tasks.md
* update task metadata
* update importing path
* fix lint errors
* correct CodeRAG task metadata description field and id for stackoverflow-posts
* fix error in test
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Update tasks table

* 1.31.8

Automatically generated by python-semantic-release

* Leaderboard: Acks (#1930)

Add acs

* misc: add warning for save_suffix removal from AbsTask (#1940)

add warning for param removal

* misc: add bgev1 models (#1928)

* add bgev1 models

* add bge-*-en

* fix naming

* Updated links in MTEB(eng) and eng,classic (#1948)

* feat: add beir (#1933)

add beir

* 1.32.0

Automatically generated by python-semantic-release

* Fixed join_revisions if results are empty (#1949)

* feat: Merge MIEB into main ðŸŽ‰  (#1944)

* mieb ZeroshotClassification
* mieb docs
* mieb implementation demo
* model meta; abstask column names; linear probe clf
* model meta; abstask column names; linear probe clf
* fix: update naming as candidate_labels
* Update README.md
* Update README.md
* i2tretrieval
* test load data ignore i2tretrieval
* [MIEB] Add image clustering (#1088)
* make lint
* wip
* add TinyImageNet and run
* type hints
* add accuracy
* lint
* remove unused &amp; fix typos
* T2I Retrieval
* Any2AnyRetrieval
* fix tests from merge
* [MIEB] Add image text pair classification and tests (#1099)
* add ImageTextPairClassification abstask and evaluator
* dataset transform into sequence of images for each sample
* fix processing logic; list of list images compatability
* lint and docstrings
* make lint
* fix failing tests in TaskMetadata
* add tests for mieb
* skip gated repo
---------
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
* [MIEB] Add image classification and zero shot classification tasks (#1101)
* fix task metadata
* use overrideable column names
* add CIFAR datasets
* add caltech101 dataset
* add FGVC aircraft dataset
* add food 101 dataset
* add OxfordPets dataset
* remove comments
* correct cifar100 path
* update cifar100 classification results
* cifar zero shot results
* add caltech101 zero shot
* matching CLIP paper implementation
* add aircraft and food zero shot
* add oxford pets zero shot
* [MIEB] Add CIFAR clustering (#1104)
add CIFAR clustering
* [MIEB] Add more image classification and zero shot classification datasets (#1103)
* update category to i2t
* add MNIST linear probe and zero shot
* add FER2013 linear probe and zero shot
* add stanford cars linear probe and zero shot
* add birdsnap linear probe and zero shot
* add eurosat linear probe and zero shot
* lint
* correct eurosat zero shot labels
* add abstask for image multilable and voc2007
* make lint
* [MIEB] Add more image classification and zero shot datasets (#1105)
* add STL10 linear probe and zero shot
* add RESISC45 linear probe and zeor shot
* add Describable textures linear probe and zero shot
* fix spacing lint
* add SUN397 linear probe and zero shot
* correct SUN397 zero shot captions
* add baai bge vista
* add e5-v
* linting
* memory issues for image linear probe &amp; zeroshot
* kknn linear probe arguments
* del comments
* Add some classification and ZeroShot classification tasks (#1107)
* Add Country211 classification task
* Add imagenet1k classification task
* Add UCF101 classification task
* Add PatchCamelyon Classification task
* Add GTSRB classification task
* Add GSTRB Zero Shot Classification
* Add country211 zero shot classification
* Add results for classification tasks
* Add zero shot classification tasks
* Add PatchCamelyon tasks and results
* Add linting
* Add results and fix prompts for zero shot
* Add results
* Add results and linting
* fix dependency &amp; clip mock test
* [MIEB] Add jina clip (#1120)
* add jina clip and mscoco i2t and t2i results
* make lint
* [MIEB] Update `mieb` with the `main` branch and some fixes (#1126)
* fix instruction retrival (#1072)
* fix instruction retrival
* fix test
* add points
* make nested results
* add test
* skip instruction test
* fix instruction passes
* fix unions
* move do_length_ablation
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update points table
* fix: fix bug-causing spelling error in function name of e5-mistral-instruct (#1106)
found bug
* 1.12.85
Automatically generated by python-semantic-release
* fix: MultilingualSentimentClassification (#1109)
* Update points table
* fix: Avoid spaces in dataset name for CQADupstack and ignore speed tasks
* 1.12.86
Automatically generated by python-semantic-release
* fix: Ensure that MLSUMClusteringP2P.v2 use the fast implementation as was intended (#1112)
* fix: Ensure that MLSUMClusteringP2P.v2 use the fast implementation as was intended
* fix: fixed formatting for cli
* docs: improve searchability in the advanced usage documentation
* 1.12.87
Automatically generated by python-semantic-release
* docs: improve searchability in the advanced usage documentation (#1113)
* docs: improve searchability in the advanced usage documentation
* docs: update based on corrections
* fix: export type for `mteb create_meta` (#1114)
* fix export type
* fix dataset version too
* 1.12.88
Automatically generated by python-semantic-release
* fix: Simplify models implementations (#1085)
* Merge
* Adapt
* Simplify
* Check for rev again
* Rmv cmmnt
* Simplify
* simplify
* Rmv comment
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Use logging; change try except; add info
* Lint
* Rmv results
* Update rev
* format
* Simplify models; Allow instructions
* Jobs
* Fix merge
* Format
* Adapt models
* fix: ensure that e5 ignores the NQ
* format
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* 1.12.89
Automatically generated by python-semantic-release
* fix: nomic models using prefix correctly (#1125)
* fix: nomic models using prefix correctly
* chore: remove comment
* fix: handling in case not torch tensor
* Fix typo
---------
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
* 1.12.90
Automatically generated by python-semantic-release
* refactor vista model wrapper to contain lib import
* python 38 type hints
---------
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: anpalmak2003 &lt;73543260+anpalmak2003@users.noreply.github.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: Zach Nussbaum &lt;zanussbaum@gmail.com&gt;
Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
* image memoery issues for all retrieval Abstasks
* Add CLEVR and SciMMIR Image-Text Understanding tasks (#1127)
* Add CLEVER and SciMMIR
* Update metadata
* remove useless comment
* Add linting
* fix typo and tests
* Add CLEVR count task
* add linting
* add fashion200k &amp; fashionIQ test passed
* clip text max seq truncation
* add WebQA, NIGHTS, OVEN
* any2any retrieval chunk encoding
* add nomic vision model; any2any topk bug
* add cv recall
* add InfoSeek; VisualNews
* [MIEB] Add Stanford Cars i2i Retrieval (#1147)
* wip
* add results
* make lint
* change back the order
* [MIEB] Add CUB200 i2i retrieval (#1154)
* add cub200 and results
* add skip_first_result
* skipped self and rerun results
* consolidate i2t and t2i to any2any
* remove abstask and evaluators
* remove references from test
* tu-add berlin sketch retrieval
* XM3600; XFlickr30kCO; mutilingual
* wit multilingual retrieval t2i
* correct multilingual t2i meta
* meta
* add dinov2 model; 4 sizes
* cls evaluator channel bug fix
* add ALIGN model
* add FORBI2IRetrieval
* forb &amp; tuberlin new revision
* disable tokenization parallelism
* add hateful meme retrieval i2tt2i
* add memotion retrieval t2ii2t
* add SciMMIR Retrieval i2tt2i
* ruff update
* Visual STS Abstask&amp;evaluator
* add visual STS17
* add visual STS 12-16
* [mieb] Add blip and blip2 models, and ImageNetDog15Clustering task (#1226)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* [mieb] add 3 compositionality evaluation tasks (#1229)
* linting &amp; update unavailable dataset path
* add aro visual relation&amp;attribution; sugarcrepe
* correct reference
* add SOPI2IRetrieval dataset/task (#1232)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* change reference
* Image text pair cls (#1233)
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* fix meta data
* fix validate points
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Add RP2kI2IRetrieval and METI2IRetrieval (#1239)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* [MIEB] Adding DataComp CLIP models (#1283)
* adding data comp CLIP models
* update model and caltech101 results
* make lint
* [mieb] Any2TextMultipleChoice Abstask&amp;Evaluator &amp; four tasks in CV-bench (#1287)
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* fix meta data
* fix validate points
* CV-Bench
* evaluator args comment
* fix
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* [mieb] adding 10 tasks (#1290)
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* add vidore benchmark 10 tasks
* fix reference
* fix old metadata
* fix meta
* [mieb] Adding MOCOv3 models (#1293)
* add moco models first try
* add as a timm model
* add large model results
* make lint
* [mieb] Add more Any2AnyRetrieval datasets (#1285)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* add two landmark datasets and results
* add Sketchy i2i retrieval
* add task metadata
* add BLINKIT2IRetrieval dataset
* add BLINKIT2TRetrieval
* add ImageCoDeT2IRetrieval
* make lint
* add vizwiz retrieval and results
* fix vizwiz duplicate texts
* add new vizwiz results
* add VQA2 results
* add GLD v2 I2T retrieval
* add gld v2 i2i retrieval
* make lint
* remove GLDv2I2IRetrieval
* [mieb] Add any2any multiple choice evaluator and abstask (and one task) (#1301)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* add two landmark datasets and results
* add Sketchy i2i retrieval
* add task metadata
* add BLINKIT2IRetrieval dataset
* add BLINKIT2TRetrieval
* add ImageCoDeT2IRetrieval
* make lint
* add vizwiz retrieval and results
* fix vizwiz duplicate texts
* add new vizwiz results
* add VQA2 results
* add GLD v2 I2T retrieval
* add gld v2 i2i retrieval
* make lint
* add AbsTaskAny2AnyMultiChoice
* make lint
* remove GLDv2I2IRetrieval
* exclude AbsTaskAny2AnyMultiChoice from test_load_data
* [mieb] Fix FORB dataset (#1306)
* correct format
* update results
* add more results
* add more results
* [mieb] run tasks fix (#1302)
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* fix e5v&amp;vista
* task type fix for running tasks
* fix wrong meta
* run mieb script
* script
* lint
* align
* [mieb] split RParisI2IRetrieval and ROxfordI2IRetrieval into easy, medium and hard versions (#1305)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* add two landmark datasets and results
* add Sketchy i2i retrieval
* add task metadata
* add BLINKIT2IRetrieval dataset
* add BLINKIT2TRetrieval
* add ImageCoDeT2IRetrieval
* make lint
* add vizwiz retrieval and results
* fix vizwiz duplicate texts
* add new vizwiz results
* add VQA2 results
* add GLD v2 I2T retrieval
* add gld v2 i2i retrieval
* make lint
* add AbsTaskAny2AnyMultiChoice
* make lint
* remove GLDv2I2IRetrieval
* exclude AbsTaskAny2AnyMultiChoice from test_load_data
* fix e5v&amp;vista
* remove duplicate corpus entries from BLINKIT2TRetreival dataset
* task type fix for running tasks
* update BLINKIT2T metadata
* fix wrong meta
* run mieb script
* split ROxford, RParis into easy, medium and hard
* make lint
---------
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
* [mieb] run tasks small fix (#1310)
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* fix e5v&amp;vista
* task type fix for running tasks
* fix wrong meta
* run mieb script
* script
* lint
* align
* fix
* linting
* [mieb] Add VLM2vec (#1323)
* wip vlm2vec model
* making i2t classification work wit Calteh101
* test vlm2vec on other task types
* move peft into class
* feat: Merge main into MIEB (#1329)
* fix: OpenAI BadRequestError by limiting input dimensions to 2048 elemâ€¦ (#1203)
* fix: OpenAI BadRequestError by limiting input dimensions to 2048 elements (#1201)
Fix OpenAI BadRequestError by limiting input dimensions to 2048 elements
- Ensure the &#39;sentences&#39; list passed to OpenAI API does not exceed 2048 elements
- Reference: OpenAI&#39;s Embedding API documentation on input limits
Co-authored-by: Ali Shiraee &lt;ShiraeA@basfad.basf.net&gt;
* fix ruff formatting
* Added minor test fixes to ensure reproducility across systems
* Ensure that tmp.json is not created within repo when running tests
* format
* fixes path issues
* Rerun CI
---------
Co-authored-by: HSILA &lt;a.shiraee@gmail.com&gt;
Co-authored-by: Ali Shiraee &lt;ShiraeA@basfad.basf.net&gt;
* fix: Ensure STS pearson and spearman does not use the p-value only the correlation (#1207)
Fixes #1206
* 1.14.16
Automatically generated by python-semantic-release
* fix: Normalize licenses including casing, uses of &#34;-&#34; etc.
* fix: Normalize licenses including casing, uses of &#34;-&#34; etc. (#1210)
* fix: Normalize licenses including casing, uses of &#34;-&#34; etc.
* fix tests
* 1.14.17
Automatically generated by python-semantic-release
* fix: Normalize benchmarks no only include task objects and added getter for benchmarks (#1208)
* Normalize benchmarks to only include tasks
- Force benchmarks to only include tasks. This fixes a few bugs where benchmarks can reference a task which is not implemented
- implements `mteb.get_benchmark`, which makes it easier to fetch benchmarks
- Added tests + updated docs
A few outstanding issues:
I would like `mteb.MTEB(benchmark)` to always reproduce the benchmark. Currently this is not possible as MTEB(eng) required the split to be specified. A solution it to allow &#34;eval_splits) to be specified when initializing a task and then pass it on to the `load_data()`. This way we can write the following:
`mteb.get_tasks(tasks=[...], eval_splits=[&#34;test&#34;], ...)`
I would also love the aggregation to be a part of the benchmark (such that it is clear how it should be aggregated). This is especially relevant for MTEB(eng) as it average the CQAD datasets before creating the global average. This way we can also create a result object for the benchmark itself. A complimenting solution for this is to allow nested benchmarks.
* fix error in tests
* format
* Added corrections based on review
* added example and formatted
* 1.14.18
Automatically generated by python-semantic-release
* docs: Fix broken links in docs (#1212)
* Added fixes for broken links in adding_a_dataset and adding_a_model docs.
* Updated link name
* Mismatch of the category of AmazonPolarityClassification (#1220)
Fixes #1219
* Update tasks table
* fix: Ensure that results are returned even when hitting cache (#1215)
Fixes #1122
* 1.14.19
Automatically generated by python-semantic-release
* fix: Allow benchmark to specify eval_splits (#1217)
* fix: Allow benchmark to specify eval_splits
This PR allow for benchmarks to specify specific eval. splits. This allow us to fully specify a benchmark within the benchmark object.
To do this it add the following:
- added eval_splits to the Abstask object, which default to metadata.eval_splits
- use the task.eval_splits unless overwritten in mteb.MTEB.run
- added eval_splits arg to mteb.get_tasks, which filter the tasks based on splits
- updated documentation
  - renamed the &#34;Advanced Usage&#34; to &#34;Usage Documentation&#34; to make it more accicible
- added tests where relevant
* Added correction based on feedback
* 1.14.20
Automatically generated by python-semantic-release
* Update points table
* Update points table
* docs: clarify adding a model (#1222)
* fix: Add RepLLaMA style models (#1223)
* init commit
* working and reproducing
* lint
* update hashes
* warning
* add pyproject
* Update points table
* 1.14.21
Automatically generated by python-semantic-release
* docs: Update points (#1228)
* Fix case
* Fix casing
* Fix case
* Fix case
* Create 971.jsonl
* Update contrib
* Add contributors
* Update points table
* docs: Add MTEB(code) dataset (#1237)
* docs: Add MTEB(code) dataset
* Fix linting
* Update points table
* Update of my affiliation (#1242)
Update points.md
* Add contributor (#1243)
* fix: @mrshu&#39;s name in `points.md` (#1246)
* Use the diacritic character to be inline with Slovak spelling.
Signed-off-by: mr.Shu &lt;mr@shu.io&gt;
* docs: Create benchmarks overview table (#1245)
* fix get_benchmarks method
* add create benchmark script
* make lint
* 1.14.22
Automatically generated by python-semantic-release
* docs: Update affiliation (#1247)
Update points.md
* Added author-information
* Add final author list
* Update points table
* docs: Added coordination point for Jimmy Lee  (#1253)
docs: Added coordination point for Jimmy lee for his work on the coordination of Crystina and Nandan
* Update points table
* fix: Add multilingual Benchmark (#1252)
* fix: Add multilingual bench
* Update mteb/benchmarks/benchmarks.py
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
* format
---------
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
* 1.14.23
Automatically generated by python-semantic-release
* docs: Small point changes &amp; more contributors (#1254)
* Update points.md
* Fix format
* Fix attribution
* Update points table
* fix: Downsample large retrieval datasets (#1236)
* most tasks
* lint
* fix other issues
* refactor
* lint and docs
* add polish
* keep case sensitive mteb paths
* add potential points
* fix points
* fix test about metadata
* update tasks and stats
* lint
* Update points table
* Update tasks table
* 1.14.24
Automatically generated by python-semantic-release
* fix: Get meta from CrossEncoder (#1255)
* remove indent after return
* handle cross encoders for model meta
* make lint
* update filename since we now have model name
* 1.14.25
Automatically generated by python-semantic-release
* fix: Add listing all available benchmarks CLI option (#1256)
* add benchmarks.md in README
* add cli option
* add benchmark cli test case
* correct typo
* 1.14.26
Automatically generated by python-semantic-release
* docs: Update affiliation (#1248)
* Update points.md
* Update points.md
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* docs: Update mteb(eng) calculation (#1258)
* Update mteb(eng) calculation
* Fixed citations
* Update MTEB(eng) + MTEB(multilingual)
* feat: leverage SentenceTransformers&#39; query/passage specific prompts (#1221)
* feat: leverage SentenceTransformer models&#39; query/passage specific prompts
* refactor: remove E5Wrapper
fix: wrong e5 revisions
* fix: default prompt_type to None
* fix: e4ce987 revision no longer exists for multilingual-e5-small on the Hub
* fix: keep `prompt_name` in kwargs when model doesn&#39;t have a `prompts` attr
* feat: use Enum for `prompt_type`
* docs: specify how to use prompts with Sentence Transformers
* feat: readd arctic models due to metadata
* 1.15.0
Automatically generated by python-semantic-release
* fix: Add Touche2020v3 and JMTEB (#1262)
* add datasets
* fix metrics
* add Touche2020v3
* fix metadata
* Apply suggestions from code review
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* upd name and supress
* add benchmark class
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update tasks table
* 1.15.1
Automatically generated by python-semantic-release
* fix: Select benchmarks CLI option (#1261)
* add test case for a list of Benchmarks
* add selecting benchmarks CLI option
* typos
* use a separate attribute for benchmarks
* try fixing tests
* should accept string as well
* revert filename change
* use Benchmark and avoid circular import
* fix: derive `results_directory` path from `results_repo` name (#1275)
fix: don&#39;t hardcode repo name when downloading results
* 1.15.2
Automatically generated by python-semantic-release
* fix: sorting benchmark tasks by MTEB, then alphabetical (#1271)
* sorted
* fixed formatting
* efficiency changes
* fix test
* make lint
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* 1.15.3
Automatically generated by python-semantic-release
* ci: Removed 3.8 dependency (#1281)
Changes include:
- remove 3.8 from tests (added 3.11 and 3.12)
- changed other CI to 3.9
- updated lint rules to use 3.8
* Update points table
* fix: Allow Numpy &gt;=2.0 (#1264)
Allow Numpy &gt;=2.0
* 1.15.4
Automatically generated by python-semantic-release
* docs: points for paper writing (#1286)
* Create 1004.jsonl
* Create 1006.jsonl
* Update docs/mmteb/points/1004.jsonl
* Update docs/mmteb/points/1006.jsonl
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update points table
* Update points table
* Update points table
* docs: Fix a link in the README (#1289)
* Fix a link in the README
And fix some typos.
* Update README.md
* Update points table
* fix: Update benchmarks (#1288)
* make benchmark var name uppercase
* update touche to v3
* add MIRACLRetrievalHardNegatives to multilingual
* add mteb(indic)
* add eu benchmark
* 1.15.5
Automatically generated by python-semantic-release
* fix: Allow numpy&lt;2.0.0 (#1291)
* 1.15.6
Automatically generated by python-semantic-release
* fix: Add metadata dict to QBQTC in C-MTEB (#1292)
* fix QBQTC in C-MTEB
* make lint
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* 1.15.7
Automatically generated by python-semantic-release
* fix: Remove non-existent eval split of CMNLI (#1294)
fix eval_splits of CMNLI
* 1.15.8
Automatically generated by python-semantic-release
* Leaderboard (#1235)
* Add leaderboard dev
* Renamed MTEBResults to TaskResult
* Moved model and model meta loading utilities into overview.py
* Added get_model_metas to retrieve filtered metadata for models
* Restructured results object and made it into a class instead of a dict
* Added utilities for filtering models on BenchmarkResults objects
* Added to_table utility function to BenchmarkResults
* Added serialization utilities to BenchmarkResults
* Attempted fixing tests
* Added get_model_metas to __init__
* Added get_benchmarks to __init__ and made it return all benchmarks by default
* Added get_benchmarks to __init__
* Made tasks hashable
* Added task filtering based on task objects on BenchmarkResults
* Added BenchmarkResults to __init__
* Added additional arguments to get_scores on two classes
* Made get_scores smarter on BenchmarkResult
* Added basic multilingual benchmark
* Modified benchmark to be able to easily access results
* Added useful properties and filtering functions to BenchmarkResults
* Added minimal functioning example
* Added smarter table, task-list updating and tried fixing dropdown scrolling
* Made restrict_results into a private function
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Removed old leaderboard scripts
* Hardcoded max and min model size
* Removed redundant utils file
* Ran linting
* added leaderboard dependencies as optional
* Fixed union type error on Python 3.9
* Removed references to Dict in task aggregation
* Fixed name errors in _restrict_task_results
* Fixed _restrict_task_results
* Made hf_subsets={&#39;default&#39;} when the task is monolingual in _restric_task_results
* Task dropdown now gets filtered based on the other criteria
* Ran linting again
* Introduced hotfix for reranking test
* Added BenchmarkResults to __all__ in __init__
* Fixed validate_and_filter_scores method, and replaced _restric_task_results with it
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* feat: Use prompts instead of encode_corpus and encode_queries (#1278)
* add prompt per task type
* fix prompt
* upd test
* lint
* fix test
* fix DeprecatedSummarizationEvaluator
* fix prompts
* add test
* lint
* logger info
* use task type only in model_encode
* lint
* update interface
* add prompt types to docs
* fix test
* mock tasks
* mock task registry
* remove last task_type
* fix tests
* lint
* fix test
* fix
* use wrapper and new prompts
* fix tests
* lint
* fix test
* remove conftest
* validate task to prompt_name
* override model prompts
* task to prompt name optional
* fix tests
* fix models
* remove task_to_prompt_name
* remove from mteb __init__
* update docs
* load existing model prompts if model_prompts is None
* fix
* lint
* change wrapper loader
* add wrapper class
* lint
* add wrapper file
* update logging
* upd logging
* refactor reranking
* lint
* remove prints
* 1.16.0
Automatically generated by python-semantic-release
* fix: Add Retrieval SK Quad dataset for Slovak search evaluation (#1276)
* Add Retrieval SK Quad dataset for Slovak search evaluation
This commit introduces the Retrieval SK Quad dataset, designed to assess Slovak search performance. The dataset is derived from SK-QuAD and includes questions with their best answers categorized post-annotation. This addition provides a significant resource for advancing Slovak language search evaluation and supporting further research and development.
* Add Retrieval SK Quad dataset for Slovak search evaluation 2
Added the requested changes on the SKQuadRetrieval.py file
* add task to init
* add missing task metadata
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update tasks table
* 1.16.1
Automatically generated by python-semantic-release
* fix: Add Slovak Hate Speech and Offensive Language Dataset (#1274)
* Add Slovak Hate Speech and Offensive Language
Dataset
This commit introduces the Slovak Hate Speech and Offensive Language Database to MTEB. The dataset includes posts from a social network, annotated by humans for hate speech and offensive content. Additionally, the corresponding task has been added to the tasks.md table to reflect this update.
* Add Slovak Hate Speech and Offensive Language Dataset
- Updated __init__.py to include the new SlovakHateSpeechClassification task.
- Modified SlovakHateSpeechClassification.py as per review suggestions to enhance functionality and readability.
* Did requested changes:
- Updated __init__.py to include the new SlovakHateSpeechClassification task.
- Modified SlovakHateSpeechClassification.py as per review suggestions to enhance functionality and readability.
* resolve linting issues by running `make lint`
* Update tasks table
* WIP: Leaderboard UI improvements (#1312)
* Fixed typos in task_results
* Fixed typos in task_results
* Added Tailwind, reorganized layout and fixed scrolling
* Ran linting
* 1.16.2
Automatically generated by python-semantic-release
* fix: remove duplicate multilingual
* 1.16.3
Automatically generated by python-semantic-release
* fix: Re-upload dataset to hub to avoid using script upload (#1322)
* fix dataset upload
* add linting
* Update tasks table
* 1.16.4
Automatically generated by python-semantic-release
* fix: Add implementations of common reranker models (#1309)
* init
* revert
* revert
* add metadata
* lint
* add reqs
* change to float16
* benchmark lint fix
* 1.16.5
Automatically generated by python-semantic-release
* Add multilingual mFollowIR dataset (#1308)
* add mFollowIR
* paper name
* edit warning-&gt;info
* convert to parquet
* lint
* Update tasks table
* Cache the embeddings when requested (#1307)
* add caching
* update test to use close
* change from json to pkl
* fix for window
* cleanup on Windows again
* infer dimension
* move cachewrapper
* add wrapper
* fix
* updates
* fix tests
* fix lint
* lint
* add test
* WIP: Leaderboard UI improvements (#1320)
* Fixed typos in task_results
* Fixed typos in task_results
* Added Tailwind, reorganized layout and fixed scrolling
* Ran linting
* Removed faux benchmark
* Updated layout
* Changed table number format
* Table highlights highest values by making them bold
* Added rank to table, removed organization from model_name
* Added mean rank to table
* Ran linting
* feat: Update metadata for all models (#1316)
* Added model meta
* format
* fixed metadata
* Metadata update for voyage models
* Update mteb/models/cohere_models.py
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
* Update mteb/models/cohere_models.py
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
* Added corrections from review
* fix spelling error
---------
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
* resolved bugs from pytest --collect-only
* Avoid wrapping all models with the SentenceTransformerWrapper
* Added normalize_embeddings_to_numpy to ensure standard embeddings during evaluations
* fixed moved on correction from @Samoed
* conditionally set .predict method on SentenceTransformerWrapper
---------
Signed-off-by: mr.Shu &lt;mr@shu.io&gt;
Co-authored-by: HSILA &lt;a.shiraee@gmail.com&gt;
Co-authored-by: Ali Shiraee &lt;ShiraeA@basfad.basf.net&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Thomas van Dongen &lt;thomas123@live.nl&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: Orion Weller &lt;31665361+orionw@users.noreply.github.com&gt;
Co-authored-by: John Yang &lt;byjohnyang@gmail.com&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: Marek Å uppa &lt;mrshu@users.noreply.github.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Xa9aX ãƒ„ &lt;mishradiganta91@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel@buad.es&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel.buades@clinia.com&gt;
Co-authored-by: Sathvik Nallamalli &lt;sathviknallamalli@gmail.com&gt;
Co-authored-by: Michael Graczyk &lt;michael@mgraczyk.com&gt;
Co-authored-by: Mariya Hendriksen &lt;35101262+mariyahendriksen@users.noreply.github.com&gt;
Co-authored-by: Santiago Castro &lt;bryant1410@gmail.com&gt;
Co-authored-by: Joey Xia &lt;77958037+ZiyiXia@users.noreply.github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
Co-authored-by: Oliver &lt;oliver.pejic@students.fhnw.ch&gt;
* [mieb] Add OpenCLIP models (#1335)
* add open clip models
* Update __init__.py
* lint
* fix model overview
* update jina clip
---------
Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
Co-authored-by: gowitheflow-1998 &lt;chenghao.xiao@durham.ac.uk&gt;
* [mieb] new version with downsampled train split to 32 per class (#1327)
* new version with downsampled train split to 32 per class
* force load truncated image file
* make lint
* add open clip models
* Update __init__.py
* lint
* fix model overview
* fix ImageCLS undersample; run birdsnap
* make lint
* make lint
---------
Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
Co-authored-by: gowitheflow-1998 &lt;chenghao.xiao@durham.ac.uk&gt;
* [mieb] Fix Jina CLIP (#1349)
fix jina clip v1
* fix: Add clevr license (#1356)
* Add BLINK as multi-choice tasks (#1348)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* add two landmark datasets and results
* add Sketchy i2i retrieval
* add task metadata
* add BLINKIT2IRetrieval dataset
* add BLINKIT2TRetrieval
* add ImageCoDeT2IRetrieval
* make lint
* add vizwiz retrieval and results
* fix vizwiz duplicate texts
* add new vizwiz results
* add VQA2 results
* add GLD v2 I2T retrieval
* add gld v2 i2i retrieval
* make lint
* add AbsTaskAny2AnyMultiChoice
* make lint
* remove GLDv2I2IRetrieval
* exclude AbsTaskAny2AnyMultiChoice from test_load_data
* fix e5v&amp;vista
* remove duplicate corpus entries from BLINKIT2TRetreival dataset
* task type fix for running tasks
* update BLINKIT2T metadata
* fix wrong meta
* run mieb script
* split ROxford, RParis into easy, medium and hard
* make lint
* add BLINK as multi choice tasks
* fix: license metadata in wrong format
---------
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
* [mieb] add Eva CLIP models (#1369)
* add Eva CLIP models
* make lint
* [mieb] add siglip, cohere multimodal &amp; some fixes for final run (#1357)
* fix dataset type error
* fix clustering metrics
* add siglip &amp; cohere
* update mieb run script
* cohere-v import
* fix
* api key name
* [mieb] fixes for final run (#1374)
* e5_v device arg
* dataloader num_workers
* vista doc
* vista doc
* run mieb
* fix
* Update run_vista.md
* [mieb] Fix torch no grad (#1378)
Fix torch no grad
* [mieb] Fix vlm2vec (#1380)
* fix vlm2vec return dtype
* make lint
* [mieb] Remove null entries from corpus of ROxford, RParis (#1371)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* add two landmark datasets and results
* add Sketchy i2i retrieval
* add task metadata
* add BLINKIT2IRetrieval dataset
* add BLINKIT2TRetrieval
* add ImageCoDeT2IRetrieval
* make lint
* add vizwiz retrieval and results
* fix vizwiz duplicate texts
* add new vizwiz results
* add VQA2 results
* add GLD v2 I2T retrieval
* add gld v2 i2i retrieval
* make lint
* add AbsTaskAny2AnyMultiChoice
* make lint
* remove GLDv2I2IRetrieval
* exclude AbsTaskAny2AnyMultiChoice from test_load_data
* fix e5v&amp;vista
* remove duplicate corpus entries from BLINKIT2TRetreival dataset
* task type fix for running tasks
* update BLINKIT2T metadata
* fix wrong meta
* run mieb script
* split ROxford, RParis into easy, medium and hard
* make lint
* add BLINK as multi choice tasks
* fix: license metadata in wrong format
* remove null examples from corpus of ROxford and RParis
---------
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
* [mieb] fixes (#1390)
* Fix torch no grad
* simplify
* make lint
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* [MIEB] Remove non-existent method for blip (#1394)
remove non-existent method for blip
* [mieb] fix ALIGN; update Winoground revision id; update run script (#1391)
* fix align &amp; winoground
* lint
* Convert task category to i2i for tasks that only calls image encode
* update categories should include img cls, clustering, and multi label clf
* no op
* no op
* make lint
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* [mieb] Fix open clip for cv bench count (#1397)
fix shape mismatch
* [mieb] Update subtasks of BLINKIT2TMultiChoice and BLINKIT2IMultiChoice (#1403)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* add two landmark datasets and results
* add Sketchy i2i retrieval
* add task metadata
* add BLINKIT2IRetrieval dataset
* add BLINKIT2TRetrieval
* add ImageCoDeT2IRetrieval
* make lint
* add vizwiz retrieval and results
* fix vizwiz duplicate texts
* add new vizwiz results
* add VQA2 results
* add GLD v2 I2T retrieval
* add gld v2 i2i retrieval
* make lint
* add AbsTaskAny2AnyMultiChoice
* make lint
* remove GLDv2I2IRetrieval
* exclude AbsTaskAny2AnyMultiChoice from test_load_data
* fix e5v&amp;vista
* remove duplicate corpus entries from BLINKIT2TRetreival dataset
* task type fix for running tasks
* update BLINKIT2T metadata
* fix wrong meta
* run mieb script
* split ROxford, RParis into easy, medium and hard
* make lint
* add BLINK as multi choice tasks
* fix: license metadata in wrong format
* remove null examples from corpus of ROxford and RParis
* fix: add/remove subtasks from BLINKIT2IMultiChoice and BLINKIT2TMultiChoice
* update blink metadata
* add updated BLINK results
---------
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
* [mieb] Fix EVA CLIP for CV Bench (#1414)
* unsqueeze after preprocess
* make lint
* [mieb] Add calculate probs for vlm2vec (#1418)
* add method
* make lint
* [mieb] Fix siglip bug &amp; add retrieval datasets (#1424)
* fix siglip
* add edis&amp;gld-v2 i2i
* results
* siglip updated results
* fix siglip non-dataloader tasks
* [mieb] use Logistic Regression classifier for AbsTaskImageMultilabelClassification (#1420)
* use moc-lr classifier
* set n_experiments=5
* run dinov2 and some laion models
* add dinov2-giant results
* [mieb] mieb scripts (siglip rerun &amp; linear probing ablation &amp; params count) (#1429)
* mieb scripts
* lint
* [MIEB] Change Flickr30k to test split (#1449)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* add two landmark datasets and results
* add Sketchy i2i retrieval
* add task metadata
* add BLINKIT2IRetrieval dataset
* add BLINKIT2TRetrieval
* add ImageCoDeT2IRetrieval
* make lint
* add vizwiz retrieval and results
* fix vizwiz duplicate texts
* add new vizwiz results
* add VQA2 results
* add GLD v2 I2T retrieval
* add gld v2 i2i retrieval
* make lint
* add AbsTaskAny2AnyMultiChoice
* make lint
* remove GLDv2I2IRetrieval
* exclude AbsTaskAny2AnyMultiChoice from test_load_data
* fix e5v&amp;vista
* remove duplicate corpus entries from BLINKIT2TRetreival dataset
* task type fix for running tasks
* update BLINKIT2T metadata
* fix wrong meta
* run mieb script
* split ROxford, RParis into easy, medium and hard
* make lint
* add BLINK as multi choice tasks
* fix: license metadata in wrong format
* remove null examples from corpus of ROxford and RParis
* fix: add/remove subtasks from BLINKIT2IMultiChoice and BLINKIT2TMultiChoice
* update blink metadata
* add updated BLINK results
* merge upstream mieb
* change Flickr30k to test split
* change flickr to test split
---------
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
* [mieb] Fix VLM2vec dtype (#1462)
* propagate dtype
* fix fuse embeddings using list of PIL images
* [mieb] run script for missing results (#1472)
* task type fix
* scripts
* [mieb] Fix Moco model on CIFAR10Clustering (#1487)
Fix Moco model on CIFAR10Clustering
* [mieb] Fix Flickr30k I2T and T2I (#1505)
* remake flickr30k it2 and t2i
* add openai clip vit-b32 b16 and jina-clip results
* make lint
* [MIEB] add missing siglip models  (#1533)
* add udpates
* lint errors
* fix typo (#1535)
* add udpates
* lint errors
* fix small typo
* [mieb] Fix numbers of CIRR, Fashion200k, FashionIQ, Flickr30k, MSCOCO data statistics (#1544)
fix numbers
* Discussing a standard for ImageEncoders
* Add Voyage&#39;s multimodal embedding (#1555)
* add voyage multimodal &amp; ran 17 tasks
* lint
* typo
* clean
* [mieb] update script for final re-run (#1576)
* mieb final runs
* lint
* fix: no longer using same query text for all of BLINKIT2TMultiChoice (#1572)
* fix: no longer using same query text for all of BLINKIT2TMultiChoice
* fix: remove blink subtask
* fix: remove subtask from blink it2i
* fix: align BLINK retrieval to multi choice
* add ROxford and RParis I2I multi choice
* add retrieval metrics to multi choice evaluator
* fix: remove wrong negatives from revisiting multichoice datasets
* fix revisiting datasets
* add new results for revisiting multichoice
* [MIEB] Make multimodal models compatible to `task_name` and `prompt_type` (#1583)
* 1. Make `get_xxx_embeddings` follow `encode`.
2. `ImageDataset.transform` could be `None`.
* Apply suggestions from code review
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Fix arguments
* Try to fix tests
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* fix image encoder (#1596)
* format
* fixed tests
* lint
* [mieb] voyage-v: add exponential backoff and other error handling (#1610)
* add voyage multimodal &amp; ran 17 tasks
* lint
* typo
* clean
* exponential backoff tmp
* downsize large images for voyage api call
* voyage error handling
* lint
* add more results
* make tenacity optional
* lint
* log
* [MIEB] Fix `get_fused_emebddings` (#1612)
* Fix fused
* fix vlm2vec
* Fix lint
* [MIEB] Add new multimodal retrieval tasks (#1611)
* Add new tasks
* Fix score type
* [MIEB] Switch to ViDoRe BEIR version (#1607)
* Fix ViDoRe corpus
* fix lint
* ViDoRe beir version
* Extend MIEB test coverage (#1629)
* add one task from each image AbsTask to test grid
* add visual sts to test grid
* [mieb] Task filtering by modality supported by models (#1633)
* fix function signature for moco loader
* filter out tasks by model modalities
* correct conditions
* add model meta to relevant models
* use modalities instead and separate out constants
* [MIEB] Fix VISTA model (#1638)
Fix vista
* Warn (#1639)
* [mieb] model task modalities matching logic (#1640)
fixing task &amp; model modalities matching logic
* [mieb] Use mock abstask classes (#1648)
* rename to downsampled_dataset_transform
* add mock tasks for mieb
* wip getting to 57%
* make lint
* update mock classes to improve coverage
* omit mock tasks from some tests
* [MIEB] Add code for GME models (#1635)
* Add GME
* Fix infoseek prompts
* Merge instructions
* fix: add version check e5-v in mieb (#1723)
* add version check for e5v model
* Update e5_v.py
* make lint
* fix: change comparison to bigger than (#1743)
change comparison to bigger than
* docs: Rework MIEB docs (#1802)
* combine mieb docs and move to main docs folder
* make flow more coherent
* tidy up
* skip AfriSentiLID for now #1785
* fix typo: exclude MIEB mock tests
* update vista doc
* Apply suggestions from code review
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* [mieb] Remove results-mieb folder (#1815)
remove results-mieb folder
* [mieb] fixing lrap computation for multi-label classification (#1834)
multi-label cls lrap computation fix
* [mieb] Merge from main (#1853)
* Update tasks table
* 1.19.0
Automatically generated by python-semantic-release
* fix: Add the_ugly_duckling.txt for speedtask to Python wheel (#1402)
Add the_ugly_duckling.txt for speedtask to Python wheel
* 1.19.1
Automatically generated by python-semantic-release
* fix: Added the necessary trust_remote_code (#1406)
* 1.19.2
Automatically generated by python-semantic-release
* docs: Update recommendation for pushing results (#1401)
fix: Update recommendation for pushing results
* docs: Fix a typo in README (#1430)
Fix typo in readme
* fix: add logging for RetrievalEvaluator NaN values for similarity scores (#1398)
Fixes #1389
* 1.19.3
Automatically generated by python-semantic-release
* fix: make samples_per_label a task attribute (#1419)
make samples_per_label a task attr
* fix: Add Korean AutoRAGRetrieval (#1388)
* feat: add AutoRAG Korean embedding retrieval benchmark
* fix: run --- ðŸ§¹ Running linters ---
ruff format . 			# running ruff formatting
716 files left unchanged
ruff check . --fix  	# running ruff linting
All checks passed!
* fix: add metadata for AutoRAGRetrieval
* change link for markers_bm
* add AutoRAGRetrieval to init.py and update metadata
* add precise metadata
* update metadata: description and license
* delete descriptive_stats in AutoRAGRetrieval.py and run calculate_matadata_metrics.py
* fix: Add missing benchmarks in benchmarks.py (#1431)
Fixes #1423
* Update tasks table
* 1.19.4
Automatically generated by python-semantic-release
* Leaderboard 2.0: added performance x n_parameters plot + more benchmark info (#1437)
* Added elementary speed/performance plot
* Refactored table formatting code
* Bumped Gradio version
* Added more general info to benchmark description markdown block
* Adjusted margin an range on plot
* Made hover information easier to read on plot
* Made range scaling dynamic in plot
* Moved citation next to benchmark description
* Made titles in benchmark info bold
* Leaderboard: Fixed code benchmarks (#1441)
* fixed code benchmarks
* fix: Made n_parameters formatting smarter and more robust
* fix: changed jina-embeddings-v3 number of parameters from 572K to 572M
* fix: Fixed use_instuctions typo in model overview
* fix: Fixed sentence-transformer compatibility switch
* Ran linting
* Added all languages, tasks, types and domains to options
* Removed resetting options when a new benchmark is selected
* All results now get displayed, but models that haven&#39;t been run on everything get nan values in the table
* fix: Count unique texts, data leaks in calculate metrics (#1438)
* add more stat
* add more stat
* update statistics
* fix: update task metadata to allow for null (#1448)
* Update tasks table
* 1.19.5
Automatically generated by python-semantic-release
* Fix: Made data parsing in the leaderboard figure more robust (#1450)
Bugfixes with data parsing in main figure
* Fixed task loading (#1451)
* Fixed task result loading from disk
* Fixed task result loading from disk
* fix: publish (#1452)
* 1.19.6
Automatically generated by python-semantic-release
* fix: Fix load external results with `None` mteb_version (#1453)
* fix
* lint
* 1.19.7
Automatically generated by python-semantic-release
* WIP: Polishing up leaderboard UI (#1461)
* fix: Removed column wrapping on the table, so that it remains readable
* Added disclaimer to figure
* fix: Added links to task info table, switched out license with metric
* fix: loading pre 1.11.0 (#1460)
* small fix
* fix: fix
* 1.19.8
Automatically generated by python-semantic-release
* fix: swap touche2020 to maintain compatibility (#1469)
swap touche2020 for parity
* 1.19.9
Automatically generated by python-semantic-release
* docs: Add sum per language for task counts (#1468)
* add sum per lang
* add sort by sum option
* make lint
* fix: pinned datasets to &lt;3.0.0 (#1470)
* 1.19.10
Automatically generated by python-semantic-release
* feat: add CUREv1 retrieval dataset (#1459)
* feat: add CUREv1 dataset
---------
Co-authored-by: nadshe &lt;nadia.sheikh@clinia.com&gt;
Co-authored-by: olivierr42 &lt;olivier.rousseau@clinia.com&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel@buad.es&gt;
* feat: add missing domains to medical tasks
* feat: modify benchmark tasks
* chore: benchmark naming
---------
Co-authored-by: nadshe &lt;nadia.sheikh@clinia.com&gt;
Co-authored-by: olivierr42 &lt;olivier.rousseau@clinia.com&gt;
* Update tasks table
* 1.20.0
Automatically generated by python-semantic-release
* fix: check if `model` attr of model exists (#1499)
* check if model attr of model exists
* lint
* Fix retrieval evaluator
* 1.20.1
Automatically generated by python-semantic-release
* fix: Leaderboard demo data loading (#1507)
* Made get_scores error tolerant
* Added join_revisions, made get_scores failsafe
* Fetching metadata fixed fr HF models
* Added failsafe metadata fetching to leaderboard code
* Added revision joining to leaderboard app
* fix
* Only show models that have metadata, when filter_models is called
* Ran linting
* 1.20.2
Automatically generated by python-semantic-release
* fix: leaderboard only shows models that have ModelMeta (#1508)
Filtering for models that have metadata
* 1.20.3
Automatically generated by python-semantic-release
* fix: align readme with current mteb (#1493)
* align readme with current mteb
* align with mieb branch
* fix test
* 1.20.4
Automatically generated by python-semantic-release
* docs: Add lang family mapping and map to task table (#1486)
* add lang family mapping and map to task table
* make lint
* add back some unclassified lang codes
* Update tasks table
* fix: Ensure that models match the names on embedding-benchmarks/results (#1519)
* 1.20.5
Automatically generated by python-semantic-release
* fix: Adding missing metadata on models and mathcing names up with the results repo (#1528)
* Added Voyage 3 models
* Added correct metadata to Cohere models and matched names with the results repo
* 1.20.6
Automatically generated by python-semantic-release
* feat: Evaluate missing splits (#1525)
* fix: evaluate missing splits (#1268)
* implement partial evaluation for missing splits
* lint
* requested changes done from scratch
* test for missing split evaluation added
* uncomment test
* lint
* avoid circular import
* use TaskResult
* skip tests for now
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* got test_all_splits_evaluated passing
* tests passing
* address review comments
* make lint
* handle None cases for kg_co2_emissions
* use new results info
---------
Co-authored-by: Thivyanth &lt;thivyanth2004@gmail.com&gt;
* 1.21.0
Automatically generated by python-semantic-release
* fix: Correct typos superseeded -&gt; superseded (#1532)
fix typo -&gt; supersededâ€¦

* lint

* rename test file to resolve pytest conflicts

* Add LoTTE Benchmark to MTEB (#2009)

* Add LoTTE Benchmark to MTEB

* incorporated PR feedback

* incorporating pr feedback across the board

* loads data correctly

* Update mteb/tasks/Retrieval/eng/LoTTERetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Custom load_data for LoTTE: iterate domains then splits; auto-download dataset if missing

* bug fixes

* all make tests pass

* no merging

* ensuring tasks can be run

* fixed structure

* refactor task loading

* add splits everywhere

* lint

* fix imports

* temporary allow url

* upload lotte to mteb

* fix model2vec

* remove abstract from citation

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* Integrate Birco V2 (#2022)

* Birco Datasets Added to V2

* Birco added to INIT files

* Fixed ndcg typo

* Changed Class to Function + Instructions Format Fixed

* MetaData Fix + Test Skeleton

* Instruction Structure inside metadata

* Ran Lint

* Removed Birco Base Class

* More Formatting

* Separate Birco Classes

* Finalized BIRCO Datasets Structures

* test split typo fix

* Fixed Train-&gt;Test

* Added .vscode folder

* Added more info in HF readme

* Removed function added by mistake

* Qrels config changed to Default

* Ran calculate_metadata

* Removed Unnecessary Files

* Ran make lint

---------

Co-authored-by: AdnanElAssadi56 &lt;adnan@LAPTOP-M2FFLBCE.localdomain&gt;
Co-authored-by: AdnanElAssadi56 &lt;adnan@LAPTOP-M2FFLBCE&gt;

* Convert task category to indicate modality (#2107)

* convert s2p -&gt; t2t

* convert s2s -&gt; t2t

* convert p2p -&gt; t2t

* update docs

* update jsaper model

* convert missed ones

* Add PUGGRetrieval task for the Polish language

* Add PUGGRetrieval

* Merge main into v2 (#2116)

* Merge main into v2

* format

* tests collect

* most tests now pass

* add missing desc. stats

* format and remove junk file

* add BuiltBenchReranking to old format reranking

* update imports

* add missing descriptive stats

* Added missing desc stats

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* [v2] reupload reranking datasets in old format (#2097)

* reupload namaa

* download only dev split

* try to load

* upload all tasks

* remove duplications

* fix task loading

* load splits correctly

* fix split loader

* lint

* get back reranking class

* get back reranking class

* reupload BuiltBenchReranking

* [v2]Â Merge from main (#2145)

* test: fix dataset availability test (#2141)

This simplified the test and also make it a lot simpler. It also removed about 100 test cases which where all to the same API call.

* fix: Update NVIDIA-Embed training data (#2143)

Added a few missing annotations for nvidia-embed

* 1.34.29

Automatically generated by python-semantic-release

* fix: Add annotations for Voyage exp (#2144)

* fix: Update NVIDIA-Embed training data

Added a few missing annotations for nvidia-embed

* fix update annotationf for voyage exp

---------

Co-authored-by: github-actions &lt;github-actions@github.com&gt;

* [v2] test: Pylate version 1.1.6 (#2190)

* wip: pylate chor

* chor pylate

* add Enum to test ModelMeta

---------

Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;

* Update mteb/tasks/Retrieval/pol/PUGGRetrieval.py

* add metadatafile

* [v2] Merge main (#2204)

* test: fix dataset availability test (#2141)

This simplified the test and also make it a lot simpler. It also removed about 100 test cases which where all to the same API call.

* fix: Update NVIDIA-Embed training data (#2143)

Added a few missing annotations for nvidia-embed

* 1.34.29

Automatically generated by python-semantic-release

* fix: Add annotations for Voyage exp (#2144)

* fix: Update NVIDIA-Embed training data

Added a few missing annotations for nvidia-embed

* fix update annotationf for voyage exp

* 1.34.30

Automatically generated by python-semantic-release

* Fix tokens num in cde models (#2148)

fix tokens

* feat: Add Qodo-Embed-1-7B model metadata and rename existing model (#2146)

* feat: Add Qodo-Embed-1-7B model metadata and rename existing model

* lint

* fix revision

* update license name

---------

Co-authored-by: Tal Sheffer &lt;tal.s@codium.ai&gt;

* 1.35.0

Automatically generated by python-semantic-release

* misc: add Any2AnyRetrievalDescriptiveStatistics (#2139)

add Any2AnyRetrievalDescriptiveStatistics

* Update tasks table

* Added zero-shot percentages and different filtering scheme (#2153)

* Added zero-shot percentages and different filtering scheme

* Update mteb/model_meta.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: Incorrect annotations for Mistral-based embedding models (#2157)

Fixes #2155

* 1.35.1

Automatically generated by python-semantic-release

* Update FaMTEBRetrieval.py (#2171)

The URL pointed to the settings page instead of the main repo URL. Now it is fixed.

* Update tasks table

* fix: Add Training data annotations (#2173)

* redo to voyage to only training data

* Add training data annotation for Kalm embeddings #2168

* Add correct training data annotations to Stella #2164

* removed fiqa PL as it does not exist

* remove ArxivClusteringS2S.v2 as it does not exist

* Add training data annotation for GIST embedding #2166

* fix max tokens for kalm models #2162

* remove eli 5

* 1.35.2

Automatically generated by python-semantic-release

* feat: Add MIEB and MIEB-lite as benchmarks (#2035)

* add mieb and mieb-lite to benchmarks

* add CompositionalityEvaluation and DocumentUnderstanding types

* add VisionCentric type

* add missing comma

* split STS17MultilingualVisualSTS and STSBenchmarkMultilingualSTS to eng and non-eng

* use aggregate task instead so we can name the subsets

* shorten names

* fix import

* alternative strategy to avoid using get_task

* follow other aggregate tasks and skip metadata test

* run LB without errors when selecting MIEB(-lite)

* add back the capability as taks type

* typo

* extend description

* split into mieb(eng) and mieb(multilingual)

* remove unneeded files

* remove aggtask additions for test

* edit descriptions based on screenshots

* shorten

* rename to Compositionality and include ImageCoDeT2IMultiChoice

* re-tag missing VisionCentric tasks

* re-tag rparis and roxford as retrieval and include fixes

* re-tag voc2007 as image cls

* make lint

* correct num task types in descriptions

* add one model to models_to_annotate

* add mieb reference models

* update task types

* relabel to multilingual retrieval task type to align with paper

* fix reference and bibtex

* edit task list to match with final list

* add back agg task to reproduce table column in paper

* fix filtering and import

* update tests

* mieb lite add back missing tasks

* fix metadata test

* multi should have all 4 variants

* fix task counts

* lite has 10 task types

* fix visualSTS-17 lang splits

* Aggregate task can now use subsets &amp; eval langs to filter TaskResults

* fix test and mark VisualSTS17 as multilingual

* fix tests

* add agg task running script

* add voyage meta

* fix citations

* capitalize

* add coarse/fine labels

---------

Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;

* Update tasks table

* 1.36.0

Automatically generated by python-semantic-release

* fix: update training datasets and revision for jina models (#2179)

* feat: update training datasets and revision for jina models

* feat: update training datasets and revision for jina models

* fix: Add more training data annotations (#2178)

* redo to voyage to only training data

* Add training data annotation for Kalm embeddings #2168

* Add correct training data annotations to Stella #2164

* removed fiqa PL as it does not exist

* remove ArxivClusteringS2S.v2 as it does not exist

* Add training data annotation for GIST embedding #2166

* fix max tokens for kalm models #2162

* remove eli 5

* fix: add training data for Bilingual Embeddings

fixes #2167

* 1.36.1

Automatically generated by python-semantic-release

* Added training data annotation for e5-base-4k (#2186)

* fix: Added training data annotations to MXBAI (#2185)

* fix: Update MTEB(Scandinavian) to use new DanFEVER (#2180)

This also resolves the missing data in the leaderboard.

Fixes #2172

* fix: Added training data annotation for MMLW models (#2188)

* Added training data annotation for MMLW models

* Added GIST annotations Kenneth missed

* Added Stella en 400m training data&#39;

* 1.36.2

Automatically generated by python-semantic-release

* fix: Added training data for sentence-croissant (#2189)

* 1.36.3

Automatically generated by python-semantic-release

* fix: update ru models annotation (#2181)

* 1.36.4

Automatically generated by python-semantic-release

* fix: Alphabetical ordering of tasks in dropdowns (#2191)

* 1.36.5

Automatically generated by python-semantic-release

* misc: Speed up qrel creation in any2anyretrieval (#2196)

* use numpy vectorized operations instead of row-by-row

* scores are int

* use &#39;mteb.MTEB&#39; instead of &#39;MTEB&#39; for custom model (#2199)

* lint

* fix code carbon

* fix aggregated

* add base models for e5 (#2183)

* add similar datasets (#2205)

* add similar datasets

* add nano

* update is filled

* Update mteb/abstasks/TaskMetadata.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* add labse annotation (#2182)

* add labse annotation

* Update mteb/models/sentence_transformers_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* fix: Fixed leaderboard crash (#2221)

* Fixed leaderboard crash

* Fixed language selection error

* Ran linting

* 1.36.6

Automatically generated by python-semantic-release

* fix: More training data annotations (#2220)

* Added training  data annotation for bge-gemma

* Added missing annotations for Voyage models

* Added training data for sts-multilingual-mpnet

* Added all mteb datasets to STS-multilingual training data

* 1.36.7

Automatically generated by python-semantic-release

* Add LLM2CLIP (OpenAI variants) (#2222)

* model loading and get_text_embeddings

* add image_emb, fused_emb, and calc probs methods

* add b16 model

* add llm2clip_openai_l_14_224 (not working yet)

* got llm2clip_openai_l_14_224 working

* make lint

* add training sets and allow py files

* Change `dataset on HF` test to use official api (#2213)

* refactor dataset checking

* increase timeout

* increase timeout

* remove timeout

* Descriptive stats functions for Any2AnyMC and ImageTextPC (#2197)

* Add Any2AnyMC descriptive stats

* Add descriptive stats function for ImageTextPC

* add descriptive stats examples

* linter

* update multi choice descriptive stats

* Update tasks table

* fix: Add training data annotations to uderver-bloom models (#2210)

* fix: Add training data annotations to uderver-bloom models

fixes #2193

* fix: add mixedbread

---------

Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;

* 1.36.8

Automatically generated by python-semantic-release

* Add comment to `voyage-3-m-exp` model (#2229)

* remove model size from voyage-3-m-exp model

* Update mteb/models/voyage_models.py

* Update mteb/models/voyage_models.py

* docs: Update description of EURLex (#2231)

* Automatically add similar tasks to training_tasks (#2228)

* refactor dataset checking

* increase timeout

* increase timeout

* remove timeout

* start

* automatically find datasets

* update comment

* fix aggregate task metadata

* fixes

* lint

* rename

* update fetch check

* lint

* refactor

* update BEIR-PL annotation

* fix

* update test

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: talshef &lt;tsheffer@gmail.com&gt;
Co-authored-by: Tal Sheffer &lt;tal.s@codium.ai&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
Co-authored-by: garciasces &lt;garciasces@madrid.es&gt;
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
Co-authored-by: Wang Bo &lt;bo.wang@jina.ai&gt;
Co-authored-by: Munot Ayush Sunil &lt;munotayush6@kgpian.iitkgp.ac.in&gt;
Co-authored-by: Yaya Sy &lt;58347382+yaya-sy@users.noreply.github.com&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* fix: Allow model to output torch.tensor (#2234)

* fix: Allow model to output torch.tensor

Adressed aspects of https://github.com/embeddings-benchmark/mteb/issues/941

# further problems
1) Unsqueeze not in array API spec, we should use expand_dims, but torch does not implement this (https://github.com/pytorch/pytorch/issues/56774). We can use reshape instead.
2) What to do with torch.functional? We would have to reimplent these to make it work.

We have a few cases of torch.compile. Which are called every time the function is called. They seem to have been added by @orionw, do we expect that these speed this up (they are compiled every time the function is called)

* remove kNN-Pytorch as it is supported by scikit-learn&gt;=1.4.0

* fixed missing imports

* cleanup

* [v2] Refactor text tasks to use DataLoader (#2198)

* update text tasks except retrieval

* update retrieval

* fix mock models

* remove change to model card

* fix tests

* fix tests

* fix tests

* change loaders to batches

* update review comments

* update clustering

* update classification

* use datasets

* lint

* Update mteb/abstasks/AbsTaskClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* update evaluators

* update clustering test

* Update mteb/abstasks/AbsTaskClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* update clustering and multilabel classification

* integrate conversations

* add conversation type to annotations

* lint

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* [v2] Merge main (#2324)

* 1.36.11

Automatically generated by python-semantic-release

* fix: Added Filter Modality (#2262)

* Added Filter Modality

* resolve suggestions

* make lint

* make sure test pass

* make lint

* added exclusive_modality_filter and unit tests

* Integrate tests on overview.py

* Update tests/test_overview.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* added task related to image modality

* Update mteb/abstasks/AbsTask.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/abstasks/AbsTask.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* update overview..py

* make lint

* update documentation

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* 1.36.12

Automatically generated by python-semantic-release

* fix: Add `ModelMeta` license &amp; custom validations (#2293)

* license validation

* move licenses

* update imports

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* 1.36.13

Automatically generated by python-semantic-release

* ci: Add pre-commit hook (#2194)

* make dev life nicer - pre-commit hooks

* add pre-commit to install

* update precommit

* update ruff pre-commit

* lint

* lint

---------

Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;

* Update tasks table

* fix: bug in voyage implementation (#2304)

* fix: Fix bug in voyage implementation

&#34;passage&#34; is not a valid input for the voyage API. Remapped to &#34;document&#34;.

* Update mteb/models/voyage_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* 1.36.14

Automatically generated by python-semantic-release

* fix: Update voyage name to include Org. (#2322)

* 1.36.15

Automatically generated by python-semantic-release

* Added VDR Model (#2290)

* Added VDR Model

* change custom wrapper to SentenceTransformer Wrapper

* remove kwargs and add TODO for Image Modality

* Update mteb/models/vdr_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* lint

* fix license

---------

Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Munot Ayush Sunil &lt;munotayush6@kgpian.iitkgp.ac.in&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Sam &lt;40773225+sam-hey@users.noreply.github.com&gt;
Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;

* Merge main -&gt; v2 (#2347)

* Merge main -&gt; v2

* fix webfaq datasets

* Introduce loader_kwargs [v2] (#2348)

* Merge main -&gt; v2

* fix webfaq datasets

* Introduce loader_kwargs

- removed all partials from loader args and moved them to new arg, loader_kwargs
- explicitly added the loader as sentence_transformers_loader, now None is not impl. - as a consequence I removed the `no_model_implementation_available` implementation.
- fixed similarity_fn_name to Enum where I saw it
- fixed typing issue where I saw it

fixes  #1779

Also:
- Should remove the bedrock version of cohere models @Samoed (I am unsure why we have them implemented)

* fix: repllama models

* fix tests and revert a few issues

* fixes for repllama models

* fix cohere

* fix and add tests for MockEncoders

* [v2] Change task categories (#2352)

change task categories

* fix: remove encode_corpus/query from `gme_v_models` (#2388)

fix: remove encode_corpus/query

fixes: #1284

* [v2] Refactor mieb to dataloaders (#2294)

* update zershot

* add classification

* add clustering

* add sts

* add text2multiplechoice

* lint

* refactor model loaders

* refactor retrieval/reranking

* refactor to image_dataloader

* refactor ImageTextPairClassificationEvaluator

* fix errors

* refactor ImageTextPairClassificationEvaluator

* small cleanup

* add transforms

* update tests

* try to fix scores

* fix after changes

* upd

* remove print

* refactor loaders

* add nomic

* fix models

* fix vista model path

* remove convert to pil

* Merge main (#2391)

* fix: Resolve conflicting dependencies (#2323)

These errors where discovered when trying to install the package using `uv`.

We have a problem with salesforce-lavis, which is not compatible with the current set of dependencies.

* 1.36.16

Automatically generated by python-semantic-release

* fix: remove SyntaxWarnings in py312 (#2325)

* fix: Resolve conflicting dependencies

These errors where discovered when trying to install the package using `uv`.

We have a problem with salesforce-lavis, which is not compatible with the current set of dependencies.

* fix: Remove syntax warnings occuring in python 3.12

```
Python 3.12.0 (main, Oct  2 2023, 20:56:14) [Clang 16.0.3 ] on darwin
Type &#34;help&#34;, &#34;copyright&#34;, &#34;credits&#34; or &#34;license&#34; for more information.
&gt;&gt;&gt; import mteb # no syntax warnings
&gt;&gt;&gt;
```

* 1.36.17

Automatically generated by python-semantic-release

* fix: add annotation models for stella zh (#2277)

* fix: add annotation models for stella zh

Additionally fixed a few annotation errors

* format

* Update mteb/models/stella_models.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* 1.36.18

Automatically generated by python-semantic-release

* fix: Add ModelMeta rubert-mini-frida, BERTA (#2330)

* Add rubert-mini-frida model meta

* Add BERTA model meta

* docs: fix typos

* 1.36.19

Automatically generated by python-semantic-release

* fix: Add WebFAQ bitext mining tasks (#2326)

* Add WebFAQ bitext mining tasks

Signed-off-by: Michael Dinzinger &lt;michael.dinzinger@uni-passau.de&gt;

* Lower number of language pairs in WebFAQBitextMining

Signed-off-by: Michael Dinzinger &lt;michael.dinzinger@uni-passau.de&gt;

---------

Signed-off-by: Michael Dinzinger &lt;michael.dinzinger@uni-passau.de&gt;

* Update tasks table

* 1.36.20

Automatically generated by python-semantic-release

* fix: Add `trust_remote_code` to MIRACLRetrieval

* fix: Add `trust_remote_code` to MIRACLRetrieval (#2344)

* 1.36.21

Automatically generated by python-semantic-release

* fix: Correctly pass trust remote code to Miracl

* fix: Ensure MIRACL pass trust_remote_code (#2346)

* fix: Add `trust_remote_code` to MIRACLRetrieval

* fix: Correctly pass trust remote code to Miracl

* fix

* 1.36.22

Automatically generated by python-semantic-release

* add-Data Korean Clustering dataset (KLUE-modified) (#2283)

* add PatentFnBClustering.py

* do make lint and revise

* rollback Makefile

* Update mteb/tasks/Clustering/kor/PatentFnBClustering.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* klue_mrc_domain

* make lint

* klue_modified_clustering_dataset

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Rename dunzhang and Jasper models to NovaResearch (#2373)

* Rename dunzhang and Jasper models to NovaResearch

* rename model in tests

* correct reference link

* correct MIEB dataset stats (#2374)

* correct stats

* update Any2AnyMultiChoice qrels stats compute logic

* final correction

* Update tasks table

* Correct -1 to No information in Zero shot (#2381)

* fix leaderboard (#2385)

* fix: Reduce logging and Warnings (#2349)

* Reduce logging and Warnings

* make lint

* format license to lowercase

* Address all comments

* Update mteb/leaderboard/app.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* 1.36.23

Automatically generated by python-semantic-release

* fix: b1ade (#2386)

* fix: added b1ade_models.py (#2340)

* added b1ade_models.py

* changing based on requested

* Update mteb/models/b1ade_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* fix: missing import and formatting

---------

Co-authored-by: Shreyas Subramanian &lt;shreyas.f117@gmail.com&gt;

* 1.36.24

Automatically generated by python-semantic-release

* fix: pin gradio dependency to ensure leaderboards works (#2387)

* 1.36.25

Automatically generated by python-semantic-release

* fix

* fix

---------

Signed-off-by: Michael Dinzinger &lt;michael.dinzinger@uni-passau.de&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: sergeyz-zh &lt;49659999+sergeyz-zh@users.noreply.github.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: Michael Dinzinger &lt;39766249+michaeldinzinger@users.noreply.github.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: OnandOn &lt;76710635+OnAnd0n@users.noreply.github.com&gt;
Co-authored-by: Munot Ayush Sunil &lt;munotayush6@kgpian.iitkgp.ac.in&gt;
Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
Co-authored-by: Shreyas Subramanian &lt;shreyas.f117@gmail.com&gt;

* fix name for NovaSearch

* [v2] Merge main (#2412)

* fix: Ensure BrightRetrieval is valid to run (#2334)

* fix: Ensure BrightRetrieval is valid to run

Not sure this is the best way to fix this. Let me know if you can find a better fix.

fixes #2327

* fix: convert brightretrieval to two tasks

* fix collecting error

* Update tasks table

* 1.36.26

Automatically generated by python-semantic-release

* Pass task name to all evaluators (#2389)

* pass task name to all tasks

* add test

* fix loader

* fix: renaming Zeroshot -&gt; ZeroShot (#2395)

* fix: renaming Zeroshot -&gt; ZeroShot

Adresses #2078

* rename 1

* rename 2

* format

* fixed error

* 1.36.27

Automatically generated by python-semantic-release

* fix: Update AmazonPolarityClassification license (#2402)

Update AmazonPolarityClassification.py

* fix b1ade name (#2403)

* 1.36.28

Automatically generated by python-semantic-release

* Minor style changes (#2396)

* fix: renaming Zeroshot -&gt; ZeroShot

Adresses #2078

* fix: minor style changes

Adresses #2078

* rename 1

* rename 2

* format

* fixed error

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Added new dataset and tasks - ClusTREC-covid , clustering of thematic covid related scientific papers  (#2302)

* Clustrec covid new dataset and task

* fix

* fix

* fix

* fix

* fix

* descriptive stats

* change all mentions of clustrec-covidp2p to clustrec-covid

* change &#39; to &#34;

* Update tasks table

* fix: Major updates to docs + make mieb dep optional (#2397)

* fix: renaming Zeroshot -&gt; ZeroShot

Adresses #2078

* fix: minor style changes

Adresses #2078

* fix: Major updates to documentation

This PR does the following:
- This introduced other modalities more clearly in the documentation as well as make it easier to transition to a full on documentation site later.
- added minor code updates due to discovered inconsistencies in docs and code.
- Added the MMTEB citation where applicable
- makes the docs ready to move torchvision to an optional dependency

* Moved VISTA example

* rename 1

* rename 2

* format

* fixed error

* fix: make torchvision optional (#2399)

* fix: make torchvision optional

* format

* add docs

* minor fix

* remove transform from Any2TextMultipleChoiceEvaluator

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* move Running SentenceTransformer model with prompts to usage

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* 1.36.29

Automatically generated by python-semantic-release

* remove Arabic_Triplet_Matryoshka_V2.py (#2405)

* update imports

* add stats

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Uri K &lt;37979288+katzurik@users.noreply.github.com&gt;

* [v2] update `ScoringFunction` &amp; set models to use Enum (#2383)

* update enums

* add max

* add codecarbon to gitignore

* update enums get value

* add cosine enum for b1ade model

* rm MAX

---------

Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;

* fix: Enable NPY ruleset for v2

* [v2] Merge main (#2485)

* [MIEB] &#34;capability measured&#34;-Abstask 1-1 matching refactor [1/3]: reimplement CV-Bench (#2414)

* refactor CV-Bench

* reimplement CV Bench

* remove abstask/evaluator/tests for Any2TextMultipleChoice

* rerun descriptive stats

* Update tasks table

* fix: Add option to remove benchmark from leaderboard (#2417)

fix: Add option to remove leaderboard from leaderboard

fixes #2413

This only removed the benchmark from the leaderboard but keep it in MTEB.

* 1.36.31

Automatically generated by python-semantic-release

* fix: Add VDR Multilingual Dataset (#2408)

* Added VDR Multilingual Dataset

* address comments

* make lint

* Formated Dataset for retrieval

* Update mteb/tasks/Retrieval/multilingual/VdrMultilingualRetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/tasks/Retrieval/multilingual/VdrMultilingualRetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* make lint

* corrected date

* fix dataset building

* move to image folder

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Update tasks table

* 1.36.32

Automatically generated by python-semantic-release

* HOTFIX: pin setuptools (#2423)

* pin setuptools

* pin setuptools

* pin setuptools in makefile

* try ci

* fix ci

* remove speed from installs

* add __init__.py Clustering &gt; kor folder,  And   edit __init__.py in Clustering folder (#2422)

* add PatentFnBClustering.py

* do make lint and revise

* rollback Makefile

* Update mteb/tasks/Clustering/kor/PatentFnBClustering.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* klue_mrc_domain

* make lint

* klue_modified_clustering_dataset

* clustering &amp; kor folder add __init.py

* clustering &amp; kor folder add __init__.py

* task.py roll-back

* correct text_creation to sample_creation &amp; delete form in MetaData

* correct task_subtype in TaskMetaData

* delete space

* edit metadata

* edit task_subtypes

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update tasks table

* Update speed dependencies with new setuptools release (#2429)

* add richinfoai models (#2427)

* add richinfoai models

add richinfoai models

* format codes by linter

format codes by linter

* Added Memory Usage column on leaderboard (#2428)

* docs: typos; Standardize spacing; Chronological order (#2436)

* Fix typos; add chrono order

* Fix spacing

* fix: Add model specific dependencies in pyproject.toml (#2424)

* Add model specific dependencies in pyproject.toml

* Update documentation

* 1.36.33

Automatically generated by python-semantic-release

* [MIEB] &#34;capability measured&#34;-Abstask 1-1 matching refactor [2/3]: reimplement r-Oxford and r-Paris (#2442)

* MutipleChoiceEvaluationMixin; reimplement r-Oxford and r-Paris; rerun stats

* modify benchmark list

* fix citation

* Update tasks table

* Error while evaluating MIRACLRetrievalHardNegatives: &#39;trust_remote_code&#39; (#2445)

Fixes #2444

* Feat/searchmap preview (#2420)

* Added meta information about SearchMap_Preview model to the model_dir

* Added meta information about SearchMap_Preview model to the model_dir

* updated revision name

* Device loading and cuda cache cleaning step left out

* removed task instructions since it&#39;s not necessary

* changed sentence transformer loader to mteb default loader and passed instructions s model prompts

* Included searchmap to the models overview page

* Included searchmap to the models overview page

* added meta data information about where model was adpated from

* Update mteb/models/searchmap_models.py

* fix lint

* lint

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* Add Background Gradients in Summary and Task Table (#2392)

* Add Background Gradients in Summary and Task Table

* Remove warnings and add light green cmap

* Address comments

* Separate styling function

* address comments

* added comments

* add ops_moa_models (#2439)

* add ops_moa_models

* add custom implementations

* Simplify custom implementation and format the code

* support SentenceTransformers

* add training datasets

* Update mteb/models/ops_moa_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* update training_datasets

---------

Co-authored-by: kunka.xgw &lt;kunka.xgw@taobao.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* leaderboard fix (#2456)

* ci: cache `~/.cache/huggingface` (#2464)

ci: cache ~/.cache/huggingface

Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;

* [MIEB] &#34;capability measured&#34;-Abstask 1-1 matching refactor [3/3]: reimplement ImageCoDe (#2468)

* reimplement ImageCoDe with ImageTextPairClassification

* add missing stats file

* Update tasks table

* fix: Adds family of NeuML/pubmedbert-base-embedding models (#2443)

* feat: added pubmedbert model2vec models

* fix: attribute model_name

* fix: fixed commit hash for pubmed_bert model2vec models

* fix: changes requested in PR 2443

* fix: add nb_sbert model (#2339)

* add_nb_sbert_model

* Update nb_sbert.py

added n_parameters and release_date

* Update mteb/models/nb_sbert.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update nb_sbert.py

fix: make lint

* added nb_sbert to overview.py + ran make lint

* Update nb_sbert.py

Fix error: Input should be a valid date or datetime, month value is outside expected range of 1-12

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* 1.36.34

Automatically generated by python-semantic-release

* suppress logging warnings on leaderboard (#2406)

* supress logging warnings

* remove loggers

* return blocks

* rename function

* fix gme models

* add server name

* update after merge

* fix ruff

* fix: E5 instruct now listed as sbert compatible (#2475)

Fixes #1442

* 1.36.35

Automatically generated by python-semantic-release

* [MIEB] rename VisionCentric to VisionCentricQA (#2479)

rename VisionCentric to VisionCentricQA

* ci: Run dataset loading only when pushing to main (#2480)

Update dataset_loading.yml

* fix table in tasks.md (#2483)

* Update tasks table

* fix imports

* update model loader

* remove unused imports

* fix clip name

* fix moco models

* fix tests

* fix tests

---------

Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Munot Ayush Sunil &lt;munotayush6@kgpian.iitkgp.ac.in&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: OnandOn &lt;76710635+OnAnd0n@users.noreply.github.com&gt;
Co-authored-by: richinfo-ai &lt;richinfoai@163.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: Adewole Babatunde &lt;40810247+Free-tek@users.noreply.github.com&gt;
Co-authored-by: ahxgw &lt;ahxgwOnePiece@gmail.com&gt;
Co-authored-by: kunka.xgw &lt;kunka.xgw@taobao.com&gt;
Co-authored-by: Sam Heymann &lt;40773225+sam-hey@users.noreply.github.com&gt;
Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
Co-authored-by: Nadia Sheikh &lt;144166074+nadshe@users.noreply.github.com&gt;
Co-authored-by: theatollersrud &lt;thea.tollersrud@nb.no&gt;

* [v2] New encoder interface (#2415)

* update mteb

* fix docs

* fix docs

* fix docs

* update image tasks

* update models

* fix imports

* fix mteb meta name

* fix mock model

* fix mock model

* fixes

* fix similarity

* fix tests

* Update docs/adding_a_model.md

* change similarity to custom

* add vision similarity

* refactor scoring function values to use .value attribute

* fixes

* upd clustering test

* add predict to encoder_interface.py

* fixes

* add test for encoder interface

* update cross encoder

* upd doc string

* fix cross encoder

* update encoders to use similarity

* fix cross encoder

* fix copilot review

* change to cosine

* rename abs encoder to model

* upd docs

* remove vision similarity

* all models inherit from AbsEncoder

* fix openclip loader

* make sure that loaders follow new loading format

* ouput image instead of tesnsor

* [v2] Remove speed task (#2492)

* remove speed tasks

* resolve comments

* remove rest of speed tasks

* [v2] set default batch_size (#2495)

* set default batch_size

* fix tests

* [v2] Change retrieval to use `self.dataset` (#2496)

* transform retrieval to use `self.dataset`

* add loader with old format

* fix tests

* refactor retrieval mock loader

* add dataset transform to retrieval

* update review

* add back retrieve time

* remove evaluate_custom

* update uploader

* fix mrr

* fix scores

* add todo comment

* [v2] Refactor retrieval dataload (#2601)

* refactor retrieval loader

* rename

* fix issue with 0 qrel

* update top_rankers

* fix corpus loading

* move brico from reranking to retrieval (#2605)

move brico to retrieval

* [v2] Dataset card generation (#2559)

* create readme generation

* update template

* remove speed

* fix dataset uploader

* fix task_categories

* move card generation to metadata

* update datasetcard template

* upd domain generation

* fix task category

* [v2] Merge dateset&#39;s readme with existing (#2625)

* add readme merge if exists

* override existing model card data params

* [v2] Merge main (#2617)

* SpeedTask add deprecated warning (#2493)

* Docs: Update README.md (#2494)

Update README.md

* fix transformers version for now (#2504)

* Fix typos (#2509)

* ci: refactor TaskMetadata eval langs test (#2501)

* refactor eval langs test

* function returns None

* add hard negaties tasks in _HISTORIC_DATASETS

* rename to ImageClustering folder (#2516)

rename folder

* Clean up trailing spaces citation (#2518)

* rename folder

* trailing spaces

* missed one

* [mieb] Memotion preprocessing code made more robust and readable (#2519)

* fix: validate lang code in ModelMeta (#2499)

* Update pyproject.toml (#2522)

* 1.36.38

Automatically generated by python-semantic-release

* Fix leaderboard version (#2524)

* fix gradio leaderboard run

* update docs

* Fix gte-multilingual-base embed_dim (#2526)

* [MIEB] Specify only the multilingual AggTask for MIEB-lite (#2539)

specify only the multilingual AggTask

* [mieb] fix hatefulmemes (#2531)

* fix hatefulmeme

* add to description and use polars instead

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Model conan (#2534)

* conan_models

* conan_models

* refactor code

* refactor code

---------

Co-authored-by: shyuli &lt;shyuli@tencent.com&gt;

* fix: Update mteb.get_tasks with an exclude_aggregate parameter to exclude aggregate tasks (#2536)

* Implement task.is_aggregate check

* Add `mteb.get_tasks` parameter `include_aggregate` to exclude aggregate tasks if needed

* Update mteb.run with the new `task.is_aggregate` parameter

* Add tests

* Ran linter

* Changed logic to `exclude_aggregate`

* Updated from review comments

* Exclude aggregate by default false in get_tasks

* 1.36.39

Automatically generated by python-semantic-release

* docs: Add MIEB citation in benchmarks (#2544)

Add MIEB citation in benchmarks

* Add 2 new Vietnamese Retrieval Datasets (#2393)

* [ADD] 2 new Datasets

* [UPDATE] Change bibtext_citation for GreenNodeTableMarkdownRetrieval as TODO

* [UPDATE] Change bibtext_citation for ZacLegalTextRetrieval as TODO

* Update tasks table

* fix: CacheWrapper per task (#2467)

* feat: CacheWrapper per task

* refactor logic

* update documentation

---------

Co-authored-by: Florian Rottach &lt;florianrottach@boehringer-ingelheim.com&gt;

* 1.36.40

Automatically generated by python-semantic-release

* misc: move MMTEB scripts and notebooks to separate repo (#2546)

move mmteb scripts and notebooks to separate repo

* fix: Update requirements in JinaWrapper (#2548)

fix: Update package requirements in JinaWrapper for einops and flash_attn

* 1.36.41

Automatically generated by python-semantic-release

* Docs: Add MIEB to README (#2550)

Add MIEB to README

* Add xlm_roberta_ua_distilled (#2547)

* defined model metadata for xlm_roberta_ua_distilled

* Update mteb/models/ua_sentence_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* included ua_sentence_models.py in overview.py

* applied linting, added missing fields in ModelMeta

* applied linting

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix me5 trainind data config to include xquad dataset (#2552)

* fix: me5 trainind data config to include xquad dataset

* Update mteb/models/e5_models.py

upddate: xquad key name

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: ME5_TRAINING_DATA format

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* feat: Added dataframe utilities to BenchmarkResults (#2542)

* fix: Added dataframe utilities to BenchmarkResults

- Added `get_results_table`. I was considering renaming it to `to_dataframe` to align with `tasks.to_dataframe`. WDYT?
- Added a tests for ModelResults and BenchmarksResults
- Added a few utility functions where needed
- Added docstring throughout ModelResults and BenchmarksResults
- Added todo comment for missing aspects - mostly v2 - but we join_revisions seems like it could use an update before then.

Prerequisite for #2454:

@ayush1298 can I ask you to review this PR as well? I hope this give an idea of what I was hinting at. Sorry that it took a while. I wanted to make sure to get it right.

* refactor to to_dataframe and combine common dependencies

* ibid

* fix revision joining after discussion with @x-tabdeveloping

* remove strict=True for zip() as it is a &gt;3.9 feature

* updated mock cache

* 1.37.0

Automatically generated by python-semantic-release

* fix e5_R_mistral_7b (#2490)

* fix e5_R_mistral_7b

* change wrapper

* address comments

* Added kwargs for pad_token

* correct lang format

* address comments

* add revision

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix unintentional working of filters on leaderboard (#2535)

* fix unintentional working of filters on leaderboard

* address comments

* make lint

* address comments

* rollback unnecessary changes

* feat: UI Overhaul (#2549)

* Bumped gradio version to latest

* Added new Gradio table functionality to leaderboard

* Removed search bar

* Changed color scheme in plot to match the table

* Added new benchmark selector in sidebar

* Changed not activated button type to secondary

* Short-circuited callbacks that are based on language selection

* Re-added column width calculation since it got messed up

* Commented out gradient for per-task table as it slowed things down substantially

* Styling and layout updates

* Adjusted comments according to reviews

* Converted all print statements to logger.debug

* Removed pydantic version fix

* Ran linting

* Remove commented out code

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Moved English,v1 to Legacy section

* Closed the benchmark sharing accordion by default

* Adjusted markdown blocks according to suggestions

* Ran linter

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* 1.38.0

Automatically generated by python-semantic-release

* add USER2 (#2560)

* add user2

* add training code

* update prompts

* Fix leaderboard entry for BuiltBench (#2563)

Fix leaderboard entry for BuiltBench (#2562)

Co-authored-by: Mehrzad Shahin-Moghadam &lt;mehr@Mehrzads-MacBook-Pro.local&gt;

* fix: jasper models embeddings having nan values (#2481)

* 1.38.1

Automatically generated by python-semantic-release

* fix frida datasets (#2565)

* Add relle (#2564)

* Add relle
* defined model metadata for relle

* Add mteb/models/relle_models.py

* Update mteb/models/relle_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* lint after commit

run after &#34;make lint&#34;

* Add into model_modules

Add model into model_modules and lint check

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Backfill task metadata for metadata for GermanDPR and GermanQuAD (#2566)

* Add metadata for GermanDPR and GermanQuAD

* PR improvements

* Update tasks table

* Add  ModelMeta for CodeSearch-ModernBERT-Crow-Plus (#2570)

* Add files via upload

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update overview.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update mteb/models/shuu_model.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Docs: Improve MIEB docs (#2569)

* Add missing annotations (#2498)

* Update tasks table

* move icon &amp; name to benchmark dataclass (#2573)

* Remove the comments from ImageEncoder (#2579)

* fix: Add Encodechka benchmark (#2561)

* add tasks

* add benchmark

* fix imports

* update stsb split

* Update tasks table

* 1.38.2

Automatically generated by python-semantic-release

* fix FlagEmbedding package name (#2588)

* fix codecarbon version (#2587)

* Add MIEB image only benchmark (#2590)

* add vision only bench

* add description

* correct zs task modalities

* specify tasks param

* Add image only MIEB benchmark to LB left panel (#2596)

* Update benchmarks.py

* make lint

* add to left side bar

* update Doubao-1.5-Embedding (#2575)

* update seed-embedding

* update seed models

* fix linting and tiktoken problem

* fix tiktoken bug

* fix lint

* update name

* Update mteb/models/seed_models.py

adopt suggestion

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* update logging

* update lint

---------

Co-authored-by: zhangpeitian &lt;zhangpeitian@bytedance.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: Add WebSSL models (#2604)

* add 2 web SSL dino models

* add models from collection and revisions

* update memory_usage_mb and embed dim

* use automodel instead

* fix mieb citation (#2606)

* 1.38.3

Automatically generated by python-semantic-release

* Update Doubao-1.5-Embedding (#2611)

* update seed-embedding

* update seed models

* fix linting and tiktoken problem

* fix tiktoken bug

* fix lint

* update name

* Update mteb/models/seed_models.py

adopt suggestion

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* update logging

* update lint

* update link

---------

Co-authored-by: zhangpeitian &lt;zhangpeitian@bytedance.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* CI: update benchmark table (#2609)

* update benchmark table

* fix table

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update Doubao-1.5-Embedding revision (#2613)

* update seed-embedding

* update seed models

* fix linting and tiktoken problem

* fix tiktoken bug

* fix lint

* update name

* Update mteb/models/seed_models.py

adopt suggestion

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* update logging

* update lint

* update link

* update revision

---------

Co-authored-by: zhangpeitian &lt;zhangpeitian@bytedance.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* CI: fix table  (#2615)

* Update tasks &amp; benchmarks tables

* fixes

* Update gradio version (#2558)

* Update gradio version

Closes https://github.com/embeddings-benchmark/mteb/issues/2557

* bump gradio

* fix: Removed missing dataset for MTEB(Multilingual) and bumped version

We should probably just have done this earlier to ensure that the multilingual benchamrk is runable.

* CI: fix infinitely committing issue (#2616)

* fix token

* try to trigger

* add token

* test ci

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* remove test lines

---------

Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;

* fix retrieval loader

* add descriptive stats

* Add ScandiSent dataset (#2620)

* add scandisent dataset

* add to init

* typo

* lint

* 1.38.4

Automatically generated by python-semantic-release

* Format all citations (#2614)

* Fix errors in bibtex_citation

* Format all bibtex_citation fields

* format benchmarks

* fix format

* Fix tests

* add formatting script

* fix citations

* update imports

* fix citations

* fix citations

* format citation

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
Co-authored-by: Munot Ayush Sunil &lt;munotayush6@kgpian.iitkgp.ac.in&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: E. Tolga Ayan &lt;33233561+tolgayan@users.noreply.github.com&gt;
Co-authored-by: lllsy12138 &lt;50816213+lllsy12138@users.noreply.github.com&gt;
Co-authored-by: shyuli &lt;shyuli@tencent.com&gt;
Co-authored-by: Siddharth M. Bhatia &lt;siddharth@sidmb.com&gt;
Co-authored-by: Bao Loc Pham &lt;67360122+BaoLocPham@users.noreply.github.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: Flo &lt;FlorianRottach@aol.com&gt;
Co-authored-by: Florian Rottach &lt;florianrottach@boehringer-ingelheim.com&gt;
Co-authored-by: Alexey Vatolin &lt;vatolinalex@gmail.com&gt;
Co-authored-by: Olesksii Horchynskyi &lt;121444758+panalexeu@users.noreply.github.com&gt;
Co-authored-by: Pandaswag &lt;110003154+torchtorchkimtorch@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
Co-authored-by: Mehrzad Shahin-Moghadam &lt;42153677+mehrzadshm@users.noreply.github.com&gt;
Co-authored-by: Mehrzad Shahin-Moghadam &lt;mehr@Mehrzads-MacBook-Pro.local&gt;
Co-authored-by: Youngjoon Jang &lt;82500463+yjoonjang@users.noreply.github.com&gt;
Co-authored-by: 24September &lt;puritysarah@naver.com&gt;
Co-authored-by: Jan KaraÅ› &lt;90987511+KTFish@users.noreply.github.com&gt;
Co-authored-by: Shuu &lt;136542198+Shun0212@users.noreply.github.com&gt;
Co-authored-by: namespace-Pt &lt;61188463+namespace-Pt@users.noreply.github.com&gt;
Co-authored-by: zhangpeitian &lt;zhangpeitian@bytedance.com&gt;

* [v2] introduce AbsAnyClassification and refactor mieb classification (#2537)

* integrating ImageTasks

* update uploading

* update typing

* move sampling

* refactor evaluators

* add more metrics

* get K directly

* create AbsAnyClassification

* remove call from abc evaluator

* fix imports

* fix descriptive stats

* update classification task handling in descriptive stats

* address review

* add mieb metadata

* fix knn metrics

* use one classifier

* update descriptive stats calculation

* update statistics

* fix test

* fix tasks classification class

* fix TalemaaderPC

* update statistics

* [v2] Create AnySTS (#2599)

* start integration any sts

* update naming

* update statistics

* update statistics

* [v2] Remove old benchmark names (#2639)

remove old benchmark names

* [v2] Add readme to all datasets (#2646)

* readme uploading

* add readme to all datasets

* [v2] split query and conversation (#2593)

* split query and conversation

* update conversation type

* always output conversations

* [v2] Fix task subtypes (#2655)

* add task subtypes

* Update mteb/abstasks/TaskMetadata.py

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

---------

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* small readme fixes

* [v2] Add task specific scores to retrieval (#2600)

* start refactor

* adapt all instruction retrieval task to custom

* move metrics to metrics file

* small refactor

* add types and use same signature

* update loader

* fix loading

* upd dataset creation

* fix tests

* fix tests

* remove qrels diff from DatasetLoader

* remove rest of qrels_diff mention

* docs: Added documentation for push_to_hub (#2747)

* fix: Specify dependencies for nomic models and ensure that they can load (#2748)

* docs: Added documentation for push_to_hub

* fix: Specify dependencies for nomic models and ensure that they can load

- added dependencies to .toml
- added require_package for error message
- reformatted the function to ensure the interface

@Samoed considered making all models implementations private (this would make a change such as the one I just made non-breaking). WDYT?

* [v2] Integrate cde models (#2076)

* start integrating

* fix clustering

* lint

* use replace

* load sentences from config

* add corpus_to_str

* lint

* always use document prefix

* always use prompt name

* refactor cde data

* rollback changes in pairclassification evaluator

* rollback changes in other classes

* update implementation

* fix cde

* fix monolingual tasks

* overwrite retrieval prompt

* fix prompt for v1 stage

* fix cde revision

* make functions private

* Merge branch &#39;main&#39; into v2.0.0 (#2760)

* Merge branch &#39;main&#39; into v2.0.0

@Samoed I have left two files unresolved (Any2AnyRetrieval.py and colbert_models.py). Will you have a look at these?

Also I believe we might be missing some task imports for retrieval

* minor formatting

* resolve conflicts

* lint

* fix score function

* make importable

* fix tests

* add descriptive stats

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* fix dataset readme (#2783)

* [v2] Merge main (#2786)

* 1.38.25

Automatically generated by python-semantic-release

* fix: Update Caltech101 datasets to latest revision [v1] (#2778)

* fix: Update Caltech101 datasets to latest revision [v2]

 fixes: #2770
Fixes the issue, but only in v1

```
# tested using:

task: mteb.AbsTask = mteb.get_task(&#34;Caltech101ZeroShot&#34;)
task.load_data()
task.get_candidate_labels()
```

* fix rev

* 1.38.26

Automatically generated by python-semantic-release

* fix: CachedEmbeddingWrapper issues in both documentation and code (#2779)

Fixes #2772

* 1.38.27

Automatically generated by python-semantic-release

* dataset: Add miracl vision (#2736)

* add miracl vision

* add miracl vision

* ruff

* cast

* image

* image

* add langs

* add langs

* add langs

* add langs

* descriptive stats

* lint

* lint

* lint

* remove com

* Update tasks &amp; benchmarks tables

* model: Add Qwen3 Embedding model (#2769)

* Init code

* Remove extra config and lint code

* use sentence transformer

* add revisions

* fix lint

* Apply suggestions from code review

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix lint

* add framework

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix loaders

---------

Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Manuel Faysse &lt;43467008+ManuelFay@users.noreply.github.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: Xin Zhang &lt;izhx404@gmail.com&gt;

* Merge main (#2794)

bump ruff (#2784)

* fix pyproject (#2797)

* Add run_task for running tasks (#2656)

* Add run_task for running tasks

This is the start the deprecation of mteb.MTEB.

The planned interface is:

```py
result: TaskResult = mteb.run_task(model, task)

results: list[TaskResult] = mteb.run_tasks(model, tasks)
```

* fix

* Added cache_strategy and overwrite_strategy

* format

* redo cache implementation following suggestions

* fixes cicular imports

* Added tests

* format

* cleanup

* format

* added corrections based on feedback

* format

* restructure test cache

* fix cache issues

* move todo to issue

* resolve tests

* fix typo in tests

* fix criteria using an Enum

* moved todos to issue #2791

* convert overwrite_strategy from literal to str | Enum

* Added deprecation warning

* format

* Add AbstaskAggregate support to run_task

* minor refactoring Enums

* Update .gitignore

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Use strEnum compatible with earlier python versions

* ensure that mteb can be imported in python 3.9

* make project uv installable

* revert enum refactors

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Make codecarbon optional (#2798)

* Add run_task for running tasks

This is the start the deprecation of mteb.MTEB.

The planned interface is:

```py
result: TaskResult = mteb.run_task(model, task)

results: list[TaskResult] = mteb.run_tasks(model, tasks)
```

* fix

* Added cache_strategy and overwrite_strategy

* format

* redo cache implementation following suggestions

* fixes cicular imports

* Added tests

* format

* cleanup

* format

* added corrections based on feedback

* format

* restructure test cache

* fix cache issues

* move todo to issue

* resolve tests

* fix typo in tests

* fix criteria using an Enum

* moved todos to issue #2791

* convert overwrite_strategy from literal to str | Enum

* Added deprecation warning

* format

* Add AbstaskAggregate support to run_task

* minor refactoring Enums

* Update .gitignore

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Use strEnum compatible with earlier python versions

* ensure that mteb can be imported in python 3.9

* make project uv installable

* formatted toml

* redisable codecarbon as a default installation

* revert enum refactors

* ensure codecarbon is present for tests

* fix grammar error

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix typo

* Update datasheet typos

based on: https://huggingface.co/datasets/mteb/CodeFeedbackST/discussions/1

* Update datasheet typos (#2805)

based on: https://huggingface.co/datasets/mteb/CodeFeedbackST/discussions/1

* Raise an error when model not found using get_model_meta instead of returning empty model_meta (#2776)

* 1) Raise an error when model not found using get_model_meta instead of returning empty model_meta
2) Added more helpful error messages

```py
import mteb

meta = mteb.get_model_meta(&#34;BAAI/bge-m3&#34;)
# Before fix: returns empty model meta and raises a warning that it was not found on HF
# expected behaviour: Raise an error

# After fix: Raises the following error:
# KeyError: &#34;Model &#39;BAI/bge-m3&#39; not found in MTEB registry nor on the Huggingface Hub. Did you mean: &#39;BAAI/bge-m3&#39; or BAAI/bge-small-zh?&#34;
```

This is technically a breaking change, I can move it to v2?

* fix undefined variable

* added loader to default model meta and now return modelmeta when it is found

* [v2]Â refactor types into a module (#2799)

* Add run_task for running tasks

This is the start the deprecation of mteb.MTEB.

The planned interface is:

```py
result: TaskResult = mteb.run_task(model, task)

results: list[TaskResult] = mteb.run_tasks(model, tasks)
```

* fix

* Added cache_strategy and overwrite_strategy

* format

* redo cache implementation following suggestions

* fixes cicular imports

* Added tests

* format

* cleanup

* format

* added corrections based on feedback

* format

* restructure test cache

* fix cache issues

* move todo to issue

* resolve tests

* fix typo in tests

* fix criteria using an Enum

* moved todos to issue #2791

* convert overwrite_strategy from literal to str | Enum

* Added deprecation warning

* format

* Add AbstaskAggregate support to run_task

* minor refactoring Enums

* Update .gitignore

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Use strEnum compatible with earlier python versions

* ensure that mteb can be imported in python 3.9

* make project uv installable

* formatted toml

* redisable codecarbon as a default installation

* Moved modalities, languages, Score, Split and converted types/* to private

* revert enum refactors

* deleted METRIC_NAME and METRIC_VALUE

* refactor LANGUAGES

* merge Split and SplitName

* refactor HFSubset

* refactored statistics

* merge UrlString and STR_URL

* delete unused LangMapping

* prevent import of TaskMetadata from mteb.abstasks

* delete now unused custom_validators.py

* delete unused caching.py

* refactored MODEL_NAME and REVISION

* Convert types to PEP8 compliant PascalCase

* refactor PR

* ensure codecarbon is present for tests

* fix grammar error

* rename types to CamelCase

* delete `normalize_embeddings.py`

* fix import issue in tests

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* [v2] fix dialog task loading (#2818)

fix dialog task loading

* fix: refactor `languages.py` [v2] (#2813)

* [v2] refactor `languages.py`

Refactored languages.py into a module. This should be fully backwards compatible.

Fixes #2808

* rename language_script.py &gt; language_scripts.py

* moved language .json object to correct module

* fixes name of test file

* fixes error messages to not refer to a path, but instead to an import

* fix: [v2] Add mock dialog retrieal task (#2824)

add mock dialog retrieval task

* fix: remove untested task selection (#2821)

If people agree then I will add a new issue for making a tutorial on task selection for benchmarks using a clustering approach.

Adresses #2809

* Merge main into v2 (#2822)

* Merge main into v2

* fix model imports

* added missing task imports

* added missing desriptive stats

* refactor task import (#2828)

* Merge main into v2

* fix model imports

* added missing task imports

* refactor task import

This refactors imports following this pattern:

```py
# tasks/__init__
from .Retrieval import *
# tasks/retrieval/__init__
from .eng import *
# tasks/retrieval/eng/__init__
from .task1 import Task1
```
proposed by @Samoed in #2825. This should reduce the number of imports required, while not exposing any of the module requires at the task definition.

* added missing desriptive stats

* format

* fix: rename TaskMetadata.py to resolve class/module ambiguity (#2829)

* Merge main into v2

* fix model imports

* added missing task imports

* refactor task import

This refactors imports following this pattern:

```py
# tasks/__init__
from .Retrieval import *
# tasks/retrieval/__init__
from .eng import *
# tasks/retrieval/eng/__init__
from .task1 import Task1
```
proposed by @Samoed in #2825. This should reduce the number of imports required, while not exposing any of the module requires at the task definition.

* added missing desriptive stats

* fix: : rename TaskMetadata.py to resolve class/module ambiguity

related to: #1124
required for: #2714

Seems like we in multiple places denote the module instead of the intended TaskMetada. This rename should fix that issue

relies on PR #2828

* format

* fix: Added docs for `mteb.evaluate` (#2831)

* Merge main into v2

* fix model imports

* added missing task imports

* added missing desriptive stats

* fix: Added docs for `mteb.evaluate`

- renamed `mteb.run_tasks` to `mteb.evaluate`. Reverting this is fairly easy but I think the rename makes a lot of sense
- Added docs to most places
  - some aren&#39;t changed yet as they haven&#39;t been tested (#2830)
  - I didn&#39;t change the datasheet to avoid confusion with uploaded datasets

partly fixes: #2793

* format

* fix import

* Update docs/mieb/readme.md

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Update docs/usage/usage.md

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* [v2] Refactor CoPali new interface (#2844)

* refactor copali to use new interface wip

* use v2 interface

* receive only dataloader

* model: add ListConRanker model (#2742)

* add ListConRanker model

* updated the implementation of  ListConRanker

* updated the release date of ListConRanker

* added the training datasets and changed the release date of ListConRanker

* updated the training datasets of ListConRanker

* lint

* fix import

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* fix colpali imports

* dataset: Add IFIR benchmark (#2815)

Add IFIR relevant tasks.

Signed-off-by: SighingSnow &lt;songtingyu220@gmail.com&gt;

* fix: Seperate model implementations and encoder specifications (#2879)

- Move all implementations into a seperate folder called `model_implementations`
- moved `encoder_interface.py` and `model_meta.py` into `models`
- renamed `models/*` to `encoder_implementions/*` to make the distinction from between the two folder clear
- merged `models/utils.py` into the only model that used it

We seems to have a few differing names when referring to a model (ModelMeta, get_model, etc.) and encoders (Encoder, AbsEncoder). Should we try to do something about this or just leave it as is?

There is also an inconsistency between how tasks and implementations are in seperate folders, but for benchmark this is not the case.

We could convert it to:
```
benchmarks/tasks/models
| - implementations/*
| - ... # definitions utilities etc.
```
But I am not sure it is worth it and for tasks it might be too much nesting. So I would probably leave it as is.

Note: There is a few refactors that I would like to do on top of this, but will add that to seperate PR (since it is too hard to review here)

Fixes #2299

* [v2] Introduce AbsTaskAnyClustering (#2880)

* introduce AbsTaskAnyClustering

* trigger CI

* remove image clustering abstask

* revert

* address review comments

* fix tests

* fix descriptive stats tests

* fix for mteb eng v1 datasets

* introduce AbsTaskAnyZeroShotClassification (#2884)

* introduce AbsTaskAnyZeroShotClassification

* fix tests

* address review comments

* add mock text ZS task and handle text case

* fix tests

* pass all encode kwargs

* [v2]Â Refactor models/ module (#2886)

* fix: refactor models modules

- refactored loading of models - now all ModelMeta are imported
- fixed a few metadata issues due to missing imports
- renamed private methods to `_{prev_name}` to indicate that they are private
- renamed `models/overview.py` &gt; `models/get_model_meta.py``
- fixed a few typing issues in the models module

* fix typing

* fixed spelling

* minor fixes to imports for clarity

* rollback readme

* allow revision to be None

* fix extract models names

* Merge main v2 07 10 (#2895)

* bump ruff (#2784)

* Update issue and pr templates (#2782)

* Update issue templates

* Update bug_report.md

* test yaml template

* add templates

* update templates

* add emojis

* fix typo

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* update issue titles

* update PR template

* remove PR templates

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* model: Add GeoGPT-Research-Project/GeoEmbedding (#2773)

* add model: geogpt_models

* update geogpt_models

* use InstructSentenceTransformerWrapper

* resolve pylint warning

* format geogpt_models.py

* Update mteb/models/geogpt_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/geogpt_models.py

---------

Co-authored-by: zhangzeqing &lt;zhangzeqing@zhejianglab.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* model: add fangxq/XYZ-embedding (#2741)

* add xyz model

* add xyz model

* add xyz model

* update

* update

* update

* update

* update

* update

* update

* lint

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* ci: fix config error for semantic release (#2800)

discussed in: https://github.com/embeddings-benchmark/mteb/issues/2796

* dataset: Add R2MED Benchmark (#2795)

* Add files via upload

* Add files via upload

* Update benchmarks.py

* Update __init__.py

* Add files via upload

* Update R2MEDRetrieval.py

* Update run_mteb_r2med.py

* Delete scripts/run_mteb_r2med.py

* Update mteb/tasks/Retrieval/eng/R2MEDRetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/tasks/Retrieval/eng/R2MEDRetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/tasks/Retrieval/eng/R2MEDRetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/tasks/Retrieval/eng/R2MEDRetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Add files via upload

* Delete mteb/descriptive_stats/Retrieval/R2MEDRetrieval.json

* Add files via upload

* Add files via upload

* Add files via upload

* Update R2MEDRetrieval.py

* Add files via upload

* Add files via upload

* Add files via upload

* Add files via upload

* format citations

* Update R2MEDRetrieval.py

* Add files via upload

* Add files via upload

---------

Co-authored-by: Li Lei &lt;34205771+ll0ruc@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update tasks &amp; benchmarks tables

* Update training datasets of GeoGPT-Research-Project/GeoEmbedding (#2802)

update training datasets

Co-authored-by: zhangzeqing &lt;zhangzeqing@zhejianglab.com&gt;

* fix: Add adapted_from to Cmedqaretrieval (#2806)

* fix: Add adapted_from to Cmedqaretrieval

Also snuck in a fix with form=None, which is no longer valid, but was still used in a few places.

* format

* 1.38.28

Automatically generated by python-semantic-release

* fix: Adding client arg to init method of OpenAI models wrapper (#2803)

* Adding OpenAI client arg to init method (e.g., for already initialized AzureOpenAI client)

To use OpenAI embedding models via Azure, the model wrapper needs to be initialized with a different client.

* Update mteb/models/openai_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/openai_models.py

* remove comment and format

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* model: Add annamodels/LGAI-Embedding-Preview (#2810)

Add LGAI-Embedding

- Add mteb/models/lgai_embedding_models.py

- defined model metadata

* fix: Ensure bright uses the correct revision (#2812)

fixes #2811

* 1.38.29

Automatically generated by python-semantic-release

* add description to issue template (#2817)

* add description to template

* fix typo

* model: Added 3 HIT-TMG&#39;s KaLM-embedding models (#2478)

* Added HIT-TMG_KaLM-embedding-multilingual-mini-instruct-v1 with instruct wrapper

* Added KaLM_embedding_multilingual_mini_instruct_v1_5

* Added model to overview.py

* Fix Task Count Per Language Table in tasks.md

* resolve conflicts

* remove tasks.md

* Modified get_instruction funcion

* Added support for prompt dict in get_instruction

* fix lang code

* Address comments

* Delete mteb/models/check_models.py

* added prompts_dict support in InstructSentenceTransformerWrapper

* corrected instruction format

* corrected prompts format

* added correct instruction format

* fix implementation

* remove `if name main`

* add comment

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* fix: Reuploaded previously unavailable SNL datasets (#2819)

* fix: Reuploaded previously unavailable SNL datasets

closes #2477

* removed exceptions from tests

* temp fixes

* added temporary fix

* clean up commented out code

* format

* Update tasks &amp; benchmarks tables

* 1.38.30

Automatically generated by python-semantic-release

* docs: Fix some typos in `docs/usage/usage.md` (#2835)

* Update usage.md

* Update usage.md

* Update docs/usage/usage.md

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* model: Add custom instructions for GigaEmbeddings (#2836)

* add custom instructions

* fixed

* lint

* fix last instruction

---------

Co-authored-by: Kolodin Egor &lt;eikolodin@sberbank.ru&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* model: add Seed-1.6-embedding model (#2841)

* add Seed-1.6-embedding model

* Update seed_1_6_embedding_models.py

* update model meta info

* support image encoder interface

* error fix

* fix: format seed_1_6_embedding_models.py with Ruff

* fix: Update model selection for the leaderboard (#2855)

* fix: Update model selection for the leaderboard

fixes #2834

This removed the lower bound selection, but generally I don&#39;t think people should care about the models being too small.

* fix 1M --&gt; 1B

* format

* rename model_size -&gt; max_model_size

* 1.38.31

Automatically generated by python-semantic-release

* fix: update training dataset info of Seed-1.6-embedding model  (#2857)

update seed1.6 model training data info

* 1.38.32

Automatically generated by python-semantic-release

* add jinav4 model meta (#2858)

* add model meta

* linting

* fix: add check for code lora

* fix: apply review comments

* fix: prompt validation for tasks with `-` (#2846)

* fix prompt validation

* fix task name split correctly

* add docstring for test

* 1.38.33

Automatically generated by python-semantic-release

* model: Adding Sailesh97/Hinvec (#2842)

* Adding Hinvec Model&#39;s Meta data.

* Adding hinvec_model.py

* Update mteb/models/hinvec_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* formated code with Black and lint with Ruff

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Bump gradio to fix leaderboard sorting (#2866)

Bump gradio

* model: Adding nvidia/llama-nemoretriever-colembed models (#2861)

* nvidia_llama_nemoretriever_colembed

* correct 3b reference

* lint fix

* add training data and license for nvidia/llama_nemoretriever_colembed

* lint

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* rename seed-1.6-embedding to seed1.6-embedding (#2870)

* fix tests to be compatible with `SentenceTransformers` `v5` (#2875)

* fix sbert `v5`

* add comment

* model: add listconranker modelmeta (#2874)

* add listconranker modelmeta

* fix bugs

* use linter

* lint

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* model: add kalm_models ModelMeta (new PR) (#2853)

* feat: add KaLM_Embedding_X_0605 in kalm_models

* Update kalm_models.py for lint format

---------

Co-authored-by: xinshuohu &lt;xinshuohu@tencent.com&gt;

* Comment kalm model (#2877)

comment kalm model

* Add and fix some Japanese datasets: ANLP datasets, JaCWIR, JQaRA (#2872)

* Add JaCWIR and JQaRA for reranking

* Fix ANLP Journal datasets

* Add NLPJournalAbsArticleRetrieval and JaCWIRRetrieval

* tackle test cases

* Remove _evaluate_subset usage

* Separate v1 and v2

* Update info for NLP Journal datasets

* Update tasks &amp; benchmarks tables

* model: add Hakim and TookaSBERTV2 models (#2826)

* add tooka v2s

* add mcinext models

* update mcinext.py

* Apply PR review suggestions

* Update mteb/models/mcinext_models.py

---------

Co-authored-by: mehran &lt;mehan.sarmadi16@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* dataset: Evalita dataset integration (#2859)

* Added DadoEvalCoarseClassification

* Removed unnecessary columns from DadoEvalCoarseClassification

* Added EmitClassification task

* added SardiStanceClassification task

* Added GeoLingItClassification task

* Added DisCoTexPairClassification tasks

* Added EmitClassification, DadoEvalCoarseClassification, GeoLingItClassification, SardiStanceClassification inside the inits

* changed import in DisCoTexPairClassification

* removed GeoLingItClassification dataset

* fixed citation formatting, missing metadata parameters and lint formatting

* - Added XGlueWRPReranking task
- Added missing __init__.py files

* fixed metadata in XGlueWRPReranking

* Added MKQARetrieval task

* fixed type in XGlueWRPReranking

* changed MKQARetrieval from  cross-lingual to monolingual

* formatted MKQARetrieval file

* removed unused const

---------

Co-authored-by: Mattia Sangermano &lt;MattiaSangermano@users.noreply.huggingface.co&gt;

* Update tasks &amp; benchmarks tables

* fix: pin datasets version (#2892)

fix datasets version

* 1.38.34

Automatically generated by python-semantic-release

* fix model implementations

* fix tasks

* add metrics

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Hypothesis-Z &lt;44766273+Hypothesis-Z@users.noreply.github.com&gt;
Co-authored-by: zhangzeqing &lt;zhangzeqing@zhejianglab.com&gt;
Co-authored-by: fangxiaoquan &lt;44112102+fangxiaoquan@users.noreply.github.com&gt;
Co-authored-by: Li Lei &lt;34205771+ll0ruc@users.noreply.github.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: malteos &lt;github@i.mieo.de&gt;
Co-authored-by: annamodels &lt;annamodels@lgresearch.ai&gt;
Co-authored-by: Munot Ayush Sunil &lt;munotayush6@kgpian.iitkgp.ac.in&gt;
Co-authored-by: Sadra Barikbin &lt;sadraqazvin1@yahoo.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Egor &lt;31567312+ekolodin@users.noreply.github.com&gt;
Co-authored-by: Kolodin Egor &lt;eikolodin@sberbank.ru&gt;
Co-authored-by: Quan Yuhan &lt;929888357@qq.com&gt;
Co-authored-by: Quan Yuhan &lt;yuhan_quan@qq.com&gt;
Co-authored-by: Mohammad Kalim Akram &lt;kalimakram@gmail.com&gt;
Co-authored-by: Sailesh Panda &lt;sailesh.panda1997@gmail.com&gt;
Co-authored-by: bschifferer &lt;benedikt.d.schifferer@gmail.com&gt;
Co-authored-by: tutuDoki &lt;53423655+tutuDoki@users.noreply.github.com&gt;
Co-authored-by: Xinshuo Hu &lt;yanshek.woo@gmail.com&gt;
Co-authored-by: xinshuohu &lt;xinshuohu@tencent.com&gt;
Co-authored-by: lsz05 &lt;lszgz0521@gmail.com&gt;
Co-authored-by: Mehran Sarmadi &lt;128898167+mehran-sarmadi@users.noreply.github.com&gt;
Co-authored-by: mehran &lt;mehan.sarmadi16@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: MattiaSangermano &lt;43407984+MattiaSangermano@users.noreply.github.com&gt;
Co-authored-by: Mattia Sangermano &lt;MattiaSangermano@users.noreply.huggingface.co&gt;

* [v2] Refactor descriptive stats (#2823)

* start adding

* standardize statistics

* remove irrelevant file

* update retrieval calculation

* update zeroshot statistics

* fix random

* [v2] Fix classification task random state generation (#2898)

* add debug print

* add comment

* reupload datasets (#2643)

* fix retrieval dataset upload

* add readme repo type

* fix adapted

* add reupload flag

* fix tasks uploading

* add reupload datasets flag

* reupload reuploaded MIRACLRetrieval.py

* fix trust remote code

* prepare miracl for reuploading

* use mteb miracl

* support qrels split

* roll back miracle

* remove reuload flag

* fix: Add docs and .load_results to ResultsCache (#2833)

* fix: Update ResultsCache

- [x] Added tests
- [x] Added utility interfaces for examining the cache
- [x]Â Added load_results
- [x] Updated docs to use ResultsCache instead

We could also update the leaderboard to use ResultCache, but I don&#39;t want to do that in this PR. When that is done I would probably depracate `mteb.load_results` or convert it to a shorthand function for
```py
ResultCache().load_result(**kwargs)
```
Deprecating leads to less breaking changes.

Minor:
- removed `results/` from .gitignore

* fixed based on copilot feedback

* fix issues in tests

* Apply suggestions from code review

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* fix tests

* fix issues arising from multiple version across remote and results folder

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* [v2] Change training datasets from dict to set (#2959)

* update training datasets

* update training datasets

* fix test

* update test

* [v2] `mteb.evaluate` now saves `model_meta.json` (#2960)

* [v2] `mteb.evaluate` now saves `model_meta.json`

Fixes #2847

* format

* remove unused arg

* [v2] split batched input by subtypes (#2966)

* split batched input by subtypes

* add text batched input

* add type annotation for dataloaders

* return array with Union

* fix union typing

* Clean v2: Removed duplicate model imp., added missing task import, deleted unused files (#2961)

* make stratification a private module

* removed duplicate model implementations which were in the wrong folder

* removed commented out model code

* add unused task imports

* update ScandiSentClassification to v2

I also ran a test and it runs without issue

* remove task aggregation script as it is unused

* add import for ClusTrecCovid and updated to v2

Also ran test - it runs just fine

* add missing task imports

* added missing task imports

* rename model_classes to dense_retrieval_exact_search

* rename utils.py to _download.py as it only contains the download function

* format

* fix evaluator import

* ibid

* remove test for unused code

* fix: Compute missing data and create issue where not possible

* computed missing task metadata

* Ignore vscode debug file

* Update pylate to be compatible with the latest version of sentence-transformers

* ibid

* fix: rename evaluators rename to snakecase (#2979)

* fix: rename evaluators rename to snakecase

same as #2962 (but avoiding merge conflicts)
fixes #1124

* format

* [v2] Change `corpus` and `queries` to use `dataset` (#2885)

* change corpus and queries to dataset

* remove commented out code

* add convertion for v1 datasets

* fix descriptive stats

* update reranking

* format

* fix tests

* lint

* change ids of mock dataset

* change score for colbert

* add type for corpus and queries datasets

* fix reranking task

* format

* update push to hub

* update statistics calculation

* simplify `create_dataloader_for_retrieval_corpus`

* remove check with queries id

* add instruction dataset type

* fully annotate retrieval types

* remove irrelevant type annotation

* fix instruction fields (#2986)

* [v2] Fix stats compute for tasks with custom load_data  (#2985)

* fix reranking stat calculation

* remove from tests

* Refactor CLI to enable changes (#2981)

* Refactor CLI to enable changes

- [x] move cli, create_meta into module
- [x]Â rename create_meta &gt; generate_readme
- [x] rename cli &gt; build_cli
  - refactored build_cli() out of main()
  - move the main function into __main__
- [x]Â moved docstring into documentation
- [x] made function with add parsers private

* fix based on comments

* format

* rename cli.main to cli.build_cli

* [v2] Integrate search interface (#2970)

* change corpus and queries to dataset

* remove commented out code

* add convertion for v1 datasets

* fix descriptive stats

* update reranking

* format

* fix tests

* lint

* change ids of mock dataset

* change score for colbert

* add type for corpus and queries datasets

* fix reranking task

* format

* update push to hub

* update statistics calculation

* simplify `create_dataloader_for_retrieval_corpus`

* remove check with queries id

* add instruction dataset type

* fully annotate retrieval types

* remove irrelevant type annotation

* init

* base search interface implementation

* base search interface implementation

* add todo comment

* add link to todo

* Update mteb/models/search/search_crossencoder.py

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* Update mteb/create_dataloaders.py

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* remove search folder

* fix imports

* fix tests

* add support for cross encoder models

* combine back encoder

* add additional check for interface

* resolve copilot comment

* fix union type

* roll back rename in validate_task_to_prompt_name

* fix descriptive stats

* [v2] Combine instructions with queries (#2984)

* combine instructions with queries

* fix old format ds

* rename `MtebSupportedModelProtocols` and add `RetrievalEvaluationResult` tuple

---------

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* [v2] Standardize `mteb_model_meta` property (#3049)

* standardize `mteb_model_meta` property

* format

* [v2] Two stage rerank (#3040)

* init two stage

* working 2 stage reranking

* upd numpy meta

* fix tests

* fix python 3.9

* format

* simplify

* fix cross encoder meta

* add meta to sentence transformers wrapper

* fix model meta

* create `RetrievalSaveResultsWrapper`

* rename

* save only model name and revision in `previous_results_model_meta`

* add results save path

* Update mteb/evaluate.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* rename results folder to prediction

* add more info about save path

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* [v2] Merge main 30 08 (#3102)

* model: add image support for jina embeddings v4 (#2893)

* feat: unify text and image embeddings for all tasks

* fix: uniform batch size

* fix: update error message

* fix: update code task

* fix: update max length

* fix: apply review suggestions

* model: add kalm_models (kalm-emb-v2) ModelMeta (new PR) (#2889)

* feat: add KaLM_Embedding_X_0605 in kalm_models

* Update kalm_models.py for lint format

* kalm-emb-v2

* kalm-emb-v2

* kalm-emb-v2

* kalm-emb-v2

* kalm-emb-v2

---------

Co-authored-by: xinshuohu &lt;xinshuohu@tencent.com&gt;
Co-authored-by: Xinshuo Hu &lt;yanshek.woo@gmail.com&gt;

* Add Classification Evaluator unit test (#2838)

* Adding Classification Evaluator test

* Modifications due to the comments

* Update tests/test_evaluators/test_ClassificationEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update tests/test_evaluators/test_ClassificationEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Modifications due to the comments

* Modifications due to the comments

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* fix: update colpali engine models (#2905)

* adding vidore benchmarks

* fix typo

* clean vidore names + per lang eval

* lint

* vidore names

* bibtex fix

* fix revision

* vidore v2 citation

* update citation format and fix per-language mappings

* lint: citations

* typo citations

* fix revisiions

* lint

* fix colnomic3b revision

* fix colqwen2.5 revision + latest repo version

* fix query agmentation tokens

* colsmol revision

* 1.38.35

Automatically generated by python-semantic-release

* Evaluator tests (#2910)

* Adding Classification Evaluator test

* Modifications due to the comments

* Update tests/test_evaluators/test_ClassificationEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update tests/test_evaluators/test_ClassificationEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Modifications due to the comments

* Modifications due to the comments

* Adding STSEvaluator and SummarizationEvaluator tests

* Correcting due to the comments

* Correcting due to the comments

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Classification dataset cleaning (#2900)

* Classification dataset cleaning

* Update pull request number

* Fix metadata test

* fix formatting

* add script for cleaning

* Update tasks &amp; benchmarks tables

* dataset: Add JapaneseSentimentClassification (#2913)

Add JapaneseSentimentClassification

* Update tasks &amp; benchmarks tables

* fix: change `passage` prompt to `document`  (#2912)

* change document to passage

* fix prompt names

* fix kwargs check

* fix default prompt

* 1.38.36

Automatically generated by python-semantic-release

* model: Add OpenSearch inf-free sparse encoding models (#2903)

add opensearch inf-free models

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* dataset: add BarExamQA dataset (#2916)

* Add BareExamQA retrieval task

* ran linter

* updated details

* updated details

* fixed subtype name

* fixed changes

* ran linter again

* Use `mteb.get_model` in adding_a_dataset.md (#2922)

Update adding_a_dataset.md

* fix: specify revision for opensearch (#2919)

specify revision for opensearch

* 1.38.37

Automatically generated by python-semantic-release

* Update the link for gemini-embedding-001 (#2928)

* fix: replace with passage (#2934)

* fix: Only import SparseEncoder once sentence-transformer version have been checked (#2940)

* fix: Only import SparseEncoder once sentence-transformer version have been checked

fixes #2936

* Update mteb/models/opensearch_neural_sparse_models.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* fix: Prevent incorrectly passing &#34;selector_state&#34; to `get_benchmark` (#2939)

The leaderboard would have (silent) errors where `get_benchmark` lead to a KeyError due to &#34;selector_state&#34; being passed as a default value. Setting `DEFAULT_BENCMARK_NAME` as the value solves this issue.

* docs: Update adding_a_dataset.md (#2947)

* docs: Update adding_a_dataset.md

* Update docs/adding_a_dataset.md

* ci: bump semantic release

* 1.38.38

Automatically generated by python-semantic-release

* dataset: Add BSARD v2, fixing the data loading issues of v1 (#2935)

* BSARD loader fixed

* BSARDv2 metadata fixed

* Update mteb/tasks/Retrieval/fra/BSARDRetrieval.py

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update tasks &amp; benchmarks tables

* dataset: add GovReport dataset (#2953)

* Added govreport task

* Updated description

* dataset: add BillSum datasets (#2943)

* Added BillSum datasets

* fixed billsumca

* Updated BillSumCA description

* Updated BillSumUS description

* Update mteb/tasks/Retrieval/eng/BillSumCA.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/BillSumUS.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* lint

* lint

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Update tasks &amp; benchmarks tables

* fix: Add new benchmark beRuSciBench along with AbsTaskTextRegression (#2716)

* Add RuSciBench

* fix bitext mining lang

* Add regression task

* fix init

* add missing files

* Improve description

* Add superseded_by

* fix lint

* Update regression task to match with v2

* Add stratified_subsampling for regression task

* Add boostrap for regression task

* Rename task class, add model as evaluator argument

* fix import

* fix import 2

* fixes

* fix

* Rename regression model protocol

* Update tasks &amp; benchmarks tables

* 1.38.39

Automatically generated by python-semantic-release

* qzhou-embedding model_meta &amp; implementation (#2975)

* qzhou-embedding model_meta &amp; implementation

* Update qzhou_models.py

* Update qzhou_models.py

Processing todo itemsï¼ˆAdd default instructionï¼‰

* Update qzhou_models.py

correct bge datalist

* Update qzhou_models.py

correct &#39;public_training_data&#39;

* Update qzhou_models.py

* Update qzhou_models.py

* Update qzhou_models.py

* Update qzhou_models.py

* Update mteb/models/qzhou_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/qzhou_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* format qzhou_models.py for ruff check

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* model: Add Voyage 3.5 model configuration (#3005)

Add Voyage 3.5 model configuration

- Add voyage_3_5 ModelMeta with 1024 embed dimensions and 32000 max tokens
- Set release date to 2025-01-21 with revision 1
- Configure for cosine similarity with instruction support
- Include standard Voyage training datasets reference

ðŸ¤– Generated with [Claude Code](https://claude.ai/code)

Co-authored-by: Claude &lt;noreply@anthropic.com&gt;

* model: BAAI/bge-m3-unsupervised Model (#3007)

* Add BAAI/bge-m3-unsupervised Model
(BAAI/bge_m3_retromae is commented out - the details are proper, but it fails during loading the model for me, so i commented out)

* Remove the commented retromae model

---------

Co-authored-by: fzowl &lt;zoltan@voyageai.com&gt;

* lint: Correcting lint errors (#3004)

* Adding Classification Evaluator test

* Modifications due to the comments

* Update tests/test_evaluators/test_ClassificationEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update tests/test_evaluators/test_ClassificationEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Modifications due to the comments

* Modifications due to the comments

* Correcting the lint errors

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* dataset: Added 50 Vietnamese dataset from vn-mteb (#2964)

* [ADD] 50 vietnamese dataset from vn-mteb

* [UPDATE] task metadata

* [UPDATE] import dependencies

* [UPDATE] task metadata, bibtext citation

* [UPDATE-TEST] test_model_meta

* [UPDATE] sample_creation to machine-translated and LM verified

* [ADD] sample creation machine-translated and LM verified

* [REMOVE] default fields metadata in Classfication tasks

* Update tasks &amp; benchmarks tables

* model: Add Cohere embed-v4.0 model support (#3006)

* Add Cohere embed-v4.0 model support

- Add text-only embed-v4.0 model in cohere_models.py
- Add multimodal embed-v4.0 model in cohere_v.py
- Support configurable dimensions (256, 512, 1024, 1536)
- Support 128,000 token context length
- Support multimodal embedding (text, images, mixed PDFs)

ðŸ¤– Generated with [Claude Code](https://claude.ai/code)

Co-Authored-By: Claude &lt;noreply@anthropic.com&gt;

* Add Cohere embed-v4.0 model support

Update cohere_v.py and cohere_models.py to include the new embed-v4.0 model with proper configuration and integration.

ðŸ¤– Generated with [Claude Code](https://claude.ai/code)

Co-Authored-By: Claude &lt;noreply@anthropic.com&gt;

---------

Co-authored-by: Claude &lt;noreply@anthropic.com&gt;

* Add OpenAI models with 512 dimension (#3008)

* Add OpenAI/text-embedding-3-small (512 dim)
Add OpenAI/text-embedding-3-large (512 dim)

* Correcting due to comments

---------

Co-authored-by: fzowl &lt;zoltan@voyageai.com&gt;

* Standardise task names and fix citation formatting (#3026)

fixes for name formatting

* Update tasks &amp; benchmarks tables

* fix: Add missing training sets for qzhou (#3023)

* Supplement missing training sets

* reformat code

* Reorganize the data list format

* update qzhou_model meta

* 1.38.40

Automatically generated by python-semantic-release

* model: Add samilpwc_models meta (#3028)

* model: Add samilpwc_models meta

* Fix: Remove CONST

* Fix: Reformat File

* Update: model revision

* model: Add granite-vision-embedding model  (#3029)

* Add files via upload

* Address review comments

* Address review comments

* ruff format

* Update mteb/models/granite_vision_embedding_models.py

* lint error fix

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* fix: incorrect revision for SNLRetrieval (#3033)

The provided revisions doesn&#39;t seem to be present on:
adrlau/navjordj-SNL_summarization_copy

Replacing with latest revision

* dataset: Add HumanEvalRetrieval task (#3022)

* Add HumanEvalRetrieval dataset

* Fix TaskMetadata structure and remove descriptive_stats

- Use TaskMetadata class instead of dict
- Remove descriptive_stats as requested in PR review
- Add date field and proper import structure

* Fix dataset path and use verified metadata

- Change path from zeroshot/humaneval-embedding-benchmark to embedding-benchmark/HumanEval
- Use actual description from HuggingFace dataset page
- Remove fabricated citation and reference
- Remove revision field that was incorrect
- Reference HuggingFace dataset page instead of arxiv

* Add correct revision hash to HumanEval

- Add revision hash: ed1f48a for reproducibility

* Fix HumanEval metadata validation

- Add date field for metadata completeness
- Add bibtex_citation field (empty string)
- Required for TaskMetadata validation to pass
- Should resolve PR test failure

* Address reviewer feedback

- Remove trust_remote_code parameter as requested
- Add revision parameter to load_dataset() calls for consistency
- Use metadata revision hash in dataset loading for reproducibility

* Fix field names in HumanEval dataset loading

Changed query_id/corpus_id to query-id/corpus-id to match actual dataset format.

* Fix deprecated metadata_dict usage

Use self.metadata.dataset instead of self.metadata_dict for v2.0 compatibility.

* Fix data structure for MTEB compatibility

- Organize data by splits as expected by MTEB retrieval tasks
- Convert scores to integers for pytrec_eval compatibility

* Address PR feedback for HumanEval dataset

- Add descriptive statistics using calculate_metadata_metrics()
- Enhance metadata description with dataset structure details
- Add complete BibTeX citation for original paper
- Update to full commit hash revision
- Add python-Code language tag for programming language
- Explain retrieval task formulation clearly

* Fix BibTeX citation formatting for HumanEvalRetrieval

- Update citation to match bibtexparser formatting requirements
- Fields now in alphabetical order with lowercase names
- Proper trailing commas and indentation

* Update tasks &amp; benchmarks tables

* 1.38.41

Automatically generated by python-semantic-release

* ci: reduce parallel runs for when checking if a dataset exists (#3035)

The hope is that this will prevent many of the current [errors](https://github.com/embeddings-benchmark/mteb/actions/runs/17019125199/job/48245690831)

* ci: Updating rerun delays to prevent false positives errors

* ci: Updating rerun delays to prevent false positives errors

* model: Add GreenNode Vietnamese Embedding models (#2994)

* [ADD] 50 vietnamese dataset from vn-mteb

* [UPDATE] task metadata

* [UPDATE] import dependencies

* [UPDATE] task metadata, bibtext citation

* [UPDATE-TEST] test_model_meta

* [UPDATE] sample_creation to machine-translated and LM verified

* [ADD] sample creation machine-translated and LM verified

* [ADD] Vietnamese Embedding models

* [REMOVE] default fields metadata in Classfication tasks

* [UPDATE] model to vi-vn language specific file

* [FIX] lint

* [FIX] model loader

* model: add granite-embedding-english R2 models (#3050)

* fix: Updated revision for jina-embeddings-v4 (#3046)

* fix: jinav4 revision

Signed-off-by: admin &lt;bo.wang@jina.ai&gt;

* change revision instead of removing it

Signed-off-by: admin &lt;bo.wang@jina.ai&gt;

---------

Signed-off-by: admin &lt;bo.wang@jina.ai&gt;
Co-authored-by: admin &lt;bo.wang@jina.ai&gt;

* 1.38.42

Automatically generated by python-semantic-release

* Fix 3 VN-MTEB Pair Classification tasks (#3053)

* [ADD] 50 vietnamese dataset from vn-mteb

* [UPDATE] task metadata

* [UPDATE] import dependencies

* [UPDATE] task metadata, bibtext citation

* [UPDATE-TEST] test_model_meta

* [UPDATE] sample_creation to machine-translated and LM verified

* [ADD] sample creation machine-translated and LM verified

* [ADD] Vietnamese Embedding models

* [REMOVE] default fields metadata in Classfication tasks

* [UPDATE] model to vi-vn language specific file

* [FIX] lint

* [FIX] model loader

* [FIX] VN-MTEB 3 datasets PairClassification rename column

* dataset: Add mbpp retrieval (#3037)

* Add MBPP retrieval task

- Code retrieval task based on 378 Python programming problems
- Natural language queries matched to Python code implementations
- Uses python-Code evaluation language for code-specific metrics
- Includes proper citations and descriptive statistics

* Add MBPPRetrieval to imports

* Add descriptive statistics for MBPPRetrieval

* Reformatting

* Reformatting

* Update tasks &amp; benchmarks tables

* dataset: Added wikisql retrieval (#3039)

* Add WikiSQL retrieval task

- Code retrieval task based on WikiSQL natural language to SQL dataset
- Natural language questions matched to SQL query implementations
- Uses sql-Code evaluation language for SQL-specific metrics
- Includes proper citations and descriptive statistics

* Add WikiSQLRetrieval to imports

* Add descriptive statistics for WikiSQLRetrieval

* Reformatting

* Reformatting

* Reformatting, correcting the revision

* Update tasks &amp; benchmarks tables

* ci: Temporarily limit pytrec version to &#34;pytrec-eval-terrier&gt;=0.5.6, &lt;0.5.8&#34; to prevent errors

try to fix CI

* fix MBPPRetrieval revision (#3055)

Update MBPPRetrieval.py

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* fix: Add VN-MTEB benchmark and Leaderboard (#2995)

* [ADD] 50 vietnamese dataset from vn-mteb

* [UPDATE] task metadata

* [UPDATE] import dependencies

* [UPDATE] task metadata, bibtext citation

* [UPDATE-TEST] test_model_meta

* [UPDATE] sample_creation to machine-translated and LM verified

* [ADD] sample creation machine-translated and LM verified

* [ADD] VN-MTEB benchmark and leaderboard

* [FIX] wrong benchmark name

* [REMOVE] default fields metadata in Classfication tasks

* Update tasks &amp; benchmarks tables

* 1.38.43

Automatically generated by python-semantic-release

* Add hc3finance retrieval (#3041)

* Add HC3Finance retrieval task

- Financial retrieval task based on HC3 Finance dataset
- Financial questions matched to human and AI-generated content
- Covers financial explanations, analysis, and educational content
- Includes proper citations and descriptive statistics

* Add HC3FinanceRetrieval to imports

* Add descriptive statistics for HC3FinanceRetrieval

* Reformatting

* Reformatting, correcting the revision

* Update mteb/tasks/Retrieval/eng/HC3FinanceRetrieval.py

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Add finqa retrieval (#3042)

* Add FinQA retrieval task

- Financial numerical reasoning retrieval task based on FinQA dataset
- Numerical financial questions matched to relevant document data
- Covers earnings reports with tables and quantitative financial data
- Includes proper citations and descriptive statistics

* Add FinQARetrieval to imports

* Add descriptive statistics for FinQARetrieval

* Reformatting

* Reformatting

* Update mteb/tasks/Retrieval/eng/FinQARetrieval.py

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Update tasks &amp; benchmarks tables

* Add FinanceBenchRetrieval task (#3044)

* Add FinanceBenchRetrieval

* Update mteb/tasks/Retrieval/eng/FinanceBenchRetrieval.py

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Update tasks &amp; benchmarks tables

* Add FreshStackRetrieval task (#3043)

* Add FreshStackRetrieval

* Reformatting, correcting the revision

* Dataset correction

* Update tasks &amp; benchmarks tables

* dataset: Add ds1000 retrieval (#3038)

* Add DS1000 retrieval task

- Code retrieval task based on 1,000 data science programming problems
- Natural language queries matched to Python data science code
- Uses python-Code evaluation language for code-specific metrics
- Covers pandas, numpy, matplotlib, scikit-learn, and scipy libraries

* Add DS1000Retrieval to imports

* Add descriptive statistics for DS1000Retrieval

* Reformatting

* Reformatting

* Update tasks &amp; benchmarks tables

* Add ChatDoctorRetrieval (#3045)

* Add ChatDoctorRetrieval

* Reformatting, correcting the revision

* Correct the dataset citation

* Correcting due to comments

* Update tasks &amp; benchmarks tables

* Correcting the (new) DS1000 dataset&#39;s revision (#3063)

* Add DS1000 retrieval task

- Code retrieval task based on 1,000 data science programming problems
- Natural language queries matched to Python data science code
- Uses python-Code evaluation language for code-specific metrics
- Covers pandas, numpy, matplotlib, scikit-learn, and scipy libraries

* Add DS1000Retrieval to imports

* Add descriptive statistics for DS1000Retrieval

* Reformatting

* Reformatting

* Add DS1000Retrieval task implementation

* dataset: Add JinaVDR (#2942)

* feat: added jinavdr benchmark

* feat: added description for jinavdr

* feat: fixed licenses and added bibtex

* feat: made jinav4 compatible with vidore benchmark

* feat: corrected query numbers

* feat: removed print

* feat: added max pixel argument for jina models

* feat: score calculation on cpu

* feat: adjust jina model for new mteb code

* feat: code cleanup

* feat: corrected bibtex

* feat: make colpali run with jinavdr

* feat: fixed comments

* feat: better reference and fixed comments

* feat: added date for tasks

* feat: fixed missing metadata and bibtex

* feat: added descriptions per dataset

* Update tasks &amp; benchmarks tables

* model: Add CoDi-Embedding-V1 (#3054)

* add codiemb-minicpm

* replace codiemb_minicpm with codi_model

* Update mteb/models/codi_model.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/codi_model.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/codi_model.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* update code

* update code

* reformat

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: ensure that there are always relevant docs attached to query (#3058)

* fix: ensure that there are always relevant docs attached to query

Here is brief test that it doesn&#39;t influence scores:
```py
t1 = mteb.get_task(&#34;TwitterHjerneRetrieval&#34;)
meta = mteb.get_model_meta(&#34;minishlab/potion-base-2M&#34;)

eval = mteb.MTEB(tasks=[t1])
res = eval.run(model=meta.load_model())

# before fix:
res[0].get_score()  # np.float64(0.02837)
res[0].scores
before_fix = {
    &#34;train&#34;: [
        {
            &#34;ndcg_at_1&#34;: 0.02597,
            &#34;ndcg_at_3&#34;: 0.02213,
            &#34;ndcg_at_5&#34;: 0.0262,
            &#34;ndcg_at_10&#34;: 0.02837,
            &#34;ndcg_at_20&#34;: 0.04548,
            &#34;ndcg_at_100&#34;: 0.13527,
            &#34;ndcg_at_1000&#34;: 0.24507,
            &#34;map_at_1&#34;: 0.00866,
            &#34;map_at_3&#34;: 0.01317,
            &#34;map_at_5&#34;: 0.0149,
            &#34;map_at_10&#34;: 0.01562,
            &#34;map_at_20&#34;: 0.01898,
            &#34;map_at_100&#34;: 0.02968,
            &#34;map_at_1000&#34;: 0.03841,
            &#34;recall_at_1&#34;: 0.00866,
            &#34;recall_at_3&#34;: 0.02056,
            &#34;recall_at_5&#34;: 0.02922,
            &#34;recall_at_10&#34;: 0.03355,
            &#34;recall_at_20&#34;: 0.08268,
            &#34;recall_at_100&#34;: 0.43766,
            &#34;recall_at_1000&#34;: 1.0,
            &#34;precision_at_1&#34;: 0.02597,
            &#34;precision_at_3&#34;: 0.02165,
            &#34;precision_at_5&#34;: 0.01818,
            &#34;precision_at_10&#34;: 0.01039,
            &#34;precision_at_20&#34;: 0.01234,
            &#34;precision_at_100&#34;: 0.01481,
            &#34;precision_at_1000&#34;: 0.0034,
            &#34;mrr_at_1&#34;: 0.025974,
            &#34;mrr_at_3&#34;: 0.041126,
            &#34;mrr_at_5&#34;: 0.04632,
            &#34;mrr_at_10&#34;: 0.048485,
            &#34;mrr_at_20&#34;: 0.058356,
            &#34;mrr_at_100&#34;: 0.070186,
            &#34;mrr_at_1000&#34;: 0.071349,
            &#34;nauc_ndcg_at_1_max&#34;: 0.33969,
            &#34;nauc_ndcg_at_1_std&#34;: -0.202864,
            &#34;nauc_ndcg_at_1_diff1&#34;: -0.127,
            &#34;nauc_ndcg_at_3_max&#34;: 0.409376,
            &#34;nauc_ndcg_at_3_std&#34;: -0.039352,
            &#34;nauc_ndcg_at_3_diff1&#34;: -0.022816,
            &#34;nauc_ndcg_at_5_max&#34;: 0.250499,
            &#34;nauc_ndcg_at_5_std&#34;: -0.115263,
            &#34;nauc_ndcg_at_5_diff1&#34;: -0.057017,
            &#34;nauc_ndcg_at_10_max&#34;: 0.238696,
            &#34;nauc_ndcg_at_10_std&#34;: -0.138396,
            &#34;nauc_ndcg_at_10_diff1&#34;: -0.045287,
            &#34;nauc_ndcg_at_20_max&#34;: 0.154456,
            &#34;nauc_ndcg_at_20_std&#34;: -0.070635,
            &#34;nauc_ndcg_at_20_diff1&#34;: 0.074499,
            &#34;nauc_ndcg_at_100_max&#34;: -0.005753,
            &#34;nauc_ndcg_at_100_std&#34;: -0.074738,
            &#34;nauc_ndcg_at_100_diff1&#34;: -0.005851,
            &#34;nauc_ndcg_at_1000_max&#34;: 0.109439,
            &#34;nauc_ndcg_at_1000_std&#34;: -0.089797,
            &#34;nauc_ndcg_at_1000_diff1&#34;: -0.021634,
            &#34;nauc_map_at_1_max&#34;: 0.33969,
            &#34;nauc_map_at_1_std&#34;: -0.202864,
            &#34;nauc_map_at_1_diff1&#34;: -0.127,
            &#34;nauc_map_at_3_max&#34;: 0.385244,
            &#34;nauc_map_at_3_std&#34;: -0.080638,
            &#34;nauc_map_at_3_diff1&#34;: -0.060991,
            &#34;nauc_map_at_5_max&#34;: 0.294871,
            &#34;nauc_map_at_5_std&#34;: -0.119069,
            &#34;nauc_map_at_5_diff1&#34;: -0.06234,
            &#34;nauc_map_at_10_max&#34;: 0.285698,
            &#34;nauc_map_at_10_std&#34;: -0.132856,
            &#34;nauc_map_at_10_diff1&#34;: -0.055015,
            &#34;nauc_map_at_20_max&#34;: 0.236619,
            &#34;nauc_map_at_20_std&#34;: -0.100673,
            &#34;nauc_map_at_20_diff1&#34;: -0.002619,
            &#34;nauc_map_at_100_max&#34;: 0.15345,
            &#34;nauc_map_at_100_std&#34;: -0.138888,
            &#34;nauc_map_at_100_diff1&#34;: -0.02257,
            &#34;nauc_map_at_1000_max&#34;: 0.171402,
            &#34;nauc_map_at_1000_std&#34;: -0.134644,
            &#34;nauc_map_at_1000_diff1&#34;: -0.034477,
            &#34;nauc_recall_at_1_max&#34;: 0.33969,
            &#34;nauc_recall_at_1_std&#34;: -0.202864,
            &#34;nauc_recall_at_1_diff1&#34;: -0.127,
            &#34;nauc_recall_at_3_max&#34;: 0.375072,
            &#34;nauc_recall_at_3_std&#34;: -0.009643,
            &#34;nauc_recall_at_3_diff1&#34;: -0.089168,
            &#34;nauc_recall_at_5_max&#34;: 0.147691,
            &#34;nauc_recall_at_5_std&#34;: -0.128654,
            &#34;nauc_recall_at_5_diff1&#34;: -0.084259,
            &#34;nauc_recall_at_10_max&#34;: 0.141055,
            &#34;nauc_recall_at_10_std&#34;: -0.165932,
            &#34;nauc_recall_at_10_diff1&#34;: -0.060966,
            &#34;nauc_recall_at_20_max&#34;: 0.043863,
            &#34;nauc_recall_at_20_std&#34;: -0.028374,
            &#34;nauc_recall_at_20_diff1&#34;: 0.157575,
            &#34;nauc_recall_at_100_max&#34;: -0.157183,
            &#34;nauc_recall_at_100_std&#34;: -0.019437,
            &#34;nauc_recall_at_100_diff1&#34;: 0.013395,
            # &#34;nauc_recall_at_1000_max&#34;: nan,
            # &#34;nauc_recall_at_1000_std&#34;: nan,
            # &#34;nauc_recall_at_1000_diff1&#34;: nan,
            &#34;nauc_precision_at_1_max&#34;: 0.33969,
            &#34;nauc_precision_at_1_std&#34;: -0.202864,
            &#34;nauc_precision_at_1_diff1&#34;: -0.127,
            &#34;nauc_precision_at_3_max&#34;: 0.406318,
            &#34;nauc_precision_at_3_std&#34;: 0.007031,
            &#34;nauc_precision_at_3_diff1&#34;: -0.034709,
            &#34;nauc_precision_at_5_max&#34;: 0.178131,
            &#34;nauc_precision_at_5_std&#34;: -0.112493,
            &#34;nauc_precision_at_5_diff1&#34;: -0.045535,
            &#34;nauc_precision_at_10_max&#34;: 0.167897,
            &#34;nauc_precision_at_10_std&#34;: -0.150626,
            &#34;nauc_precision_at_10_diff1&#34;: -0.027811,
            &#34;nauc_precision_at_20_max&#34;: 0.081428,
            &#34;nauc_precision_at_20_std&#34;: -0.042304,
            &#34;nauc_precision_at_20_diff1&#34;: 0.17278,
            &#34;nauc_precision_at_100_max&#34;: -0.150619,
            &#34;nauc_precision_at_100_std&#34;: 0.016133,
            &#34;nauc_precision_at_100_diff1&#34;: -0.065571,
            &#34;nauc_precision_at_1000_max&#34;: -0.017244,
            &#34;nauc_precision_at_1000_std&#34;: 0.046614,
            &#34;nauc_precision_at_1000_diff1&#34;: -0.028258,
            &#34;nauc_mrr_at_1_max&#34;: 0.33969,
            &#34;nauc_mrr_at_1_std&#34;: -0.202864,
            &#34;nauc_mrr_at_1_diff1&#34;: -0.127,
            &#34;nauc_mrr_at_3_max&#34;: 0.409511,
            &#34;nauc_mrr_at_3_std&#34;: -0.064671,
            &#34;nauc_mrr_at_3_diff1&#34;: -0.01911,
            &#34;nauc_mrr_at_5_max&#34;: 0.319584,
            &#34;nauc_mrr_at_5_std&#34;: -0.103546,
            &#34;nauc_mrr_at_5_diff1&#34;: -0.025109,
            &#34;nauc_mrr_at_10_max&#34;: 0.309614,
            &#34;nauc_mrr_at_10_std&#34;: -0.117564,
            &#34;nauc_mrr_at_10_diff1&#34;: -0.019691,
            &#34;nauc_mrr_at_20_max&#34;: 0.262976,
            &#34;nauc_mrr_at_20_std&#34;: -0.092222,
            &#34;nauc_mrr_at_20_diff1&#34;: 0.024507,
            &#34;nauc_mrr_at_100_max&#34;: 0.256052,
            &#34;nauc_mrr_at_100_std&#34;: -0.094249,
            &#34;nauc_mrr_at_100_diff1&#34;: 0.012432,
            &#34;nauc_mrr_at_1000_max&#34;: 0.260112,
            &#34;nauc_mrr_at_1000_std&#34;: -0.098845,
            &#34;nauc_mrr_at_1000_diff1&#34;: 0.009697,
            &#34;main_score&#34;: 0.02837,
            &#34;hf_subset&#34;: &#34;default&#34;,
            &#34;languages&#34;: [&#34;dan-Latn&#34;],
        }
    ]
}

# with update:
res[0].get_score()  # np.float64(0.02837)
res[0].scores
with_fix = {
    &#34;train&#34;: [
        {
            &#34;ndcg_at_1&#34;: 0.02597,
            &#34;ndcg_at_3&#34;: 0.02213,
            &#34;ndcg_at_5&#34;: 0.0262,
            &#34;ndcg_at_10&#34;: 0.02837,
            &#34;ndcg_at_20&#34;: 0.04548,
            &#34;ndcg_at_100&#34;: 0.13527,
            &#34;ndcg_at_1000&#34;: 0.24507,
            &#34;map_at_1&#34;: 0.00866,
            &#34;map_at_3&#34;: 0.01317,
            &#34;map_at_5&#34;: 0.0149,
            &#34;map_at_10&#34;: 0.01562,
            &#34;map_at_20&#34;: 0.01898,
            &#34;map_at_100&#34;: 0.02968,
            &#34;map_at_1000&#34;: 0.03841,
            &#34;recall_at_1&#34;: 0.00866,
            &#34;recall_at_3&#34;: 0.02056,
            &#34;recall_at_5&#34;: 0.02922,
            &#34;recall_at_10&#34;: 0.03355,
            &#34;recall_at_20&#34;: 0.08268,
            &#34;recall_at_100&#34;: 0.43766,
            &#34;recall_at_1000&#34;: 1.0,
            &#34;precision_at_1&#34;: 0.02597,
            &#34;precision_at_3&#34;: 0.02165,
            &#34;precision_at_5&#34;: 0.01818,
            &#34;precision_at_10&#34;: 0.01039,
            &#34;precision_at_20&#34;: 0.01234,
            &#34;precision_at_100&#34;: 0.01481,
            &#34;precision_at_1000&#34;: 0.0034,
            &#34;mrr_at_1&#34;: 0.025974,
            &#34;mrr_at_3&#34;: 0.041126,
            &#34;mrr_at_5&#34;: 0.04632,
            &#34;mrr_at_10&#34;: 0.048485,
            &#34;mrr_at_20&#34;: 0.058356,
            &#34;mrr_at_100&#34;: 0.070186,
            &#34;mrr_at_1000&#34;: 0.071349,
            &#34;nauc_ndcg_at_1_max&#34;: 0.33969,
            &#34;nauc_ndcg_at_1_std&#34;: -0.202864,
            &#34;nauc_ndcg_at_1_diff1&#34;: -0.127,
            &#34;nauc_ndcg_at_3_max&#34;: 0.409376,
            &#34;nauc_ndcg_at_3_std&#34;: -0.039352,
            &#34;nauc_ndcg_at_3_diff1&#34;: -0.022816,
            &#34;nauc_ndcg_at_5_max&#34;: 0.250499,
            &#34;nauc_ndcg_at_5_std&#34;: -0.115263,
            &#34;nauc_ndcg_at_5_diff1&#34;: -0.057017,
            &#34;nauc_ndcg_at_10_max&#34;: 0.238696,
            &#34;nauc_ndcg_at_10_std&#34;: -0.138396,
            &#34;nauc_ndcg_at_10_diff1&#34;: -0.045287,
            &#34;nauc_ndcg_at_20_max&#34;: 0.154456,
            &#34;nauc_ndcg_at_20_std&#34;: -0.070635,
            &#34;nauc_ndcg_at_20_diff1&#34;: 0.074499,
            &#34;nauc_ndcg_at_100_max&#34;: -0.005753,
            &#34;nauc_ndcg_at_100_std&#34;: -0.074738,
            &#34;nauc_ndcg_at_100_diff1&#34;: -0.005851,
            &#34;nauc_ndcg_at_1000_max&#34;: 0.109439,
            &#34;nauc_ndcg_at_1000_std&#34;: -0.089797,
            &#34;nauc_ndcg_at_1000_diff1&#34;: -0.021634,
            &#34;nauc_map_at_1_max&#34;: 0.33969,
            &#34;nauc_map_at_1_std&#34;: -0.202864,
            &#34;nauc_map_at_1_diff1&#34;: -0.127,
            &#34;nauc_map_at_3_max&#34;: 0.385244,
            &#34;nauc_map_at_3_std&#34;: -0.080638,
            &#34;nauc_map_at_3_diff1&#34;: -0.060991,
            &#34;nauc_map_at_5_max&#34;: 0.294871,
            &#34;nauc_map_at_5_std&#34;: -0.119069,
            &#34;nauc_map_at_5_diff1&#34;: -0.06234,
            &#34;nauc_map_at_10_max&#34;: 0.285698,
            &#34;nauc_map_at_10_std&#34;: -0.132856,
            &#34;nauc_map_at_10_diff1&#34;: -0.055015,
            &#34;nauc_map_at_20_max&#34;: 0.236619,
            &#34;nauc_map_at_20_std&#34;: -0.100673,
            &#34;nauc_map_at_20_diff1&#34;: -0.002619,
            &#34;nauc_map_at_100_max&#34;: 0.15345,
            &#34;nauc_map_at_100_std&#34;: -0.138888,
            &#34;nauc_map_at_100_diff1&#34;: -0.02257,
            &#34;nauc_map_at_1000_max&#34;: 0.171402,
            &#34;nauc_map_at_1000_std&#34;: -0.134644,
            &#34;nauc_map_at_1000_diff1&#34;: -0.034477,
            &#34;nauc_recall_at_1_max&#34;: 0.33969,
            &#34;nauc_recall_at_1_std&#34;: -0.202864,
            &#34;nauc_recall_at_1_diff1&#34;: -0.127,
            &#34;nauc_recall_at_3_max&#34;: 0.375072,
            &#34;nauc_recall_at_3_std&#34;: -0.009643,
            &#34;nauc_recall_at_3_diff1&#34;: -0.089168,
            &#34;nauc_recall_at_5_max&#34;: 0.147691,
            &#34;nauc_recall_at_5_std&#34;: -0.128654,
            &#34;nauc_recall_at_5_diff1&#34;: -0.084259,
            &#34;nauc_recall_at_10_max&#34;: 0.141055,
            &#34;nauc_recall_at_10_std&#34;: -0.165932,
            &#34;nauc_recall_at_10_diff1&#34;: -0.060966,
            &#34;nauc_recall_at_20_max&#34;: 0.043863,
            &#34;nauc_recall_at_20_std&#34;: -0.028374,
            &#34;nauc_recall_at_20_diff1&#34;: 0.157575,
            &#34;nauc_recall_at_100_max&#34;: -0.157183,
            &#34;nauc_recall_at_100_std&#34;: -0.019437,
            &#34;nauc_recall_at_100_diff1&#34;: 0.013395,
            # &#34;nauc_recall_at_1000_max&#34;: nan,
            # &#34;nauc_recall_at_1000_std&#34;: nan,
            # &#34;nauc_recall_at_1000_diff1&#34;: nan,
            &#34;nauc_precision_at_1_max&#34;: 0.33969,
            &#34;nauc_precision_at_1_std&#34;: -0.202864,
            &#34;nauc_precision_at_1_diff1&#34;: -0.127,
            &#34;nauc_precision_at_3_max&#34;: 0.406318,
            &#34;nauc_precision_at_3_std&#34;: 0.007031,
            &#34;nauc_precision_at_3_diff1&#34;: -0.034709,
            &#34;nauc_precision_at_5_max&#34;: 0.178131,
            &#34;nauc_precision_at_5_std&#34;: -0.112493,
            &#34;nauc_precision_at_5_diff1&#34;: -0.045535,
            &#34;nauc_precision_at_10_max&#34;: 0.167897,
            &#34;nauc_precision_at_10_std&#34;: -0.150626,
            &#34;nauc_precision_at_10_diff1&#34;: -0.027811,
            &#34;nauc_precision_at_20_max&#34;: 0.081428,
            &#34;nauc_precision_at_20_std&#34;: -0.042304,
            &#34;nauc_precision_at_20_diff1&#34;: 0.17278,
            &#34;nauc_precision_at_100_max&#34;: -0.150619,
            &#34;nauc_precision_at_100_std&#34;: 0.016133,
            &#34;nauc_precision_at_100_diff1&#34;: -0.065571,
            &#34;nauc_precision_at_1000_max&#34;: -0.017244,
            &#34;nauc_precision_at_1000_std&#34;: 0.046614,
            &#34;nauc_precision_at_1000_diff1&#34;: -0.028258,
            &#34;nauc_mrr_at_1_max&#34;: 0.33969,
            &#34;nauc_mrr_at_1_std&#34;: -0.202864,
            &#34;nauc_mrr_at_1_diff1&#34;: -0.127,
            &#34;nauc_mrr_at_3_max&#34;: 0.409511,
            &#34;nauc_mrr_at_3_std&#34;: -0.064671,
            &#34;nauc_mrr_at_3_diff1&#34;: -0.01911,
            &#34;nauc_mrr_at_5_max&#34;: 0.319584,
            &#34;nauc_mrr_at_5_std&#34;: -0.103546,
            &#34;nauc_mrr_at_5_diff1&#34;: -0.025109,
            &#34;nauc_mrr_at_10_max&#34;: 0.309614,
            &#34;nauc_mrr_at_10_std&#34;: -0.117564,
            &#34;nauc_mrr_at_10_diff1&#34;: -0.019691,
            &#34;nauc_mrr_at_20_max&#34;: 0.262976,
            &#34;nauc_mrr_at_20_std&#34;: -0.092222,
            &#34;nauc_mrr_at_20_diff1&#34;: 0.024507,
            &#34;nauc_mrr_at_100_max&#34;: 0.256052,
            &#34;nauc_mrr_at_100_std&#34;: -0.094249,
            &#34;nauc_mrr_at_100_diff1&#34;: 0.012432,
            &#34;nauc_mrr_at_1000_max&#34;: 0.260112,
            &#34;nauc_mrr_at_1000_std&#34;: -0.098845,
            &#34;nauc_mrr_at_1000_diff1&#34;: 0.009697,
            &#34;main_score&#34;: 0.02837,
            &#34;hf_subset&#34;: &#34;default&#34;,
            &#34;languages&#34;: [&#34;dan-Latn&#34;],
        }
    ]
}

# check
with_fix == before_fix  # True

* restructure

* format

* relax pytrec versions

* fix incorrect parsing

* 1.38.44

Automatically generated by python-semantic-release

* Correcting the JINA models with SentenceTransformerWrapper (#3071)

* ci: Add stale workflow (#3066)

* add stale workflow

* add permissions

* add bug label to bug issue template

* revert bug issue and only look at more info needed issues

* more accurate name

* override default

* fix: open_clip package validation (#3073)

* 1.38.45

Automatically generated by python-semantic-release

* fix: Update revision for  qzhou models (#3069)

* 1.38.46

Automatically generated by python-semantic-release

* Fix the reference link for CoDi-Embedding-V1 (#3075)

Fix reference link

* fix: Add beta version of RTEB related benchmarks (#3048)

* Add RTEB related benchmarks

* Add RTEB related benchmarks

* Correcting the task names in the RTEB benchmarks

* Update mteb/leaderboard/benchmark_selector.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Adding the CURE dataset to RTEB benchmarks

* Use the right language subset

* Fix broken finance icon URL in RTEB benchmarks

Replace broken libre-finance-dollar.svg with working libre-gui-price-tag.svg
Validated all icon URLs and confirmed accessibility compliance

* Add the rteb_benchmarks to the BENCHMARK_REGISTRY

* Add the rteb_benchmarks to the BENCHMARK_REGISTRY

* Add the rteb_benchmarks to the BENCHMARK_REGISTRY

* Add the rteb_benchmarks to the BENCHMARK_REGISTRY

* Add the rteb_benchmarks to the BENCHMARK_REGISTRY

* Add the rteb_benchmarks to the BENCHMARK_REGISTRY

* Add the rteb_benchmarks to the BENCHMARK_REGISTRY

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* 1.38.47

Automatically generated by python-semantic-release

* fix: run `ruff check` on all files during ci (#3086)

* fix: run `ruff check` on all files during ci

* format

* 1.38.48

Automatically generated by python-semantic-release

* Move dev to dependency groups (#3088)

add dependency groups

* fix: Improving validate_task_to_prompt_name logs and error messages (#3079)

* Improving validate_task_to_prompt_name logs and error messages

* linter fixes

* Adding None prompts tests

* Update test_benchmark_sentence_transformer

* Update mteb/leaderboard/benchmark_selector.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: duplicate mteb multilingual variables (#3080)

* fix benchmark naming

* format

* lint

* Update tasks &amp; benchmarks tables

* model: mdbr-leaf models (#3081)

* added MDBR leaf models

* fixed revision for mdbr-leaf-ir

* added model prompts

* updated training datasets

* fixed linting

* lotte task reference

---------

Co-authored-by: Robin Vujanic &lt;robin.vujanic@mongodb.com&gt;

* 1.38.49

Automatically generated by python-semantic-release

* CI: Set upper limit for xdist version  (#3098)

* Commentout bibtex formatting

* Remove `-n auto`

* get back bibtex

* try limiting versions

* revert coverage

* revert coverage

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Combine Plots and Tables into a Single (#3047)

* feat - Combine Plots and Tables into a Single Tab #3009

* feat - Resize the plot to make it more readable

* feat - Remove the (radar chart)

* feat - Add a comment stating that it only shows the Top 5 models in the table.

* feat - adjust layout

* Update mteb/leaderboard/app.py

* format

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* mteb importable

* format

* fix model implementations

* fix `validate_task_to_prompt_name`

* align regression task with others

* remove model overview

* remove partials

* format

* fix tests

* fix evaluators tests

* add trust remote code to bsard

* pre-commit run all files

* add all descriptive stats

* fix trust remote code test

* add `RetrievalSplitData` to reranking

---------

Signed-off-by: admin &lt;bo.wang@jina.ai&gt;
Co-authored-by: Mohammad Kalim Akram &lt;kalim.akram@jina.ai&gt;
Co-authored-by: ItsukiFujii &lt;42373615+ItsukiFujii@users.noreply.github.com&gt;
Co-authored-by: xinshuohu &lt;xinshuohu@tencent.com&gt;
Co-authored-by: Xinshuo Hu &lt;yanshek.woo@gmail.com&gt;
Co-authored-by: fzowl &lt;160063452+fzowl@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: Paul Teiletche &lt;73120933+paultltc@users.noreply.github.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Alexey Vatolin &lt;vatolinalex@gmail.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: lsz05 &lt;shengzhe.li@sbintuitions.co.jp&gt;
Co-authored-by: zhichao-aws &lt;zhichaog@amazon.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Abdur-Rahman Butler &lt;79828536+abdurrahmanbutler@users.noreply.github.com&gt;
Co-authored-by: Feiyang &lt;feiyangc@google.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: semantic-release &lt;semantic-release&gt;
Co-authored-by: Nikolay Banar &lt;nikc20008@gmail.com&gt;
Co-authored-by: Penny Yu &lt;51702222+PennyYu123@users.noreply.github.com&gt;
Co-authored-by: Claude &lt;noreply@anthropic.com&gt;
Co-authored-by: fzoll &lt;5575946+fzoll@users.noreply.github.com&gt;
Co-authored-by: fzowl &lt;zoltan@voyageai.com&gt;
Co-authored-by: Bao Loc Pham &lt;67360122+BaoLocPham@users.noreply.github.com&gt;
Co-authored-by: Kritias &lt;50093609+ElPlaguister@users.noreply.github.com&gt;
Co-authored-by: roipony &lt;roipony@gmail.com&gt;
Co-authored-by: Aashka Trivedi &lt;aashka.trivedi@gmail.com&gt;
Co-authored-by: Saba Sturua &lt;45267439+jupyterjazz@users.noreply.github.com&gt;
Co-authored-by: admin &lt;bo.wang@jina.ai&gt;
Co-authored-by: Maximilian Werk &lt;maximilian.werk@gmx.de&gt;
Co-authored-by: Victor &lt;zbwkeepgoing@126.com&gt;
Co-authored-by: Yong woo Song &lt;ywsong.dev@kakao.com&gt;
Co-authored-by: Ryan Mullins &lt;ryan@ryanmullins.org&gt;
Co-authored-by: Robin Vujanic &lt;robin-vjc@users.noreply.github.com&gt;
Co-authored-by: Robin Vujanic &lt;robin.vujanic@mongodb.com&gt;
Co-authored-by: ç¬‘å°¿ä¼Šäºº &lt;44760272+q275343119@users.noreply.github.com&gt;

* Add new dataset: LIMIT (#3093)

* init commit

* revert k=2 add to main

* add paper link

* fix bibtex

* Fix `eval_langs`

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* [v2] Use `mteb.evaluate` for two-stage retrieval (#3110)

* docs: Update docs to use mteb.evaluate for two stage retrieval

* fix: Minor fixes to docstring and code

* format

* Update late interaction example

* replace minishlab model with static-similarity-mrl-multilingual-v1

* add fix for top_ranked_path

* restructure evaluators into folders to match supported modalities (#3118)

* docs: Update docs to use mteb.evaluate for two stage retrieval

* fix: Minor fixes to docstring and code

* format

* Update late interaction example

* replace minishlab model with static-similarity-mrl-multilingual-v1

* add fix for top_ranked_path

* rename image to lower

* ibid

* fix: restructure evaluators into folders to match supported modalities

- [x] restructure evaluators into folders to match supported modalities

Will be done in a future PR:

- [ ] rename evaluators to reflect supported modalities. I would probably drop `Any` and instead rename old ones to `Text*`
- [ ] make evaluators a private module

related to  #1337
previously PR on this #2980

* move regression evaluator back

* rename image evalautors script to snakecase

* format

* [v2] Refactor CLI to not use MTEB (#3119)

* docs: Update docs to use mteb.evaluate for two stage retrieval

* fix: Minor fixes to docstring and code

* format

* Update late interaction example

* replace minishlab model with static-similarity-mrl-multilingual-v1

* add fix for top_ranked_path

* rename image to lower

* ibid

* fix: restructure evaluators into folders to match supported modalities

- [x] restructure evaluators into folders to match supported modalities

Will be done in a future PR:

- [ ] rename evaluators to reflect supported modalities. I would probably drop `Any` and instead rename old ones to `Text*`
- [ ] make evaluators a private module

related to  #1337
previously PR on this #2980

* [v2] Refactor CLI to not use MTEB

* move regression evaluator back

* rename image evalautors script to snakecase

* format

* correct input type

* re-add previous benchmark names and fix bright(long) naming issue

* fixed docs where relevant

* fix benchmarks.md

* langauges &gt; languages

* remove commented out code

* update tests to new changes

* format

* add missing init

* convert overwrite strategy to choices

* replaced &#34;_&#34; with &#34;-&#34; throughout the cli

* format

* Update LIMITRetrieval Language Format (#3133)

Update LIMITRetrieval.py

* fix: error in computing missing splits when checking if cache is hit (#3130)

* fix: error in computing missing splits when checking if cache is hit

fixes 3123

and also only add batch_size to encode_kwargs is the model is actually run intended to be run.

* format

* move logging of bs so it only happens once instead of pr task

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* fix: save results also when raise_error=False (#3138)

Fixes #3135

* Deprecated `load_results` and added an update page (#3122)

* docs: Update docs to use mteb.evaluate for two stage retrieval

* fix: Minor fixes to docstring and code

* format

* Update late interaction example

* replace minishlab model with static-similarity-mrl-multilingual-v1

* add fix for top_ranked_path

* rename image to lower

* ibid

* fix: restructure evaluators into folders to match supported modalities

- [x] restructure evaluators into folders to match supported modalities

Will be done in a future PR:

- [ ] rename evaluators to reflect supported modalities. I would probably drop `Any` and instead rename old ones to `Text*`
- [ ] make evaluators a private module

related to  #1337
previously PR on this #2980

* [v2] Refactor CLI to not use MTEB

* move regression evaluator back

* rename image evalautors script to snakecase

* format

* correct input type

* re-add previous benchmark names and fix bright(long) naming issue

* fixed docs where relevant

* fix benchmarks.md

* langauges &gt; languages

* remove commented out code

* update tests to new changes

* format

* add missing init

* convert overwrite strategy to choices

* replaced &#34;_&#34; with &#34;-&#34; throughout the cli

* format

* [v2]Â Lots of docs updates for API docs (#3120)

* [v2]Â Lots of docs updates

* fix based on comments

* format

* fix failing test

* Deprecated `load_results` and added an update page

- Deprecated `load_results`
- Added New in v2.0 page, which include &#34;upgrading from v1&#34; section
- Added usage.md to docs (could probably use some work, but that is another pr)
- added empty landing page (and renamed the old index.md)

* don&#39;t integrate toc and add refs

* fix deprecated

* [v2]Â Split up usage.md for better readability  (#3124)

* Add better logo for docs

* remove copyright notice from docs

* [v2] Refactor CLI to not use MTEB (#3119)

* docs: Update docs to use mteb.evaluate for two stage retrieval

* fix: Minor fixes to docstring and code

* format

* Update late interaction example

* replace minishlab model with static-similarity-mrl-multilingual-v1

* add fix for top_ranked_path

* rename image to lower

* ibid

* fix: restructure evaluators into folders to match supported modalities

- [x] restructure evaluators into folders to match supported modalities

Will be done in a future PR:

- [ ] rename evaluators to reflect supported modalities. I would probably drop `Any` and instead rename old ones to `Text*`
- [ ] make evaluators a private module

related to  #1337
previously PR on this #2980

* [v2] Refactor CLI to not use MTEB

* move regression evaluator back

* rename image evalautors script to snakecase

* format

* correct input type

* re-add previous benchmark names and fix bright(long) naming issue

* fixed docs where relevant

* fix benchmarks.md

* langauges &gt; languages

* remove commented out code

* update tests to new changes

* format

* add missing init

* convert overwrite strategy to choices

* replaced &#34;_&#34; with &#34;-&#34; throughout the cli

* format

* Added an initial index.md

* minor

* added cli docs

* minor

* minor fixes to cli docs

* moved cli to usage

* addded docs for loading results

* added installation guide

* split up usage.md for better readability

* Update LIMITRetrieval Language Format (#3133)

Update LIMITRetrieval.py

* fix: error in computing missing splits when checking if cache is hit (#3130)

* fix: error in computing missing splits when checking if cache is hit

fixes 3123

and also only add batch_size to encode_kwargs is the model is actually run intended to be run.

* format

* move logging of bs so it only happens once instead of pr task

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* Apply suggestions from code review

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* remove results

---------

Co-authored-by: Orion Weller &lt;31665361+orionw@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Orion Weller &lt;31665361+orionw@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* [v2]: Make the `evaluator` module private (#3136)

* docs: Update docs to use mteb.evaluate for two stage retrieval

* fix: Minor fixes to docstring and code

* format

* Update late interaction example

* replace minishlab model with static-similarity-mrl-multilingual-v1

* add fix for top_ranked_path

* rename image to lower

* ibid

* fix: restructure evaluators into folders to match supported modalities

- [x] restructure evaluators into folders to match supported modalities

Will be done in a future PR:

- [ ] rename evaluators to reflect supported modalities. I would probably drop `Any` and instead rename old ones to `Text*`
- [ ] make evaluators a private module

related to  #1337
previously PR on this #2980

* [v2] Refactor CLI to not use MTEB

* move regression evaluator back

* rename image evalautors script to snakecase

* format

* correct input type

* re-add previous benchmark names and fix bright(long) naming issue

* fixed docs where relevant

* fix benchmarks.md

* langauges &gt; languages

* remove commented out code

* update tests to new changes

* format

* add missing init

* convert overwrite strategy to choices

* replaced &#34;_&#34; with &#34;-&#34; throughout the cli

* format

* [v2]Â Lots of docs updates for API docs (#3120)

* [v2]Â Lots of docs updates

* fix based on comments

* format

* fix failing test

* Deprecated `load_results` and added an update page

- Deprecated `load_results`
- Added New in v2.0 page, which include &#34;upgrading from v1&#34; section
- Added usage.md to docs (could probably use some work, but that is another pr)
- added empty landing page (and renamed the old index.md)

* don&#39;t integrate toc and add refs

* Add better logo for docs

* remove copyright notice from docs

* Added an initial index.md

* minor

* added cli docs

* minor

* minor fixes to cli docs

* moved cli to usage

* addded docs for loading results

* added installation guide

* split up usage.md for better readability

* [v2]: Restructure evaluators to be private

- [x] rename `evaluators` to `_evaluators`
- [x] delete `evaluations` folder and move `MTEB.py` and `_evaluators` out

* cleanup of imports

* [v2]Â fix logging, minor cache fixes (#3141)

* clean

* minor cache fixes

* fix logging issues

* remove results_cache

* [v2] Added documentation of MTEB types (#3146)

* docs: Update docs to use mteb.evaluate for two stage retrieval

* fix: Minor fixes to docstring and code

* format

* Update late interaction example

* replace minishlab model with static-similarity-mrl-multilingual-v1

* add fix for top_ranked_path

* rename image to lower

* ibid

* fix: restructure evaluators into folders to match supported modalities

- [x] restructure evaluators into folders to match supported modalities

Will be done in a future PR:

- [ ] rename evaluators to reflect supported modalities. I would probably drop `Any` and instead rename old ones to `Text*`
- [ ] make evaluators a private module

related to  #1337
previously PR on this #2980

* [v2] Refactor CLI to not use MTEB

* move regression evaluator back

* rename image evalautors script to snakecase

* format

* correct input type

* re-add previous benchmark names and fix bright(long) naming issue

* fixed docs where relevant

* fix benchmarks.md

* langauges &gt; languages

* remove commented out code

* update tests to new changes

* format

* add missing init

* convert overwrite strategy to choices

* replaced &#34;_&#34; with &#34;-&#34; throughout the cli

* format

* [v2]Â Lots of docs updates for API docs (#3120)

* [v2]Â Lots of docs updates

* fix based on comments

* format

* fix failing test

* Deprecated `load_results` and added an update page

- Deprecated `load_results`
- Added New in v2.0 page, which include &#34;upgrading from v1&#34; section
- Added usage.md to docs (could probably use some work, but that is another pr)
- added empty landing page (and renamed the old index.md)

* don&#39;t integrate toc and add refs

* Add better logo for docs

* remove copyright notice from docs

* Added an initial index.md

* minor

* added cli docs

* minor

* minor fixes to cli docs

* moved cli to usage

* addded docs for loading results

* added installation guide

* split up usage.md for better readability

* [v2]: Restructure evaluators to be private

- [x] rename `evaluators` to `_evaluators`
- [x] delete `evaluations` folder and move `MTEB.py` and `_evaluators` out

* cleanup of imports

* [v2] Added documentation of MTEB types

The hope is that this reduce confusion with many of our custom types.

also resolved a lot of links, converted some `args:` to `attributes`, and updated a few docstrings

* ignore specific paths during page construction to make debugging easier

* Update mteb/types/_metadata.py

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

---------

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* [v2] Don&#39;t use cache with override (#3150)

don&#39;t use cache with override

* [v2] Remove kwargs from load data (#3151)

* remove kwargs from load data

* remove cache from args

* remove last cache from args

* add test for model meta (#3153)

* add test for model meta

* fix test

* [v2] Rename descriptive stats (#3152)

`calculate_metadata_metrics` -&gt; `calculate_descriptive_statistics`

* Started adopting PEP8 naming convention (#3154)

for #1124

@Samoed you are currently working with a few abstask, can I ask you to adopt snakecase for these (so that I don&#39;t cause conflicts for you)

We also have to decide if we want to snake_case task (should be easy enough to do, but will take a while)

* [v2] Refactor mieb retrieval (#3125)

* start unifying any retrieval tasks

* working multimodal retrieval

* fixes

* fix imports

* fix imports

* pass image column name

* fix retrieval loader

* fix cv_recall

* try add top ranked

* make task reranking

* update descriptive stats

* fix tests

* fix queries statistics calculation

* remove unnecessary checks for retrieval tasks

* handle `skip_first_result`

* add accuracy comment

* Update retrieval_metrics.py

* update cached wrapper (#3149)

* update cached wrapper

* update cached wrapper

* update cached wrapper

* support multimodal for cache

* add test

* add test

* remove test for testing model&#39;s functions

* [v2] Refactor multilabel classification (#3137)

* start unifying any retrieval tasks

* working multimodal retrieval

* fixes

* fix imports

* fix imports

* pass image column name

* fix retrieval loader

* fix cv_recall

* try add top ranked

* make task reranking

* update descriptive stats

* fix tests

* fix queries statistics calculation

* remove unnecessary checks for retrieval tasks

* handle `skip_first_result`

* refactor multilabel classification

* refactor multilabel classification

* remove cache

* make select columns directly

# Conflicts:
#	mteb/abstasks/AbsTaskMultilabelClassification.py

* make select columns directly

* add accuracy comment

* Update retrieval_metrics.py

* add typehint

* fix import

* Use `SentenceTransformer` `encode_query`/`encode_document` (#3158)

use `encode_query`

* [v2] Support dialogs with different lengths (#3156)

* support dialogs with different lenght

* update stats

* Update tests/test_benchmark/mock_tasks.py

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* change numpy model

* fix test

* remove co2 change

---------

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* fix dataset card creation (#3162)

* add `MulimodalSentenceTransformer` and `mme5` (#3159)

add mme5

* add dark theme (#3165)

* fix: make sentence_transformers an optional import (#3167)

* fix: make sentence_transformers an optional import

It is still a required dependency, but this makes the import time consistenly 0.5-1s faster.

Also did a minor refactor of `evaluate.py`

* remove comment

* add missing import

* format

* added mteb_model_mete to cachewrapper

* fix crossencoder

* format

* [v2] build benchmark registry only when needed (#3171)

* [v2] build benchmark registry only when needed

*Note*: This means that people will no longer be able to &#34;ingest&#34; a benchmark import the `BENCHMARK_REGISTRY`. Unless they monkey patch the build_registry.

```
# analysis from branch without import of transformers and sentence-transformers
python -X importtime -c &#34;import mteb&#34; 2&gt; import_times.txt
grep &#34;import time:&#34; import_times.txt | sort -k4 -nr | head -10
```

```
import time: self [us] | cumulative | imported package
import time:    618575 |     686134 |           mteb.benchmarks.benchmarks.benchmarks
import time:    158307 |     158307 |           torch._C
import time:    136095 |     139684 |                 torch._prims
import time:     58651 |      58651 |           mteb.tasks.BitextMining.multilingual.WebFAQBitextMining
import time:     55521 |      60088 |               mteb.models.model_implementations
import time:     52461 |     192145 |               torch._decomp.decompositions
import time:     50383 |      50383 |               mteb.tasks.Retrieval.multilingual.BelebeleRetrieval
import time:     45397 |      62903 |           fsspec
import time:     41405 |     275138 |           torch._meta_registrations
```

import times before (from v2.0.0):
9.013, 8.588, 8.660

import times now:
7.769, 7.525, 7.799

* fix casing

* [v2] don&#39;t import transformers on import (#3170)

* fix: make sentence_transformers an optional import

It is still a required dependency, but this makes the import time consistenly 0.5-1s faster.

Also did a minor refactor of `evaluate.py`

* remove comment

* add missing import

* [v2] don&#39;t import transformers on intialization

set_seed is called during the initialization of the aggregate tasks. I have refactored it to take the main components from transformers set_seed. We do not initialize the seed for specialized hardware, but maybe that is also not needed?

With this change we no longer need make transformers an optional install.

This give a notably increase in load time
6.511, 6.798, 6.423
to
5.213, 5.230, 4.929

* [v2]: Added task, benchmark, model overview to docs (#3164)

* [v2]: Added task overview to docs

We could consider removing the task table. However, it is currently not a big cost to keep it.

Updated are available at:
https://embeddings-benchmark.github.io/mteb/

* fix python script reference

* minor ci fiks

* restructure based on feedback

* added models overview

* add benchmark overview

* minor

* minor fixes to descriptions

* add fixes based on comments

* add fixes based on comments

* don&#39;t add benchmarks to TOC

* fix based on corrections

* fixed issue with CQAD

* [v2]: Fix unclear warning (#3182)

* [v2]: Fix unclear warning

This warning can be quite unclear when running models. I think this rewrite is more clear.

* format

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* [v2] Select required columns to run (#3190)

* select required columns to run

* fix tasks

* [v2] refactor and create docs for results objects (#3155)

* [v2] refactor and create docs for results objects

This is the last thing needed for a documentation of the API.

https://embeddings-benchmark.github.io/mteb/

- renamed `load_results` to `results`
- moved `ModelResult` to its own script
- restructured import of results to use `results` module
- added documentation for the results module
- converted a few function marked with TODOs to private and deleted legacy loaders/converters
- moved `load_results.py` out of `results`
- Added missing documentation for a few of the types

sidenote: I really feel like we are starting to resolve some of our circular import issues, I rarely run into them now and when I do they are typically very easy to fix

* avoid rename of namespace during import

* Merge branch &#39;v2.0.0&#39; of https://github.com/embeddings-benchmark/mteb into refactor-results

* remove comment

* Reupload datasets with `trust remote code` (#3161)

* start removing trust remote code

* fix dataset uploading

* upload bitext as parallel

* fix uploading

* try to upload all

* continue reuploading

* fix zeroshot upload

* add comment to trust remote code

* reupload legal bench

* fix datasets

* remove exceptions

* fix tests

* fix bitext loading

* fix bitext

* try to fix retrieval

* fix

* fix revisions

* remove parameter from metadata dataset dict

* [v2] Start type checking (#3176)

* start type check integration

* fix imports

* fix validation

* fix required import

* fix comments

* [v2] Merge main 20 09 (#3193)

* fix: Updating the default batch size calculation in the voyage models (#3091)

* 1.38.50

Automatically generated by python-semantic-release

* fix: Add @classmethod for @field_validators in TaskMetadata  (#3100)

* Align task prompt dict with `PromptType` (#3101)

* align task prompt dict with `PromptType`

* use value instead of enum

* 1.38.51

Automatically generated by python-semantic-release

* model: Add ModelMeta for OrdalieTech/Solon-embeddings-mini-beta-1.1 (#3090)

* Add ModelMeta for OrdalieTech/Solon-embeddings-mini-beta-1.1

* Add training_datasets (common_corpus, fineweb, wiki_fr, private LLM-synth)

* Format with ruff + add loader per review

* Apply ruff format/fixes

* Update mteb/models/ordalietech_solon_embeddings_mini_beta_1_1.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/ordalietech_solon_embeddings_mini_beta_1_1.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Register OrdalieTech/Solon-embeddings-mini-beta-1.1 in overview (ModelMeta + loader)

* Update mteb/models/ordalietech_solon_embeddings_mini_beta_1_1.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* fix import

* Add memory_usage_mb=808.0 and required fields to ModelMeta

* Fix 210 milions of parameters

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* fix: Allow closed datasets (#3059)

* - Added an include_private parameter to the get_tasks() function that defaults to False
  - This ensures that by default, tests only run on public datasets
  - Tests can explicitly set include_private=True when needed to test private datasets

  - Added is_public: bool | None = None field to TaskMetadata
  - The field is optional and defaults to None (treated as public)
  - Updated the is_filled() method to exclude is_public from required fields
  - Added documentation

* - Added an include_private parameter to the get_tasks() function that defaults to False
  - This ensures that by default, tests only run on public datasets
  - Tests can explicitly set include_private=True when needed to test private datasets

  - Added is_public: bool | None = None field to TaskMetadata
  - The field is optional and defaults to None (treated as public)
  - Updated the is_filled() method to exclude is_public from required fields
  - Added documentation

* Correcting due to comments

* Update mteb/abstasks/TaskMetadata.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/overview.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Removing the not used filter_tasks_by_privacy function

* Correcting due to comments

* Correcting due to comments

* Correcting due to comments

* Removing the test case

* Rename the include_private parameter to exclude_private

* Rename the include_private parameter to exclude_private

* Add private tasks tests

* Add private tasks tests

* Update tests/test_tasks/test_private_tasks.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Add private tasks tests

* Add private tasks tests

* Add private tasks tests

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* 1.38.52

Automatically generated by python-semantic-release

* Ci: test out GH models with welcoming new comers (#3112)

test out GH models with welcoming new comers

* ci: Dataset check on new PR (#3103)

* add dataset check on new PR

* add extract datasets

* run as module

* update startswith

* update workflow name

* add GitPython

* export var

* same shell session

* address review comments

* add to docs to say what this script does

* add docs

* model: add Youtu-Embedding-V1 (#3115)

* add youtu models

* add a blank line

* fix the optional dependencies and lint the code

* remove unused dependencies and reformat

* revise prompt_type

---------

Co-authored-by: springxchen &lt;springxchen@tencent.com&gt;

* fix: add voyage quantization models (#3092)

* Adding quantization support

* Update mteb/models/voyage_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/model_meta.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/model_meta.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Simplifying the quantization/output_dtype

* Update mteb/model_meta.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* 1.38.53

Automatically generated by python-semantic-release

* model: EmbeddingGemma 300M (#3129)

* model: EmbeddingGemma 300M

* Add license and revision

* fix: Add dedicated display for RTEB benchmark results (#3089)

* feat - remove special filtering, keep zero-shot, keep borda rank

* feat - remove get_rteb_benchmark.py

* feat - delete get_rteb_benchmark.py;RTEB_BENCHMARK_ENTRIES changes

* feat -format

* Update mteb/load_results/benchmark_results.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update tasks &amp; benchmarks tables

* 1.38.54

Automatically generated by python-semantic-release

* dataset: Add Dapfam patent retrieval tasks (#2946)

* chore: add &#39;Patent retrieval&#39; subtype to TaskMetadata

* feat(retrieval): add DAPFAM patent retrieval tasks (+18 variants)

* Dapfam patent retrieval PR #2946 : refactor DAPFAM tasks (explicit classes, license, metadata, custom definition explanation ...)

* Dapfam patent retrieval PR #2946 : refactor DAPFAM tasks (explicit classes, license, metadata, custom definition explanation ...)

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Changes :

- Added possibility to opt in or out of quantization through the &#34;quantize&#34; argument.
- Added possibility to compute raw dot product without normalization. (to reproduce the paper method the &#34;similarity&#34; argument should be &#34;cosine&#34;).
- Removed unecessary function and overhauled the tasks descriptions to be more clear.

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Changes made :
- Overhauled task descriptions as well as naming to conform with the naming scheme of mteb retrieval tasks.
- Similarity is now computed using the similarity function of the passed model.
- Changed optional quantization method to conform with sentence transformers similarity function.

to reproduce the paper metrics, one can use the following snippet :

```python
from mteb import mteb
from sentence_transformers import SentenceTransformer

model_name = &#34;Snowflake/snowflake-arctic-embed-m-v2.0&#34;
model = SentenceTransformer(model_name,
                           model_kwargs={
                            &#34;torch_dtype&#34;: &#34;float16&#34;,
                            },
                           trust_remote_code=True,
                            ).cuda().eval()

tasks = mteb.get_tasks(tasks=[
    &#34;DAPFAMInTitlAbsToTitlAbsClmRetrieval&#34;,
    &#34;DAPFAMAllTitlAbsToTitlAbsClmRetrieval&#34;,
    &#34;DAPFAMOutTitlAbsToTitlAbsClmRetrieval&#34;,
     add the other 3 remaining tasks ...
    ])

evaluation = mteb.MTEB(tasks=tasks)
results = evaluation.run(
		model,
		output_folder=f&#34;mteb_res/{model_name}&#34;,
		quantize=True, # if set to false or not set, the obtained ndcg@10 and map@10 will be ~0.001 higher
		encode_kwargs= {&#34;batch_size&#34; : 32}
	)
```

* changed default value of quantization to false

* added the import to all DAPFAM tasks; tested that the  works; verified compliance with the checklist

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* added revision numbers to all dataset loading operations as well as the metadata itself

* intermediate changes, refresh local branch

* intermediate changes, refresh local branch again

* scale back to standard evaluation with empty set exclusion, various cosmetic/formatting changes

* minor cosmetic/formatting changes

* fixed main metric to be ndcg_at_100 as in the paper

* removed old code artifacts from previous versions

* read appropriate loading arguments from task metadata, remove unecessary class attribute

* reformat bibtex ( remark on the assertion since it tries to match literal string instead of bibtex formatting, format inconsistent with arXiv default), fixed metadata, parameters read from task metadata, all tests passed

* refactor data loading to read from metadata class attributes

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update tasks &amp; benchmarks tables

* Align max tokens (#3172)

* Correct the VoyageAI model&#39;s batch creation/batch size calculation (#3185)

Correct the batch creation

* dataset: Adding JapaneseCode1Retrieval as the first non-public dataset (#3168)

* Adding JapaneseCode1Retrieval as the first non-public dataset

* Transformed dataset

* Adding as private dataset to tests

* Correct the private task test

* Use the sample dataset as a reference

* Use the sample dataset as a reference

* fix ds loading

* allow on forks

* upd aciton

* remove paths

* try to trigger ci

* add ref

* add permissions

* remove paths

* add paths back

* get back to pull request

* rollback action

* Trying to resolve the token/secret problem

* Trying to resolve the token/secret problem

* Update dataset_loading_pr.yml

* Update dataset_loading_pr.yml

* Try the latest datasets package (worked for me)

* Try the latest datasets package (worked for me)

* Try the latest datasets package (worked for me)

* (last?) try

* (last?) try

* (last?) try

* Reverting the changes

* Exclude the private datasets from tests

* Apply suggestions from code review

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Solomatin Roman &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* fix: add version check for `embeddinggemma-300m` (#3189)

add version check

* dataset: Added a set of  closed datasets (#3186)

* Add 12 more closed datasets
Extend the RTEB benchmarks

* trust_remote_code

* trust_remote_code

* Enabling JapaneseCode1Retrieval in the RTEB benchmarks

* Add closed datasets as private tasks

* Correct due to the comment

* Update tasks &amp; benchmarks tables

* fix: Edit ack &amp; sponsors (#3187)

* dataset: Update FaMTEB to Version 2 (#3157)

* Update benchmark to version 2

* make others in benchmark selector one line code

* small changes

* update a few tasks metadata

* update faintent license with correct form

* remove redundant trust remote codes

* fix hardnegatives revision

* make lint

* fix errors

* apply suggestions

* fix citation problem

* add PR link to benchmark desc

* remove duplicate dataset names in mcinext_models

* update prompts

---------

Co-authored-by: mehran &lt;mehan.sarmadi16@gmail.com&gt;

* Update tasks &amp; benchmarks tables

* 1.38.55

Automatically generated by python-semantic-release

* fix: Add conflicting dependencies to toml (#3191)

fix conflict dependencies

* 1.38.56

Automatically generated by python-semantic-release

* fix

* add dapfam

* add stats

* fix descriptive_stats package

* fix descriptive stat loading

* fix descriptive stat loading

* fix dapfam

* add stats

* move models files

* fix training datasets

---------

Co-authored-by: fzoll &lt;5575946+fzoll@users.noreply.github.com&gt;
Co-authored-by: semantic-release &lt;semantic-release&gt;
Co-authored-by: mathlesage &lt;134429083+mathlesage@users.noreply.github.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: spring-quan &lt;38248619+spring-quan@users.noreply.github.com&gt;
Co-authored-by: springxchen &lt;springxchen@tencent.com&gt;
Co-authored-by: Ryan Mullins &lt;ryanmullins@google.com&gt;
Co-authored-by: ç¬‘å°¿ä¼Šäºº &lt;44760272+q275343119@users.noreply.github.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: Iliass Ayaou &lt;iliass.ayaou@insa-strasbourg.fr&gt;
Co-authored-by: Niklas &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: Mehran Sarmadi &lt;128898167+mehran-sarmadi@users.noreply.github.com&gt;
Co-authored-by: mehran &lt;mehan.sarmadi16@gmail.com&gt;

* [v2] allow datasets v4 (#3175)

* start removing trust remote code

* fix dataset uploading

* upload bitext as parallel

* fix uploading

* try to upload all

* continue reuploading

* fix zeroshot upload

* add comment to trust remote code

* reupload legal bench

* fix datasets

* remove exceptions

* fix tests

* fix bitext loading

* fix bitext

* try to fix retrieval

* fix

* fix revisions

* allow ds v4

* fix datasets

* fix datasets v4

* fix datasets column combine

* Apply suggestion from KennethEnevoldsen

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* [v2] Refactor `create metadata` (#3199)

* refactor create metadata

* add docstring

* add warning message

* sort results and add results table

* optionally create table

* remove tables

* Remove accidently added models (#3208)

remove models

* [v2] enable `RUF` rules (#3198)

update ruff rules

* [v2] add multi-vector indexes so we can scale multi-vector search (#3183)

* add pylate models

* move pylate search to separate class

* remove encoder

* remove `is_pylate_compatible`

* add link to search class

* don&#39;t use idnex on rerank

* disable triton kernels

* fix pyproject version

---------

Co-authored-by: oweller2 &lt;oweller2@dsailogin.mgmt.ai.cluster&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* [v2] make more functions private (#3200)

* make more functions private

* fix imports

* make cli and langs public

* fix import

* [v2] Enable `PTH` rule (#3197)

* enable `PTH` rule

* fix script

* Merge main 05 10 (#3246)

* fix: Correct metadata for ArguAna dataset (#3202)

* Update tasks &amp; benchmarks tables

* 1.38.57

Automatically generated by python-semantic-release

* model: Add BMRetriever (#3195)

* model: Add BMRetriever

* Update mteb/models/bmretriever_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/bmretriever_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: remove trust_remote_code option

* feat: implement BMREtrieverWrapper based on InstructSentenceTransformerWrapper

* refactor: update training datasets for bmretriever

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Revert &#34;Ci: test out GH models with welcoming new comers&#34; (#3206)

Revert &#34;Ci: test out GH models with welcoming new comers (#3112)&#34;

This reverts commit 73a35e0bb02e61108d50385f4c43fd7d1b16e984.

* model: Add Codefuse models (#3205)

* add codefuse models

* add codefuse models

* Update codefuse_models.py

* lint codefuse.py

* fix(models): ensure prompt_type is passed to format_instruction (#3216)

* 1.38.58

Automatically generated by python-semantic-release

* Adding Cohere&#39;s output_dimension and embedding_type parameter (#3204)

* Adding Cohere&#39;s output_dimension and embedding_type parameter
Cohere&#39;s embed-v4 binary and int8

* Correcting due to comments

* dataset: add swedish cpc patent classifications to mteb (#3072)

* feat: add swedish cpc patent classifications to mteb

* fix: formatting and init imports

* fix: update mteb task according to feedback

* fix: perform citation and code formatting

* fix: add train and test split for both datasets

* fix: AttributeError in ColPaliEngineWrapper similarity method (#3177)

* fix: delete kwargs for similarity score in ColPaliEngineWrapper for method behavior

* chore: fix colpali_models similarity  handle device

* Update tasks &amp; benchmarks tables

* 1.38.59

Automatically generated by python-semantic-release

* fix: prevent EOS token truncation (#3218)

* fix(models): prevent EOS token truncation for BMRetriever

* refactor(models): refactor tokenizer setup in `InstructSentenceTransformerWrapper`

* fix(models): correct eos token handling in `BMRetrieverWrapper`

* 1.38.60

Automatically generated by python-semantic-release

* Update giga embeddings (#3210)

* update giga embeddings

* update giga embeddings

* 3b-september-2025

* fixed

* lint

* Update mteb/models/ru_sentence_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* change revision due to flash-attn dependency

* change apply_instruction_to_passages

---------

Co-authored-by: Kolodin Egor &lt;eikolodin@sberbank.ru&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ722497 &lt;dolegosmirnov@sberbank.ru&gt;

* fix: Refactor split create_tables into static Benchmark methods (#3126)

* feat - Split create_tables into static Benchmark methods

* feat - format

* Update mteb/leaderboard/table.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* feat - remove search query;take benchmark result as input;addressing the circular import,

* feat - format

* Update mteb/benchmarks/benchmark.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/benchmarks/benchmark.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* feat - use to_dataframe;clean table.py;move creat_table

* feat - fix circular import

* feat - clean-up

* feat - format

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* 1.38.61

Automatically generated by python-semantic-release

* Extending the RTEB benchmark (#3223)

Adding another voyageai model

* Update tasks &amp; benchmarks tables

* model: New qzmodel (#3211)

* Update qzhou_models.py

* Update qzhou_models.py

* reformat script code

* Update configuration

* According to our new decision, the model name has been changed to &#34;QZhou-Embedding-Zh&#34;.

* Fix variable naming issues.

* model: Update Youtu embedding model (#3227)

* add youtu models

* add a blank line

* fix the optional dependencies and lint the code

* remove unused dependencies and reformat

* revise prompt_type

* update youtu_models

---------

Co-authored-by: springxchen &lt;springxchen@tencent.com&gt;

* dataset: Add Software Issue Localization Datasets (#3178)

* add software issue localization datasets

* add software issue localization datasets

* update and add multilingual datasets

* fix citation format issues

* Update mteb/tasks/Reranking/eng/SWEbenchVerifiedReranking.py

* fix linting issues

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update tasks &amp; benchmarks tables

* feat: Officially include RTEB in the leaderboard (#3222)

* feat - adjust Rteb&#39;s Benchmark

* feat - add blank

* fix menu names

* Update mteb/leaderboard/benchmark_selector.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* moving around tasks

* fix: Update RTEB summary columns (#3226)

* fix(models): ensure prompt_type is passed to format_instruction (#3216)

* 1.38.58

Automatically generated by python-semantic-release

* Adding Cohere&#39;s output_dimension and embedding_type parameter (#3204)

* Adding Cohere&#39;s output_dimension and embedding_type parameter
Cohere&#39;s embed-v4 binary and int8

* Correcting due to comments

* dataset: add swedish cpc patent classifications to mteb (#3072)

* feat: add swedish cpc patent classifications to mteb

* fix: formatting and init imports

* fix: update mteb task according to feedback

* fix: perform citation and code formatting

* fix: add train and test split for both datasets

* fix: AttributeError in ColPaliEngineWrapper similarity method (#3177)

* fix: delete kwargs for similarity score in ColPaliEngineWrapper for method behavior

* chore: fix colpali_models similarity  handle device

* Update tasks &amp; benchmarks tables

* 1.38.59

Automatically generated by python-semantic-release

* fix: prevent EOS token truncation (#3218)

* fix(models): prevent EOS token truncation for BMRetriever

* refactor(models): refactor tokenizer setup in `InstructSentenceTransformerWrapper`

* fix(models): correct eos token handling in `BMRetrieverWrapper`

* 1.38.60

Automatically generated by python-semantic-release

* Update giga embeddings (#3210)

* update giga embeddings

* update giga embeddings

* 3b-september-2025

* fixed

* lint

* Update mteb/models/ru_sentence_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* change revision due to flash-attn dependency

* change apply_instruction_to_passages

---------

Co-authored-by: Kolodin Egor &lt;eikolodin@sberbank.ru&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ722497 &lt;dolegosmirnov@sberbank.ru&gt;

* fix: Refactor split create_tables into static Benchmark methods (#3126)

* feat - Split create_tables into static Benchmark methods

* feat - format

* Update mteb/leaderboard/table.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* feat - remove search query;take benchmark result as input;addressing the circular import,

* feat - format

* Update mteb/benchmarks/benchmark.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/benchmarks/benchmark.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* feat - use to_dataframe;clean table.py;move creat_table

* feat - fix circular import

* feat - clean-up

* feat - format

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* 1.38.61

Automatically generated by python-semantic-release

* Extending the RTEB benchmark (#3223)

Adding another voyageai model

* Update tasks &amp; benchmarks tables

* feat - filter_by_privacy

* feat - add new fields for rteb part

* feat - getattr

* feat - adjust privacy filter logic

* feat - enhance summary table column renaming and add &#39;is_public&#39; field mapping

* fix: remove unused &#39;is_public&#39; attribute from TaskResult

---------

Co-authored-by: Yongbin Choi &lt;whybe.choi@gmail.com&gt;
Co-authored-by: semantic-release &lt;semantic-release&gt;
Co-authored-by: fzoll &lt;5575946+fzoll@users.noreply.github.com&gt;
Co-authored-by: Atheer &lt;atheer2104@protonmail.com&gt;
Co-authored-by: Yong woo Song &lt;ywsong.dev@kakao.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: Egor &lt;31567312+ekolodin@users.noreply.github.com&gt;
Co-authored-by: Kolodin Egor &lt;eikolodin@sberbank.ru&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ722497 &lt;dolegosmirnov@sberbank.ru&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: smile &lt;smile@pinai.io&gt;
Co-authored-by: ethan &lt;smiletoye@gmail.com&gt;

* removed show_rteb args

* avoid defining function where we can just use the metadata

* minor fixes

* minor fixes

* fix: Correct logic for filtering public tasks in ModelResult class (#3230)

Co-authored-by: ethan &lt;smiletoye@gmail.com&gt;

---------

Co-authored-by: q275343119 &lt;275343119@qq.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: ç¬‘å°¿ä¼Šäºº &lt;44760272+q275343119@users.noreply.github.com&gt;
Co-authored-by: Yongbin Choi &lt;whybe.choi@gmail.com&gt;
Co-authored-by: fzoll &lt;5575946+fzoll@users.noreply.github.com&gt;
Co-authored-by: Atheer &lt;atheer2104@protonmail.com&gt;
Co-authored-by: Yong woo Song &lt;ywsong.dev@kakao.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: Egor &lt;31567312+ekolodin@users.noreply.github.com&gt;
Co-authored-by: Kolodin Egor &lt;eikolodin@sberbank.ru&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ722497 &lt;dolegosmirnov@sberbank.ru&gt;
Co-authored-by: smile &lt;smile@pinai.io&gt;
Co-authored-by: ethan &lt;smiletoye@gmail.com&gt;

* Update tasks &amp; benchmarks tables

* 1.39.0

Automatically generated by python-semantic-release

* fix: Add submission references for RTEB (#3233)

* fix: Add rteb submission references and improve descriptions.

* Added evaluation request

* added field for tasks

* 1.39.1

Automatically generated by python-semantic-release

* dataset: add human tasks and benchmark (#3214)

* Human Subsets Tasks

* Fixed Multilingual Classification Subset

* linting

* fix citations format

* make lint

* fix tests

* remove human folder

* fix relative imports

* add adapted_from for all human subsets

* fix pydantic errors

* add benchmark object

* make benchmark discoverable

* bibtex test

* Apply suggestion

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* rename &amp; reupload

* upd tests

* upd tests again

* add model

* add benchmark to leaderboard

* change branch of leaderboard

* remove branch of load data

* fix model meta path

* make mteb importable

* update repo

* Update mteb/benchmarks/benchmarks/benchmarks.py

* Update mteb/leaderboard/benchmark_selector.py

* Update mteb/load_results/load_results.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Adnan El Assadi &lt;aassadi22@ku.edu.tr&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: AdnanElAssadi56 &lt;115242814+AdnanElAssadi56@users.noreply.github.com&gt;

* Update tasks &amp; benchmarks tables

* Remove &#39;HUME(v1)&#39; from leaderboard benchmark (#3236)

* Remove &#39;HUME(v1)&#39; from leaderboard benchmark

* lint

* docs: Update adding benchmark documentation (#3229)

* update adding_a_benchmark.md documentation

* fix numbers

* fix: Further specified macro-language code for Norwegian (#3228)

* fix: Further specified macro-language code for Norwegian

&#34;nor&#34; is a macro-language code that covers bokmÃ¥l and nynorsk (both norwegian), but this means that these datasets will be missed if using &#34;nob&#34; or &#34;nno&#34;. Specifying it like this should allow this.

* furhter specified macro language &#34;nor&#34;

* Update tasks &amp; benchmarks tables

* 1.39.2

Automatically generated by python-semantic-release

* fix max tokens (#3243)

* fix models

* fix imports

* fix task import

* reupload HUME tasks

* reupload SWE tasks

* add stats

* fix python39 transformers compatibility (#3254)

* fix python39 transformers

* fix

* Aggregate by subset for HUMEv1 (#3255)

aggregate by subset for HUMEv1

* Update tasks &amp; benchmarks tables

* Fix AbsTaskTextRegression task (#3257)

Fix AbsTaskTextRegression

* Added Japanese to Retrieval (#3252)

* feat - add Japanese

* feat - use mteb.get_benchmark

* fix - 3.9 test error

* Revert &#34;fix - 3.9 test error&#34;

This reverts commit 6bfee53cff48304cc22d8248aa275dcc9e385475.

* fix - 3.9 test error

* Update tasks &amp; benchmarks tables

* fix bm25 on small datasets (#3261)

---------

Co-authored-by: Yongbin Choi &lt;whybe.choi@gmail.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: semantic-release &lt;semantic-release&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Geralt &lt;94539084+Geralt-Targaryen@users.noreply.github.com&gt;
Co-authored-by: fzoll &lt;5575946+fzoll@users.noreply.github.com&gt;
Co-authored-by: Atheer &lt;atheer2104@protonmail.com&gt;
Co-authored-by: Yong woo Song &lt;ywsong.dev@kakao.com&gt;
Co-authored-by: Egor &lt;31567312+ekolodin@users.noreply.github.com&gt;
Co-authored-by: Kolodin Egor &lt;eikolodin@sberbank.ru&gt;
Co-authored-by: ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ722497 &lt;dolegosmirnov@sberbank.ru&gt;
Co-authored-by: ç¬‘å°¿ä¼Šäºº &lt;44760272+q275343119@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: Peter &lt;51702222+PennyYu123@users.noreply.github.com&gt;
Co-authored-by: spring-quan &lt;38248619+spring-quan@users.noreply.github.com&gt;
Co-authored-by: springxchen &lt;springxchen@tencent.com&gt;
Co-authored-by: Tarun Suresh &lt;68882529+tarsur909@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: q275343119 &lt;275343119@qq.com&gt;
Co-authored-by: smile &lt;smile@pinai.io&gt;
Co-authored-by: ethan &lt;smiletoye@gmail.com&gt;
Co-authored-by: Adnan El Assadi &lt;aassadi22@ku.edu.tr&gt;
Co-authored-by: AdnanElAssadi56 &lt;115242814+AdnanElAssadi56@users.noreply.github.com&gt;
Co-authored-by: Niklas &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: Alexey Vatolin &lt;vatolinalex@gmail.com&gt;

* [v2] fix issues when loading results (#3180)

* [v2] fix issues when loading results

These issues arose when testing out v2.

Problem:
```py
import mteb
from mteb.cache import ResultCache

# specify models
noninstruct = mteb.get_model_meta(&#34;intfloat/multilingual-e5-large&#34;)
instruct = mteb.get_model_meta(&#34;intfloat/multilingual-e5-large-instruct&#34;)
models = [noninstruct, instruct]

cache_path = &#34;/Users/au561649/Github/prompt-hacking/data/mteb_cache&#34;
cache = ResultCache(cache_path)
cache.download_from_remote(download_latest=False)

benchmark = mteb.get_benchmark(&#34;MTEB(eng, v2)&#34;)

m_names: list[str] = [m.name for m in models]  # type: ignore
results = cache.load_results(m_names, benchmark.tasks) # fails

# Problem 1: fails to load external results -- fixed by allowing by not removing `mteb_version = None` from the data.
# I couldn&#39;t find any reason that it was there. Tests pass and leaderboard runs fine without it. The original commit also seems to both pop it and add None as allowed so my guess is that
# both solutions were considered and accidentally removing it was also merged.

# Problem 1.1: arose when checking if leaderboard works -- fixed by catching KeyError in addition to ValueError when calling `mteb.get_model_meta`. I assume the chance to get KeyError was added in v2
meta = mteb.get_model_meta(&#34;Snowflake/snowflake-arctic-embed-l&#34;)
meta.get_training_datasets()
```

* add leaderboard build to all PRs

* run build docs on all PRs

* [v2] fix ci (#3267)

* fix ci

* fix in another place

* fix `filter_tasks` in leaderboard

* Add save predictions to `STS`, `Classification`, `MultilabelClassification` (#3262)

* start adding predictions

* fix task result validation

* fix tests

* v2: Added description of new multimodal input and new desc. stats (#3269)

* v2: Added description of new multimodal input and new desc. stats

* fixes from review

* Updated docs to include saving predictions

* Update docs/whats_new.md

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* [v2] fix category in retrieval tasks (#3277)

fix category in retrieval tasks

* [v2] update gh readme to point to the new documentation (#3276)

* v2: Added description of new multimodal input and new desc. stats

* fixes from review

* Updated docs to include saving predictions

* [v2] update gh readme to point to the new documentation

Also made a few minor fixes to the datasets

* Update mteb/tasks/Clustering/nob/snl_clustering.py

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

---------

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* Update PyLate model revision to fix inference without FA (#3278)

Fix revision of moderncolbert

Co-authored-by: Antoine Chaffin &lt;antoine.chaffin@lighton.ai&gt;

* Update Hugging Face logo path in README (#3281)

* v2: Added description of new multimodal input and new desc. stats

* fixes from review

* Updated docs to include saving predictions

* [v2] update gh readme to point to the new documentation

Also made a few minor fixes to the datasets

* Update mteb/tasks/Clustering/nob/snl_clustering.py

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* Update Hugging Face logo path in README

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* [v2] Make co2 optioinal (#3288)

disable co2 by default in `mteb.MTEB`

* Reupload last datasets with `trust_remote_code` (#3293)

* reupload last datasets

* fix bucc

* [v2] Use `tqdm.auto` everywhere (#3290)

* `from tqdm import tqdm`

* `import tqdm`

* [v2]Â Add better prints classification (#3286)

* Better prints classification [draft]

First shot at improving prints. I am starting with

- fixed warning for np.mean
- redid experiments to use tqdm
  - I am unsure if people would like to be able to turn if off and if so how?
- I added two logs*.txt files to show how the logging changed (will be removed later)
- Added a logOnce function to reduce unec. repititions
- Added nesting for tqdm (unsure if the complexity here is too much)

run using:
```py
import logging
import os

import mteb

os.environ[&#34;TOKENIZERS_PARALLELISM&#34;] = &#34;false&#34;
# happens to to sklearn .fit parallelism (unsure if we should handle this)

logging.basicConfig(level=logging.INFO)

model_name = &#34;sentence-transformers/static-similarity-mrl-multilingual-v1&#34;
model = mteb.get_model(model_name)
tasks = mteb.get_tasks(tasks=[&#34;Banking77Classification&#34;])
results = mteb.evaluate(model, tasks=tasks, cache=None, overwrite_strategy=&#34;always&#34;)
```

I purposefully didn&#39;t use rich as I want it work cleanly without it.

* fixed based on review

* add show_progress_bar to evaluate and clean up

* format

* removed nested tqdm to simplify

* Add predictions for `ZeroShot` and `BitextMining` (#3292)

* update bitext mining and zeroshot

* fix bitext

* fix bitext tasks

* add tests

* [v2] remove support for 3.9 and add support for 3.13 (#3304)

* [v2] remove support for 3.9 and add support for 3.13

* bounded pylate dependency

* update to 3.10

* fixed comments

* [v2] Add constent logging for all tasks  (#3291)

* Better prints classification [draft]

First shot at improving prints. I am starting with

- fixed warning for np.mean
- redid experiments to use tqdm
  - I am unsure if people would like to be able to turn if off and if so how?
- I added two logs*.txt files to show how the logging changed (will be removed later)
- Added a logOnce function to reduce unec. repititions
- Added nesting for tqdm (unsure if the complexity here is too much)

run using:
```py
import logging
import os

import mteb

os.environ[&#34;TOKENIZERS_PARALLELISM&#34;] = &#34;false&#34;
# happens to to sklearn .fit parallelism (unsure if we should handle this)

logging.basicConfig(level=logging.INFO)

model_name = &#34;sentence-transformers/static-similarity-mrl-multilingual-v1&#34;
model = mteb.get_model(model_name)
tasks = mteb.get_tasks(tasks=[&#34;Banking77Classification&#34;])
results = mteb.evaluate(model, tasks=tasks, cache=None, overwrite_strategy=&#34;always&#34;)
```

I purposefully didn&#39;t use rich as I want it work cleanly without it.

* fixed based on review

* add show_progress_bar to evaluate and clean up

* format

* removed nested tqdm to simplify

* [v2] Add logging for clustering

- Added logging for AbstaskClusteringFast
- Added logging for AbsTaskAnyClustering
- Minor tweaks to Classification clustering to ensure consistent style

* format

* add logger.debug

* Added sts and zero shot

* clean

* added logging to other tasks

* fixes

* format and fix error

* [v2] Add save predictions to `PairClassification` (#3298)

* update bitext mining and zeroshot

* fix bitext

* fix bitext tasks

* add tests

* refactor pair classification

* fix tests

* [v2] Align `ImageText` statistics with others (#3289)

* align descriptive stats

* fix

* get back statistics

* update tests

* remove `from __future__ import annotations` (#3311)

* remove `from __future__ import __annotations__`

* fix some places with `TYPE_CHECKING`

* [v2] Result cache improvements (#3312)

deduplicate get models and get tasks from results cache

* [v2] fix 3.13 tests (#3315)

* fix 3.13 tests

* fix tests

* [v2] Fix leaderboard (#3308)

* try to fix leaderboard

* fix load results

* fix path

* change to results cache

* fix `filter tasks`

* fix cache generation

* load all models results

* add tests

* fix selector loader

* fix imports

* Merge main 11 10 (#3321)

* fix: Move zero-shot percentage calculation to the end of summary (#3231)

* Refactor: Move zero-shot percentage calculation to the end of summary table creation which only apply to RTEB table.

* Update RTEB benchmark name from &#34;RTEB(beta)&#34; to &#34;RTEB&#34; for consistency in display.

* feat - RTEB(beta)

* feat - remove Zero-shot

---------

Co-authored-by: ethan &lt;smiletoye@gmail.com&gt;

* model: Add ReasonIR (#3221)

* model: Add ReasonIR

* Update mteb/models/reasonir_model.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/reasonir_model.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* update n_parameters of ReasonIR

Co-authored-by: Niklas &lt;n.muennighoff@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Niklas &lt;n.muennighoff@gmail.com&gt;

* fix: Only pin model name and rank (#3263)

Currently we pin 3 columns, this makes it hard or impossible to view on phones. The 3rd column is also no longer garuanteed as RTEB leaderboard does not use the zero-shot column

* 1.39.3

Automatically generated by python-semantic-release

* fix: resolve flash-attention dependency issue (#3265)

* fix: Only pin model name and rank

Currently we pin 3 columns, this makes it hard or impossible to view on phones. The 3rd column is also no longer garuanteed as RTEB leaderboard does not use the zero-shot column

* fix: resolve flash-attention dependency issue

This has been tested and works.

fixed Resolve flash-attention dependency issues
Fixes #3240

* 1.39.4

Automatically generated by python-semantic-release

* fix: Add retry and token counting in Cohere models (#3253)

* Retry and token counting in Cohere models

* Retry and token counting in Cohere models

* Retry and token counting in Cohere models

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* 1.39.5

Automatically generated by python-semantic-release

* Align MIEB leaderboards with paper (#3272)

* sort by mean task type and use pure rank for MIEB LBs

* lint

* rename task type column for readability

* fix: add prompt for MIRACLRetrievalHardNegatives (#3266)

* add prompt for MIRACLRetrievalHardNegatives

* add `MIRACLRetrievalHardNegatives.v2`

* Update mteb/tasks/Retrieval/multilingual/MIRACLRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* move common metadata to dict

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update tasks &amp; benchmarks tables

* Add Regression task mock (#3271)

* 1.39.6

Automatically generated by python-semantic-release

* fix: Change language for task SlovakMovieReviewSentimentClassification (#3296)

* Update tasks &amp; benchmarks tables

* 1.39.7

Automatically generated by python-semantic-release

* Add english code retriever model (#3302)

* Add en code retriever model

* fix model_name

* Update mteb/models/en_code_retriever.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* correct lint

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* updates after merge

* fix tests

* fix tests

---------

Co-authored-by: ç¬‘å°¿ä¼Šäºº &lt;44760272+q275343119@users.noreply.github.com&gt;
Co-authored-by: ethan &lt;smiletoye@gmail.com&gt;
Co-authored-by: Yongbin Choi &lt;whybe.choi@gmail.com&gt;
Co-authored-by: Niklas &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: semantic-release &lt;semantic-release&gt;
Co-authored-by: fzoll &lt;5575946+fzoll@users.noreply.github.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: ÐÐ°ÑÑ‚Ñ Ð¨Ð°Ñ…Ð¼Ð°Ñ‚Ð¾Ð²Ð° &lt;90767498+Drozhzhinastya@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: Alexey Vatolin &lt;vatolinalex@gmail.com&gt;
Co-authored-by: Andrej Ridzik &lt;andrej.ridzik@gmail.com&gt;
Co-authored-by: fedor28 &lt;37560717+fedor28@users.noreply.github.com&gt;

* [v2]: Starting to clean up tests (#3306)

* [v2]: Starting to clean up tests

Plan:
- Started to remove tests that tests for exisitng functionality
- if a test uses MTEB I generally refactor it to use evaluate
- generally move stuff around to reflect the structure on the package
- If test file contains semantically different tests split it up into multiple
- removed `intfloat/multilingual-e5-small` from the integration test so reduce the number of model downloads required

* refactor test_models.py into test_bm25 and test_colbert.py

* refactor MTEB specific tests out of test_model_meta.py into test_deprecated/test_MTEB.py

* move load_results to test_deprecated folder

* fix failing test

* replace InstructIR with IFIRNFCorpus in the test task grid

* format

* Move test_split_evaluation.py to test_deprecated and rename to test_MTEB_splits.py

* rename test_embedding_caching to test_CachedEmbeddingWrapper.py and moved to models.py

* rename test_load_results to test_results in accordance with package structure

* removed fixed todo

* refactored out validate_task_to_prompt.py from test_reproducible_workflows.py

* sped up get_tasks_size_differences()

* refactored test_benchmarks.py out to multiple components

* ibid

* fix import issues after refactors

* format

* fix test errors

* format

* fix based on comments

* don&#39;t cache results when not needed

* don&#39;t cache results when not needed

* minor fixes

* moved and refactored test_mieb_datasets &gt; test_integrations/test_image_model_task.py

* remove added TODOs

* added minor type casting to resolve type errors

* reduce grid for testing get_tasks from 2592 to 16+18+24+54=112

* remove test_load_data

* remove unec. condition in `test_all_metadata_is_filled_and_valid`

* reduce sub tests in get_tasks_size_differences

* default prompts with empty dict instead of None

* fix tests

* fix missing cases

* reduce iteration of test classification

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* [v2] Rename and restructure AbsTasks files (#3318)

* rename and restructure abstasks files

* update docs and tables

* fix imports

* Rename AbsTask.py to abstask.py

* rename folder

* Rename image_text_pair_classification.py to image_text_pair_classification.py

* add init

* move retrieval up as it is any-type

* move regression up one level

* Add mock image clustering fast (#3328)

* add image clustering fast

* upd descriptive stats

* [v2] Finish predictions (#3322)

* add all predictions

* fully unify regression and classification

* fix summarization

* fix regression/classification logging

* fix clustering

* fix imagetext pair

* roundup tests

* fix tests

* fix `mxbai-embed-large-v1` training datasets (#3334)

* Remove CHAIN19 from leaderboard (#3333)

* remove `CHAIN19` from leaderboard

* delete chain

* Move ClusteringFast and Multilabel-Clf out of text folder (#3335)

* move ClusteringFast out of text folder

* move multilabel classification out of text folder

* Add deprecation warning to reranking (#3329)

add deprecation warning to reranking

* update cli `help` for prediction folder (#3336)

* [v2] Additional fixes for tests (#3327)

- [x] removed duplicate test testing for MIEB models + encoders the current one is in `test_integrations/test_image_model_task.py`
- [x]Â figure out where additional  files come from and send them to tmp_path
- [x]Â fix test which fails locally only by introducing a new model `mteb/random-baseline` that produced a random vector which is consistent on the input
- [x]Â minor fixes to cases which didn&#39;t handle numpy as output
- [x]Â removed test which tests that private datasets are in fact listed as private (we have the inverse)
- [x] reduced grid size of `test_encoder_dtype_on_task`
- [x]Â combined tests for metadata so that we have ~1k test instead of ~3k for metadata (runs a bit faster)
- [x] reduced task_grid to only include one classification task and switched out the classification task for a smaller one
- [x] replaced test_cli classification task with a smaller one

All of this combined put us under 3 mins locally (hot cache)

&lt;img width=&#34;884&#34; height=&#34;112&#34; alt=&#34;Screenshot 2025-10-12 at 21 09 54&#34; src=&#34;https://github.com/user-attachments/assets/032de17f-4a69-4c29-916c-36269d577489&#34; /&gt;


fixes https://github.com/embeddings-benchmark/mteb/issues/2957
fixes #3324 

Added the `mteb/random-baseline` as a fully fledged model, as I could imagine it being relevant as a baseline as well.

* fix reranking tasks main metrics (#3332)

* activate `TID` (#3343)

* activate `TID`

* move `type_checking` import

* [v2]: Improved logging for CLI (#3349)

* [v2]: Improved logging for CLI

* minor logging update

* [v2] Rename task folders to align pep8 and move image tasks (#3353)

* rename task folders to align with pep8

* try if this detects the change

* back to lower case

* register the change

* back to lowercase

* build docs and fix init

* [v2] Rename clustering fast to be default (#3356)

rename AbsTaskClusteringFast -&gt; AbsTaskClustering and AbsTaskAnyClustering -&gt; AbsTaskClusteringLegacy

* [v2] refactor tests to align with module structure (#3355)

* rename to pep8 compliant

* refactor task metadata into two tests (one for the object and one for task metadata)

* refactor test_tasks into two one for the abstask module and one for implemented tasks

* refactored task collection to avoid collecting mock task. This new implementation is also cleaner and avoid the need for filtering abstasks.

To do this I also had to fix a few naming issue where classes names colided.

* format

* avoid calling std out for simple CLI

* minor speed improvement

* Refactor models tests (#3347)

* refactor tests

* fix tests

* fix tests

* Update tests/test_integrations/test_mock_cross_encoder.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* add more mock models

* fix tests

* fix seed for clustering

* specify seed from evaluator/class seed

* refactor to use `mteb.evaluate`

* use only `mteb/random-encoder-baseline`

* rename mock cross-encoder to mteb cross-encoder

* add array_framework and dtype

* tried to resolve test_predictions

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Add documentation to abstasks (#3357)

* update docstrings to classes

* update docs

* update clustring paths in docs

* Update mteb/abstasks/any_clustering.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* add changes after review

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* [v2] Fix classification descsriptive stats (#3361)

fix classification descriptive stats calculation

* [v2] refactor filter_tasks.py out of overview.py and rename overview.py to get_tasks.py (#3358)

* rename to pep8 compliant

* refactor task metadata into two tests (one for the object and one for task metadata)

* refactor test_tasks into two one for the abstask module and one for implemented tasks

* refactored task collection to avoid collecting mock task. This new implementation is also cleaner and avoid the need for filtering abstasks.

To do this I also had to fix a few naming issue where classes names colided.

* format

* avoid calling std out for simple CLI

* minor speed improvement

* [v2] refactor filter_tasks.py out of overview.py and rename overview.py to get_tasks.py

Q: `abstask.filter_modalities`, does it actually filter anything (doesn&#39;t it just change the metadata which isn&#39;t used anywhere?)

* add docs

* remove filter_modalities from abstask and get_task

* fixed tests

* merge

* Tests for V2.0.0 desc.stats (#3362)

* Test for v2.0 descriptive stats

* [v2] Fix classification descsriptive stats (#3361)

fix classification descriptive stats calculation

* Tests for v2.0 descriptive stats

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* [v2] Filter out tasks by models modality (#3351)

* filter task by modality

* add comment

* move task/model modality check into `evaluate`

* fix test check

* Update mteb/evaluate.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* add partly support modalities run

* fix overlap

* remove query, doc overlap check

* fix empty model meta modality

* try to fix test with multi worker

* fix tests

* fix full check retrieval

* fix import

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* [v2] remove abstracts from citation (#3363)

* fix logging

* remove abstracts from citations

* [v2] Rename abstasks (#3366)

* rename clustering files to reflect task names

* rename zeroshot

* rename sts

* rename classification

* fix docs

* format

* [v2] try to fix clustering prediction task (#3360)

* try to fix clustering prediction task

* align labels with sentences

* fix clustering

* minor changes

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* [v2]: Denote non-public functions (#3371)

* convert set_seed to private

* make function private in similiarity functions

* move generate_model_card.py to cli

* make almost all leaderboard functions private

* format

* Add more info to `what&#39;s new` (#3368)

* start updating doc

* add more info to whats new section

* update links

* Update docs/whats_new.md

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* Apply suggestions from code review

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* fix model parameters

* update docs

* Apply suggestions from code review

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* rename `Encoder` to `EncoderProtocol`

* add section about converting old reranking dataset format

---------

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* Add image regression (#3377)

* Add image regression

* move regression task to different grid

* add result cache to doc (#3378)

* add result cache to doc

* fix :

* add link to whats new to cache

* (v2.0.0) (bugfix) Correcting the task filtering issue (#3372)

Fix aggregate task filtering bug

- Use issubclass/isinstance to check if task is aggregate instead of creating instances
- Add regression test for filtering task classes with exclude_aggregate
- Add additional tests for privacy filtering and task validation

Fixes bug introduced in 3587df15 where accessing t.is_aggregate on a task
class would fail because is_aggregate is a property requiring an instance.

* remove unec. tests

didn&#39;t see these in my first pass though #3372

* Desc stats part1 (#3384)

* Fix aggregate task filtering bug

- Use issubclass/isinstance to check if task is aggregate instead of creating instances
- Add regression test for filtering task classes with exclude_aggregate
- Add additional tests for privacy filtering and task validation

Fixes bug introduced in 3587df15 where accessing t.is_aggregate on a task
class would fail because is_aggregate is a property requiring an instance.

* Descriptive stats, part 1

* Descriptive stats, part 1

* benchmark use cache directly (#3376)

* benchmark use cache directly

* remove `benchmark.load_result`

* fix tasks selection

* Rename tasks to snake_case (#3392)

* rename all tasks to snake case

* add script for renaming

* rename terra

* fix classes for reranking tasks

* make cli compatible with `v1` (#3386)

* make cli compatible with `v1`

* fix tests

* add co2 tracker None

* add `save_predictions` to test

* fix co2 help

* [V2] Activate ruff `D` and `W` rules. Partly run `DOC` (#3375)

* add more doc

* fixes

* remove unused imports

* Update mteb/models/model_implementations/vista_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* deactivate `DOC` rule

* deactivate `D101-103`, `D205` rules

* remove raises

* Apply suggestions from code review

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* Update mteb/models/search_wrappers.py

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* fix load results naming

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* Update pyproject for `v2` (#3389)

* update pyproject

* Apply suggestions from code review

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* Update pyproject.toml

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* roll back version

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Move `superseded_by` to `TaskMetadata` (#3387)

* move superseded_by to task metadata

* remove unused `type: ignore`

* fix `is_filled`

* fix task filtering

* add suppressed by to similar tasks

* fully activate `N` (#3390)

* fully activate `N`

* activate f403

* rename `MTEB` to `deprecated_evaluator`

* Restructure agg tasks into lang subfolders (#3394)

* restructure agg tasks into lang subfolders

* add inits

* fix import

* import multilingual tasks

* fix indentation in whats new

* Restructure usage examples (#3385)

* add two stage reranking doc

* Apply suggestions from code review

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

* Clarify model usage in reranking example

Added comment for clarity on model usage.

* add two stage reranking in mkdocs

* Apply suggestions from code review

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* restructure usage

* Apply suggestions from code review

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;

---------

Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Fix indent on what&#39;s news (#3397)

fix indentation in whats new

* Move cache wrapper (#3398)

* move cache wrapper to different folder

* upd docstring

* add missing init

* use model&#39;s similarity functions

* make search encoder compatible with encoder (#3404)

* Recompute desc. stats, part2 (#3408)

* Correcting the get_tasks filtering issue

* Correcting the get_tasks filtering issue

* Descriptive stats, part 2

* Descriptive stats, part 2

* fix: add citation to models (#3403)

fix: add citations to models

* fix: datasets loading (#3421)

* fix retrieval loading

* fix `_convert_to_fast`

* fix `CIFAR100Clustering`

* fix `CQADupstack*-NL`

* add Kluestats

* fix `IndicXnliPairClassification`

* fix `STL10`

* fix `OpusparcusPC`

* compute more pair classification

* add comments to pair classification

* compute stats for CQADupstack*-NL

* Recalculating desc. stats - part3 (#3420)

* Correcting the get_tasks filtering issue

* Correcting the get_tasks filtering issue

* Descriptive stats, part 2

* Descriptive stats, part 3

* remove non-public model without API

The models seems to no longer be available. So I will take it down.

Mentioned https://github.com/embeddings-benchmark/mteb/issues/3405#issuecomment-3418074994

@ZBWpro seems like you made the initial PR here.

* remove non-public model without API

The models seems to no longer be available. So I will take it down.

Mentioned https://github.com/embeddings-benchmark/mteb/issues/3405#issuecomment-3418074994

@ZBWpro seems like you made the initial PR here.

* revert

* revert

* set OMP_NUM_THREADS during clustering to ensure reproducibility (#3400)

set OMP_NUM_THREADS during clustering to ensure reproducibility

* remove non-public model without API (#3425)

The models seems to no longer be available. So I will take it down.

Mentioned https://github.com/embeddings-benchmark/mteb/issues/3405#issuecomment-3418074994

@ZBWpro seems like you made the initial PR here.

* fix: Remove links from models with a reference (#3426)

* fix: Remove links from models with a reference

Avoid adding a link to a model which does not have a reference specified

* format

* Make pair classification multimodal (#3412)

* move pair classification from text folder

* make pair classification multimodal

* fix init path

* fix test

* docs: add contribution section to the docs (#3396)

* add contribution section to the docs

* add more changes to doc

* simply dataset doc

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* add protocols link

* move into subfolder

* add search protocols

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Recalculate descriptive stats, part 4 (#3429)

* Correcting the get_tasks filtering issue

* Correcting the get_tasks filtering issue

* Descriptive stats, part 2

* Add more stats (#3427)

* fix webfaqretrieval

* add commit message

* reupload `FGVCAircraft`

* add more statistics

* update reuploaded datasets

* remove web faq custom load_data

* remove custom load from mind small

* fix topiocqa

* fix bitext tasks

* fix `IndicGenBenchFloresBitextMining`

* add msmarco stats

* model: llama-embed-nemotron-8b (#3407)

* add llama-embed-nemotron-8b

* take batch size from encode_kwargs + lint

* align with `v2`

* fix for v2.0.0

---------

Co-authored-by: ybabakhin &lt;ybabakhin@nvidia.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;

* feat: Add faiss cache backend (#3402)

* move cache wrapper to different folder

* upd docstring

* add missing init

* use model&#39;s similarity functions

* add faiss cache backend

* add faiss cache backend

* Update mteb/models/cache_wrappers/cache_wrapper.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* update cache index

* add faiss to tests

* remove faiss gpu

* upd docs

* Update docs/advanced_usage/cache_embeddings.md

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* update init

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* fix gerdalir dataset (#3433)

* dataset: Add TREC DL  (#3379)

* feat: create TRECDLRetrieval

* feat: add TREC Deep Learning 2019 and 2020 retrieval tasks

* feat: rename TRECDLRetrieval.py to trecdl_retrieval.py

* fix: replace relative imports from parent modules with absolute imports

* feat: add TRECDL retrieval tasks to English registry

* fix: correct task category

* feat: add TRECDL2019 and TRECDL2020 descriptive stats

* fix: recompute descriptive stats to match v2 format

* fix: use official judged queries for TREC-DL 2019/2020 datasets

* Resolve merge conflict in docs/adding_a_benchmark.md

---------

Signed-off-by: mr.Shu &lt;mr@shu.io&gt;
Signed-off-by: Michael Dinzinger &lt;michael.dinzinger@uni-passau.de&gt;
Signed-off-by: SighingSnow &lt;songtingyu220@gmail.com&gt;
Signed-off-by: admin &lt;bo.wang@jina.ai&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Pengfei He &lt;hepengfe@gmail.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
Co-authored-by: Nikolay Banar &lt;nikc20008@gmail.com&gt;
Co-authored-by: Samuel Yang &lt;samuelyang150@gmail.com&gt;
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: anpalmak2003 &lt;73543260+anpalmak2003@users.noreply.github.com&gt;
Co-authored-by: Zach Nussbaum &lt;zanussbaum@gmail.com&gt;
Co-authored-by: Jamie-Stirling &lt;36764530+Jamie-Stirling@users.noreply.github.com&gt;
Co-authored-by: HSILA &lt;a.shiraee@gmail.com&gt;
Co-authored-by: Ali Shiraee &lt;ShiraeA@basfad.basf.net&gt;
Co-authored-by: Thomas van Dongen &lt;thomas123@live.nl&gt;
Co-authored-by: Orion Weller &lt;31665361+orionw@users.noreply.github.com&gt;
Co-authored-by: John Yang &lt;byjohnyang@gmail.com&gt;
Co-authored-by: Marek Å uppa &lt;mrshu@users.noreply.github.com&gt;
Co-authored-by: Xa9aX ãƒ„ &lt;mishradiganta91@gmail.com&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel@buad.es&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel.buades@clinia.com&gt;
Co-authored-by: Sathvik Nallamalli &lt;sathviknallamalli@gmail.com&gt;
Co-authored-by: Michael Graczyk &lt;michael@mgraczyk.com&gt;
Co-authored-by: Mariya Hendriksen &lt;35101262+mariyahendriksen@users.noreply.github.com&gt;
Co-authored-by: Santiago Castro &lt;bryant1410@gmail.com&gt;
Co-authored-by: Joey Xia &lt;77958037+ZiyiXia@users.noreply.github.com&gt;
Co-authored-by: Oliver &lt;oliver.pejic@students.fhnw.ch&gt;
Co-authored-by: gowitheflow-1998 &lt;chenghao.xiao@durham.ac.uk&gt;
Co-authored-by: Saiteja Utpala &lt;73220310+SaitejaUtpala@users.noreply.github.com&gt;
Co-authored-by: Xin Zhang &lt;izhx404@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: Aditya Shrivastava &lt;40591753+imadtyx@users.noreply.github.com&gt;
Co-authored-by: Ressnn &lt;prdevarinti@gmail.com&gt;
Co-authored-by: sergeyz-zh &lt;49659999+sergeyz-zh@users.noreply.github.com&gt;
Co-authored-by: afalf &lt;101537385+afalf@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Agam Bhatia &lt;121401992+agu18dec@users.noreply.github.com&gt;
Co-authored-by: AdnanElAssadi56 &lt;115242814+AdnanElAssadi56@users.noreply.github.com&gt;
Co-authored-by: AdnanElAssadi56 &lt;adnan@LAPTOP-M2FFLBCE.localdomain&gt;
Co-authored-by: AdnanElAssadi56 &lt;adnan@LAPTOP-M2FFLBCE&gt;
Co-authored-by: Konrad Wojtasik &lt;konrad.wojtasik@pwr.edu.pl&gt;
Co-authored-by: Sam &lt;40773225+sam-hey@users.noreply.github.com&gt;
Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
Co-authored-by: talshef &lt;tsheffer@gmail.com&gt;
Co-authored-by: Tal Sheffer &lt;tal.s@codium.ai&gt;
Co-authored-by: garciasces &lt;garciasces@madrid.es&gt;
Co-authored-by: Wang Bo &lt;bo.wang@jina.ai&gt;
Co-authored-by: Munot Ayush Sunil &lt;munotayush6@kgpian.iitkgp.ac.in&gt;
Co-authored-by: Yaya Sy &lt;58347382+yaya-sy@users.noreply.github.com&gt;
Co-authored-by: Michael Dinzinger &lt;39766249+michaeldinzinger@users.noreply.github.com&gt;
Co-authored-by: OnandOn &lt;76710635+OnAnd0n@users.noreply.github.com&gt;
Co-authored-by: Shreyas Subramanian &lt;shreyas.f117@gmail.com&gt;
Co-authored-by: Uri K &lt;37979288+katzurik@users.noreply.github.com&gt;
Co-authored-by: richinfo-ai &lt;richinfoai@163.com&gt;
Co-authored-by: Adewole Babatunde &lt;40810247+Free-tek@users.noreply.github.com&gt;
Co-authored-by: ahxgw &lt;ahxgwOnePiece@gmail.com&gt;
Co-authored-by: kunka.xgw &lt;kunka.xgw@taobao.com&gt;
Co-authored-by: Nadia Sheikh &lt;144166074+nadshe@users.noreply.github.com&gt;
Co-authored-by: theatollersrud &lt;thea.tollersrud@nb.no&gt;
Co-authored-by: E. Tolga Ayan &lt;33233561+tolgayan@users.noreply.github.com&gt;
Co-authored-by: lllsy12138 &lt;50816213+lllsy12138@users.noreply.github.com&gt;
Co-authored-by: shyuli &lt;shyuli@tencent.com&gt;
Co-authored-by: Siddharth M. Bhatia &lt;siddharth@sidmb.com&gt;
Co-authored-by: Bao Loc Pham &lt;67360122+BaoLocPham@users.noreply.github.com&gt;
Co-authored-by: Flo &lt;FlorianRottach@aol.com&gt;
Co-authored-by: Florian Rottach &lt;florianrottach@boehringer-ingelheim.com&gt;
Co-authored-by: Alexey Vatolin &lt;vatolinalex@gmail.com&gt;
Co-authored-by: Olesksii Horchynskyi &lt;121444758+panalexeu@users.noreply.github.com&gt;
Co-authored-by: Pandaswag &lt;110003154+torchtorchkimtorch@users.noreply.github.com&gt;
Co-authored-by: Mehrzad Shahin-Moghadam &lt;42153677+mehrzadshm@users.noreply.github.com&gt;
Co-authored-by: Mehrzad Shahin-Moghadam &lt;mehr@Mehrzads-MacBook-Pro.local&gt;
Co-authored-by: Youngjoon Jang &lt;82500463+yjoonjang@users.noreply.github.com&gt;
Co-authored-by: 24September &lt;puritysarah@naver.com&gt;
Co-authored-by: Jan KaraÅ› &lt;90987511+KTFish@users.noreply.github.com&gt;
Co-authored-by: Shuu &lt;136542198+Shun0212@users.noreply.github.com&gt;
Co-authored-by: namespace-Pt &lt;61188463+namespace-Pt@users.noreply.github.com&gt;
Co-authored-by: zhangpeitian &lt;zhangpeitian@bytedance.com&gt;
Co-authored-by: Copilot &lt;175728472+Copilot@users.noreply.github.com&gt;
Co-authored-by: Manuel Faysse &lt;43467008+ManuelFay@users.noreply.github.com&gt;
Co-authored-by: tutuDoki &lt;53423655+tutuDoki@users.noreply.github.com&gt;
Co-authored-by: Song Tingyu &lt;53935948+SighingSnow@users.noreply.github.com&gt;
Co-authored-by: Hypothesis-Z &lt;44766273+Hypothesis-Z@users.noreply.github.com&gt;
Co-authored-by: zhangzeqing &lt;zhangzeqing@zhejianglab.com&gt;
Co-authored-by: fangxiaoquan &lt;44112102+fangxiaoquan@users.noreply.github.com&gt;
Co-authored-by: Li Lei &lt;34205771+ll0ruc@users.noreply.github.com&gt;
Co-authored-by: malteos &lt;github@i.mieo.de&gt;
Co-authored-by: annamodels &lt;annamodels@lgresearch.ai&gt;
Co-authored-by: Sadra Barikbin &lt;sadraqazvin1@yahoo.com&gt;
Co-authored-by: Egor &lt;31567312+ekolodin@users.noreply.github.com&gt;
Co-authored-by: Kolodin Egor &lt;eikolodin@sberbank.ru&gt;
Co-authored-by: Quan Yuhan &lt;929888357@qq.com&gt;
Co-authored-by: Quan Yuhan &lt;yuhan_quan@qq.com&gt;
Co-authored-by: Mohammad Kalim Akram &lt;kalimakram@gmail.com&gt;
Co-authored-by: Sailesh Panda &lt;sailesh.panda1997@gmail.com&gt;
Co-authored-by: bschifferer &lt;benedikt.d.schifferer@gmail.com&gt;
Co-authored-by: Xinshuo Hu &lt;yanshek.woo@gmail.com&gt;
Co-authored-by: xinshuohu &lt;xinshuohu@tencent.com&gt;
Co-authored-by: lsz05 &lt;lszgz0521@gmail.com&gt;
Co-authored-by: Mehran Sarmadi &lt;128898167+mehran-sarmadi@users.noreply.github.com&gt;
Co-authored-by: mehran &lt;mehan.sarmadi16@gmail.com&gt;
Co-authored-by: MattiaSangermano &lt;43407984+MattiaSangermano@users.noreply.github.com&gt;
Co-authored-by: Mattia Sangermano &lt;MattiaSangermano@users.noreply.huggingface.co&gt;
Co-authored-by: Mohammad Kalim Akram &lt;kalim.akram@jina.ai&gt;
Co-authored-by: ItsukiFujii &lt;42373615+ItsukiFujii@users.noreply.github.com&gt;
Co-authored-by: fzowl &lt;160063452+fzowl@users.noreply.github.com&gt;
Co-authored-by: Paul Teiletche &lt;73120933+paultltc@users.noreply.github.com&gt;
Co-authored-by: lsz05 &lt;shengzhe.li@sbintuitions.co.jp&gt;
Co-authored-by: zhichao-aws &lt;zhichaog@amazon.com&gt;
Co-authored-by: Abdur-Rahman Butler &lt;79828536+abdurrahmanbutler@users.noreply.github.com&gt;
Co-authored-by: Feiyang &lt;feiyangc@google.com&gt;
Co-authored-by: Penny Yu &lt;51702222+PennyYu123@users.noreply.github.com&gt;
Co-authored-by: Claude &lt;noreply@anthropic.com&gt;
Co-authored-by: fzoll &lt;5575946+fzoll@users.noreply.github.com&gt;
Co-authored-by: fzowl &lt;zoltan@voyageai.com&gt;
Co-authored-by: Kritias &lt;50093609+ElPlaguister@users.noreply.github.com&gt;
Co-authored-by: roipony &lt;roipony@gmail.com&gt;
Co-authored-by: Aashka Trivedi &lt;aashka.trivedi@gmail.com&gt;
Co-authored-by: Saba Sturua &lt;45267439+jupyterjazz@users.noreply.github.com&gt;
Co-authored-by: Maximilian Werk &lt;maximilian.werk@gmx.de&gt;
Co-authored-by: Victor &lt;zbwkeepgoing@126.com&gt;
Co-authored-by: Yong woo Song &lt;ywsong.dev@kakao.com&gt;
Co-authored-by: Ryan Mullins &lt;ryan@ryanmullins.org&gt;
Co-authored-by: Robin Vujanic &lt;robin-vjc@users.noreply.github.com&gt;
Co-authored-by: Robin Vujanic &lt;robin.vujanic@mongodb.com&gt;
Co-authored-by: ç¬‘å°¿ä¼Šäºº &lt;44760272+q275343119@users.noreply.github.com&gt;
Co-authored-by: mathlesage &lt;134429083+mathlesage@users.noreply.github.com&gt;
Co-authored-by: spring-quan &lt;38248619+spring-quan@users.noreply.github.com&gt;
Co-authored-by: springxchen &lt;springxchen@tencent.com&gt;
Co-authored-by: Ryan Mullins &lt;ryanmullins@google.com&gt;
Co-authored-by: Iliass Ayaou &lt;iliass.ayaou@insa-strasbourg.fr&gt;
Co-authored-by: oweller2 &lt;oweller2@dsailogin.mgmt.ai.cluster&gt;
Co-authored-by: Yongbin Choi &lt;whybe.choi@gmail.com&gt;
Co-authored-by: Geralt &lt;94539084+Geralt-Targaryen@users.noreply.github.com&gt;
Co-authored-by: Atheer &lt;atheer2104@protonmail.com&gt;
Co-authored-by: ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ722497 &lt;dolegosmirnov@sberbank.ru&gt;
Co-authored-by: Tarun Suresh &lt;68882529+tarsur909@users.noreply.github.com&gt;
Co-authored-by: q275343119 &lt;275343119@qq.com&gt;
Co-authored-by: smile &lt;smile@pinai.io&gt;
Co-authored-by: ethan &lt;smiletoye@gmail.com&gt;
Co-authored-by: Adnan El Assadi &lt;aassadi22@ku.edu.tr&gt;
Co-authored-by: Antoine Chaffin &lt;38869395+NohTow@users.noreply.github.com&gt;
Co-authored-by: Antoine Chaffin &lt;antoine.chaffin@lighton.ai&gt;
Co-authored-by: ÐÐ°ÑÑ‚Ñ Ð¨Ð°Ñ…Ð¼Ð°Ñ‚Ð¾Ð²Ð° &lt;90767498+Drozhzhinastya@users.noreply.github.com&gt;
Co-authored-by: Andrej Ridzik &lt;andrej.ridzik@gmail.com&gt;
Co-authored-by: fedor28 &lt;37560717+fedor28@users.noreply.github.com&gt;
Co-authored-by: Yauhen Babakhin &lt;y.babakhin@gmail.com&gt;
Co-authored-by: ybabakhin &lt;ybabakhin@nvidia.com&gt; ([`c07c289`](https://github.com/embeddings-benchmark/mteb/commit/c07c289b0bf1975e4a128ba10414d9a815bebd70))

* Add english code retriever model (#3302)

* Add en code retriever model

* fix model_name

* Update mteb/models/en_code_retriever.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* correct lint

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`67f7ad9`](https://github.com/embeddings-benchmark/mteb/commit/67f7ad92d2d8db8e9ee6332e542f27a038ccb232))

## v1.39.7 (2025-10-08)

### Fix

* fix: Change language for task SlovakMovieReviewSentimentClassification (#3296) ([`0a902a3`](https://github.com/embeddings-benchmark/mteb/commit/0a902a3c6a68cd0dc7c116239c2eb8edb081c320))

### Unknown

* Update tasks &amp; benchmarks tables ([`94aa0d5`](https://github.com/embeddings-benchmark/mteb/commit/94aa0d590b12b177a967b1fe43f43fb67743a7dc))

## v1.39.6 (2025-10-07)

### Fix

* fix: add prompt for MIRACLRetrievalHardNegatives (#3266)

* add prompt for MIRACLRetrievalHardNegatives

* add `MIRACLRetrievalHardNegatives.v2`

* Update mteb/tasks/Retrieval/multilingual/MIRACLRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* move common metadata to dict

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`9b6f320`](https://github.com/embeddings-benchmark/mteb/commit/9b6f320828fa9419e991a3da819c92ead96da109))

### Unknown

* Add Regression task mock (#3271) ([`e176ba6`](https://github.com/embeddings-benchmark/mteb/commit/e176ba611c3ef85161cae6f31a134c24be5c57d0))

* Update tasks &amp; benchmarks tables ([`5a5bcfd`](https://github.com/embeddings-benchmark/mteb/commit/5a5bcfd9354f1012f478b8d72c41cf0e87c5ed6e))

* Align MIEB leaderboards with paper (#3272)

* sort by mean task type and use pure rank for MIEB LBs

* lint

* rename task type column for readability ([`30de619`](https://github.com/embeddings-benchmark/mteb/commit/30de6197c5acd4fbfe3e6f452aba796bf6d08b9e))

## v1.39.5 (2025-10-07)

### Fix

* fix: Add retry and token counting in Cohere models (#3253)

* Retry and token counting in Cohere models

* Retry and token counting in Cohere models

* Retry and token counting in Cohere models

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`e81c94f`](https://github.com/embeddings-benchmark/mteb/commit/e81c94f6a04bdcfc9905ab09d4328903005ad847))

## v1.39.4 (2025-10-06)

### Fix

* fix: resolve flash-attention dependency issue (#3265)

* fix: Only pin model name and rank

Currently we pin 3 columns, this makes it hard or impossible to view on phones. The 3rd column is also no longer garuanteed as RTEB leaderboard does not use the zero-shot column

* fix: resolve flash-attention dependency issue

This has been tested and works.

fixed Resolve flash-attention dependency issues
Fixes #3240 ([`1e29385`](https://github.com/embeddings-benchmark/mteb/commit/1e29385ec891a9ef58220e0232db6559aa1be278))

## v1.39.3 (2025-10-06)

### Fix

* fix: Only pin model name and rank (#3263)

Currently we pin 3 columns, this makes it hard or impossible to view on phones. The 3rd column is also no longer garuanteed as RTEB leaderboard does not use the zero-shot column ([`58a81a9`](https://github.com/embeddings-benchmark/mteb/commit/58a81a9cfbe23999ad75ee77c9ffcd4a2552f7f8))

* fix: Move zero-shot percentage calculation to the end of summary (#3231)

* Refactor: Move zero-shot percentage calculation to the end of summary table creation which only apply to RTEB table.

* Update RTEB benchmark name from &#34;RTEB(beta)&#34; to &#34;RTEB&#34; for consistency in display.

* feat - RTEB(beta)

* feat - remove Zero-shot

---------

Co-authored-by: ethan &lt;smiletoye@gmail.com&gt; ([`65829bd`](https://github.com/embeddings-benchmark/mteb/commit/65829bdc4c09f6e8260bc711aa661338cc3aa063))

### Unknown

* model: Add ReasonIR (#3221)

* model: Add ReasonIR

* Update mteb/models/reasonir_model.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/reasonir_model.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* update n_parameters of ReasonIR

Co-authored-by: Niklas &lt;n.muennighoff@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Niklas &lt;n.muennighoff@gmail.com&gt; ([`f2504bd`](https://github.com/embeddings-benchmark/mteb/commit/f2504bd11700ade0ec23b2026b8253f6056674b6))

* fix bm25 on small datasets (#3261) ([`237d8dc`](https://github.com/embeddings-benchmark/mteb/commit/237d8dc3ee6f16a056b0b2c26af8609df1c84818))

* Update tasks &amp; benchmarks tables ([`c8ae52c`](https://github.com/embeddings-benchmark/mteb/commit/c8ae52c2af3e4dc491803290479a2237c82c450e))

* Added Japanese to Retrieval (#3252)

* feat - add Japanese

* feat - use mteb.get_benchmark

* fix - 3.9 test error

* Revert &#34;fix - 3.9 test error&#34;

This reverts commit 6bfee53cff48304cc22d8248aa275dcc9e385475.

* fix - 3.9 test error ([`53b1c29`](https://github.com/embeddings-benchmark/mteb/commit/53b1c296cb7d5c0589736a2386209136116a141f))

* Fix AbsTaskTextRegression task (#3257)

Fix AbsTaskTextRegression ([`08b98cd`](https://github.com/embeddings-benchmark/mteb/commit/08b98cd25797d24a2005444221e2c5a7f2466222))

* Update tasks &amp; benchmarks tables ([`89bec7d`](https://github.com/embeddings-benchmark/mteb/commit/89bec7dba89d65f690f4e246322facb1226aa5a7))

* Aggregate by subset for HUMEv1 (#3255)

aggregate by subset for HUMEv1 ([`36901eb`](https://github.com/embeddings-benchmark/mteb/commit/36901ebf552baa36a95134461274a9eee89f01e1))

* fix python39 transformers compatibility (#3254)

* fix python39 transformers

* fix ([`85e1dd9`](https://github.com/embeddings-benchmark/mteb/commit/85e1dd94e35ac36d4164b3c5347db65f1a4dfa9c))

* fix max tokens (#3243) ([`2f6eb2a`](https://github.com/embeddings-benchmark/mteb/commit/2f6eb2af9034e94e8e4acc9305790a65f8ed9838))

## v1.39.2 (2025-10-02)

### Documentation

* docs: Update adding benchmark documentation (#3229)

* update adding_a_benchmark.md documentation

* fix numbers ([`50aa4ac`](https://github.com/embeddings-benchmark/mteb/commit/50aa4acb08be810b97b3d3751f2f3d2e8aef8226))

### Fix

* fix: Further specified macro-language code for Norwegian (#3228)

* fix: Further specified macro-language code for Norwegian

&#34;nor&#34; is a macro-language code that covers bokmÃ¥l and nynorsk (both norwegian), but this means that these datasets will be missed if using &#34;nob&#34; or &#34;nno&#34;. Specifying it like this should allow this.

* furhter specified macro language &#34;nor&#34; ([`a2f7488`](https://github.com/embeddings-benchmark/mteb/commit/a2f748802918a1a0317d483704c657c574dea7a7))

### Unknown

* Update tasks &amp; benchmarks tables ([`810ae28`](https://github.com/embeddings-benchmark/mteb/commit/810ae28bfc152a9aca6519780bd3f7ff5db97f30))

* Remove &#39;HUME(v1)&#39; from leaderboard benchmark (#3236)

* Remove &#39;HUME(v1)&#39; from leaderboard benchmark

* lint ([`e419b54`](https://github.com/embeddings-benchmark/mteb/commit/e419b54118322e46d1e8310649b574774bd494f8))

* Update tasks &amp; benchmarks tables ([`9a606a0`](https://github.com/embeddings-benchmark/mteb/commit/9a606a0d9b49e4d05306dc4335064767fb29d91a))

* dataset: add human tasks and benchmark (#3214)

* Human Subsets Tasks

* Fixed Multilingual Classification Subset

* linting

* fix citations format

* make lint

* fix tests

* remove human folder

* fix relative imports

* add adapted_from for all human subsets

* fix pydantic errors

* add benchmark object

* make benchmark discoverable

* bibtex test

* Apply suggestion

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* rename &amp; reupload

* upd tests

* upd tests again

* add model

* add benchmark to leaderboard

* change branch of leaderboard

* remove branch of load data

* fix model meta path

* make mteb importable

* update repo

* Update mteb/benchmarks/benchmarks/benchmarks.py

* Update mteb/leaderboard/benchmark_selector.py

* Update mteb/load_results/load_results.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Adnan El Assadi &lt;aassadi22@ku.edu.tr&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: AdnanElAssadi56 &lt;115242814+AdnanElAssadi56@users.noreply.github.com&gt; ([`48a01fc`](https://github.com/embeddings-benchmark/mteb/commit/48a01fc122037e8b41af85a3c6b2761898b91d72))

## v1.39.1 (2025-10-01)

### Fix

* fix: Add submission references for RTEB (#3233)

* fix: Add rteb submission references and improve descriptions.

* Added evaluation request

* added field for tasks ([`600c290`](https://github.com/embeddings-benchmark/mteb/commit/600c2905e183051a07b5fcb46673f430842e33f8))

## v1.39.0 (2025-10-01)

### Feature

* feat: Officially include RTEB in the leaderboard (#3222)

* feat - adjust Rteb&#39;s Benchmark

* feat - add blank

* fix menu names

* Update mteb/leaderboard/benchmark_selector.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* moving around tasks

* fix: Update RTEB summary columns (#3226)

* fix(models): ensure prompt_type is passed to format_instruction (#3216)

* 1.38.58

Automatically generated by python-semantic-release

* Adding Cohere&#39;s output_dimension and embedding_type parameter (#3204)

* Adding Cohere&#39;s output_dimension and embedding_type parameter
Cohere&#39;s embed-v4 binary and int8

* Correcting due to comments

* dataset: add swedish cpc patent classifications to mteb (#3072)

* feat: add swedish cpc patent classifications to mteb

* fix: formatting and init imports

* fix: update mteb task according to feedback

* fix: perform citation and code formatting

* fix: add train and test split for both datasets

* fix: AttributeError in ColPaliEngineWrapper similarity method (#3177)

* fix: delete kwargs for similarity score in ColPaliEngineWrapper for method behavior

* chore: fix colpali_models similarity  handle device

* Update tasks &amp; benchmarks tables

* 1.38.59

Automatically generated by python-semantic-release

* fix: prevent EOS token truncation (#3218)

* fix(models): prevent EOS token truncation for BMRetriever

* refactor(models): refactor tokenizer setup in `InstructSentenceTransformerWrapper`

* fix(models): correct eos token handling in `BMRetrieverWrapper`

* 1.38.60

Automatically generated by python-semantic-release

* Update giga embeddings (#3210)

* update giga embeddings

* update giga embeddings

* 3b-september-2025

* fixed

* lint

* Update mteb/models/ru_sentence_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* change revision due to flash-attn dependency

* change apply_instruction_to_passages

---------

Co-authored-by: Kolodin Egor &lt;eikolodin@sberbank.ru&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ722497 &lt;dolegosmirnov@sberbank.ru&gt;

* fix: Refactor split create_tables into static Benchmark methods (#3126)

* feat - Split create_tables into static Benchmark methods

* feat - format

* Update mteb/leaderboard/table.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* feat - remove search query;take benchmark result as input;addressing the circular import,

* feat - format

* Update mteb/benchmarks/benchmark.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/benchmarks/benchmark.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* feat - use to_dataframe;clean table.py;move creat_table

* feat - fix circular import

* feat - clean-up

* feat - format

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* 1.38.61

Automatically generated by python-semantic-release

* Extending the RTEB benchmark (#3223)

Adding another voyageai model

* Update tasks &amp; benchmarks tables

* feat - filter_by_privacy

* feat - add new fields for rteb part

* feat - getattr

* feat - adjust privacy filter logic

* feat - enhance summary table column renaming and add &#39;is_public&#39; field mapping

* fix: remove unused &#39;is_public&#39; attribute from TaskResult

---------

Co-authored-by: Yongbin Choi &lt;whybe.choi@gmail.com&gt;
Co-authored-by: semantic-release &lt;semantic-release&gt;
Co-authored-by: fzoll &lt;5575946+fzoll@users.noreply.github.com&gt;
Co-authored-by: Atheer &lt;atheer2104@protonmail.com&gt;
Co-authored-by: Yong woo Song &lt;ywsong.dev@kakao.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: Egor &lt;31567312+ekolodin@users.noreply.github.com&gt;
Co-authored-by: Kolodin Egor &lt;eikolodin@sberbank.ru&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ722497 &lt;dolegosmirnov@sberbank.ru&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: smile &lt;smile@pinai.io&gt;
Co-authored-by: ethan &lt;smiletoye@gmail.com&gt;

* removed show_rteb args

* avoid defining function where we can just use the metadata

* minor fixes

* minor fixes

* fix: Correct logic for filtering public tasks in ModelResult class (#3230)

Co-authored-by: ethan &lt;smiletoye@gmail.com&gt;

---------

Co-authored-by: q275343119 &lt;275343119@qq.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: ç¬‘å°¿ä¼Šäºº &lt;44760272+q275343119@users.noreply.github.com&gt;
Co-authored-by: Yongbin Choi &lt;whybe.choi@gmail.com&gt;
Co-authored-by: fzoll &lt;5575946+fzoll@users.noreply.github.com&gt;
Co-authored-by: Atheer &lt;atheer2104@protonmail.com&gt;
Co-authored-by: Yong woo Song &lt;ywsong.dev@kakao.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: Egor &lt;31567312+ekolodin@users.noreply.github.com&gt;
Co-authored-by: Kolodin Egor &lt;eikolodin@sberbank.ru&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ722497 &lt;dolegosmirnov@sberbank.ru&gt;
Co-authored-by: smile &lt;smile@pinai.io&gt;
Co-authored-by: ethan &lt;smiletoye@gmail.com&gt; ([`11f9c1d`](https://github.com/embeddings-benchmark/mteb/commit/11f9c1db7a76e24887b9882857789b9f08a21782))

### Unknown

* Update tasks &amp; benchmarks tables ([`867105f`](https://github.com/embeddings-benchmark/mteb/commit/867105f60be27fb62d134b457a116ded39172c3c))

* Update tasks &amp; benchmarks tables ([`65f29e6`](https://github.com/embeddings-benchmark/mteb/commit/65f29e67eaf037e1617fd03a5bacb264827dd582))

* dataset: Add Software Issue Localization Datasets (#3178)

* add software issue localization datasets

* add software issue localization datasets

* update and add multilingual datasets

* fix citation format issues

* Update mteb/tasks/Reranking/eng/SWEbenchVerifiedReranking.py

* fix linting issues

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`e56e7c4`](https://github.com/embeddings-benchmark/mteb/commit/e56e7c4ade3a762b323076db1ffef0510e68ef3b))

* model: Update Youtu embedding model (#3227)

* add youtu models

* add a blank line

* fix the optional dependencies and lint the code

* remove unused dependencies and reformat

* revise prompt_type

* update youtu_models

---------

Co-authored-by: springxchen &lt;springxchen@tencent.com&gt; ([`0000ae2`](https://github.com/embeddings-benchmark/mteb/commit/0000ae237a32ef8f49abef62ee7b345b1ad1d7ef))

* model: New qzmodel (#3211)

* Update qzhou_models.py

* Update qzhou_models.py

* reformat script code

* Update configuration

* According to our new decision, the model name has been changed to &#34;QZhou-Embedding-Zh&#34;.

* Fix variable naming issues. ([`e299345`](https://github.com/embeddings-benchmark/mteb/commit/e2993452a0b9b1b9addb71f8ff7ed25f79d50825))

* Update tasks &amp; benchmarks tables ([`7f5990a`](https://github.com/embeddings-benchmark/mteb/commit/7f5990a226d807b7e271e6375e56fbd0037efb32))

* Extending the RTEB benchmark (#3223)

Adding another voyageai model ([`4f58684`](https://github.com/embeddings-benchmark/mteb/commit/4f5868491c09506d256ebaff0c07e02fec0f70b4))

## v1.38.61 (2025-09-29)

### Fix

* fix: Refactor split create_tables into static Benchmark methods (#3126)

* feat - Split create_tables into static Benchmark methods

* feat - format

* Update mteb/leaderboard/table.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* feat - remove search query;take benchmark result as input;addressing the circular import,

* feat - format

* Update mteb/benchmarks/benchmark.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/benchmarks/benchmark.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* feat - use to_dataframe;clean table.py;move creat_table

* feat - fix circular import

* feat - clean-up

* feat - format

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`cb03bd4`](https://github.com/embeddings-benchmark/mteb/commit/cb03bd4edbdc626401f5877f7630df2ec3c6fc46))

### Unknown

* Update giga embeddings (#3210)

* update giga embeddings

* update giga embeddings

* 3b-september-2025

* fixed

* lint

* Update mteb/models/ru_sentence_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* change revision due to flash-attn dependency

* change apply_instruction_to_passages

---------

Co-authored-by: Kolodin Egor &lt;eikolodin@sberbank.ru&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ722497 &lt;dolegosmirnov@sberbank.ru&gt; ([`15f9909`](https://github.com/embeddings-benchmark/mteb/commit/15f99091e740bea471264f8b202b1fb30bf0d023))

## v1.38.60 (2025-09-27)

### Fix

* fix: prevent EOS token truncation (#3218)

* fix(models): prevent EOS token truncation for BMRetriever

* refactor(models): refactor tokenizer setup in `InstructSentenceTransformerWrapper`

* fix(models): correct eos token handling in `BMRetrieverWrapper` ([`f58ac2b`](https://github.com/embeddings-benchmark/mteb/commit/f58ac2bb21b3c3cef7787335025f435adf2b8855))

## v1.38.59 (2025-09-27)

### Fix

* fix: AttributeError in ColPaliEngineWrapper similarity method (#3177)

* fix: delete kwargs for similarity score in ColPaliEngineWrapper for method behavior

* chore: fix colpali_models similarity  handle device ([`8c180d4`](https://github.com/embeddings-benchmark/mteb/commit/8c180d4ed5a9d437c7740e746cf960602790be29))

### Unknown

* Update tasks &amp; benchmarks tables ([`0aacba4`](https://github.com/embeddings-benchmark/mteb/commit/0aacba4bfa6f630bd57daf898927e2a69cfc801c))

* dataset: add swedish cpc patent classifications to mteb (#3072)

* feat: add swedish cpc patent classifications to mteb

* fix: formatting and init imports

* fix: update mteb task according to feedback

* fix: perform citation and code formatting

* fix: add train and test split for both datasets ([`e863bc1`](https://github.com/embeddings-benchmark/mteb/commit/e863bc1db388361996409ebb3950f560ae7b0ff5))

* Adding Cohere&#39;s output_dimension and embedding_type parameter (#3204)

* Adding Cohere&#39;s output_dimension and embedding_type parameter
Cohere&#39;s embed-v4 binary and int8

* Correcting due to comments ([`08bba49`](https://github.com/embeddings-benchmark/mteb/commit/08bba494f03ab0933aa1fcdab59b848002069d30))

## v1.38.58 (2025-09-27)

### Fix

* fix(models): ensure prompt_type is passed to format_instruction (#3216) ([`82d9e29`](https://github.com/embeddings-benchmark/mteb/commit/82d9e297eb08a1d9c1f6b1cf854bc316ac978fe5))

### Unknown

* model: Add Codefuse models (#3205)

* add codefuse models

* add codefuse models

* Update codefuse_models.py

* lint codefuse.py ([`4f6d791`](https://github.com/embeddings-benchmark/mteb/commit/4f6d791cf60f439d0ba018ee86a90c9c220c2cfe))

* Revert &#34;Ci: test out GH models with welcoming new comers&#34; (#3206)

Revert &#34;Ci: test out GH models with welcoming new comers (#3112)&#34;

This reverts commit 73a35e0bb02e61108d50385f4c43fd7d1b16e984. ([`6e72dc0`](https://github.com/embeddings-benchmark/mteb/commit/6e72dc0e30577c2fde2bb5c6cb55c79bf8e1eaec))

* model: Add BMRetriever (#3195)

* model: Add BMRetriever

* Update mteb/models/bmretriever_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/bmretriever_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: remove trust_remote_code option

* feat: implement BMREtrieverWrapper based on InstructSentenceTransformerWrapper

* refactor: update training datasets for bmretriever

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`6718290`](https://github.com/embeddings-benchmark/mteb/commit/6718290e644326939a02fe4b2b3bff5b04c6268b))

## v1.38.57 (2025-09-21)

### Fix

* fix: Correct metadata for ArguAna dataset (#3202) ([`90e9f43`](https://github.com/embeddings-benchmark/mteb/commit/90e9f4308bda75726caac0147fe0167893dc18ab))

### Unknown

* Update tasks &amp; benchmarks tables ([`920dafe`](https://github.com/embeddings-benchmark/mteb/commit/920dafea572c41cba48e4068d5f9fde8803a12c6))

## v1.38.56 (2025-09-18)

### Fix

* fix: Add conflicting dependencies to toml (#3191)

fix conflict dependencies ([`0cc6802`](https://github.com/embeddings-benchmark/mteb/commit/0cc680242309e9a04339f7a82bff78a997f6cfb1))

## v1.38.55 (2025-09-18)

### Fix

* fix: Edit ack &amp; sponsors (#3187) ([`57ffd43`](https://github.com/embeddings-benchmark/mteb/commit/57ffd431aa6eeb1c654793563c29c2b4c002d1d9))

* fix: add version check for `embeddinggemma-300m` (#3189)

add version check ([`2093798`](https://github.com/embeddings-benchmark/mteb/commit/2093798b41e55f747b852808b0234c848ecc3251))

### Unknown

* Update tasks &amp; benchmarks tables ([`7266873`](https://github.com/embeddings-benchmark/mteb/commit/7266873a23baa586764e26a7f257fabe54af7c88))

* dataset: Update FaMTEB to Version 2 (#3157)

* Update benchmark to version 2

* make others in benchmark selector one line code

* small changes

* update a few tasks metadata

* update faintent license with correct form

* remove redundant trust remote codes

* fix hardnegatives revision

* make lint

* fix errors

* apply suggestions

* fix citation problem

* add PR link to benchmark desc

* remove duplicate dataset names in mcinext_models

* update prompts

---------

Co-authored-by: mehran &lt;mehan.sarmadi16@gmail.com&gt; ([`5f4ea31`](https://github.com/embeddings-benchmark/mteb/commit/5f4ea3198c8086f6651ce1401b24c4437cf05fbf))

* Update tasks &amp; benchmarks tables ([`d682c85`](https://github.com/embeddings-benchmark/mteb/commit/d682c8550ea20973ed5b597fc86832bb990ed22b))

* dataset: Added a set of  closed datasets (#3186)

* Add 12 more closed datasets
Extend the RTEB benchmarks

* trust_remote_code

* trust_remote_code

* Enabling JapaneseCode1Retrieval in the RTEB benchmarks

* Add closed datasets as private tasks

* Correct due to the comment ([`bc303ad`](https://github.com/embeddings-benchmark/mteb/commit/bc303adcf9ede845a993b2e6e8d064028c9648e7))

* dataset: Adding JapaneseCode1Retrieval as the first non-public dataset (#3168)

* Adding JapaneseCode1Retrieval as the first non-public dataset

* Transformed dataset

* Adding as private dataset to tests

* Correct the private task test

* Use the sample dataset as a reference

* Use the sample dataset as a reference

* fix ds loading

* allow on forks

* upd aciton

* remove paths

* try to trigger ci

* add ref

* add permissions

* remove paths

* add paths back

* get back to pull request

* rollback action

* Trying to resolve the token/secret problem

* Trying to resolve the token/secret problem

* Update dataset_loading_pr.yml

* Update dataset_loading_pr.yml

* Try the latest datasets package (worked for me)

* Try the latest datasets package (worked for me)

* Try the latest datasets package (worked for me)

* (last?) try

* (last?) try

* (last?) try

* Reverting the changes

* Exclude the private datasets from tests

* Apply suggestions from code review

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Solomatin Roman &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`e7141d9`](https://github.com/embeddings-benchmark/mteb/commit/e7141d9401485568015790f515f3ecd38628c7bf))

* Correct the VoyageAI model&#39;s batch creation/batch size calculation (#3185)

Correct the batch creation ([`ed68a89`](https://github.com/embeddings-benchmark/mteb/commit/ed68a89969afcc50df4ddb0824aef431fe8c4c1a))

* Align max tokens (#3172) ([`10c4948`](https://github.com/embeddings-benchmark/mteb/commit/10c49482402cfb86812d167d35e4163bc7f7524e))

* Update tasks &amp; benchmarks tables ([`b622870`](https://github.com/embeddings-benchmark/mteb/commit/b6228709ab63aa3337da5b9c7f70e0eab9af5865))

* dataset: Add Dapfam patent retrieval tasks (#2946)

* chore: add &#39;Patent retrieval&#39; subtype to TaskMetadata

* feat(retrieval): add DAPFAM patent retrieval tasks (+18 variants)

* Dapfam patent retrieval PR #2946 : refactor DAPFAM tasks (explicit classes, license, metadata, custom definition explanation ...)

* Dapfam patent retrieval PR #2946 : refactor DAPFAM tasks (explicit classes, license, metadata, custom definition explanation ...)

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Changes :

- Added possibility to opt in or out of quantization through the &#34;quantize&#34; argument.
- Added possibility to compute raw dot product without normalization. (to reproduce the paper method the &#34;similarity&#34; argument should be &#34;cosine&#34;).
- Removed unecessary function and overhauled the tasks descriptions to be more clear.

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Changes made :
- Overhauled task descriptions as well as naming to conform with the naming scheme of mteb retrieval tasks.
- Similarity is now computed using the similarity function of the passed model.
- Changed optional quantization method to conform with sentence transformers similarity function.

to reproduce the paper metrics, one can use the following snippet :

```python
from mteb import mteb
from sentence_transformers import SentenceTransformer

model_name = &#34;Snowflake/snowflake-arctic-embed-m-v2.0&#34;
model = SentenceTransformer(model_name,
                           model_kwargs={
                            &#34;torch_dtype&#34;: &#34;float16&#34;,
                            },
                           trust_remote_code=True,
                            ).cuda().eval()

tasks = mteb.get_tasks(tasks=[
    &#34;DAPFAMInTitlAbsToTitlAbsClmRetrieval&#34;,
    &#34;DAPFAMAllTitlAbsToTitlAbsClmRetrieval&#34;,
    &#34;DAPFAMOutTitlAbsToTitlAbsClmRetrieval&#34;,
     add the other 3 remaining tasks ...
    ])

evaluation = mteb.MTEB(tasks=tasks)
results = evaluation.run(
		model,
		output_folder=f&#34;mteb_res/{model_name}&#34;,
		quantize=True, # if set to false or not set, the obtained ndcg@10 and map@10 will be ~0.001 higher
		encode_kwargs= {&#34;batch_size&#34; : 32}
	)
```

* changed default value of quantization to false

* added the import to all DAPFAM tasks; tested that the  works; verified compliance with the checklist

* Update mteb/tasks/Retrieval/eng/DAPFAMPatentRetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* added revision numbers to all dataset loading operations as well as the metadata itself

* intermediate changes, refresh local branch

* intermediate changes, refresh local branch again

* scale back to standard evaluation with empty set exclusion, various cosmetic/formatting changes

* minor cosmetic/formatting changes

* fixed main metric to be ndcg_at_100 as in the paper

* removed old code artifacts from previous versions

* read appropriate loading arguments from task metadata, remove unecessary class attribute

* reformat bibtex ( remark on the assertion since it tries to match literal string instead of bibtex formatting, format inconsistent with arXiv default), fixed metadata, parameters read from task metadata, all tests passed

* refactor data loading to read from metadata class attributes

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`8f8ed49`](https://github.com/embeddings-benchmark/mteb/commit/8f8ed4973ac065649daeb92a70513e98d093a3ec))

## v1.38.54 (2025-09-08)

### Fix

* fix: Add dedicated display for RTEB benchmark results (#3089)

* feat - remove special filtering, keep zero-shot, keep borda rank

* feat - remove get_rteb_benchmark.py

* feat - delete get_rteb_benchmark.py;RTEB_BENCHMARK_ENTRIES changes

* feat -format

* Update mteb/load_results/benchmark_results.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`53f49ec`](https://github.com/embeddings-benchmark/mteb/commit/53f49ecc4d4c50eb6ac45fe9832208693bb2502d))

### Unknown

* Update tasks &amp; benchmarks tables ([`32c9746`](https://github.com/embeddings-benchmark/mteb/commit/32c9746dae1bbd651fdff5aba61f89724c3c4bf3))

* model: EmbeddingGemma 300M (#3129)

* model: EmbeddingGemma 300M

* Add license and revision ([`729f20a`](https://github.com/embeddings-benchmark/mteb/commit/729f20adbbcda328ac38528d27c7136d79f946da))

## v1.38.53 (2025-09-03)

### Ci

* ci: Dataset check on new PR (#3103)

* add dataset check on new PR

* add extract datasets

* run as module

* update startswith

* update workflow name

* add GitPython

* export var

* same shell session

* address review comments

* add to docs to say what this script does

* add docs ([`6e8eba1`](https://github.com/embeddings-benchmark/mteb/commit/6e8eba15ac7bff94f9a99929b395f76e703d99b2))

### Fix

* fix: add voyage quantization models (#3092)

* Adding quantization support

* Update mteb/models/voyage_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/model_meta.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/model_meta.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Simplifying the quantization/output_dtype

* Update mteb/model_meta.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`9c7804c`](https://github.com/embeddings-benchmark/mteb/commit/9c7804cc786e22be0043f0d8abe09be4e56eedb3))

### Unknown

* model: add Youtu-Embedding-V1 (#3115)

* add youtu models

* add a blank line

* fix the optional dependencies and lint the code

* remove unused dependencies and reformat

* revise prompt_type

---------

Co-authored-by: springxchen &lt;springxchen@tencent.com&gt; ([`652ff2b`](https://github.com/embeddings-benchmark/mteb/commit/652ff2bacdb2b4d5b57573012f38939743cbb0a2))

* Ci: test out GH models with welcoming new comers (#3112)

test out GH models with welcoming new comers ([`73a35e0`](https://github.com/embeddings-benchmark/mteb/commit/73a35e0bb02e61108d50385f4c43fd7d1b16e984))

## v1.38.52 (2025-09-01)

### Fix

* fix: Allow closed datasets (#3059)

* - Added an include_private parameter to the get_tasks() function that defaults to False
  - This ensures that by default, tests only run on public datasets
  - Tests can explicitly set include_private=True when needed to test private datasets

  - Added is_public: bool | None = None field to TaskMetadata
  - The field is optional and defaults to None (treated as public)
  - Updated the is_filled() method to exclude is_public from required fields
  - Added documentation

* - Added an include_private parameter to the get_tasks() function that defaults to False
  - This ensures that by default, tests only run on public datasets
  - Tests can explicitly set include_private=True when needed to test private datasets

  - Added is_public: bool | None = None field to TaskMetadata
  - The field is optional and defaults to None (treated as public)
  - Updated the is_filled() method to exclude is_public from required fields
  - Added documentation

* Correcting due to comments

* Update mteb/abstasks/TaskMetadata.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/overview.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Removing the not used filter_tasks_by_privacy function

* Correcting due to comments

* Correcting due to comments

* Correcting due to comments

* Removing the test case

* Rename the include_private parameter to exclude_private

* Rename the include_private parameter to exclude_private

* Add private tasks tests

* Add private tasks tests

* Update tests/test_tasks/test_private_tasks.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Add private tasks tests

* Add private tasks tests

* Add private tasks tests

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`5844cc7`](https://github.com/embeddings-benchmark/mteb/commit/5844cc7f7b0df6a6c79d65bf8d78c65a5b7de259))

### Unknown

* model: Add ModelMeta for OrdalieTech/Solon-embeddings-mini-beta-1.1 (#3090)

* Add ModelMeta for OrdalieTech/Solon-embeddings-mini-beta-1.1

* Add training_datasets (common_corpus, fineweb, wiki_fr, private LLM-synth)

* Format with ruff + add loader per review

* Apply ruff format/fixes

* Update mteb/models/ordalietech_solon_embeddings_mini_beta_1_1.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/ordalietech_solon_embeddings_mini_beta_1_1.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Register OrdalieTech/Solon-embeddings-mini-beta-1.1 in overview (ModelMeta + loader)

* Update mteb/models/ordalietech_solon_embeddings_mini_beta_1_1.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* fix import

* Add memory_usage_mb=808.0 and required fields to ModelMeta

* Fix 210 milions of parameters

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`4774b74`](https://github.com/embeddings-benchmark/mteb/commit/4774b74a610b5aed9257ef7f979b78883a497c8a))

## v1.38.51 (2025-09-01)

### Fix

* fix: Add @classmethod for @field_validators in TaskMetadata  (#3100) ([`4012517`](https://github.com/embeddings-benchmark/mteb/commit/40125175024c82f1efa6e00f272c8bf4a1caf211))

### Unknown

* Align task prompt dict with `PromptType` (#3101)

* align task prompt dict with `PromptType`

* use value instead of enum ([`7303c15`](https://github.com/embeddings-benchmark/mteb/commit/7303c15604dceb5c45193015bf1cb0e10a02f79e))

## v1.38.50 (2025-09-01)

### Fix

* fix: Updating the default batch size calculation in the voyage models (#3091) ([`5851c7a`](https://github.com/embeddings-benchmark/mteb/commit/5851c7a7d22b41927a57457b347daa38c462578a))

### Unknown

* Combine Plots and Tables into a Single (#3047)

* feat - Combine Plots and Tables into a Single Tab #3009

* feat - Resize the plot to make it more readable

* feat - Remove the (radar chart)

* feat - Add a comment stating that it only shows the Top 5 models in the table.

* feat - adjust layout

* Update mteb/leaderboard/app.py

* format

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`9586697`](https://github.com/embeddings-benchmark/mteb/commit/9586697f82b6c80a8abd6eea8607495810df3e9e))

* CI: Set upper limit for xdist version  (#3098)

* Commentout bibtex formatting

* Remove `-n auto`

* get back bibtex

* try limiting versions

* revert coverage

* revert coverage

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`17fa697`](https://github.com/embeddings-benchmark/mteb/commit/17fa69744a1ed93942daa0784a1edf1e633fe148))

## v1.38.49 (2025-08-28)

### Fix

* fix: duplicate mteb multilingual variables (#3080)

* fix benchmark naming

* format

* lint ([`27be671`](https://github.com/embeddings-benchmark/mteb/commit/27be67143393fc6eebe86bf247184d6a37e47bab))

* fix: Improving validate_task_to_prompt_name logs and error messages (#3079)

* Improving validate_task_to_prompt_name logs and error messages

* linter fixes

* Adding None prompts tests

* Update test_benchmark_sentence_transformer

* Update mteb/leaderboard/benchmark_selector.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`139fc73`](https://github.com/embeddings-benchmark/mteb/commit/139fc737fc012b3d3ae69c700a37f717747ccc24))

### Unknown

* model: mdbr-leaf models (#3081)

* added MDBR leaf models

* fixed revision for mdbr-leaf-ir

* added model prompts

* updated training datasets

* fixed linting

* lotte task reference

---------

Co-authored-by: Robin Vujanic &lt;robin.vujanic@mongodb.com&gt; ([`e4c2a95`](https://github.com/embeddings-benchmark/mteb/commit/e4c2a956ead462ffa9882d5557fcdf61018e09da))

* Update tasks &amp; benchmarks tables ([`5bf303b`](https://github.com/embeddings-benchmark/mteb/commit/5bf303b2a0ee021c90746221ad4eaa930fa8d190))

* Move dev to dependency groups (#3088)

add dependency groups ([`cd14ef6`](https://github.com/embeddings-benchmark/mteb/commit/cd14ef691888165dd70d4be1206c0a42408c3287))

## v1.38.48 (2025-08-27)

### Fix

* fix: run `ruff check` on all files during ci (#3086)

* fix: run `ruff check` on all files during ci

* format ([`b46b633`](https://github.com/embeddings-benchmark/mteb/commit/b46b633689a800e8147d49ef2fdcebc898f41337))

## v1.38.47 (2025-08-27)

### Fix

* fix: Add beta version of RTEB related benchmarks (#3048)

* Add RTEB related benchmarks

* Add RTEB related benchmarks

* Correcting the task names in the RTEB benchmarks

* Update mteb/leaderboard/benchmark_selector.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Adding the CURE dataset to RTEB benchmarks

* Use the right language subset

* Fix broken finance icon URL in RTEB benchmarks

Replace broken libre-finance-dollar.svg with working libre-gui-price-tag.svg
Validated all icon URLs and confirmed accessibility compliance

* Add the rteb_benchmarks to the BENCHMARK_REGISTRY

* Add the rteb_benchmarks to the BENCHMARK_REGISTRY

* Add the rteb_benchmarks to the BENCHMARK_REGISTRY

* Add the rteb_benchmarks to the BENCHMARK_REGISTRY

* Add the rteb_benchmarks to the BENCHMARK_REGISTRY

* Add the rteb_benchmarks to the BENCHMARK_REGISTRY

* Add the rteb_benchmarks to the BENCHMARK_REGISTRY

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`1541318`](https://github.com/embeddings-benchmark/mteb/commit/1541318c02cd963c7b78778b0a52cfbb03f048ac))

### Unknown

* Fix the reference link for CoDi-Embedding-V1 (#3075)

Fix reference link ([`d2c3570`](https://github.com/embeddings-benchmark/mteb/commit/d2c35704a530491390a63d050b54fee9b2566897))

## v1.38.46 (2025-08-25)

### Fix

* fix: Update revision for  qzhou models (#3069) ([`63a0c60`](https://github.com/embeddings-benchmark/mteb/commit/63a0c6075f56224a040bb61af235ab4cb7d436c9))

## v1.38.45 (2025-08-25)

### Ci

* ci: Add stale workflow (#3066)

* add stale workflow

* add permissions

* add bug label to bug issue template

* revert bug issue and only look at more info needed issues

* more accurate name

* override default ([`df719cc`](https://github.com/embeddings-benchmark/mteb/commit/df719cc05308068f47436ba0967a8f59e93340e8))

### Fix

* fix: open_clip package validation (#3073) ([`1f9641a`](https://github.com/embeddings-benchmark/mteb/commit/1f9641aeffb038baa9547b9d0b68c3a22ddf0b18))

### Unknown

* Correcting the JINA models with SentenceTransformerWrapper (#3071) ([`70724e7`](https://github.com/embeddings-benchmark/mteb/commit/70724e724f998c60dccc4553cc587775ebd1402d))

## v1.38.44 (2025-08-22)

### Fix

* fix: ensure that there are always relevant docs attached to query (#3058)

* fix: ensure that there are always relevant docs attached to query

Here is brief test that it doesn&#39;t influence scores:
```py
t1 = mteb.get_task(&#34;TwitterHjerneRetrieval&#34;)
meta = mteb.get_model_meta(&#34;minishlab/potion-base-2M&#34;)

eval = mteb.MTEB(tasks=[t1])
res = eval.run(model=meta.load_model())

# before fix:
res[0].get_score()  # np.float64(0.02837)
res[0].scores
before_fix = {
    &#34;train&#34;: [
        {
            &#34;ndcg_at_1&#34;: 0.02597,
            &#34;ndcg_at_3&#34;: 0.02213,
            &#34;ndcg_at_5&#34;: 0.0262,
            &#34;ndcg_at_10&#34;: 0.02837,
            &#34;ndcg_at_20&#34;: 0.04548,
            &#34;ndcg_at_100&#34;: 0.13527,
            &#34;ndcg_at_1000&#34;: 0.24507,
            &#34;map_at_1&#34;: 0.00866,
            &#34;map_at_3&#34;: 0.01317,
            &#34;map_at_5&#34;: 0.0149,
            &#34;map_at_10&#34;: 0.01562,
            &#34;map_at_20&#34;: 0.01898,
            &#34;map_at_100&#34;: 0.02968,
            &#34;map_at_1000&#34;: 0.03841,
            &#34;recall_at_1&#34;: 0.00866,
            &#34;recall_at_3&#34;: 0.02056,
            &#34;recall_at_5&#34;: 0.02922,
            &#34;recall_at_10&#34;: 0.03355,
            &#34;recall_at_20&#34;: 0.08268,
            &#34;recall_at_100&#34;: 0.43766,
            &#34;recall_at_1000&#34;: 1.0,
            &#34;precision_at_1&#34;: 0.02597,
            &#34;precision_at_3&#34;: 0.02165,
            &#34;precision_at_5&#34;: 0.01818,
            &#34;precision_at_10&#34;: 0.01039,
            &#34;precision_at_20&#34;: 0.01234,
            &#34;precision_at_100&#34;: 0.01481,
            &#34;precision_at_1000&#34;: 0.0034,
            &#34;mrr_at_1&#34;: 0.025974,
            &#34;mrr_at_3&#34;: 0.041126,
            &#34;mrr_at_5&#34;: 0.04632,
            &#34;mrr_at_10&#34;: 0.048485,
            &#34;mrr_at_20&#34;: 0.058356,
            &#34;mrr_at_100&#34;: 0.070186,
            &#34;mrr_at_1000&#34;: 0.071349,
            &#34;nauc_ndcg_at_1_max&#34;: 0.33969,
            &#34;nauc_ndcg_at_1_std&#34;: -0.202864,
            &#34;nauc_ndcg_at_1_diff1&#34;: -0.127,
            &#34;nauc_ndcg_at_3_max&#34;: 0.409376,
            &#34;nauc_ndcg_at_3_std&#34;: -0.039352,
            &#34;nauc_ndcg_at_3_diff1&#34;: -0.022816,
            &#34;nauc_ndcg_at_5_max&#34;: 0.250499,
            &#34;nauc_ndcg_at_5_std&#34;: -0.115263,
            &#34;nauc_ndcg_at_5_diff1&#34;: -0.057017,
            &#34;nauc_ndcg_at_10_max&#34;: 0.238696,
            &#34;nauc_ndcg_at_10_std&#34;: -0.138396,
            &#34;nauc_ndcg_at_10_diff1&#34;: -0.045287,
            &#34;nauc_ndcg_at_20_max&#34;: 0.154456,
            &#34;nauc_ndcg_at_20_std&#34;: -0.070635,
            &#34;nauc_ndcg_at_20_diff1&#34;: 0.074499,
            &#34;nauc_ndcg_at_100_max&#34;: -0.005753,
            &#34;nauc_ndcg_at_100_std&#34;: -0.074738,
            &#34;nauc_ndcg_at_100_diff1&#34;: -0.005851,
            &#34;nauc_ndcg_at_1000_max&#34;: 0.109439,
            &#34;nauc_ndcg_at_1000_std&#34;: -0.089797,
            &#34;nauc_ndcg_at_1000_diff1&#34;: -0.021634,
            &#34;nauc_map_at_1_max&#34;: 0.33969,
            &#34;nauc_map_at_1_std&#34;: -0.202864,
            &#34;nauc_map_at_1_diff1&#34;: -0.127,
            &#34;nauc_map_at_3_max&#34;: 0.385244,
            &#34;nauc_map_at_3_std&#34;: -0.080638,
            &#34;nauc_map_at_3_diff1&#34;: -0.060991,
            &#34;nauc_map_at_5_max&#34;: 0.294871,
            &#34;nauc_map_at_5_std&#34;: -0.119069,
            &#34;nauc_map_at_5_diff1&#34;: -0.06234,
            &#34;nauc_map_at_10_max&#34;: 0.285698,
            &#34;nauc_map_at_10_std&#34;: -0.132856,
            &#34;nauc_map_at_10_diff1&#34;: -0.055015,
            &#34;nauc_map_at_20_max&#34;: 0.236619,
            &#34;nauc_map_at_20_std&#34;: -0.100673,
            &#34;nauc_map_at_20_diff1&#34;: -0.002619,
            &#34;nauc_map_at_100_max&#34;: 0.15345,
            &#34;nauc_map_at_100_std&#34;: -0.138888,
            &#34;nauc_map_at_100_diff1&#34;: -0.02257,
            &#34;nauc_map_at_1000_max&#34;: 0.171402,
            &#34;nauc_map_at_1000_std&#34;: -0.134644,
            &#34;nauc_map_at_1000_diff1&#34;: -0.034477,
            &#34;nauc_recall_at_1_max&#34;: 0.33969,
            &#34;nauc_recall_at_1_std&#34;: -0.202864,
            &#34;nauc_recall_at_1_diff1&#34;: -0.127,
            &#34;nauc_recall_at_3_max&#34;: 0.375072,
            &#34;nauc_recall_at_3_std&#34;: -0.009643,
            &#34;nauc_recall_at_3_diff1&#34;: -0.089168,
            &#34;nauc_recall_at_5_max&#34;: 0.147691,
            &#34;nauc_recall_at_5_std&#34;: -0.128654,
            &#34;nauc_recall_at_5_diff1&#34;: -0.084259,
            &#34;nauc_recall_at_10_max&#34;: 0.141055,
            &#34;nauc_recall_at_10_std&#34;: -0.165932,
            &#34;nauc_recall_at_10_diff1&#34;: -0.060966,
            &#34;nauc_recall_at_20_max&#34;: 0.043863,
            &#34;nauc_recall_at_20_std&#34;: -0.028374,
            &#34;nauc_recall_at_20_diff1&#34;: 0.157575,
            &#34;nauc_recall_at_100_max&#34;: -0.157183,
            &#34;nauc_recall_at_100_std&#34;: -0.019437,
            &#34;nauc_recall_at_100_diff1&#34;: 0.013395,
            # &#34;nauc_recall_at_1000_max&#34;: nan,
            # &#34;nauc_recall_at_1000_std&#34;: nan,
            # &#34;nauc_recall_at_1000_diff1&#34;: nan,
            &#34;nauc_precision_at_1_max&#34;: 0.33969,
            &#34;nauc_precision_at_1_std&#34;: -0.202864,
            &#34;nauc_precision_at_1_diff1&#34;: -0.127,
            &#34;nauc_precision_at_3_max&#34;: 0.406318,
            &#34;nauc_precision_at_3_std&#34;: 0.007031,
            &#34;nauc_precision_at_3_diff1&#34;: -0.034709,
            &#34;nauc_precision_at_5_max&#34;: 0.178131,
            &#34;nauc_precision_at_5_std&#34;: -0.112493,
            &#34;nauc_precision_at_5_diff1&#34;: -0.045535,
            &#34;nauc_precision_at_10_max&#34;: 0.167897,
            &#34;nauc_precision_at_10_std&#34;: -0.150626,
            &#34;nauc_precision_at_10_diff1&#34;: -0.027811,
            &#34;nauc_precision_at_20_max&#34;: 0.081428,
            &#34;nauc_precision_at_20_std&#34;: -0.042304,
            &#34;nauc_precision_at_20_diff1&#34;: 0.17278,
            &#34;nauc_precision_at_100_max&#34;: -0.150619,
            &#34;nauc_precision_at_100_std&#34;: 0.016133,
            &#34;nauc_precision_at_100_diff1&#34;: -0.065571,
            &#34;nauc_precision_at_1000_max&#34;: -0.017244,
            &#34;nauc_precision_at_1000_std&#34;: 0.046614,
            &#34;nauc_precision_at_1000_diff1&#34;: -0.028258,
            &#34;nauc_mrr_at_1_max&#34;: 0.33969,
            &#34;nauc_mrr_at_1_std&#34;: -0.202864,
            &#34;nauc_mrr_at_1_diff1&#34;: -0.127,
            &#34;nauc_mrr_at_3_max&#34;: 0.409511,
            &#34;nauc_mrr_at_3_std&#34;: -0.064671,
            &#34;nauc_mrr_at_3_diff1&#34;: -0.01911,
            &#34;nauc_mrr_at_5_max&#34;: 0.319584,
            &#34;nauc_mrr_at_5_std&#34;: -0.103546,
            &#34;nauc_mrr_at_5_diff1&#34;: -0.025109,
            &#34;nauc_mrr_at_10_max&#34;: 0.309614,
            &#34;nauc_mrr_at_10_std&#34;: -0.117564,
            &#34;nauc_mrr_at_10_diff1&#34;: -0.019691,
            &#34;nauc_mrr_at_20_max&#34;: 0.262976,
            &#34;nauc_mrr_at_20_std&#34;: -0.092222,
            &#34;nauc_mrr_at_20_diff1&#34;: 0.024507,
            &#34;nauc_mrr_at_100_max&#34;: 0.256052,
            &#34;nauc_mrr_at_100_std&#34;: -0.094249,
            &#34;nauc_mrr_at_100_diff1&#34;: 0.012432,
            &#34;nauc_mrr_at_1000_max&#34;: 0.260112,
            &#34;nauc_mrr_at_1000_std&#34;: -0.098845,
            &#34;nauc_mrr_at_1000_diff1&#34;: 0.009697,
            &#34;main_score&#34;: 0.02837,
            &#34;hf_subset&#34;: &#34;default&#34;,
            &#34;languages&#34;: [&#34;dan-Latn&#34;],
        }
    ]
}

# with update:
res[0].get_score()  # np.float64(0.02837)
res[0].scores
with_fix = {
    &#34;train&#34;: [
        {
            &#34;ndcg_at_1&#34;: 0.02597,
            &#34;ndcg_at_3&#34;: 0.02213,
            &#34;ndcg_at_5&#34;: 0.0262,
            &#34;ndcg_at_10&#34;: 0.02837,
            &#34;ndcg_at_20&#34;: 0.04548,
            &#34;ndcg_at_100&#34;: 0.13527,
            &#34;ndcg_at_1000&#34;: 0.24507,
            &#34;map_at_1&#34;: 0.00866,
            &#34;map_at_3&#34;: 0.01317,
            &#34;map_at_5&#34;: 0.0149,
            &#34;map_at_10&#34;: 0.01562,
            &#34;map_at_20&#34;: 0.01898,
            &#34;map_at_100&#34;: 0.02968,
            &#34;map_at_1000&#34;: 0.03841,
            &#34;recall_at_1&#34;: 0.00866,
            &#34;recall_at_3&#34;: 0.02056,
            &#34;recall_at_5&#34;: 0.02922,
            &#34;recall_at_10&#34;: 0.03355,
            &#34;recall_at_20&#34;: 0.08268,
            &#34;recall_at_100&#34;: 0.43766,
            &#34;recall_at_1000&#34;: 1.0,
            &#34;precision_at_1&#34;: 0.02597,
            &#34;precision_at_3&#34;: 0.02165,
            &#34;precision_at_5&#34;: 0.01818,
            &#34;precision_at_10&#34;: 0.01039,
            &#34;precision_at_20&#34;: 0.01234,
            &#34;precision_at_100&#34;: 0.01481,
            &#34;precision_at_1000&#34;: 0.0034,
            &#34;mrr_at_1&#34;: 0.025974,
            &#34;mrr_at_3&#34;: 0.041126,
            &#34;mrr_at_5&#34;: 0.04632,
            &#34;mrr_at_10&#34;: 0.048485,
            &#34;mrr_at_20&#34;: 0.058356,
            &#34;mrr_at_100&#34;: 0.070186,
            &#34;mrr_at_1000&#34;: 0.071349,
            &#34;nauc_ndcg_at_1_max&#34;: 0.33969,
            &#34;nauc_ndcg_at_1_std&#34;: -0.202864,
            &#34;nauc_ndcg_at_1_diff1&#34;: -0.127,
            &#34;nauc_ndcg_at_3_max&#34;: 0.409376,
            &#34;nauc_ndcg_at_3_std&#34;: -0.039352,
            &#34;nauc_ndcg_at_3_diff1&#34;: -0.022816,
            &#34;nauc_ndcg_at_5_max&#34;: 0.250499,
            &#34;nauc_ndcg_at_5_std&#34;: -0.115263,
            &#34;nauc_ndcg_at_5_diff1&#34;: -0.057017,
            &#34;nauc_ndcg_at_10_max&#34;: 0.238696,
            &#34;nauc_ndcg_at_10_std&#34;: -0.138396,
            &#34;nauc_ndcg_at_10_diff1&#34;: -0.045287,
            &#34;nauc_ndcg_at_20_max&#34;: 0.154456,
            &#34;nauc_ndcg_at_20_std&#34;: -0.070635,
            &#34;nauc_ndcg_at_20_diff1&#34;: 0.074499,
            &#34;nauc_ndcg_at_100_max&#34;: -0.005753,
            &#34;nauc_ndcg_at_100_std&#34;: -0.074738,
            &#34;nauc_ndcg_at_100_diff1&#34;: -0.005851,
            &#34;nauc_ndcg_at_1000_max&#34;: 0.109439,
            &#34;nauc_ndcg_at_1000_std&#34;: -0.089797,
            &#34;nauc_ndcg_at_1000_diff1&#34;: -0.021634,
            &#34;nauc_map_at_1_max&#34;: 0.33969,
            &#34;nauc_map_at_1_std&#34;: -0.202864,
            &#34;nauc_map_at_1_diff1&#34;: -0.127,
            &#34;nauc_map_at_3_max&#34;: 0.385244,
            &#34;nauc_map_at_3_std&#34;: -0.080638,
            &#34;nauc_map_at_3_diff1&#34;: -0.060991,
            &#34;nauc_map_at_5_max&#34;: 0.294871,
            &#34;nauc_map_at_5_std&#34;: -0.119069,
            &#34;nauc_map_at_5_diff1&#34;: -0.06234,
            &#34;nauc_map_at_10_max&#34;: 0.285698,
            &#34;nauc_map_at_10_std&#34;: -0.132856,
            &#34;nauc_map_at_10_diff1&#34;: -0.055015,
            &#34;nauc_map_at_20_max&#34;: 0.236619,
            &#34;nauc_map_at_20_std&#34;: -0.100673,
            &#34;nauc_map_at_20_diff1&#34;: -0.002619,
            &#34;nauc_map_at_100_max&#34;: 0.15345,
            &#34;nauc_map_at_100_std&#34;: -0.138888,
            &#34;nauc_map_at_100_diff1&#34;: -0.02257,
            &#34;nauc_map_at_1000_max&#34;: 0.171402,
            &#34;nauc_map_at_1000_std&#34;: -0.134644,
            &#34;nauc_map_at_1000_diff1&#34;: -0.034477,
            &#34;nauc_recall_at_1_max&#34;: 0.33969,
            &#34;nauc_recall_at_1_std&#34;: -0.202864,
            &#34;nauc_recall_at_1_diff1&#34;: -0.127,
            &#34;nauc_recall_at_3_max&#34;: 0.375072,
            &#34;nauc_recall_at_3_std&#34;: -0.009643,
            &#34;nauc_recall_at_3_diff1&#34;: -0.089168,
            &#34;nauc_recall_at_5_max&#34;: 0.147691,
            &#34;nauc_recall_at_5_std&#34;: -0.128654,
            &#34;nauc_recall_at_5_diff1&#34;: -0.084259,
            &#34;nauc_recall_at_10_max&#34;: 0.141055,
            &#34;nauc_recall_at_10_std&#34;: -0.165932,
            &#34;nauc_recall_at_10_diff1&#34;: -0.060966,
            &#34;nauc_recall_at_20_max&#34;: 0.043863,
            &#34;nauc_recall_at_20_std&#34;: -0.028374,
            &#34;nauc_recall_at_20_diff1&#34;: 0.157575,
            &#34;nauc_recall_at_100_max&#34;: -0.157183,
            &#34;nauc_recall_at_100_std&#34;: -0.019437,
            &#34;nauc_recall_at_100_diff1&#34;: 0.013395,
            # &#34;nauc_recall_at_1000_max&#34;: nan,
            # &#34;nauc_recall_at_1000_std&#34;: nan,
            # &#34;nauc_recall_at_1000_diff1&#34;: nan,
            &#34;nauc_precision_at_1_max&#34;: 0.33969,
            &#34;nauc_precision_at_1_std&#34;: -0.202864,
            &#34;nauc_precision_at_1_diff1&#34;: -0.127,
            &#34;nauc_precision_at_3_max&#34;: 0.406318,
            &#34;nauc_precision_at_3_std&#34;: 0.007031,
            &#34;nauc_precision_at_3_diff1&#34;: -0.034709,
            &#34;nauc_precision_at_5_max&#34;: 0.178131,
            &#34;nauc_precision_at_5_std&#34;: -0.112493,
            &#34;nauc_precision_at_5_diff1&#34;: -0.045535,
            &#34;nauc_precision_at_10_max&#34;: 0.167897,
            &#34;nauc_precision_at_10_std&#34;: -0.150626,
            &#34;nauc_precision_at_10_diff1&#34;: -0.027811,
            &#34;nauc_precision_at_20_max&#34;: 0.081428,
            &#34;nauc_precision_at_20_std&#34;: -0.042304,
            &#34;nauc_precision_at_20_diff1&#34;: 0.17278,
            &#34;nauc_precision_at_100_max&#34;: -0.150619,
            &#34;nauc_precision_at_100_std&#34;: 0.016133,
            &#34;nauc_precision_at_100_diff1&#34;: -0.065571,
            &#34;nauc_precision_at_1000_max&#34;: -0.017244,
            &#34;nauc_precision_at_1000_std&#34;: 0.046614,
            &#34;nauc_precision_at_1000_diff1&#34;: -0.028258,
            &#34;nauc_mrr_at_1_max&#34;: 0.33969,
            &#34;nauc_mrr_at_1_std&#34;: -0.202864,
            &#34;nauc_mrr_at_1_diff1&#34;: -0.127,
            &#34;nauc_mrr_at_3_max&#34;: 0.409511,
            &#34;nauc_mrr_at_3_std&#34;: -0.064671,
            &#34;nauc_mrr_at_3_diff1&#34;: -0.01911,
            &#34;nauc_mrr_at_5_max&#34;: 0.319584,
            &#34;nauc_mrr_at_5_std&#34;: -0.103546,
            &#34;nauc_mrr_at_5_diff1&#34;: -0.025109,
            &#34;nauc_mrr_at_10_max&#34;: 0.309614,
            &#34;nauc_mrr_at_10_std&#34;: -0.117564,
            &#34;nauc_mrr_at_10_diff1&#34;: -0.019691,
            &#34;nauc_mrr_at_20_max&#34;: 0.262976,
            &#34;nauc_mrr_at_20_std&#34;: -0.092222,
            &#34;nauc_mrr_at_20_diff1&#34;: 0.024507,
            &#34;nauc_mrr_at_100_max&#34;: 0.256052,
            &#34;nauc_mrr_at_100_std&#34;: -0.094249,
            &#34;nauc_mrr_at_100_diff1&#34;: 0.012432,
            &#34;nauc_mrr_at_1000_max&#34;: 0.260112,
            &#34;nauc_mrr_at_1000_std&#34;: -0.098845,
            &#34;nauc_mrr_at_1000_diff1&#34;: 0.009697,
            &#34;main_score&#34;: 0.02837,
            &#34;hf_subset&#34;: &#34;default&#34;,
            &#34;languages&#34;: [&#34;dan-Latn&#34;],
        }
    ]
}

# check
with_fix == before_fix  # True

* restructure

* format

* relax pytrec versions

* fix incorrect parsing ([`9c27f71`](https://github.com/embeddings-benchmark/mteb/commit/9c27f71e44612f190756d41f1fcffeb817b0f3e3))

### Unknown

* model: Add CoDi-Embedding-V1 (#3054)

* add codiemb-minicpm

* replace codiemb_minicpm with codi_model

* Update mteb/models/codi_model.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/codi_model.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/codi_model.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* update code

* update code

* reformat

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`4994ea1`](https://github.com/embeddings-benchmark/mteb/commit/4994ea1758baf7d7bc183215280595fdb2b36c10))

* Update tasks &amp; benchmarks tables ([`26468f8`](https://github.com/embeddings-benchmark/mteb/commit/26468f8db5633b06f328d163c43f31e195062a96))

* dataset: Add JinaVDR (#2942)

* feat: added jinavdr benchmark

* feat: added description for jinavdr

* feat: fixed licenses and added bibtex

* feat: made jinav4 compatible with vidore benchmark

* feat: corrected query numbers

* feat: removed print

* feat: added max pixel argument for jina models

* feat: score calculation on cpu

* feat: adjust jina model for new mteb code

* feat: code cleanup

* feat: corrected bibtex

* feat: make colpali run with jinavdr

* feat: fixed comments

* feat: better reference and fixed comments

* feat: added date for tasks

* feat: fixed missing metadata and bibtex

* feat: added descriptions per dataset ([`cf3e1bb`](https://github.com/embeddings-benchmark/mteb/commit/cf3e1bbe62b53abeec7a932373c52e7d852f97cd))

* Correcting the (new) DS1000 dataset&#39;s revision (#3063)

* Add DS1000 retrieval task

- Code retrieval task based on 1,000 data science programming problems
- Natural language queries matched to Python data science code
- Uses python-Code evaluation language for code-specific metrics
- Covers pandas, numpy, matplotlib, scikit-learn, and scipy libraries

* Add DS1000Retrieval to imports

* Add descriptive statistics for DS1000Retrieval

* Reformatting

* Reformatting

* Add DS1000Retrieval task implementation ([`8e1c354`](https://github.com/embeddings-benchmark/mteb/commit/8e1c3547b4b2b3b18241e4f6456fc48360c6a041))

* Update tasks &amp; benchmarks tables ([`69099fe`](https://github.com/embeddings-benchmark/mteb/commit/69099fe216fe1ac4eaf8c5f68c0ba5b1dcd60cee))

* Add ChatDoctorRetrieval (#3045)

* Add ChatDoctorRetrieval

* Reformatting, correcting the revision

* Correct the dataset citation

* Correcting due to comments ([`e91cb8e`](https://github.com/embeddings-benchmark/mteb/commit/e91cb8ec97b24f8fa8547093ed573f4eea752989))

* Update tasks &amp; benchmarks tables ([`d2fcbac`](https://github.com/embeddings-benchmark/mteb/commit/d2fcbac461f300e2f44b281f31e079e8e6ade348))

* dataset: Add ds1000 retrieval (#3038)

* Add DS1000 retrieval task

- Code retrieval task based on 1,000 data science programming problems
- Natural language queries matched to Python data science code
- Uses python-Code evaluation language for code-specific metrics
- Covers pandas, numpy, matplotlib, scikit-learn, and scipy libraries

* Add DS1000Retrieval to imports

* Add descriptive statistics for DS1000Retrieval

* Reformatting

* Reformatting ([`53f0986`](https://github.com/embeddings-benchmark/mteb/commit/53f09860ea6a68a1b5650b064cf86ce8c93333a2))

* Update tasks &amp; benchmarks tables ([`e1ede42`](https://github.com/embeddings-benchmark/mteb/commit/e1ede4251b6d39ed86e59cbc9738863021193494))

* Add FreshStackRetrieval task (#3043)

* Add FreshStackRetrieval

* Reformatting, correcting the revision

* Dataset correction ([`a291a05`](https://github.com/embeddings-benchmark/mteb/commit/a291a055e8fc7814c2827a2becb1e32f7e4c7077))

* Update tasks &amp; benchmarks tables ([`fe57390`](https://github.com/embeddings-benchmark/mteb/commit/fe573902ad7dba42a50b03186e813ec4ea854c61))

* Add FinanceBenchRetrieval task (#3044)

* Add FinanceBenchRetrieval

* Update mteb/tasks/Retrieval/eng/FinanceBenchRetrieval.py

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`4da11c6`](https://github.com/embeddings-benchmark/mteb/commit/4da11c6b8d23bef2ea85d89636c4e9224bd30832))

* Update tasks &amp; benchmarks tables ([`fd8f89e`](https://github.com/embeddings-benchmark/mteb/commit/fd8f89ebc71a3fcb64deef94adbe00a3ec2b4bbd))

* Add finqa retrieval (#3042)

* Add FinQA retrieval task

- Financial numerical reasoning retrieval task based on FinQA dataset
- Numerical financial questions matched to relevant document data
- Covers earnings reports with tables and quantitative financial data
- Includes proper citations and descriptive statistics

* Add FinQARetrieval to imports

* Add descriptive statistics for FinQARetrieval

* Reformatting

* Reformatting

* Update mteb/tasks/Retrieval/eng/FinQARetrieval.py

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`7b57185`](https://github.com/embeddings-benchmark/mteb/commit/7b57185c0fadeabf3eddf534d00bfd3ca57a920a))

* Add hc3finance retrieval (#3041)

* Add HC3Finance retrieval task

- Financial retrieval task based on HC3 Finance dataset
- Financial questions matched to human and AI-generated content
- Covers financial explanations, analysis, and educational content
- Includes proper citations and descriptive statistics

* Add HC3FinanceRetrieval to imports

* Add descriptive statistics for HC3FinanceRetrieval

* Reformatting

* Reformatting, correcting the revision

* Update mteb/tasks/Retrieval/eng/HC3FinanceRetrieval.py

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`53d7d84`](https://github.com/embeddings-benchmark/mteb/commit/53d7d84b1e51111edbae63283f4630115156f3ab))

## v1.38.43 (2025-08-20)

### Ci

* ci: Temporarily limit pytrec version to &#34;pytrec-eval-terrier&gt;=0.5.6, &lt;0.5.8&#34; to prevent errors

try to fix CI ([`6fa6efa`](https://github.com/embeddings-benchmark/mteb/commit/6fa6efa4ac52acc4f5487cf1985a6eb33ebe9709))

### Fix

* fix: Add VN-MTEB benchmark and Leaderboard (#2995)

* [ADD] 50 vietnamese dataset from vn-mteb

* [UPDATE] task metadata

* [UPDATE] import dependencies

* [UPDATE] task metadata, bibtext citation

* [UPDATE-TEST] test_model_meta

* [UPDATE] sample_creation to machine-translated and LM verified

* [ADD] sample creation machine-translated and LM verified

* [ADD] VN-MTEB benchmark and leaderboard

* [FIX] wrong benchmark name

* [REMOVE] default fields metadata in Classfication tasks ([`0a6e855`](https://github.com/embeddings-benchmark/mteb/commit/0a6e855ccb6d8a86831b64e023829beedca61a3f))

### Unknown

* Update tasks &amp; benchmarks tables ([`def1377`](https://github.com/embeddings-benchmark/mteb/commit/def137706479cdc7c24cb47febdef767205972af))

* fix MBPPRetrieval revision (#3055)

Update MBPPRetrieval.py

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`ea801ec`](https://github.com/embeddings-benchmark/mteb/commit/ea801ec63af88ed82e52f93c9f1f2b0892540ad4))

* Update tasks &amp; benchmarks tables ([`7da3cf9`](https://github.com/embeddings-benchmark/mteb/commit/7da3cf989a7b326c42052f360d997e3598ca578b))

* dataset: Added wikisql retrieval (#3039)

* Add WikiSQL retrieval task

- Code retrieval task based on WikiSQL natural language to SQL dataset
- Natural language questions matched to SQL query implementations
- Uses sql-Code evaluation language for SQL-specific metrics
- Includes proper citations and descriptive statistics

* Add WikiSQLRetrieval to imports

* Add descriptive statistics for WikiSQLRetrieval

* Reformatting

* Reformatting

* Reformatting, correcting the revision ([`7b289f5`](https://github.com/embeddings-benchmark/mteb/commit/7b289f5881c74ea9971057ace24a47c83edf3793))

* Update tasks &amp; benchmarks tables ([`1fff5ce`](https://github.com/embeddings-benchmark/mteb/commit/1fff5ce63aa3015328c6401385ba4a755b24223d))

* dataset: Add mbpp retrieval (#3037)

* Add MBPP retrieval task

- Code retrieval task based on 378 Python programming problems
- Natural language queries matched to Python code implementations
- Uses python-Code evaluation language for code-specific metrics
- Includes proper citations and descriptive statistics

* Add MBPPRetrieval to imports

* Add descriptive statistics for MBPPRetrieval

* Reformatting

* Reformatting ([`ac69263`](https://github.com/embeddings-benchmark/mteb/commit/ac69263cf2743ec8a432e5d536f0637bfb18d807))

* Fix 3 VN-MTEB Pair Classification tasks (#3053)

* [ADD] 50 vietnamese dataset from vn-mteb

* [UPDATE] task metadata

* [UPDATE] import dependencies

* [UPDATE] task metadata, bibtext citation

* [UPDATE-TEST] test_model_meta

* [UPDATE] sample_creation to machine-translated and LM verified

* [ADD] sample creation machine-translated and LM verified

* [ADD] Vietnamese Embedding models

* [REMOVE] default fields metadata in Classfication tasks

* [UPDATE] model to vi-vn language specific file

* [FIX] lint

* [FIX] model loader

* [FIX] VN-MTEB 3 datasets PairClassification rename column ([`4e3fcd8`](https://github.com/embeddings-benchmark/mteb/commit/4e3fcd8d246abc1cf1f31730b7afd7af96903c9d))

## v1.38.42 (2025-08-18)

### Ci

* ci: Updating rerun delays to prevent false positives errors ([`e476dc3`](https://github.com/embeddings-benchmark/mteb/commit/e476dc3ec084956f033437f7125c9449e08cf1b5))

* ci: reduce parallel runs for when checking if a dataset exists (#3035)

The hope is that this will prevent many of the current [errors](https://github.com/embeddings-benchmark/mteb/actions/runs/17019125199/job/48245690831) ([`4aaf47e`](https://github.com/embeddings-benchmark/mteb/commit/4aaf47e16883218a2753f78e40ccce1dbade83e1))

### Fix

* fix: Updated revision for jina-embeddings-v4 (#3046)

* fix: jinav4 revision

Signed-off-by: admin &lt;bo.wang@jina.ai&gt;

* change revision instead of removing it

Signed-off-by: admin &lt;bo.wang@jina.ai&gt;

---------

Signed-off-by: admin &lt;bo.wang@jina.ai&gt;
Co-authored-by: admin &lt;bo.wang@jina.ai&gt; ([`c58b319`](https://github.com/embeddings-benchmark/mteb/commit/c58b319c60b0ce472caeac07a128fe4630fdd033))

### Unknown

* model: add granite-embedding-english R2 models (#3050) ([`e08ec56`](https://github.com/embeddings-benchmark/mteb/commit/e08ec56990d3a64cc6b5f314cc7a390ad9df754f))

* model: Add GreenNode Vietnamese Embedding models (#2994)

* [ADD] 50 vietnamese dataset from vn-mteb

* [UPDATE] task metadata

* [UPDATE] import dependencies

* [UPDATE] task metadata, bibtext citation

* [UPDATE-TEST] test_model_meta

* [UPDATE] sample_creation to machine-translated and LM verified

* [ADD] sample creation machine-translated and LM verified

* [ADD] Vietnamese Embedding models

* [REMOVE] default fields metadata in Classfication tasks

* [UPDATE] model to vi-vn language specific file

* [FIX] lint

* [FIX] model loader ([`72f7b05`](https://github.com/embeddings-benchmark/mteb/commit/72f7b05db237fa36e358d338694d26ecabf7eec3))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`d729d32`](https://github.com/embeddings-benchmark/mteb/commit/d729d327f0255c680c0f246eb18a5f178fe591af))

## v1.38.41 (2025-08-17)

### Ci

* ci: Updating rerun delays to prevent false positives errors ([`e124b56`](https://github.com/embeddings-benchmark/mteb/commit/e124b56ea87aaf1a1a444f13c27ad2e0798da88a))

### Fix

* fix: incorrect revision for SNLRetrieval (#3033)

The provided revisions doesn&#39;t seem to be present on:
adrlau/navjordj-SNL_summarization_copy

Replacing with latest revision ([`5c65913`](https://github.com/embeddings-benchmark/mteb/commit/5c659134996d1b1b0c53ed0589c8cfe4960f13bc))

### Unknown

* Update tasks &amp; benchmarks tables ([`a96f2e4`](https://github.com/embeddings-benchmark/mteb/commit/a96f2e4f5b5fd71ce16bc43633aad717e853a19f))

* dataset: Add HumanEvalRetrieval task (#3022)

* Add HumanEvalRetrieval dataset

* Fix TaskMetadata structure and remove descriptive_stats

- Use TaskMetadata class instead of dict
- Remove descriptive_stats as requested in PR review
- Add date field and proper import structure

* Fix dataset path and use verified metadata

- Change path from zeroshot/humaneval-embedding-benchmark to embedding-benchmark/HumanEval
- Use actual description from HuggingFace dataset page
- Remove fabricated citation and reference
- Remove revision field that was incorrect
- Reference HuggingFace dataset page instead of arxiv

* Add correct revision hash to HumanEval

- Add revision hash: ed1f48a for reproducibility

* Fix HumanEval metadata validation

- Add date field for metadata completeness
- Add bibtex_citation field (empty string)
- Required for TaskMetadata validation to pass
- Should resolve PR test failure

* Address reviewer feedback

- Remove trust_remote_code parameter as requested
- Add revision parameter to load_dataset() calls for consistency
- Use metadata revision hash in dataset loading for reproducibility

* Fix field names in HumanEval dataset loading

Changed query_id/corpus_id to query-id/corpus-id to match actual dataset format.

* Fix deprecated metadata_dict usage

Use self.metadata.dataset instead of self.metadata_dict for v2.0 compatibility.

* Fix data structure for MTEB compatibility

- Organize data by splits as expected by MTEB retrieval tasks
- Convert scores to integers for pytrec_eval compatibility

* Address PR feedback for HumanEval dataset

- Add descriptive statistics using calculate_metadata_metrics()
- Enhance metadata description with dataset structure details
- Add complete BibTeX citation for original paper
- Update to full commit hash revision
- Add python-Code language tag for programming language
- Explain retrieval task formulation clearly

* Fix BibTeX citation formatting for HumanEvalRetrieval

- Update citation to match bibtexparser formatting requirements
- Fields now in alphabetical order with lowercase names
- Proper trailing commas and indentation ([`d4e6223`](https://github.com/embeddings-benchmark/mteb/commit/d4e6223bd8318df9e77f62ccc62cba5141a5a026))

* model: Add granite-vision-embedding model  (#3029)

* Add files via upload

* Address review comments

* Address review comments

* ruff format

* Update mteb/models/granite_vision_embedding_models.py

* lint error fix

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`37d115a`](https://github.com/embeddings-benchmark/mteb/commit/37d115a508164ee68b05b0a2a676e84fb05220d1))

* model: Add samilpwc_models meta (#3028)

* model: Add samilpwc_models meta

* Fix: Remove CONST

* Fix: Reformat File

* Update: model revision ([`96a7cc5`](https://github.com/embeddings-benchmark/mteb/commit/96a7cc525e85bf83cff723fac91d8f9345b36367))

## v1.38.40 (2025-08-16)

### Fix

* fix: Add missing training sets for qzhou (#3023)

* Supplement missing training sets

* reformat code

* Reorganize the data list format

* update qzhou_model meta ([`20bc80c`](https://github.com/embeddings-benchmark/mteb/commit/20bc80c2c2b7e7f99654e3525db1f70425eb4478))

### Unknown

* Update tasks &amp; benchmarks tables ([`177997f`](https://github.com/embeddings-benchmark/mteb/commit/177997f0144690eac0c082e5f973cfc89cdaa331))

* Standardise task names and fix citation formatting (#3026)

fixes for name formatting ([`ea41e7a`](https://github.com/embeddings-benchmark/mteb/commit/ea41e7a757d8aefd24365326f0c7d45fdacf0c99))

* Add OpenAI models with 512 dimension (#3008)

* Add OpenAI/text-embedding-3-small (512 dim)
Add OpenAI/text-embedding-3-large (512 dim)

* Correcting due to comments

---------

Co-authored-by: fzowl &lt;zoltan@voyageai.com&gt; ([`d8b2910`](https://github.com/embeddings-benchmark/mteb/commit/d8b2910c97cf0ab2df41f2d30faf12128fa33fce))

* model: Add Cohere embed-v4.0 model support (#3006)

* Add Cohere embed-v4.0 model support

- Add text-only embed-v4.0 model in cohere_models.py
- Add multimodal embed-v4.0 model in cohere_v.py
- Support configurable dimensions (256, 512, 1024, 1536)
- Support 128,000 token context length
- Support multimodal embedding (text, images, mixed PDFs)

ðŸ¤– Generated with [Claude Code](https://claude.ai/code)

Co-Authored-By: Claude &lt;noreply@anthropic.com&gt;

* Add Cohere embed-v4.0 model support

Update cohere_v.py and cohere_models.py to include the new embed-v4.0 model with proper configuration and integration.

ðŸ¤– Generated with [Claude Code](https://claude.ai/code)

Co-Authored-By: Claude &lt;noreply@anthropic.com&gt;

---------

Co-authored-by: Claude &lt;noreply@anthropic.com&gt; ([`87eb27c`](https://github.com/embeddings-benchmark/mteb/commit/87eb27ca1434bc65d8ee206bfd18eaee2e9edf4a))

* Update tasks &amp; benchmarks tables ([`4adf565`](https://github.com/embeddings-benchmark/mteb/commit/4adf56523ca64275150771aeb7b84b14e92b1a9d))

* dataset: Added 50 Vietnamese dataset from vn-mteb (#2964)

* [ADD] 50 vietnamese dataset from vn-mteb

* [UPDATE] task metadata

* [UPDATE] import dependencies

* [UPDATE] task metadata, bibtext citation

* [UPDATE-TEST] test_model_meta

* [UPDATE] sample_creation to machine-translated and LM verified

* [ADD] sample creation machine-translated and LM verified

* [REMOVE] default fields metadata in Classfication tasks ([`741b022`](https://github.com/embeddings-benchmark/mteb/commit/741b0224441b8f0aef40d58759c77b886bc25a88))

* lint: Correcting lint errors (#3004)

* Adding Classification Evaluator test

* Modifications due to the comments

* Update tests/test_evaluators/test_ClassificationEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update tests/test_evaluators/test_ClassificationEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Modifications due to the comments

* Modifications due to the comments

* Correcting the lint errors

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`01840ce`](https://github.com/embeddings-benchmark/mteb/commit/01840ce29ea81853a5c7d0428ce6ad8a8b0850aa))

* model: BAAI/bge-m3-unsupervised Model (#3007)

* Add BAAI/bge-m3-unsupervised Model
(BAAI/bge_m3_retromae is commented out - the details are proper, but it fails during loading the model for me, so i commented out)

* Remove the commented retromae model

---------

Co-authored-by: fzowl &lt;zoltan@voyageai.com&gt; ([`042db73`](https://github.com/embeddings-benchmark/mteb/commit/042db73a84e9747abbc79cdf30335197314b5567))

* model: Add Voyage 3.5 model configuration (#3005)

Add Voyage 3.5 model configuration

- Add voyage_3_5 ModelMeta with 1024 embed dimensions and 32000 max tokens
- Set release date to 2025-01-21 with revision 1
- Configure for cosine similarity with instruction support
- Include standard Voyage training datasets reference

ðŸ¤– Generated with [Claude Code](https://claude.ai/code)

Co-authored-by: Claude &lt;noreply@anthropic.com&gt; ([`e5d386b`](https://github.com/embeddings-benchmark/mteb/commit/e5d386bde906464824acfefe855cc3ce29fefbc8))

* qzhou-embedding model_meta &amp; implementation (#2975)

* qzhou-embedding model_meta &amp; implementation

* Update qzhou_models.py

* Update qzhou_models.py

Processing todo itemsï¼ˆAdd default instructionï¼‰

* Update qzhou_models.py

correct bge datalist

* Update qzhou_models.py

correct &#39;public_training_data&#39;

* Update qzhou_models.py

* Update qzhou_models.py

* Update qzhou_models.py

* Update qzhou_models.py

* Update mteb/models/qzhou_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/qzhou_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* format qzhou_models.py for ruff check

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`6c1f1c6`](https://github.com/embeddings-benchmark/mteb/commit/6c1f1c659457dd3b38a853df5ebf01a71bb3b4a3))

## v1.38.39 (2025-08-03)

### Fix

* fix: Add new benchmark beRuSciBench along with AbsTaskTextRegression (#2716)

* Add RuSciBench

* fix bitext mining lang

* Add regression task

* fix init

* add missing files

* Improve description

* Add superseded_by

* fix lint

* Update regression task to match with v2

* Add stratified_subsampling for regression task

* Add boostrap for regression task

* Rename task class, add model as evaluator argument

* fix import

* fix import 2

* fixes

* fix

* Rename regression model protocol ([`36df9ca`](https://github.com/embeddings-benchmark/mteb/commit/36df9ca6d20b450e48b58700ee4988fa95db9515))

### Unknown

* Update tasks &amp; benchmarks tables ([`a86e2dd`](https://github.com/embeddings-benchmark/mteb/commit/a86e2dd0632de0ffd4d4f5787d8d2b3bc2a0b0c5))

* Update tasks &amp; benchmarks tables ([`e4f30e9`](https://github.com/embeddings-benchmark/mteb/commit/e4f30e9bbc0beec516ef8a98d93076ce751124f3))

* dataset: add BillSum datasets (#2943)

* Added BillSum datasets

* fixed billsumca

* Updated BillSumCA description

* Updated BillSumUS description

* Update mteb/tasks/Retrieval/eng/BillSumCA.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update mteb/tasks/Retrieval/eng/BillSumUS.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* lint

* lint

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`007d19f`](https://github.com/embeddings-benchmark/mteb/commit/007d19f8e8e29b05283e6e787eea8edc82d7a0c0))

* dataset: add GovReport dataset (#2953)

* Added govreport task

* Updated description ([`42dfe0d`](https://github.com/embeddings-benchmark/mteb/commit/42dfe0dd7b5dcc18f11bae3fa336282eed23c919))

* Update tasks &amp; benchmarks tables ([`da46c8e`](https://github.com/embeddings-benchmark/mteb/commit/da46c8e0a254b47021d658e7d321e27b832e59ad))

* dataset: Add BSARD v2, fixing the data loading issues of v1 (#2935)

* BSARD loader fixed

* BSARDv2 metadata fixed

* Update mteb/tasks/Retrieval/fra/BSARDRetrieval.py

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`8416541`](https://github.com/embeddings-benchmark/mteb/commit/84165413c7c1ab50b694d360d969f23fcfce5e68))

## v1.38.38 (2025-07-25)

### Ci

* ci: bump semantic release ([`4ef8571`](https://github.com/embeddings-benchmark/mteb/commit/4ef85716fdc0efe0bd9e4e81a4e331f32cf2060b))

### Documentation

* docs: Update adding_a_dataset.md (#2947)

* docs: Update adding_a_dataset.md

* Update docs/adding_a_dataset.md ([`a78debf`](https://github.com/embeddings-benchmark/mteb/commit/a78debff104aca1c64045da5d0033aca40fb89c8))

### Fix

* fix: Prevent incorrectly passing &#34;selector_state&#34; to `get_benchmark` (#2939)

The leaderboard would have (silent) errors where `get_benchmark` lead to a KeyError due to &#34;selector_state&#34; being passed as a default value. Setting `DEFAULT_BENCMARK_NAME` as the value solves this issue. ([`8496ec2`](https://github.com/embeddings-benchmark/mteb/commit/8496ec217578b4cf3bc17cb5f681d43d0884f389))

* fix: Only import SparseEncoder once sentence-transformer version have been checked (#2940)

* fix: Only import SparseEncoder once sentence-transformer version have been checked

fixes #2936

* Update mteb/models/opensearch_neural_sparse_models.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`79a43af`](https://github.com/embeddings-benchmark/mteb/commit/79a43af0a5f6df0dcb2f42b1877f1205693024b6))

* fix: replace with passage (#2934) ([`5ed6c90`](https://github.com/embeddings-benchmark/mteb/commit/5ed6c909f8d451ea63e4f664d39d80544d2c37d8))

### Unknown

* Update the link for gemini-embedding-001 (#2928) ([`533ce59`](https://github.com/embeddings-benchmark/mteb/commit/533ce591f3bff06fca2e7c952a54f9be0c617b08))

## v1.38.37 (2025-07-21)

### Fix

* fix: specify revision for opensearch (#2919)

specify revision for opensearch ([`0ac0231`](https://github.com/embeddings-benchmark/mteb/commit/0ac0231c7465aff5f2ebddb1d7624b6d3100930e))

### Unknown

* Use `mteb.get_model` in adding_a_dataset.md (#2922)

Update adding_a_dataset.md ([`c1922c8`](https://github.com/embeddings-benchmark/mteb/commit/c1922c8037c20dfbe3325411597312c685fdfa57))

* dataset: add BarExamQA dataset (#2916)

* Add BareExamQA retrieval task

* ran linter

* updated details

* updated details

* fixed subtype name

* fixed changes

* ran linter again ([`1dcc6dc`](https://github.com/embeddings-benchmark/mteb/commit/1dcc6dc3782279cd73a822e37308226b69b845fd))

* model: Add OpenSearch inf-free sparse encoding models (#2903)

add opensearch inf-free models

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`5a868e3`](https://github.com/embeddings-benchmark/mteb/commit/5a868e3829e0d41a09927f5a0076da203ce85f61))

## v1.38.36 (2025-07-20)

### Fix

* fix: change `passage` prompt to `document`  (#2912)

* change document to passage

* fix prompt names

* fix kwargs check

* fix default prompt ([`a298fa9`](https://github.com/embeddings-benchmark/mteb/commit/a298fa95d544036efbe6f06af878e10e0e5cf8f9))

### Unknown

* Update tasks &amp; benchmarks tables ([`372fc4c`](https://github.com/embeddings-benchmark/mteb/commit/372fc4c691b67d48da6206d1180cebc89b06b439))

* dataset: Add JapaneseSentimentClassification (#2913)

Add JapaneseSentimentClassification ([`57438c2`](https://github.com/embeddings-benchmark/mteb/commit/57438c2071b9ec0224621d9d8cfb9de48e4df975))

* Update tasks &amp; benchmarks tables ([`56c98ed`](https://github.com/embeddings-benchmark/mteb/commit/56c98ede6800f404d0aae8b5cdb38d56762b2f79))

* Classification dataset cleaning (#2900)

* Classification dataset cleaning

* Update pull request number

* Fix metadata test

* fix formatting

* add script for cleaning ([`aef1e33`](https://github.com/embeddings-benchmark/mteb/commit/aef1e33c80811041fb38ca70c63ec2157efef935))

* Evaluator tests (#2910)

* Adding Classification Evaluator test

* Modifications due to the comments

* Update tests/test_evaluators/test_ClassificationEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update tests/test_evaluators/test_ClassificationEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Modifications due to the comments

* Modifications due to the comments

* Adding STSEvaluator and SummarizationEvaluator tests

* Correcting due to the comments

* Correcting due to the comments

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`c7078af`](https://github.com/embeddings-benchmark/mteb/commit/c7078af1f31aa072328618335f8de6471ad26fe7))

## v1.38.35 (2025-07-16)

### Fix

* fix: update colpali engine models (#2905)

* adding vidore benchmarks

* fix typo

* clean vidore names + per lang eval

* lint

* vidore names

* bibtex fix

* fix revision

* vidore v2 citation

* update citation format and fix per-language mappings

* lint: citations

* typo citations

* fix revisiions

* lint

* fix colnomic3b revision

* fix colqwen2.5 revision + latest repo version

* fix query agmentation tokens

* colsmol revision ([`9864e2a`](https://github.com/embeddings-benchmark/mteb/commit/9864e2a0fafff094f628adb519108b6d2983e3f4))

### Unknown

* Add Classification Evaluator unit test (#2838)

* Adding Classification Evaluator test

* Modifications due to the comments

* Update tests/test_evaluators/test_ClassificationEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Update tests/test_evaluators/test_ClassificationEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt;

* Modifications due to the comments

* Modifications due to the comments

---------

Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`4a47f90`](https://github.com/embeddings-benchmark/mteb/commit/4a47f90db1b2fe4a4e1ab75574d2518bbd8f7776))

* model: add kalm_models (kalm-emb-v2) ModelMeta (new PR) (#2889)

* feat: add KaLM_Embedding_X_0605 in kalm_models

* Update kalm_models.py for lint format

* kalm-emb-v2

* kalm-emb-v2

* kalm-emb-v2

* kalm-emb-v2

* kalm-emb-v2

---------

Co-authored-by: xinshuohu &lt;xinshuohu@tencent.com&gt;
Co-authored-by: Xinshuo Hu &lt;yanshek.woo@gmail.com&gt; ([`9ecac21`](https://github.com/embeddings-benchmark/mteb/commit/9ecac2104bec034a33dfb2043d2ae5fe3becd62a))

* model: add image support for jina embeddings v4 (#2893)

* feat: unify text and image embeddings for all tasks

* fix: uniform batch size

* fix: update error message

* fix: update code task

* fix: update max length

* fix: apply review suggestions ([`17be7e5`](https://github.com/embeddings-benchmark/mteb/commit/17be7e548dbd3080e9dcc1abdc509d6762ccf1b6))

## v1.38.34 (2025-07-10)

### Fix

* fix: pin datasets version (#2892)

fix datasets version ([`00c95cf`](https://github.com/embeddings-benchmark/mteb/commit/00c95cff6846a03a478ee43a0b8a69d2846db325))

### Unknown

* Update tasks &amp; benchmarks tables ([`5303fec`](https://github.com/embeddings-benchmark/mteb/commit/5303fec13d52ca4a82c669475954e9433d61cbe7))

* dataset: Evalita dataset integration (#2859)

* Added DadoEvalCoarseClassification

* Removed unnecessary columns from DadoEvalCoarseClassification

* Added EmitClassification task

* added SardiStanceClassification task

* Added GeoLingItClassification task

* Added DisCoTexPairClassification tasks

* Added EmitClassification, DadoEvalCoarseClassification, GeoLingItClassification, SardiStanceClassification inside the inits

* changed import in DisCoTexPairClassification

* removed GeoLingItClassification dataset

* fixed citation formatting, missing metadata parameters and lint formatting

* - Added XGlueWRPReranking task
- Added missing __init__.py files

* fixed metadata in XGlueWRPReranking

* Added MKQARetrieval task

* fixed type in XGlueWRPReranking

* changed MKQARetrieval from  cross-lingual to monolingual

* formatted MKQARetrieval file

* removed unused const

---------

Co-authored-by: Mattia Sangermano &lt;MattiaSangermano@users.noreply.huggingface.co&gt; ([`ee17a6e`](https://github.com/embeddings-benchmark/mteb/commit/ee17a6e511cd0a1126b92905b564136a96b42d91))

* model: add Hakim and TookaSBERTV2 models (#2826)

* add tooka v2s

* add mcinext models

* update mcinext.py

* Apply PR review suggestions

* Update mteb/models/mcinext_models.py

---------

Co-authored-by: mehran &lt;mehan.sarmadi16@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kenevoldsen@pm.me&gt; ([`04dc6d4`](https://github.com/embeddings-benchmark/mteb/commit/04dc6d4ff088639f09ed5c363782b5b24beff339))

* Update tasks &amp; benchmarks tables ([`5be02c1`](https://github.com/embeddings-benchmark/mteb/commit/5be02c172903897fd0b5fb5f712009041cde19f9))

* Add and fix some Japanese datasets: ANLP datasets, JaCWIR, JQaRA (#2872)

* Add JaCWIR and JQaRA for reranking

* Fix ANLP Journal datasets

* Add NLPJournalAbsArticleRetrieval and JaCWIRRetrieval

* tackle test cases

* Remove _evaluate_subset usage

* Separate v1 and v2

* Update info for NLP Journal datasets ([`70768b5`](https://github.com/embeddings-benchmark/mteb/commit/70768b588f42e1651a0725bd71a1e82d6ca21256))

* Comment kalm model (#2877)

comment kalm model ([`a3ca95c`](https://github.com/embeddings-benchmark/mteb/commit/a3ca95ccf5eaa50c4bc7ba7d0597cc0255b71a25))

* model: add kalm_models ModelMeta (new PR) (#2853)

* feat: add KaLM_Embedding_X_0605 in kalm_models

* Update kalm_models.py for lint format

---------

Co-authored-by: xinshuohu &lt;xinshuohu@tencent.com&gt; ([`b67bd04`](https://github.com/embeddings-benchmark/mteb/commit/b67bd043fe7575e91f08c16a16e318fc4baaa1d6))

* model: add listconranker modelmeta (#2874)

* add listconranker modelmeta

* fix bugs

* use linter

* lint

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`5846f56`](https://github.com/embeddings-benchmark/mteb/commit/5846f56255ee5cdfe724580791c7414375f54a71))

* fix tests to be compatible with `SentenceTransformers` `v5` (#2875)

* fix sbert `v5`

* add comment ([`f346a37`](https://github.com/embeddings-benchmark/mteb/commit/f346a37d190e0753e899661fcbe40887757d69e0))

* rename seed-1.6-embedding to seed1.6-embedding (#2870) ([`f27648b`](https://github.com/embeddings-benchmark/mteb/commit/f27648baec2086389b162b2b94026d2ed6325416))

* model: Adding nvidia/llama-nemoretriever-colembed models (#2861)

* nvidia_llama_nemoretriever_colembed

* correct 3b reference

* lint fix

* add training data and license for nvidia/llama_nemoretriever_colembed

* lint

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`4ff1413`](https://github.com/embeddings-benchmark/mteb/commit/4ff1413316727ecec7ddaeb280fe963f06e7c3fb))

* Bump gradio to fix leaderboard sorting (#2866)

Bump gradio ([`a4388c2`](https://github.com/embeddings-benchmark/mteb/commit/a4388c26c56a2d1cc39a9532e8557b298df3e786))

* model: Adding Sailesh97/Hinvec (#2842)

* Adding Hinvec Model&#39;s Meta data.

* Adding hinvec_model.py

* Update mteb/models/hinvec_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* formated code with Black and lint with Ruff

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`e3286d5`](https://github.com/embeddings-benchmark/mteb/commit/e3286d5a6d1d7c7dbe46608b6c216672463c9f9e))

## v1.38.33 (2025-06-27)

### Fix

* fix: prompt validation for tasks with `-` (#2846)

* fix prompt validation

* fix task name split correctly

* add docstring for test ([`430357c`](https://github.com/embeddings-benchmark/mteb/commit/430357cdff0cc719da2a1a7c4df65016ba7dfcce))

### Unknown

* add jinav4 model meta (#2858)

* add model meta

* linting

* fix: add check for code lora

* fix: apply review comments ([`f1d560a`](https://github.com/embeddings-benchmark/mteb/commit/f1d560af3f86b2b16962e0480cfe241bc59f94fd))

## v1.38.32 (2025-06-25)

### Fix

* fix: update training dataset info of Seed-1.6-embedding model  (#2857)

update seed1.6 model training data info ([`a8214e2`](https://github.com/embeddings-benchmark/mteb/commit/a8214e2ed7111340f1d213c43a7829a9ffe83da0))

## v1.38.31 (2025-06-25)

### Documentation

* docs: Fix some typos in `docs/usage/usage.md` (#2835)

* Update usage.md

* Update usage.md

* Update docs/usage/usage.md

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`774a942`](https://github.com/embeddings-benchmark/mteb/commit/774a9429adc13da3b40e65e63ec32b37a89b1337))

### Fix

* fix: Update model selection for the leaderboard (#2855)

* fix: Update model selection for the leaderboard

fixes #2834

This removed the lower bound selection, but generally I don&#39;t think people should care about the models being too small.

* fix 1M --&gt; 1B

* format

* rename model_size -&gt; max_model_size ([`9a800d3`](https://github.com/embeddings-benchmark/mteb/commit/9a800d32bd3d84ff220d702e78f6d51ae0e85017))

### Unknown

* model: add Seed-1.6-embedding model (#2841)

* add Seed-1.6-embedding model

* Update seed_1_6_embedding_models.py

* update model meta info

* support image encoder interface

* error fix

* fix: format seed_1_6_embedding_models.py with Ruff ([`8851bf0`](https://github.com/embeddings-benchmark/mteb/commit/8851bf0a6a261c74dae10f8deb82a840864779df))

* model: Add custom instructions for GigaEmbeddings (#2836)

* add custom instructions

* fixed

* lint

* fix last instruction

---------

Co-authored-by: Kolodin Egor &lt;eikolodin@sberbank.ru&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`d7ff1ab`](https://github.com/embeddings-benchmark/mteb/commit/d7ff1ab3168ddf765d497b22e928af355f0cffe6))

## v1.38.30 (2025-06-16)

### Fix

* fix: Reuploaded previously unavailable SNL datasets (#2819)

* fix: Reuploaded previously unavailable SNL datasets

closes #2477

* removed exceptions from tests

* temp fixes

* added temporary fix

* clean up commented out code

* format ([`c790269`](https://github.com/embeddings-benchmark/mteb/commit/c7902698d76071e8bb21d3b8ec226422c88a6088))

### Unknown

* Update tasks &amp; benchmarks tables ([`74d17b2`](https://github.com/embeddings-benchmark/mteb/commit/74d17b277058e3d513ffd3f3190a5b014bf90259))

* model: Added 3 HIT-TMG&#39;s KaLM-embedding models (#2478)

* Added HIT-TMG_KaLM-embedding-multilingual-mini-instruct-v1 with instruct wrapper

* Added KaLM_embedding_multilingual_mini_instruct_v1_5

* Added model to overview.py

* Fix Task Count Per Language Table in tasks.md

* resolve conflicts

* remove tasks.md

* Modified get_instruction funcion

* Added support for prompt dict in get_instruction

* fix lang code

* Address comments

* Delete mteb/models/check_models.py

* added prompts_dict support in InstructSentenceTransformerWrapper

* corrected instruction format

* corrected prompts format

* added correct instruction format

* fix implementation

* remove `if name main`

* add comment

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`03e084b`](https://github.com/embeddings-benchmark/mteb/commit/03e084bc37d48809dd9ce6f6bc43311ede77570d))

* add description to issue template (#2817)

* add description to template

* fix typo ([`04c9511`](https://github.com/embeddings-benchmark/mteb/commit/04c9511e2064ec5ba492992a6d0c506b29c3cb43))

## v1.38.29 (2025-06-11)

### Fix

* fix: Ensure bright uses the correct revision (#2812)

fixes #2811 ([`56dc620`](https://github.com/embeddings-benchmark/mteb/commit/56dc62072760f7b9651e24a36bbd12e2b255e06c))

* fix: Adding client arg to init method of OpenAI models wrapper (#2803)

* Adding OpenAI client arg to init method (e.g., for already initialized AzureOpenAI client)

To use OpenAI embedding models via Azure, the model wrapper needs to be initialized with a different client.

* Update mteb/models/openai_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/openai_models.py

* remove comment and format

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`873ee76`](https://github.com/embeddings-benchmark/mteb/commit/873ee7612e2d655846aae1d0987e18872a613dc1))

### Unknown

* model: Add annamodels/LGAI-Embedding-Preview (#2810)

Add LGAI-Embedding

- Add mteb/models/lgai_embedding_models.py

- defined model metadata ([`3e291f3`](https://github.com/embeddings-benchmark/mteb/commit/3e291f3343bfaf09b7960331fb4e0c5926bc4004))

## v1.38.28 (2025-06-10)

### Ci

* ci: fix config error for semantic release (#2800)

discussed in: https://github.com/embeddings-benchmark/mteb/issues/2796 ([`3d8dd9e`](https://github.com/embeddings-benchmark/mteb/commit/3d8dd9e2d35e7a3340f848bbd69e97a3cda45d26))

### Fix

* fix: Add adapted_from to Cmedqaretrieval (#2806)

* fix: Add adapted_from to Cmedqaretrieval

Also snuck in a fix with form=None, which is no longer valid, but was still used in a few places.

* format ([`fef1837`](https://github.com/embeddings-benchmark/mteb/commit/fef1837e19c00855a59b43979334e72fc9c49674))

### Unknown

* Update training datasets of GeoGPT-Research-Project/GeoEmbedding (#2802)

update training datasets

Co-authored-by: zhangzeqing &lt;zhangzeqing@zhejianglab.com&gt; ([`36a3c67`](https://github.com/embeddings-benchmark/mteb/commit/36a3c674fe5ca2c35ab5c7166eda7269520cd14d))

* Update tasks &amp; benchmarks tables ([`5e6aa9d`](https://github.com/embeddings-benchmark/mteb/commit/5e6aa9d91e3f696ca6c9ef94e48d9cc0a552474b))

* dataset: Add R2MED Benchmark (#2795)

* Add files via upload

* Add files via upload

* Update benchmarks.py

* Update __init__.py

* Add files via upload

* Update R2MEDRetrieval.py

* Update run_mteb_r2med.py

* Delete scripts/run_mteb_r2med.py

* Update mteb/tasks/Retrieval/eng/R2MEDRetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/tasks/Retrieval/eng/R2MEDRetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/tasks/Retrieval/eng/R2MEDRetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/tasks/Retrieval/eng/R2MEDRetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Add files via upload

* Delete mteb/descriptive_stats/Retrieval/R2MEDRetrieval.json

* Add files via upload

* Add files via upload

* Add files via upload

* Update R2MEDRetrieval.py

* Add files via upload

* Add files via upload

* Add files via upload

* Add files via upload

* format citations

* Update R2MEDRetrieval.py

* Add files via upload

* Add files via upload

---------

Co-authored-by: Li Lei &lt;34205771+ll0ruc@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`b8e64e1`](https://github.com/embeddings-benchmark/mteb/commit/b8e64e1a09ab0386c3ac05db3f8bbc002532bfa1))

* model: add fangxq/XYZ-embedding (#2741)

* add xyz model

* add xyz model

* add xyz model

* update

* update

* update

* update

* update

* update

* update

* lint

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`1c08974`](https://github.com/embeddings-benchmark/mteb/commit/1c08974d0a482012e8b0c42cc3f16a6fe1ce5c40))

* model: Add GeoGPT-Research-Project/GeoEmbedding (#2773)

* add model: geogpt_models

* update geogpt_models

* use InstructSentenceTransformerWrapper

* resolve pylint warning

* format geogpt_models.py

* Update mteb/models/geogpt_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/geogpt_models.py

---------

Co-authored-by: zhangzeqing &lt;zhangzeqing@zhejianglab.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`8817670`](https://github.com/embeddings-benchmark/mteb/commit/88176701e23f83df17d8903636e81972c4d40a0d))

* Update issue and pr templates (#2782)

* Update issue templates

* Update bug_report.md

* test yaml template

* add templates

* update templates

* add emojis

* fix typo

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* update issue titles

* update PR template

* remove PR templates

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`af7adbf`](https://github.com/embeddings-benchmark/mteb/commit/af7adbf4add02801305fc3f452d477e54f6ba599))

* bump ruff (#2784) ([`9e2e972`](https://github.com/embeddings-benchmark/mteb/commit/9e2e972797cf020976413c04c069947108a7755f))

* model: Add Qwen3 Embedding model (#2769)

* Init code

* Remove extra config and lint code

* use sentence transformer

* add revisions

* fix lint

* Apply suggestions from code review

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix lint

* add framework

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`fe137d0`](https://github.com/embeddings-benchmark/mteb/commit/fe137d04865467e2f312c77e29bff28407097fc8))

* Update tasks &amp; benchmarks tables ([`360bf51`](https://github.com/embeddings-benchmark/mteb/commit/360bf51db2a1b768ce9ebd2456f7aedda2c9f81f))

* dataset: Add miracl vision (#2736)

* add miracl vision

* add miracl vision

* ruff

* cast

* image

* image

* add langs

* add langs

* add langs

* add langs

* descriptive stats

* lint

* lint

* lint

* remove com ([`61dc369`](https://github.com/embeddings-benchmark/mteb/commit/61dc369f1f822183a97b114321d1a95ddba38fd9))

## v1.38.27 (2025-06-05)

### Fix

* fix: CachedEmbeddingWrapper issues in both documentation and code (#2779)

Fixes #2772 ([`f7656d5`](https://github.com/embeddings-benchmark/mteb/commit/f7656d50c8be7bb233deab76a305f36bd2b01cc3))

## v1.38.26 (2025-06-05)

### Fix

* fix: Update Caltech101 datasets to latest revision [v1] (#2778)

* fix: Update Caltech101 datasets to latest revision [v2]

 fixes: #2770
Fixes the issue, but only in v1

```
# tested using:

task: mteb.AbsTask = mteb.get_task(&#34;Caltech101ZeroShot&#34;)
task.load_data()
task.get_candidate_labels()
```

* fix rev ([`40f0841`](https://github.com/embeddings-benchmark/mteb/commit/40f08419c8ab7495c3b40e43340dc36d39baa20b))

## v1.38.25 (2025-06-05)

### Ci

* ci: add new prefixes to releases (#2766)

add new prefixes ([`755a6eb`](https://github.com/embeddings-benchmark/mteb/commit/755a6eb76650a887307547ce7ce199fa62ec12a3))

### Fix

* fix: Update giga embeddings (#2774)

* update giga embeddings

* update giga embeddings

---------

Co-authored-by: Kolodin Egor &lt;eikolodin@sberbank.ru&gt; ([`5b71e34`](https://github.com/embeddings-benchmark/mteb/commit/5b71e34dfae1232e92ca0d7c8851a1fe3ed15c1e))

## v1.38.24 (2025-06-05)

### Documentation

* docs: Leaderboard simplifications (#2764)

* docs: Leaderboard simplifications

Simplified sidebar, notably:

1) Combined Language and Regional (since these are all languages)
2) Folded all (With Visual document retrieval then images start to take up a lot of space)
3) Removed legacy and instead added &#34;Other&#34; in language, where I moved &#34;English Legacy&#34;

I also restructured the code so that nesting is easier.

Is it also possible to create a seperate section (see dummy screenshot)

* refactor to reduce nesting

* format ([`33fddfe`](https://github.com/embeddings-benchmark/mteb/commit/33fddfe89b963bba33e029eef5e9295a5a32e05d))

### Fix

* fix: add xet support (#2603)

* add xet version

* add doc comment

* change xet requirements

* Update docs/usage/usage.md

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`5ffcd63`](https://github.com/embeddings-benchmark/mteb/commit/5ffcd6381c50166c2ddc85d5a6c74654139e17d1))

### Unknown

* Fixing Google embedding task type for STS (#2767)

The type `SIMILARITY` is invalid. Correct one: `SEMANTIC_SIMILARITY`. See https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/task-types#supported_task_types ([`db43120`](https://github.com/embeddings-benchmark/mteb/commit/db43120f34a83dc19b9b90b0a4251646b6e3d2be))

## v1.38.23 (2025-06-03)

### Ci

* ci: Delete cache in Model loading test only when model is loaded (#2761)

* only delete cache when model loaded

* testing it out ([`9827ec8`](https://github.com/embeddings-benchmark/mteb/commit/9827ec8d3972538e64d8b67c8b07d3906bda1a87))

### Fix

* fix: Add `cadet-embed-base-v1` (#2727)

* update

* update overview.py for models

* update

* update ([`39a391d`](https://github.com/embeddings-benchmark/mteb/commit/39a391de2fa18380ff38e89c827ab29a7d17aade))

### Unknown

* Add missing PatchCamelyon_labels.txt (#2756) ([`96706a8`](https://github.com/embeddings-benchmark/mteb/commit/96706a892b6f24d0b461e0898fc797ec76db66b4))

## v1.38.22 (2025-06-02)

### Documentation

* docs: Updated description of FEVER (#2745)

* docs: Updated description of FEVER

Update the description to state that the corpus is the same as fever as we have have [multiple questions on it](https://huggingface.co/datasets/mteb/climate-fever/discussions/2)

* minor ([`82f0bb9`](https://github.com/embeddings-benchmark/mteb/commit/82f0bb9b106d27743f3a121faaf072d81c5da2d8))

### Fix

* fix: Update caltech101 (#2759)

* docs: Updated description of FEVER

Update the description to state that the corpus is the same as fever as we have have [multiple questions on it](https://huggingface.co/datasets/mteb/climate-fever/discussions/2)

* fix: Update Caltech101 to different source

Run both versions of one of the task using `nomic-ai/nomic-embed-text-v1.5` and both scores match:

### Old

```
{
  &#34;dataset_revision&#34;: &#34;851374102055782c84f89b1b4e9d128a6568847b&#34;,
  &#34;task_name&#34;: &#34;Caltech101&#34;,
  &#34;mteb_version&#34;: &#34;1.38.4&#34;,
  &#34;scores&#34;: {
    &#34;test&#34;: [
      {
        &#34;accuracy&#34;: 0.897863,
```

### New
```
{
  &#34;dataset_revision&#34;: &#34;52439cf6d4f6ebf563d8cdc7f2c5371d9efd2686&#34;,
  &#34;task_name&#34;: &#34;Caltech101&#34;,
  &#34;mteb_version&#34;: &#34;1.38.4&#34;,
  &#34;scores&#34;: {
    &#34;test&#34;: [
      {
        &#34;accuracy&#34;: 0.897929,
``` ([`1651f60`](https://github.com/embeddings-benchmark/mteb/commit/1651f60afeed767eba0fd0aae895108080301fee))

### Unknown

* Update Seed1.5 training data (#2749)

* update seed1.5 training data

* update seed1.5 training data ([`ccc5714`](https://github.com/embeddings-benchmark/mteb/commit/ccc5714938c690998a3c3e5807f55436e3e29af5))

* Update tasks &amp; benchmarks tables ([`fe6729f`](https://github.com/embeddings-benchmark/mteb/commit/fe6729ff4ebbbe4373a984ab9dadbdf7df5a4f2c))

* Backfill task metadata for metadata for BigPatentClustering and AllegroReviews (#2755)

* big-patent

* allegro-reviews ([`e151fbd`](https://github.com/embeddings-benchmark/mteb/commit/e151fbd7920e5778a16c0cbeefcfb239362935e2))

## v1.38.21 (2025-05-29)

### Fix

* fix: Correct embedding dimension for bge-m3 (#2738)

Fixes #2735 ([`d5ccf10`](https://github.com/embeddings-benchmark/mteb/commit/d5ccf108686254d98c3589b06deaeb3e186ac1b5))

## v1.38.20 (2025-05-28)

### Fix

* fix: Add colpali models family (#2721)

* add colpali models

* add colpali as framework

* add colpali as framework

* update metadata and add colsmol

* ix typos

* account for revision

* add training data info and lint

* modify meta

* correct colmodels meta and add colnomic 7b

* fix typo in toml (colpali subdeps)

* refine colmodel loading and metadata ([`6303839`](https://github.com/embeddings-benchmark/mteb/commit/630383955232e04575d7e2cb4d32008a05036c55))

## v1.38.19 (2025-05-27)

### Fix

* fix: Rename display name of VDR (#2734) ([`b0988e2`](https://github.com/embeddings-benchmark/mteb/commit/b0988e2d20b44745b205409bf6a70732d8542d19))

### Unknown

* Update tasks &amp; benchmarks tables ([`836d7d9`](https://github.com/embeddings-benchmark/mteb/commit/836d7d9450dacf5acb6349c85b3c54f28c36ab64))

* Update tasks &amp; benchmarks tables ([`85cd957`](https://github.com/embeddings-benchmark/mteb/commit/85cd95794612c93c59ecd45efd628b436ef2b38f))

* Add ViDoRe combined benchmark and add to leaderboard side panel (#2732)

* add ViDoRe combined benchmark and add to leaderboard side panel

* Update benchmark_selector.py ([`0565dfa`](https://github.com/embeddings-benchmark/mteb/commit/0565dfa6665303bf622e51eca9443ec7cb322601))

## v1.38.18 (2025-05-27)

### Fix

* fix: Promote Persian benchmark to v1 (#2707)

* Switch versioning from beta to v1 and add v1 to benchmark selector

* Update Farsi benchmark display name, task IDs, and metadata

* Add Hakim Model

* fix hakim version

* update

* make lint

* fix: Promote Persian benchmark to v1

---------

Co-authored-by: mehran &lt;mehan.sarmadi16@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`1098109`](https://github.com/embeddings-benchmark/mteb/commit/10981090685d283a89acc40c0de9dc83db10366d))

### Unknown

* Update tasks &amp; benchmarks tables ([`274b28e`](https://github.com/embeddings-benchmark/mteb/commit/274b28e65cbc7f30df32da86a18d382d5222d1fa))

## v1.38.17 (2025-05-27)

### Fix

* fix: `IndicQARetrieval` loader (#2729)

* fix indic qa

* add kwargs ([`c3b66d9`](https://github.com/embeddings-benchmark/mteb/commit/c3b66d96438893082e2e7fe43a9469b11604b83a))

## v1.38.16 (2025-05-26)

### Fix

* fix: Add vidore v2 benchmarks (#2713)

* adding vidore benchmarks

* fix typo

* clean vidore names + per lang eval

* lint

* vidore names

* bibtex fix

* fix revision

* vidore v2 citation

* update citation format and fix per-language mappings

* lint: citations

* typo citations ([`175de94`](https://github.com/embeddings-benchmark/mteb/commit/175de9447965d91be93599fa9b4cc0ed1910648f))

### Unknown

* Update tasks &amp; benchmarks tables ([`f3e706c`](https://github.com/embeddings-benchmark/mteb/commit/f3e706c4a742dbc2b56525e87f6c8f512fc3fd97))

## v1.38.15 (2025-05-26)

### Fix

* fix: Update Seed1.5-Embedding API (#2724)

* update seed1.5-embedding api

* update seed1.5-embedding api

* update Seed1.5-Embedding API

* update Seed1.5-Embedding resolve comments

* update Seed1.5-Embedding lint

* Update mteb/models/seed_models.py

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`1da660e`](https://github.com/embeddings-benchmark/mteb/commit/1da660eca1651a23c67cdbddfccf0d0a3f50775f))

* fix: Ara and ben classification dataset cleaning (#2632)

* Improve classification datasets quality for ara and ben langs

* add missing AJGT

* fix format

* change ajgt description

* Fix numbers in description, add link to pull request

* Add too short filter

* Link in markdown format ([`4093099`](https://github.com/embeddings-benchmark/mteb/commit/40930991dc700a41d36285e87a9b1a5dd2933cf1))

### Unknown

* Update tasks &amp; benchmarks tables ([`e214854`](https://github.com/embeddings-benchmark/mteb/commit/e2148547180123edb06b4a57c8384f06e24544f4))

* Update the max tokens for gemini-embedding-001 (#2725) ([`b52069e`](https://github.com/embeddings-benchmark/mteb/commit/b52069eb5ed8dedcd252fa4360ca7da3bc2256ec))

## v1.38.14 (2025-05-23)

### Documentation

* docs: fix number of tasks for eng, v2 in docs (#2720) ([`7586624`](https://github.com/embeddings-benchmark/mteb/commit/75866242f7e5d23738562b233d250a46e8f5eaa6))

### Fix

* fix: Added potion-multilingual-128M (#2717)

* Added ModelMeta for potion-multilingual-128M

* Fixed linting

* Fixed linting

* Updated date ([`08b72c9`](https://github.com/embeddings-benchmark/mteb/commit/08b72c909887c4c4f53dddf6b29cfb923a9b76d4))

## v1.38.13 (2025-05-22)

### Fix

* fix: Integrate `lightonai/GTE-ModernColBERT-v1` (#2708)

* fix: Integrate `lightonai/GTE-ModernColBERT-v1`

Fixes #2673

* fixes based on corrections ([`2b13659`](https://github.com/embeddings-benchmark/mteb/commit/2b13659ccce91140a1c74817fdfc5e0d200f2fa6))

## v1.38.12 (2025-05-21)

### Fix

* fix: Rename gemini-embedding-exp-03-07 to gemini-embedding-001 (#2711)

* Rename gemini-embedding-exp-03-07 to gemini-embedding-001

* update referenfe link to the vertexAI API doc ([`0c0ad05`](https://github.com/embeddings-benchmark/mteb/commit/0c0ad053fc510223e78b06adea04efc82afc661f))

## v1.38.11 (2025-05-19)

### Documentation

* docs: Updated the PR template and improved submission docs (#2704)

* docs: Updated the PR template and improved submission docs

1) Updated PR template to only include checklist for datasets and models. The other checklists were essentially just tests.
2) I have updated the documentation for adding models. Notably I have split out the implementation segment, which I think makes it more readable.
3) Required that you argue for a dataset before addition

fixes #2568

* Apply suggestions from code review

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`835f6e6`](https://github.com/embeddings-benchmark/mteb/commit/835f6e67d1a27b5d6c0ed4e7e178e5444fbdd071))

### Fix

* fix: Remove models from the leaderboard (#2705)

* fix: Remove models from the leaderboard

I remove both models from the leaderboard by unlinking them from the import tree. I think this is the easiest way to add a model that not currently public.

* format ([`78080cd`](https://github.com/embeddings-benchmark/mteb/commit/78080cd8aff671845dda6ffadd276607eb4d91b8))

## v1.38.10 (2025-05-19)

### Fix

* fix: Only install mteb into site packages (#2618)

* Restrict installation directory

* fix

* namespace false

* add star

* add pont

* fix import

* fix import

* add init files

* fix setuptools find

* fix image init

* add missing templates

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`1c803a1`](https://github.com/embeddings-benchmark/mteb/commit/1c803a135f2201d6a466d55e111e5924631caa2a))

* fix: Ensure that optional dependencies are compatible and if not state it (#2706)

Fixes mistakes introduced in https://github.com/embeddings-benchmark/mteb/pull/2424

It seems like many of these requirements doesn&#39;t exist (voyageai&gt;=1.0.0). @ayush1298 I am hoping you could clear up how this happened? ([`7222458`](https://github.com/embeddings-benchmark/mteb/commit/72224581553e2d4c753be61a0f7cda1c565c34ca))

### Unknown

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`272b20e`](https://github.com/embeddings-benchmark/mteb/commit/272b20eb7de449ffb5228ea586a7146c08dd7cd3))

* Fix for Openai_Text-Embedding3-Small (#2702)

* Fix for Openai_Text-Embedding3-Small

* better syntax for readability ([`94edb6d`](https://github.com/embeddings-benchmark/mteb/commit/94edb6d6037f55577b3a040bcd9c275c1c5e3ee5))

* Fix for Openai_Text-Embedding3-Small (#2702)

* Fix for Openai_Text-Embedding3-Small

* better syntax for readability ([`2c1fb62`](https://github.com/embeddings-benchmark/mteb/commit/2c1fb622c30da35bd2f757ca924108db370b8afc))

* Correction in docs (#2688) ([`e97f606`](https://github.com/embeddings-benchmark/mteb/commit/e97f606c89be86c84e0bd41acc12c7112367fe59))

## v1.38.9 (2025-05-09)

### Fix

* fix: `MTEB(Code, v1)`  languages (#2679)

fix code languages ([`40ce571`](https://github.com/embeddings-benchmark/mteb/commit/40ce5716f6d586c9c159601cec624c4aba4569cc))

### Unknown

* fix modality for `OVENIT2TRetrieval` (#2678)

fix modality ([`21506ed`](https://github.com/embeddings-benchmark/mteb/commit/21506edb76b189fbe87826e7778858de1e188c9f))

* Leaderboard: UI simplifications for menus (#2672)

* Leaderboard: UI simplifications for menus

Did a few things to improve the simplify the leaderboard UI.

Changes:
- Combined FAQ entries
- Created dropdowns in the select benchmark menu sidebar
- Removed reference to arena
- Removed reference to old leaderboard
- reduced size of select menu
- reduced the size of acknowledgements
- removed farsi from the selection (as it is a beta)

refactors:
- refactored to use a class for menu items
- refactored texts segments out of app.py

* fixed comment

* fixes for sizes ([`debab47`](https://github.com/embeddings-benchmark/mteb/commit/debab47e6b069e9a5d7ba3dfee2d3d022e51cc28))

## v1.38.8 (2025-05-09)

### Fix

* fix: Allow empty string for openai models (#2676)

* fix for empty string input to openai/text-embedding-3-large

* fix: Allow empty string in openai models

closes: #1650

* fix based on review

* Updated docstring

---------

Co-authored-by: ayush1298 &lt;munotayush6@kgpian.iitkgp.ac.in&gt; ([`6f0b08d`](https://github.com/embeddings-benchmark/mteb/commit/6f0b08d63d997f6ced98b4817aafc1414496a2ff))

### Unknown

* Update final version of Doubao-1.5-Embedding (Rename to Seed1.5-Embedding) (#2674)

* update seed-embedding

* update seed models

* fix linting and tiktoken problem

* fix tiktoken bug

* fix lint

* update name

* Update mteb/models/seed_models.py

adopt suggestion

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* update logging

* update lint

* update link

* update revision

* update Doubao-1.5-Embedding revision 3

* rename Doubao-1.5-Embedding to Seed1.5-Embedding

---------

Co-authored-by: zhangpeitian &lt;zhangpeitian@bytedance.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`5194c23`](https://github.com/embeddings-benchmark/mteb/commit/5194c2338f2038215617514bfaf3249f8d10a2b5))

## v1.38.7 (2025-05-07)

### Fix

* fix: Update datasets wich can&#39;t be loaded with `datasets&gt;=3.0`  (#2661)

fix: Update datasets wich can&#39;t be loaded with `datasets&gt;=3.0` (#1619)

* reupload datasets

* fix loader

* remove commented code

* lint

* update pyproject dependencies ([`1ba6716`](https://github.com/embeddings-benchmark/mteb/commit/1ba671665919ce50532c8e38b06271c370b0d969))

### Unknown

* rename model RELLE to CHAIN19 (#2671)

* Add relle
* defined model metadata for relle

* Add mteb/models/relle_models.py

* Update mteb/models/relle_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* lint after commit

run after &#34;make lint&#34;

* Add into model_modules

Add model into model_modules and lint check

* rename model
change model name

* rename model
change model name

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`bbbaa42`](https://github.com/embeddings-benchmark/mteb/commit/bbbaa42618e7ceafade0e70575cb55dc4ac8211e))

## v1.38.6 (2025-05-06)

### Fix

* fix: SIB200 machine translated &gt; human translated (#2665)

As correctly pointed out in:

https://huggingface.co/datasets/mteb/sib200/discussions/1 ([`ebdf0ca`](https://github.com/embeddings-benchmark/mteb/commit/ebdf0cafb61a997ed66becb10cd0546f82dffbf3))

### Unknown

* Add tests for leaderboard build (#2631)

* Add tests for leaderboard build

* add new action

* remove build tests from other actions

* fix tests

* correct exclusion of test

* added timeout constant ([`0b7f571`](https://github.com/embeddings-benchmark/mteb/commit/0b7f5715f61e3f2a4b68c7a10ba50c0f91f26501))

## v1.38.5 (2025-05-05)

### Fix

* fix: Update VisualSTS Aggregate task modalities (#2597)

* Update STS17MultilingualVisualSTS.py

* fix STSBenchmarkMultilingualVisualSTS

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`671dc04`](https://github.com/embeddings-benchmark/mteb/commit/671dc04c7116c1da3531e93a43dbf62dd5eb6206))

### Unknown

* CI format citations (#2649)

* ci format citations

* add files

* remove from lint CI

* test lint

* test lint

* fix names ([`03b9a7f`](https://github.com/embeddings-benchmark/mteb/commit/03b9a7f0ab23db2fb6f983f71e3a3bba937b525c))

* Remove `typer` dependency from citation script (#2629)

remove typer dependency from citation script ([`2f27544`](https://github.com/embeddings-benchmark/mteb/commit/2f27544b74b78bfbc0a8497d70d8e551b5189b34))

* Update tasks &amp; benchmarks tables ([`9deae69`](https://github.com/embeddings-benchmark/mteb/commit/9deae69bb6b596f7a588583a29007e80148a2d85))

* Revert &#34;CI: fix infinitely committing issue (#2616)&#34; (#2636)

This reverts commit 82dcb3dd03da0294d8a72ddca7a951680f33d67d. ([`6ee7e46`](https://github.com/embeddings-benchmark/mteb/commit/6ee7e466e887c3ee52580e5f2f85a22b5b0aeb6b))

* Remove irrelevant test (#2630)

remove irrelevant test ([`c8949be`](https://github.com/embeddings-benchmark/mteb/commit/c8949be20e56ecc620c8268de6c1c0996244fc1c))

* add Bilingual English-Danish parallel corpus from The Danish Medicines Agency (#2633)

* add Bilingual English-Danish parallel corpus from The Danish Medicines Agency

* bump dataset revision

* format bibtex

* format bibtex ([`c61ffb4`](https://github.com/embeddings-benchmark/mteb/commit/c61ffb4bb4703e8350fe1e6aaa01914842e9e55b))

* Add Talemaader pair classification task (#2621)

Add talemaader pair classification task ([`a52ea2f`](https://github.com/embeddings-benchmark/mteb/commit/a52ea2f7ac9c6e3f7e6a67cfe6739071b456b4c3))

* fix citations (#2628) ([`54eb70e`](https://github.com/embeddings-benchmark/mteb/commit/54eb70e9d74f73ec6e45cb05552628d4f75d0373))

* Format all citations (#2614)

* Fix errors in bibtex_citation

* Format all bibtex_citation fields

* format benchmarks

* fix format

* Fix tests

* add formatting script ([`e0c2dc9`](https://github.com/embeddings-benchmark/mteb/commit/e0c2dc9d9fdd1bda720547792e56808f181928bb))

## v1.38.4 (2025-05-02)

### Fix

* fix: Removed missing dataset for MTEB(Multilingual) and bumped version

We should probably just have done this earlier to ensure that the multilingual benchamrk is runable. ([`f063638`](https://github.com/embeddings-benchmark/mteb/commit/f063638aece517e038951b371820f0a60d91a219))

### Unknown

* lint ([`2ecd7ad`](https://github.com/embeddings-benchmark/mteb/commit/2ecd7ade8e8cfbc374d16ac3b26c8f6e9fa3c83a))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`485941b`](https://github.com/embeddings-benchmark/mteb/commit/485941b10f20c620fae986da693d469ce3faa83a))

* Add ScandiSent dataset (#2620)

* add scandisent dataset

* add to init

* typo ([`cb57999`](https://github.com/embeddings-benchmark/mteb/commit/cb57999c973d937ab32f85c03705d8ef9aa971ce))

* CI: fix infinitely committing issue (#2616)

* fix token

* try to trigger

* add token

* test ci

* Update tasks &amp; benchmarks tables

* Update tasks &amp; benchmarks tables

* remove test lines

---------

Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt; ([`82dcb3d`](https://github.com/embeddings-benchmark/mteb/commit/82dcb3dd03da0294d8a72ddca7a951680f33d67d))

* Update gradio version (#2558)

* Update gradio version

Closes https://github.com/embeddings-benchmark/mteb/issues/2557

* bump gradio ([`eabd9a5`](https://github.com/embeddings-benchmark/mteb/commit/eabd9a59eced4cf16c1cae75bae4ef44e07d360b))

* Update tasks &amp; benchmarks tables ([`603aa5b`](https://github.com/embeddings-benchmark/mteb/commit/603aa5bdaab89d95c0c5c4b46d1604957d12ece8))

* CI: fix table  (#2615) ([`4d09a1a`](https://github.com/embeddings-benchmark/mteb/commit/4d09a1ac396fce48c35a3018d7918b65841a46fd))

* Update tasks &amp; benchmarks tables ([`20baefb`](https://github.com/embeddings-benchmark/mteb/commit/20baefb1ae916ef6f9db76c0ddebb2010a003941))

* Update tasks &amp; benchmarks tables ([`69937da`](https://github.com/embeddings-benchmark/mteb/commit/69937da846d2ac398ad221dc56e013b341ea9a15))

* Update tasks &amp; benchmarks tables ([`b2bfa6b`](https://github.com/embeddings-benchmark/mteb/commit/b2bfa6b1671a6aebf17451f9c2356c064ee8d3ec))

* Update tasks &amp; benchmarks tables ([`94e7585`](https://github.com/embeddings-benchmark/mteb/commit/94e7585a20800bb5b4c84d9b8e4f2a7e8d56fa45))

* Update tasks &amp; benchmarks tables ([`73afd47`](https://github.com/embeddings-benchmark/mteb/commit/73afd47907f90a4f1de912ebd26d9926e98b1677))

* Update tasks &amp; benchmarks tables ([`b0c9e63`](https://github.com/embeddings-benchmark/mteb/commit/b0c9e6366ebf9ce40d959ae34f4bc40b0babc4ec))

* Update tasks &amp; benchmarks tables ([`60e1d2e`](https://github.com/embeddings-benchmark/mteb/commit/60e1d2e90c0b99f5aa86b4e542e260fda5842338))

* Update tasks &amp; benchmarks tables ([`979716d`](https://github.com/embeddings-benchmark/mteb/commit/979716db6176e8cd4caada588a846a63a96c4367))

* Update tasks &amp; benchmarks tables ([`eb30080`](https://github.com/embeddings-benchmark/mteb/commit/eb30080c6fd08b402bc7a4264bdfd460a984a62e))

* Update tasks &amp; benchmarks tables ([`26cb06c`](https://github.com/embeddings-benchmark/mteb/commit/26cb06c3c745cd1911f306ba1d35d52317fe5500))

* Update tasks &amp; benchmarks tables ([`e228e94`](https://github.com/embeddings-benchmark/mteb/commit/e228e940fd29d26e14c441cb4fcc398e35c271db))

* Update tasks &amp; benchmarks tables ([`1c1e179`](https://github.com/embeddings-benchmark/mteb/commit/1c1e179086f19b1eb3903c9edb8207617453af5b))

* Update tasks &amp; benchmarks tables ([`17120b2`](https://github.com/embeddings-benchmark/mteb/commit/17120b2f2c8bc74137d7434cd2bc1d82d2d57e61))

* Update tasks &amp; benchmarks tables ([`4844ab5`](https://github.com/embeddings-benchmark/mteb/commit/4844ab52454c722322c3c64ee9b39c8ba6315d49))

* Update tasks &amp; benchmarks tables ([`43b364f`](https://github.com/embeddings-benchmark/mteb/commit/43b364fc469fea433ec74c1472e902be15bb34eb))

* Update tasks &amp; benchmarks tables ([`d92e507`](https://github.com/embeddings-benchmark/mteb/commit/d92e5071160b42ddcd3d48422f25015ac8672f5d))

* Update tasks &amp; benchmarks tables ([`e47b902`](https://github.com/embeddings-benchmark/mteb/commit/e47b90267ee989b107511f0bd8d1f7bebbe43eb7))

* Update tasks &amp; benchmarks tables ([`df48ec9`](https://github.com/embeddings-benchmark/mteb/commit/df48ec99f9168bf5ebca532001c2c69431974bbd))

* Update tasks &amp; benchmarks tables ([`4584831`](https://github.com/embeddings-benchmark/mteb/commit/458483171a8a56e248cc4d3b28b9d9ccf91ac4c7))

* Update tasks &amp; benchmarks tables ([`b620a12`](https://github.com/embeddings-benchmark/mteb/commit/b620a12a33065b00eb88b3cf4cc672718a7dc583))

* Update tasks &amp; benchmarks tables ([`44cec12`](https://github.com/embeddings-benchmark/mteb/commit/44cec123888b8e75151f0d95c7649777355dce01))

* Update tasks &amp; benchmarks tables ([`480ba52`](https://github.com/embeddings-benchmark/mteb/commit/480ba52a004e14b5ec1faa8b794a66de65a6704b))

* Update tasks &amp; benchmarks tables ([`4fd00cc`](https://github.com/embeddings-benchmark/mteb/commit/4fd00cc1c10c7fb04dff80d584aa1da55657571c))

* Update tasks &amp; benchmarks tables ([`11b5b33`](https://github.com/embeddings-benchmark/mteb/commit/11b5b334a9cd34115bcc46f44cb8d4eafb39af9e))

* Update tasks &amp; benchmarks tables ([`36e4172`](https://github.com/embeddings-benchmark/mteb/commit/36e4172fdea256834bdf44cb4fe38b055a5c8f3d))

* Update tasks &amp; benchmarks tables ([`5b65218`](https://github.com/embeddings-benchmark/mteb/commit/5b65218aec10c657aea0cc143cc17c3fda85288d))

* Update tasks &amp; benchmarks tables ([`ee272f2`](https://github.com/embeddings-benchmark/mteb/commit/ee272f20f65f01e27c57bfa76c7c25e79d1bf035))

* Update tasks &amp; benchmarks tables ([`309c51f`](https://github.com/embeddings-benchmark/mteb/commit/309c51fbc933e0283081f2050f730fc66e2c09dc))

* Update tasks &amp; benchmarks tables ([`b59392d`](https://github.com/embeddings-benchmark/mteb/commit/b59392d899690c2c2dc9c6196bc9618703ea33a2))

* Update tasks &amp; benchmarks tables ([`4b97a83`](https://github.com/embeddings-benchmark/mteb/commit/4b97a8317002d9148cc83f5556d55a3321e738e8))

* Update tasks &amp; benchmarks tables ([`62a967b`](https://github.com/embeddings-benchmark/mteb/commit/62a967b353ada0f98e8bc823acb796ff1e8ce371))

* Update tasks &amp; benchmarks tables ([`b720cfd`](https://github.com/embeddings-benchmark/mteb/commit/b720cfd05ef64f31194c5c741a7e62413074b427))

* Update tasks &amp; benchmarks tables ([`5f4daf5`](https://github.com/embeddings-benchmark/mteb/commit/5f4daf5d11c002dce594961f20c97a0a8a362ba0))

* Update tasks &amp; benchmarks tables ([`5694e30`](https://github.com/embeddings-benchmark/mteb/commit/5694e30c1921027ca6f055b80669a702024c4be8))

* Update tasks &amp; benchmarks tables ([`e4935e2`](https://github.com/embeddings-benchmark/mteb/commit/e4935e2832b0a6c72fd59f8ca3d60baaeafa0b6b))

* Update tasks &amp; benchmarks tables ([`000d5bf`](https://github.com/embeddings-benchmark/mteb/commit/000d5bffbf89c2628c4632e8c7d3f01f6027742c))

* Update tasks &amp; benchmarks tables ([`ab42110`](https://github.com/embeddings-benchmark/mteb/commit/ab4211045707759fd038465e27b688d54b9f15c6))

* Update tasks &amp; benchmarks tables ([`bd7e85a`](https://github.com/embeddings-benchmark/mteb/commit/bd7e85a904d6db52d7b7f89d383bee4755089aea))

* Update tasks &amp; benchmarks tables ([`ca5c3ad`](https://github.com/embeddings-benchmark/mteb/commit/ca5c3ad0e042b7130380ee30ccc72b794f2c730d))

* Update tasks &amp; benchmarks tables ([`422fca2`](https://github.com/embeddings-benchmark/mteb/commit/422fca29efb024bf15c5833fa56db7c384be7d1f))

* Update tasks &amp; benchmarks tables ([`8e7d4f4`](https://github.com/embeddings-benchmark/mteb/commit/8e7d4f41e6353d2ca057603e946318ef6c30bf0a))

* Update tasks &amp; benchmarks tables ([`e731eaa`](https://github.com/embeddings-benchmark/mteb/commit/e731eaaa6b503bc03cb2a895ed41dbe2a18ceeb4))

* Update tasks &amp; benchmarks tables ([`758be74`](https://github.com/embeddings-benchmark/mteb/commit/758be74c0aff8a25695b5703c6cafc593e64cd80))

* Update tasks &amp; benchmarks tables ([`258dd4e`](https://github.com/embeddings-benchmark/mteb/commit/258dd4e373357ccafd55d07eb0f82712c961db57))

* Update tasks &amp; benchmarks tables ([`daa7807`](https://github.com/embeddings-benchmark/mteb/commit/daa780791919842ce3e80ff8b575e0a3f2bc73c5))

* Update tasks &amp; benchmarks tables ([`3e41806`](https://github.com/embeddings-benchmark/mteb/commit/3e41806bdc34920064acd911754c6adc4fe023cd))

* Update tasks &amp; benchmarks tables ([`437b5e6`](https://github.com/embeddings-benchmark/mteb/commit/437b5e6407bce3382b8a8a1ac4da67eaa17e48d7))

* Update tasks &amp; benchmarks tables ([`2dd457c`](https://github.com/embeddings-benchmark/mteb/commit/2dd457ca9009b23c4a132a5857df0948ffc49c75))

* Update tasks &amp; benchmarks tables ([`e2d43cf`](https://github.com/embeddings-benchmark/mteb/commit/e2d43cffe3fbd236daaf85f1dadc6b7ad6cec659))

* Update tasks &amp; benchmarks tables ([`4e42192`](https://github.com/embeddings-benchmark/mteb/commit/4e42192299bc731496c84335ccffcf1bbeb2dc51))

* Update tasks &amp; benchmarks tables ([`936dafb`](https://github.com/embeddings-benchmark/mteb/commit/936dafb9affced74a33e37d73ad1bafa2135ef6a))

* Update tasks &amp; benchmarks tables ([`5f1b3d0`](https://github.com/embeddings-benchmark/mteb/commit/5f1b3d0fabe1916f0ec4dfca197bc2a066291912))

* Update tasks &amp; benchmarks tables ([`e9b5706`](https://github.com/embeddings-benchmark/mteb/commit/e9b57061a6c09754dde21aa5c60c68d116cc3d56))

* Update tasks &amp; benchmarks tables ([`630c5bb`](https://github.com/embeddings-benchmark/mteb/commit/630c5bbb4ef11e1b024d4ccd6b8673b514b88591))

* Update tasks &amp; benchmarks tables ([`d03650c`](https://github.com/embeddings-benchmark/mteb/commit/d03650c6f02cc1d4b59d3b179ebaee1d10fb1c69))

* Update tasks &amp; benchmarks tables ([`1ae5750`](https://github.com/embeddings-benchmark/mteb/commit/1ae5750beee4ee08e28b3dd4ea5be5e85bc8d46d))

* Update tasks &amp; benchmarks tables ([`da5bf31`](https://github.com/embeddings-benchmark/mteb/commit/da5bf31071cc3494f141770e8d01aa87eb379bf5))

* Update tasks &amp; benchmarks tables ([`49c33e2`](https://github.com/embeddings-benchmark/mteb/commit/49c33e2f40fe610f1f12b8c8e987f0edad096565))

* Update tasks &amp; benchmarks tables ([`b78ea7d`](https://github.com/embeddings-benchmark/mteb/commit/b78ea7d05261e746ec180aa6f28558a207e5575d))

* Update tasks &amp; benchmarks tables ([`a2427d3`](https://github.com/embeddings-benchmark/mteb/commit/a2427d319d96068cfdc655ca008455c3c6b50ede))

* Update tasks &amp; benchmarks tables ([`fccc9b7`](https://github.com/embeddings-benchmark/mteb/commit/fccc9b77819c0b9f35598d973f8761659d14ae53))

* Update tasks &amp; benchmarks tables ([`4dcffb9`](https://github.com/embeddings-benchmark/mteb/commit/4dcffb90f9fa20f03f79bdf53ac61ba07bb39409))

* Update tasks &amp; benchmarks tables ([`17ae76e`](https://github.com/embeddings-benchmark/mteb/commit/17ae76e94ec8a3b636fc9ea44da0c4a737799eb6))

* Update tasks &amp; benchmarks tables ([`18faed2`](https://github.com/embeddings-benchmark/mteb/commit/18faed24b05dafcf490b3f63f423911a4e5a0686))

* Update tasks &amp; benchmarks tables ([`5d9332c`](https://github.com/embeddings-benchmark/mteb/commit/5d9332c7fc6d919cde8454c663032ccaced5a6fd))

* Update tasks &amp; benchmarks tables ([`5aafe93`](https://github.com/embeddings-benchmark/mteb/commit/5aafe93d39aec655ee8a3734dfc527771938b92e))

* Update tasks &amp; benchmarks tables ([`c32f3a9`](https://github.com/embeddings-benchmark/mteb/commit/c32f3a9a0e88164e5881de9118723e12ab5ee707))

* Update tasks &amp; benchmarks tables ([`a2e14ae`](https://github.com/embeddings-benchmark/mteb/commit/a2e14aea81fde4542114ff511f78f84fc8d7d6d7))

* Update tasks &amp; benchmarks tables ([`6ae644c`](https://github.com/embeddings-benchmark/mteb/commit/6ae644c9340bf89db51820b6f946b193659372b7))

* Update tasks &amp; benchmarks tables ([`6ed9b90`](https://github.com/embeddings-benchmark/mteb/commit/6ed9b909e807e4d25f3413a65c8e9ad87e9496a9))

* Update tasks &amp; benchmarks tables ([`0c24f8d`](https://github.com/embeddings-benchmark/mteb/commit/0c24f8d032b732ad3ac81365295910ff3bc2549b))

* Update tasks &amp; benchmarks tables ([`23b999d`](https://github.com/embeddings-benchmark/mteb/commit/23b999d1ba0381fb5053e2a5b036aaaa6ce5e273))

* Update tasks &amp; benchmarks tables ([`350181f`](https://github.com/embeddings-benchmark/mteb/commit/350181f2610eddfdec1d2b6792985f814cf12fba))

* Update tasks &amp; benchmarks tables ([`2168d9c`](https://github.com/embeddings-benchmark/mteb/commit/2168d9c8cf314d1db9f72f1c77d1e5227004d4e1))

* Update tasks &amp; benchmarks tables ([`f1f09f8`](https://github.com/embeddings-benchmark/mteb/commit/f1f09f8666ce868f4266736237b955192999a723))

* Update tasks &amp; benchmarks tables ([`6432ea8`](https://github.com/embeddings-benchmark/mteb/commit/6432ea8f4ac1eb6b9a66f50496cf6b787b02ff1e))

* Update tasks &amp; benchmarks tables ([`917263c`](https://github.com/embeddings-benchmark/mteb/commit/917263c85d2ac4d56d64de9a1806aaefcc93c1b2))

* Update tasks &amp; benchmarks tables ([`952070e`](https://github.com/embeddings-benchmark/mteb/commit/952070e3f4cd1f4629644287014f1a4fd54df014))

* Update tasks &amp; benchmarks tables ([`86069c7`](https://github.com/embeddings-benchmark/mteb/commit/86069c7f1cd7a6379f4bcbc56e96b318ed5b6017))

* Update tasks &amp; benchmarks tables ([`2c2ed55`](https://github.com/embeddings-benchmark/mteb/commit/2c2ed55e2dd0a72307a92b1ce2c9632ebe0b9e45))

* Update tasks &amp; benchmarks tables ([`cd4670c`](https://github.com/embeddings-benchmark/mteb/commit/cd4670c170dbc292ce5a9d9d35a145688b70b563))

* Update tasks &amp; benchmarks tables ([`cd83936`](https://github.com/embeddings-benchmark/mteb/commit/cd83936cc274b42df56b50ec7a0bebc0b2e3ecfa))

* Update tasks &amp; benchmarks tables ([`54b863e`](https://github.com/embeddings-benchmark/mteb/commit/54b863ecbdf04299776d6df7c66bc7f163552a37))

* Update tasks &amp; benchmarks tables ([`b65f0ec`](https://github.com/embeddings-benchmark/mteb/commit/b65f0ec4d58c8fa862543f4aee0d8c961a3052d8))

* Update tasks &amp; benchmarks tables ([`3fd7bec`](https://github.com/embeddings-benchmark/mteb/commit/3fd7bec70a5b874a4a405832e8fb6ff67384bd04))

* Update tasks &amp; benchmarks tables ([`9e5ce29`](https://github.com/embeddings-benchmark/mteb/commit/9e5ce2909b21e89f2cc9b846a13453395876e985))

* Update tasks &amp; benchmarks tables ([`2942557`](https://github.com/embeddings-benchmark/mteb/commit/294255724be741485c5ccd64b558c15305153798))

* Update tasks &amp; benchmarks tables ([`046ecf0`](https://github.com/embeddings-benchmark/mteb/commit/046ecf0fdaf4e2bb42481cfcfd67b3d57a747877))

* Update tasks &amp; benchmarks tables ([`90cd48a`](https://github.com/embeddings-benchmark/mteb/commit/90cd48a1e915c468fa6c24ec31aef935aee938dd))

* Update tasks &amp; benchmarks tables ([`0eec584`](https://github.com/embeddings-benchmark/mteb/commit/0eec584d089d1dddc9c643f79ab9a42155ca0c74))

* Update tasks &amp; benchmarks tables ([`bd9bb89`](https://github.com/embeddings-benchmark/mteb/commit/bd9bb89144820fa9b279899d7b2d053ada9aee89))

* Update tasks &amp; benchmarks tables ([`607eb6f`](https://github.com/embeddings-benchmark/mteb/commit/607eb6f950ef02068d18de9b7cdccbeff66d948b))

* Update tasks &amp; benchmarks tables ([`f4d72bc`](https://github.com/embeddings-benchmark/mteb/commit/f4d72bc35f357b256c276ba58db76a23699fa7bd))

* Update tasks &amp; benchmarks tables ([`f17902a`](https://github.com/embeddings-benchmark/mteb/commit/f17902a7e2ba1aef127399b2b822c8e0e7e5e216))

* Update tasks &amp; benchmarks tables ([`296c1ee`](https://github.com/embeddings-benchmark/mteb/commit/296c1eecf6b2ae39967c05205a08012084ef8e09))

* Update tasks &amp; benchmarks tables ([`edbf218`](https://github.com/embeddings-benchmark/mteb/commit/edbf21803e47e1c4e8648abfb6bbdf1af225a7f8))

* Update tasks &amp; benchmarks tables ([`edb9c78`](https://github.com/embeddings-benchmark/mteb/commit/edb9c7832012f68f54b856261a45873a4eed92c1))

* Update tasks &amp; benchmarks tables ([`72eea70`](https://github.com/embeddings-benchmark/mteb/commit/72eea705ae7fbd925346cb1ced0f7747fcc14740))

* Update tasks &amp; benchmarks tables ([`c54e88f`](https://github.com/embeddings-benchmark/mteb/commit/c54e88f7d3a212ec4a0884fd1a5136af49426d1a))

* Update tasks &amp; benchmarks tables ([`3703f11`](https://github.com/embeddings-benchmark/mteb/commit/3703f1132504c4b4315a01f655b58206420dec8c))

* Update tasks &amp; benchmarks tables ([`5b34e6a`](https://github.com/embeddings-benchmark/mteb/commit/5b34e6adb3975c26d6a98019203aa40a16b99b02))

* Update tasks &amp; benchmarks tables ([`0665cd2`](https://github.com/embeddings-benchmark/mteb/commit/0665cd234ae5bb8b5435debf8c1a602ff5039e1e))

* Update tasks &amp; benchmarks tables ([`8914793`](https://github.com/embeddings-benchmark/mteb/commit/8914793b019d7ea5f1249476e9e4345eafcdfa50))

* Update tasks &amp; benchmarks tables ([`f9b747f`](https://github.com/embeddings-benchmark/mteb/commit/f9b747f5094da214daf95af59e27d2caa8e2acc7))

* Update tasks &amp; benchmarks tables ([`61c611f`](https://github.com/embeddings-benchmark/mteb/commit/61c611fcf937be0e1d546f9cbe543d8366cfe19e))

* Update tasks &amp; benchmarks tables ([`ad232aa`](https://github.com/embeddings-benchmark/mteb/commit/ad232aa929a941db8c7ceddfebcef9ec5de1560d))

* Update tasks &amp; benchmarks tables ([`75db6fb`](https://github.com/embeddings-benchmark/mteb/commit/75db6fb03d87370b8a06acbbf8b3dcb4073f3e32))

* Update tasks &amp; benchmarks tables ([`37f86e2`](https://github.com/embeddings-benchmark/mteb/commit/37f86e28552d414292c778466ceec5a54643c034))

* Update tasks &amp; benchmarks tables ([`7060607`](https://github.com/embeddings-benchmark/mteb/commit/7060607ce7f1a54be7d71325d2d90eade7eda08e))

* Update tasks &amp; benchmarks tables ([`114c273`](https://github.com/embeddings-benchmark/mteb/commit/114c273bf71350b0142bfe3c93070aa076be28a3))

* Update Doubao-1.5-Embedding revision (#2613)

* update seed-embedding

* update seed models

* fix linting and tiktoken problem

* fix tiktoken bug

* fix lint

* update name

* Update mteb/models/seed_models.py

adopt suggestion

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* update logging

* update lint

* update link

* update revision

---------

Co-authored-by: zhangpeitian &lt;zhangpeitian@bytedance.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`bcf532e`](https://github.com/embeddings-benchmark/mteb/commit/bcf532e11c8fea7aa701611d9ddc91b6116e34e9))

* Update tasks &amp; benchmarks tables ([`3a7b723`](https://github.com/embeddings-benchmark/mteb/commit/3a7b7232dc7ccc0b214d0d12417dbeac5166e45d))

* Update tasks &amp; benchmarks tables ([`7bc22e2`](https://github.com/embeddings-benchmark/mteb/commit/7bc22e2fa18d1dba88c01c3807b810fdbba96ae1))

* CI: update benchmark table (#2609)

* update benchmark table

* fix table ([`c020ebb`](https://github.com/embeddings-benchmark/mteb/commit/c020ebbc67a3852407747aad723be98b2768baa9))

* Update Doubao-1.5-Embedding (#2611)

* update seed-embedding

* update seed models

* fix linting and tiktoken problem

* fix tiktoken bug

* fix lint

* update name

* Update mteb/models/seed_models.py

adopt suggestion

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* update logging

* update lint

* update link

---------

Co-authored-by: zhangpeitian &lt;zhangpeitian@bytedance.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`7eba525`](https://github.com/embeddings-benchmark/mteb/commit/7eba5251d68e800111bd3a87eb4ace1be71627ae))

## v1.38.3 (2025-05-01)

### Fix

* fix: Add WebSSL models (#2604)

* add 2 web SSL dino models

* add models from collection and revisions

* update memory_usage_mb and embed dim

* use automodel instead ([`afb72ac`](https://github.com/embeddings-benchmark/mteb/commit/afb72ac1e6d96cb63439b9a7032bf4558934b9f4))

### Unknown

* fix mieb citation (#2606) ([`5a74754`](https://github.com/embeddings-benchmark/mteb/commit/5a74754b79f5c4a4a272707bfc3ea3569ceec4ae))

* update Doubao-1.5-Embedding (#2575)

* update seed-embedding

* update seed models

* fix linting and tiktoken problem

* fix tiktoken bug

* fix lint

* update name

* Update mteb/models/seed_models.py

adopt suggestion

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* update logging

* update lint

---------

Co-authored-by: zhangpeitian &lt;zhangpeitian@bytedance.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`0bda363`](https://github.com/embeddings-benchmark/mteb/commit/0bda3632a1e42fc34542888de7b548b2dccc0c2b))

* Add image only MIEB benchmark to LB left panel (#2596)

* Update benchmarks.py

* make lint

* add to left side bar ([`039a965`](https://github.com/embeddings-benchmark/mteb/commit/039a965c658f2a97eb53232a639d7d5162493844))

* Add MIEB image only benchmark (#2590)

* add vision only bench

* add description

* correct zs task modalities

* specify tasks param ([`7b6d9d7`](https://github.com/embeddings-benchmark/mteb/commit/7b6d9d74d977f7263fc87281200b4b02c653aa77))

* fix codecarbon version (#2587) ([`ca10bac`](https://github.com/embeddings-benchmark/mteb/commit/ca10baceab14b8315856fd3244c87c33c43322f7))

* fix FlagEmbedding package name (#2588) ([`b1606ff`](https://github.com/embeddings-benchmark/mteb/commit/b1606ff614229a0a37e28a46a80f949fdf376847))

## v1.38.2 (2025-04-27)

### Fix

* fix: Add Encodechka benchmark (#2561)

* add tasks

* add benchmark

* fix imports

* update stsb split ([`0737e78`](https://github.com/embeddings-benchmark/mteb/commit/0737e78c0c9a4c18fb604613c32f78791ad44156))

### Unknown

* Update tasks table ([`4f23d62`](https://github.com/embeddings-benchmark/mteb/commit/4f23d62d284b2ef568e20e2ad332ceb9ce861c95))

* Remove the comments from ImageEncoder (#2579) ([`951bae3`](https://github.com/embeddings-benchmark/mteb/commit/951bae38dfd7f84d619cc6e8c17aa5566f52034c))

* move icon &amp; name to benchmark dataclass (#2573) ([`fa5f034`](https://github.com/embeddings-benchmark/mteb/commit/fa5f0342388aadce77fc552366edd85cee88e445))

* Update tasks table ([`e03333f`](https://github.com/embeddings-benchmark/mteb/commit/e03333f4c4ffef772d2de2e4cd01b476fb7bc901))

* Add missing annotations (#2498) ([`235906b`](https://github.com/embeddings-benchmark/mteb/commit/235906b111b110ac4ccf6bdf616c368f49384bdd))

* Docs: Improve MIEB docs (#2569) ([`adfd92a`](https://github.com/embeddings-benchmark/mteb/commit/adfd92a3a4d4181b186af5025eb39ae922fe5e3e))

* Add  ModelMeta for CodeSearch-ModernBERT-Crow-Plus (#2570)

* Add files via upload

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update overview.py

* Update shuu_model.py

* Update shuu_model.py

* Update shuu_model.py

* Update mteb/models/shuu_model.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`713635a`](https://github.com/embeddings-benchmark/mteb/commit/713635a4d8b175252e0cc7fbece57d5928076195))

* Update tasks table ([`e56aab5`](https://github.com/embeddings-benchmark/mteb/commit/e56aab5e699dca0d8c254fa9cf144aa7c4b52c33))

* Backfill task metadata for metadata for GermanDPR and GermanQuAD (#2566)

* Add metadata for GermanDPR and GermanQuAD

* PR improvements ([`c0d3ca0`](https://github.com/embeddings-benchmark/mteb/commit/c0d3ca0525ec03e731b1ec59848bc8cb042fb809))

* Add relle (#2564)

* Add relle
* defined model metadata for relle

* Add mteb/models/relle_models.py

* Update mteb/models/relle_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* lint after commit

run after &#34;make lint&#34;

* Add into model_modules

Add model into model_modules and lint check

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`f11ac2a`](https://github.com/embeddings-benchmark/mteb/commit/f11ac2aa507355ba21636999f20cc034f857204d))

* fix frida datasets (#2565) ([`d475c7e`](https://github.com/embeddings-benchmark/mteb/commit/d475c7ec4ed27777f62805f2ec4605b55d1c7f1d))

## v1.38.1 (2025-04-20)

### Fix

* fix: jasper models embeddings having nan values (#2481) ([`f7072d5`](https://github.com/embeddings-benchmark/mteb/commit/f7072d51f1cbfbf4c4accdaabc2b6a85cfbf3a51))

### Unknown

* Fix leaderboard entry for BuiltBench (#2563)

Fix leaderboard entry for BuiltBench (#2562)

Co-authored-by: Mehrzad Shahin-Moghadam &lt;mehr@Mehrzads-MacBook-Pro.local&gt; ([`4b755a3`](https://github.com/embeddings-benchmark/mteb/commit/4b755a331e5c1fdb9f1bf7e0a127e9ab771eba00))

* add USER2 (#2560)

* add user2

* add training code

* update prompts ([`5ed6773`](https://github.com/embeddings-benchmark/mteb/commit/5ed677368534729c4a46ab92d4f09b8a802d0c52))

## v1.38.0 (2025-04-17)

### Feature

* feat: UI Overhaul (#2549)

* Bumped gradio version to latest

* Added new Gradio table functionality to leaderboard

* Removed search bar

* Changed color scheme in plot to match the table

* Added new benchmark selector in sidebar

* Changed not activated button type to secondary

* Short-circuited callbacks that are based on language selection

* Re-added column width calculation since it got messed up

* Commented out gradient for per-task table as it slowed things down substantially

* Styling and layout updates

* Adjusted comments according to reviews

* Converted all print statements to logger.debug

* Removed pydantic version fix

* Ran linting

* Remove commented out code

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Moved English,v1 to Legacy section

* Closed the benchmark sharing accordion by default

* Adjusted markdown blocks according to suggestions

* Ran linter

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`0ab947b`](https://github.com/embeddings-benchmark/mteb/commit/0ab947bd5f73dc4fdae3f672d5dd599b6b6598b3))

### Unknown

* fix unintentional working of filters on leaderboard (#2535)

* fix unintentional working of filters on leaderboard

* address comments

* make lint

* address comments

* rollback unnecessary changes ([`50d7e9e`](https://github.com/embeddings-benchmark/mteb/commit/50d7e9e139729d0373030884255bc78be4ed17b0))

* fix e5_R_mistral_7b (#2490)

* fix e5_R_mistral_7b

* change wrapper

* address comments

* Added kwargs for pad_token

* correct lang format

* address comments

* add revision

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`4a6e539`](https://github.com/embeddings-benchmark/mteb/commit/4a6e5392605331e3582a5dda3906a6ea4639c164))

## v1.37.0 (2025-04-16)

### Feature

* feat: Added dataframe utilities to BenchmarkResults (#2542)

* fix: Added dataframe utilities to BenchmarkResults

- Added `get_results_table`. I was considering renaming it to `to_dataframe` to align with `tasks.to_dataframe`. WDYT?
- Added a tests for ModelResults and BenchmarksResults
- Added a few utility functions where needed
- Added docstring throughout ModelResults and BenchmarksResults
- Added todo comment for missing aspects - mostly v2 - but we join_revisions seems like it could use an update before then.

Prerequisite for #2454:

@ayush1298 can I ask you to review this PR as well? I hope this give an idea of what I was hinting at. Sorry that it took a while. I wanted to make sure to get it right.

* refactor to to_dataframe and combine common dependencies

* ibid

* fix revision joining after discussion with @x-tabdeveloping

* remove strict=True for zip() as it is a &gt;3.9 feature

* updated mock cache ([`8fe5742`](https://github.com/embeddings-benchmark/mteb/commit/8fe5742b150abb0bfa40d7c7e208cfcd58669be4))

### Unknown

* fix me5 trainind data config to include xquad dataset (#2552)

* fix: me5 trainind data config to include xquad dataset

* Update mteb/models/e5_models.py

upddate: xquad key name

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* fix: ME5_TRAINING_DATA format

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`1f82b59`](https://github.com/embeddings-benchmark/mteb/commit/1f82b596d79549bbfcf01c884ec7af670e11023a))

* Add xlm_roberta_ua_distilled (#2547)

* defined model metadata for xlm_roberta_ua_distilled

* Update mteb/models/ua_sentence_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* included ua_sentence_models.py in overview.py

* applied linting, added missing fields in ModelMeta

* applied linting

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`3ff993d`](https://github.com/embeddings-benchmark/mteb/commit/3ff993d35d856c4ddf74532b2e156cf6f08852ba))

* Docs: Add MIEB to README (#2550)

Add MIEB to README ([`75d3597`](https://github.com/embeddings-benchmark/mteb/commit/75d359766ece2f307127daca7a520f2605c0895e))

## v1.36.41 (2025-04-15)

### Fix

* fix: Update requirements in JinaWrapper (#2548)

fix: Update package requirements in JinaWrapper for einops and flash_attn ([`caa6e70`](https://github.com/embeddings-benchmark/mteb/commit/caa6e7020ffedf91c4c2de9254ca531d79b8b97d))

### Unknown

* misc: move MMTEB scripts and notebooks to separate repo (#2546)

move mmteb scripts and notebooks to separate repo ([`58769c4`](https://github.com/embeddings-benchmark/mteb/commit/58769c42e73ef4d3752ebd9ff0847f625415d559))

## v1.36.40 (2025-04-15)

### Documentation

* docs: Add MIEB citation in benchmarks (#2544)

Add MIEB citation in benchmarks ([`99c22b5`](https://github.com/embeddings-benchmark/mteb/commit/99c22b5268ae886072203114cac0fbc74bac537b))

### Fix

* fix: CacheWrapper per task (#2467)

* feat: CacheWrapper per task

* refactor logic

* update documentation

---------

Co-authored-by: Florian Rottach &lt;florianrottach@boehringer-ingelheim.com&gt; ([`67881c4`](https://github.com/embeddings-benchmark/mteb/commit/67881c470dc6ee1be4373d11fba2a446d8a09caf))

### Unknown

* Update tasks table ([`b7e447a`](https://github.com/embeddings-benchmark/mteb/commit/b7e447a34efa79b175ae26bd27f5ea3608b28009))

* Add 2 new Vietnamese Retrieval Datasets (#2393)

* [ADD] 2 new Datasets

* [UPDATE] Change bibtext_citation for GreenNodeTableMarkdownRetrieval as TODO

* [UPDATE] Change bibtext_citation for ZacLegalTextRetrieval as TODO ([`f2f37f8`](https://github.com/embeddings-benchmark/mteb/commit/f2f37f86206c7ce810f81de9f86226813746eca7))

## v1.36.39 (2025-04-14)

### Fix

* fix: Update mteb.get_tasks with an exclude_aggregate parameter to exclude aggregate tasks (#2536)

* Implement task.is_aggregate check

* Add `mteb.get_tasks` parameter `include_aggregate` to exclude aggregate tasks if needed

* Update mteb.run with the new `task.is_aggregate` parameter

* Add tests

* Ran linter

* Changed logic to `exclude_aggregate`

* Updated from review comments

* Exclude aggregate by default false in get_tasks ([`c52690d`](https://github.com/embeddings-benchmark/mteb/commit/c52690d565e7acca794f4226a042c81eb731253f))

### Unknown

* Model conan (#2534)

* conan_models

* conan_models

* refactor code

* refactor code

---------

Co-authored-by: shyuli &lt;shyuli@tencent.com&gt; ([`7fcb582`](https://github.com/embeddings-benchmark/mteb/commit/7fcb58254b0ce509b110aa60cb3f45f061cc1fc2))

* [mieb] fix hatefulmemes (#2531)

* fix hatefulmeme

* add to description and use polars instead

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`06da74e`](https://github.com/embeddings-benchmark/mteb/commit/06da74e65bd99df689aa1e1423bf9d9bf93a9f1a))

* [MIEB] Specify only the multilingual AggTask for MIEB-lite (#2539)

specify only the multilingual AggTask ([`fc6ee95`](https://github.com/embeddings-benchmark/mteb/commit/fc6ee95be6700876afe067db3534dde2daf576e6))

* Fix gte-multilingual-base embed_dim (#2526) ([`d7a70fc`](https://github.com/embeddings-benchmark/mteb/commit/d7a70fc960ddc5590630197800b0aa7f422c4825))

* Fix leaderboard version (#2524)

* fix gradio leaderboard run

* update docs ([`d53e585`](https://github.com/embeddings-benchmark/mteb/commit/d53e585f47c46de33d6dd1aee0665651f06dfe7f))

## v1.36.38 (2025-04-08)

### Ci

* ci: refactor TaskMetadata eval langs test (#2501)

* refactor eval langs test

* function returns None

* add hard negaties tasks in _HISTORIC_DATASETS ([`cb2825c`](https://github.com/embeddings-benchmark/mteb/commit/cb2825ce21a6308fe51fbda5384f6d134b1e3cb1))

### Fix

* fix: validate lang code in ModelMeta (#2499) ([`2d15895`](https://github.com/embeddings-benchmark/mteb/commit/2d15895ab4f1ebcf37025c610085058abd5497a5))

### Unknown

* Update pyproject.toml (#2522) ([`efcbbe1`](https://github.com/embeddings-benchmark/mteb/commit/efcbbe1fad72089e84ab1e0e8324707fdbb34ff7))

* [mieb] Memotion preprocessing code made more robust and readable (#2519) ([`2356e49`](https://github.com/embeddings-benchmark/mteb/commit/2356e4938597db42ce02f80e6f5b55769393a1d8))

* Clean up trailing spaces citation (#2518)

* rename folder

* trailing spaces

* missed one ([`2e612e4`](https://github.com/embeddings-benchmark/mteb/commit/2e612e486c7e9f6ce56ab67e6517d5294aea2b8e))

* rename to ImageClustering folder (#2516)

rename folder ([`e7d67c5`](https://github.com/embeddings-benchmark/mteb/commit/e7d67c5bea4607c5f99e17e956a5559ca90ced39))

* Fix typos (#2509) ([`77bef06`](https://github.com/embeddings-benchmark/mteb/commit/77bef06186c365ee6945fe234663439c3c984f77))

* fix transformers version for now (#2504) ([`deb4766`](https://github.com/embeddings-benchmark/mteb/commit/deb4766ff2f71ea38eb093566210a2d68e68c8cc))

* Docs: Update README.md (#2494)

Update README.md ([`315522c`](https://github.com/embeddings-benchmark/mteb/commit/315522c4b6ec57757ac5116727c12f80d56e0c56))

* SpeedTask add deprecated warning (#2493) ([`ef59031`](https://github.com/embeddings-benchmark/mteb/commit/ef59031248c80929134bdabc9a75401bc2a4cbd3))

* typo in model name (#2491) ([`944fed7`](https://github.com/embeddings-benchmark/mteb/commit/944fed72817cc1dbd15728a5f883b325578ac29e))

* [MIEB] align main metrics with leaderboard (#2489)

align main metrics with leaderboard ([`cc3ad3b`](https://github.com/embeddings-benchmark/mteb/commit/cc3ad3b0e5fc92c7219a47c084650374e4afb007))

## v1.36.37 (2025-04-04)

### Fix

* fix: Ignore datasets not available in tests (#2484) ([`8d87f41`](https://github.com/embeddings-benchmark/mteb/commit/8d87f41aab8c4ef0f7d9de1054d2faeec539575b))

### Unknown

* Fix Task Lang Table (#2487)

* Fix Task Lang Table

* added tasks.md

* fix ([`c2cbdac`](https://github.com/embeddings-benchmark/mteb/commit/c2cbdac199323c611c42426b300b9c908822fd3f))

## v1.36.36 (2025-04-04)

### Ci

* ci: Run dataset loading only when pushing to main (#2480)

Update dataset_loading.yml ([`17b53b4`](https://github.com/embeddings-benchmark/mteb/commit/17b53b4f586a62a0b675082fabea09be813e27df))

### Fix

* fix: add prompt to NanoDBPedia (#2486) ([`7d4302e`](https://github.com/embeddings-benchmark/mteb/commit/7d4302e2022e4202f3bcdc6c31cf097d2209b5a7))

### Unknown

* Update tasks table ([`9117c2f`](https://github.com/embeddings-benchmark/mteb/commit/9117c2fe7f6b1969b4db77338b7046b41d7fcae9))

* fix table in tasks.md (#2483) ([`f5881b0`](https://github.com/embeddings-benchmark/mteb/commit/f5881b00e58f5072eb1c9095185e8faddc511cc7))

* [MIEB] rename VisionCentric to VisionCentricQA (#2479)

rename VisionCentric to VisionCentricQA ([`295ad0a`](https://github.com/embeddings-benchmark/mteb/commit/295ad0a0a2b79c16264bff50e127af1bf0cc4d16))

## v1.36.35 (2025-04-02)

### Fix

* fix: E5 instruct now listed as sbert compatible (#2475)

Fixes #1442 ([`6c8c8d2`](https://github.com/embeddings-benchmark/mteb/commit/6c8c8d240d710cdf662d0b8d095d85966affaeb5))

### Unknown

* suppress logging warnings on leaderboard (#2406)

* supress logging warnings

* remove loggers

* return blocks

* rename function

* fix gme models

* add server name

* update after merge

* fix ruff ([`e837b09`](https://github.com/embeddings-benchmark/mteb/commit/e837b093e256a105ba13aa77bd0706ba364a10c7))

## v1.36.34 (2025-04-01)

### Ci

* ci: cache `~/.cache/huggingface` (#2464)

ci: cache ~/.cache/huggingface

Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt; ([`d11934f`](https://github.com/embeddings-benchmark/mteb/commit/d11934fd03655011527045afca02adacac0a8d0d))

### Fix

* fix: add nb_sbert model (#2339)

* add_nb_sbert_model

* Update nb_sbert.py

added n_parameters and release_date

* Update mteb/models/nb_sbert.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update nb_sbert.py

fix: make lint

* added nb_sbert to overview.py + ran make lint

* Update nb_sbert.py

Fix error: Input should be a valid date or datetime, month value is outside expected range of 1-12

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`c617598`](https://github.com/embeddings-benchmark/mteb/commit/c61759807fa8b32d5969598c127139ff38f96062))

* fix: Adds family of NeuML/pubmedbert-base-embedding models (#2443)

* feat: added pubmedbert model2vec models

* fix: attribute model_name

* fix: fixed commit hash for pubmed_bert model2vec models

* fix: changes requested in PR 2443 ([`f293d8b`](https://github.com/embeddings-benchmark/mteb/commit/f293d8bf65470b0e431c39f18082fe3845fe233e))

### Unknown

* Update tasks table ([`5b567bf`](https://github.com/embeddings-benchmark/mteb/commit/5b567bf9d39e5ebffb2d947849b1eee3a80a446a))

* [MIEB] &#34;capability measured&#34;-Abstask 1-1 matching refactor [3/3]: reimplement ImageCoDe (#2468)

* reimplement ImageCoDe with ImageTextPairClassification

* add missing stats file ([`8799126`](https://github.com/embeddings-benchmark/mteb/commit/8799126c8e2f294326e1840832159aea980327ef))

* leaderboard fix (#2456) ([`35a8a5b`](https://github.com/embeddings-benchmark/mteb/commit/35a8a5b3ae2606bc3a64ab50319a877f497f888d))

* add ops_moa_models (#2439)

* add ops_moa_models

* add custom implementations

* Simplify custom implementation and format the code

* support SentenceTransformers

* add training datasets

* Update mteb/models/ops_moa_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* update training_datasets

---------

Co-authored-by: kunka.xgw &lt;kunka.xgw@taobao.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`61d3c6c`](https://github.com/embeddings-benchmark/mteb/commit/61d3c6c29ddafb633c1ab112d88a8a4c4ce893f8))

* Add Background Gradients in Summary and Task Table (#2392)

* Add Background Gradients in Summary and Task Table

* Remove warnings and add light green cmap

* Address comments

* Separate styling function

* address comments

* added comments ([`5af5547`](https://github.com/embeddings-benchmark/mteb/commit/5af55479ea10f27ee3e10a4a5be5bbaec49f60e7))

* Feat/searchmap preview (#2420)

* Added meta information about SearchMap_Preview model to the model_dir

* Added meta information about SearchMap_Preview model to the model_dir

* updated revision name

* Device loading and cuda cache cleaning step left out

* removed task instructions since it&#39;s not necessary

* changed sentence transformer loader to mteb default loader and passed instructions s model prompts

* Included searchmap to the models overview page

* Included searchmap to the models overview page

* added meta data information about where model was adpated from

* Update mteb/models/searchmap_models.py

* fix lint

* lint

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`43adb0c`](https://github.com/embeddings-benchmark/mteb/commit/43adb0cd2a0cc611edc85c11df120629a7963de1))

* Error while evaluating MIRACLRetrievalHardNegatives: &#39;trust_remote_code&#39; (#2445)

Fixes #2444 ([`dadafbe`](https://github.com/embeddings-benchmark/mteb/commit/dadafbe50a214ef099b15550746f61927323093d))

* Update tasks table ([`19dc625`](https://github.com/embeddings-benchmark/mteb/commit/19dc625583a0206ae68779830cebb7390158bfcb))

* [MIEB] &#34;capability measured&#34;-Abstask 1-1 matching refactor [2/3]: reimplement r-Oxford and r-Paris (#2442)

* MutipleChoiceEvaluationMixin; reimplement r-Oxford and r-Paris; rerun stats

* modify benchmark list

* fix citation ([`65446e5`](https://github.com/embeddings-benchmark/mteb/commit/65446e5d9b9580021ae52bdb25480ee1438191dc))

## v1.36.33 (2025-03-26)

### Documentation

* docs: typos; Standardize spacing; Chronological order (#2436)

* Fix typos; add chrono order

* Fix spacing ([`0db0a20`](https://github.com/embeddings-benchmark/mteb/commit/0db0a20d48d422d3f3db25d50b73ada2525ccc19))

### Fix

* fix: Add model specific dependencies in pyproject.toml (#2424)

* Add model specific dependencies in pyproject.toml

* Update documentation ([`8a024be`](https://github.com/embeddings-benchmark/mteb/commit/8a024be2e69a4f42c8cc281a5af21e08d69ff0ff))

### Unknown

* Added Memory Usage column on leaderboard (#2428) ([`d3eab6f`](https://github.com/embeddings-benchmark/mteb/commit/d3eab6f1f483e4e5b9e1e871289397c8e114f713))

* add richinfoai models (#2427)

* add richinfoai models

add richinfoai models

* format codes by linter

format codes by linter ([`98ab0ef`](https://github.com/embeddings-benchmark/mteb/commit/98ab0ef357a1233441b13f4137f3a7a9d5c28cc4))

* Update speed dependencies with new setuptools release (#2429) ([`731c4fc`](https://github.com/embeddings-benchmark/mteb/commit/731c4fccf82f5841d30a50210b6945255d5dea58))

* Update tasks table ([`55c542b`](https://github.com/embeddings-benchmark/mteb/commit/55c542be5cd577159a74c0172e470daf16821d25))

* add __init__.py Clustering &gt; kor folder,  And   edit __init__.py in Clustering folder (#2422)

* add PatentFnBClustering.py

* do make lint and revise

* rollback Makefile

* Update mteb/tasks/Clustering/kor/PatentFnBClustering.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* klue_mrc_domain

* make lint

* klue_modified_clustering_dataset

* clustering &amp; kor folder add __init.py

* clustering &amp; kor folder add __init__.py

* task.py roll-back

* correct text_creation to sample_creation &amp; delete form in MetaData

* correct task_subtype in TaskMetaData

* delete space

* edit metadata

* edit task_subtypes

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`39cee62`](https://github.com/embeddings-benchmark/mteb/commit/39cee62dc20c60f78143e261aae0a03784b06b17))

* HOTFIX: pin setuptools (#2423)

* pin setuptools

* pin setuptools

* pin setuptools in makefile

* try ci

* fix ci

* remove speed from installs ([`071741d`](https://github.com/embeddings-benchmark/mteb/commit/071741d201643f5e2537cb4ac20545032914d5f4))

## v1.36.32 (2025-03-23)

### Fix

* fix: Add VDR Multilingual Dataset (#2408)

* Added VDR Multilingual Dataset

* address comments

* make lint

* Formated Dataset for retrieval

* Update mteb/tasks/Retrieval/multilingual/VdrMultilingualRetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/tasks/Retrieval/multilingual/VdrMultilingualRetrieval.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* make lint

* corrected date

* fix dataset building

* move to image folder

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`9d9b0b4`](https://github.com/embeddings-benchmark/mteb/commit/9d9b0b4329f29351b4c6dc596845205a97893744))

### Unknown

* Update tasks table ([`34edcd5`](https://github.com/embeddings-benchmark/mteb/commit/34edcd552e9d4a055d794cdef5c985701b572892))

## v1.36.31 (2025-03-23)

### Fix

* fix: Add option to remove benchmark from leaderboard (#2417)

fix: Add option to remove leaderboard from leaderboard

fixes #2413

This only removed the benchmark from the leaderboard but keep it in MTEB. ([`e8faf3f`](https://github.com/embeddings-benchmark/mteb/commit/e8faf3fb1c132d17caba4da5b6f570739f005a91))

### Unknown

* Update tasks table ([`065159d`](https://github.com/embeddings-benchmark/mteb/commit/065159d999dacc2dce87beb5f876d2cc9ebcfc13))

* [MIEB] &#34;capability measured&#34;-Abstask 1-1 matching refactor [1/3]: reimplement CV-Bench (#2414)

* refactor CV-Bench

* reimplement CV Bench

* remove abstask/evaluator/tests for Any2TextMultipleChoice

* rerun descriptive stats ([`2833138`](https://github.com/embeddings-benchmark/mteb/commit/283313845fdde1b07b33b280e74b7602bdcf79f3))

## v1.36.30 (2025-03-22)

### Fix

* fix: Add validation to model_name in `ModelMeta` (#2404)

* add test for name validation

* upd docs

* upd cohere name

* fix tests

* fix name for average_word_embeddings_komninos

* fix name for average_word_embeddings_komninos

* fix reranker test

* fix reranker test ([`095851f`](https://github.com/embeddings-benchmark/mteb/commit/095851f66fbb87560fd677b04332b57293c3da61))

### Unknown

* Min torchvision&gt;0.2.1 (#2410)

matching torch&gt;1.0.0 ([`146a893`](https://github.com/embeddings-benchmark/mteb/commit/146a893c3fdcb0833fc1bd625ed567d6c2dba93d))

* remove Arabic_Triplet_Matryoshka_V2.py (#2405) ([`811dbf6`](https://github.com/embeddings-benchmark/mteb/commit/811dbf6e16070731940c84de67ffb5bdbc256dcb))

## v1.36.29 (2025-03-22)

### Fix

* fix: Major updates to docs + make mieb dep optional (#2397)

* fix: renaming Zeroshot -&gt; ZeroShot

Adresses #2078

* fix: minor style changes

Adresses #2078

* fix: Major updates to documentation

This PR does the following:
- This introduced other modalities more clearly in the documentation as well as make it easier to transition to a full on documentation site later.
- added minor code updates due to discovered inconsistencies in docs and code.
- Added the MMTEB citation where applicable
- makes the docs ready to move torchvision to an optional dependency

* Moved VISTA example

* rename 1

* rename 2

* format

* fixed error

* fix: make torchvision optional (#2399)

* fix: make torchvision optional

* format

* add docs

* minor fix

* remove transform from Any2TextMultipleChoiceEvaluator

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* move Running SentenceTransformer model with prompts to usage

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`cae1575`](https://github.com/embeddings-benchmark/mteb/commit/cae157558e984c8dd6472e0b65df786b8cd217ae))

### Unknown

* Update tasks table ([`5b0bd56`](https://github.com/embeddings-benchmark/mteb/commit/5b0bd56748be08be89b569e680b842d27a66b95a))

* Added new dataset and tasks - ClusTREC-covid , clustering of thematic covid related scientific papers  (#2302)

* Clustrec covid new dataset and task

* fix

* fix

* fix

* fix

* fix

* descriptive stats

* change all mentions of clustrec-covidp2p to clustrec-covid

* change &#39; to &#34; ([`e2476d2`](https://github.com/embeddings-benchmark/mteb/commit/e2476d2644e2753cf0671f3b221032a452ab906e))

* Minor style changes (#2396)

* fix: renaming Zeroshot -&gt; ZeroShot

Adresses #2078

* fix: minor style changes

Adresses #2078

* rename 1

* rename 2

* format

* fixed error

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`8be95b7`](https://github.com/embeddings-benchmark/mteb/commit/8be95b78c6de0023d0429bb0af4ffc4b202584cf))

## v1.36.28 (2025-03-20)

### Fix

* fix: Update AmazonPolarityClassification license (#2402)

Update AmazonPolarityClassification.py ([`cf84a79`](https://github.com/embeddings-benchmark/mteb/commit/cf84a79085c1499235c519d5fb913019870c060e))

### Unknown

* fix b1ade name (#2403) ([`a0990cb`](https://github.com/embeddings-benchmark/mteb/commit/a0990cb21dd77583ca5a283c262ce08cfb7759d3))

## v1.36.27 (2025-03-20)

### Fix

* fix: renaming Zeroshot -&gt; ZeroShot (#2395)

* fix: renaming Zeroshot -&gt; ZeroShot

Adresses #2078

* rename 1

* rename 2

* format

* fixed error ([`e7b04a6`](https://github.com/embeddings-benchmark/mteb/commit/e7b04a67c0c4010753c5f4bd0efa0d3e8aa21865))

### Unknown

* Pass task name to all evaluators (#2389)

* pass task name to all tasks

* add test

* fix loader ([`5ebee24`](https://github.com/embeddings-benchmark/mteb/commit/5ebee24e2d4718287c8b485565b3798df2f14c80))

## v1.36.26 (2025-03-18)

### Fix

* fix: Ensure BrightRetrieval is valid to run (#2334)

* fix: Ensure BrightRetrieval is valid to run

Not sure this is the best way to fix this. Let me know if you can find a better fix.

fixes #2327

* fix: convert brightretrieval to two tasks

* fix collecting error ([`cf26764`](https://github.com/embeddings-benchmark/mteb/commit/cf26764f62efbf62c6bdac3bc545a75166de8d85))

### Unknown

* Update tasks table ([`042d6e7`](https://github.com/embeddings-benchmark/mteb/commit/042d6e7fd4c797e461ad78901d27f16de91daf95))

## v1.36.25 (2025-03-17)

### Fix

* fix: pin gradio dependency to ensure leaderboards works (#2387) ([`43b5b69`](https://github.com/embeddings-benchmark/mteb/commit/43b5b69fe85c6ed99e0843fc1bac465391c1d471))

## v1.36.24 (2025-03-17)

### Fix

* fix: b1ade (#2386)

* fix: added b1ade_models.py (#2340)

* added b1ade_models.py

* changing based on requested

* Update mteb/models/b1ade_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* fix: missing import and formatting

---------

Co-authored-by: Shreyas Subramanian &lt;shreyas.f117@gmail.com&gt; ([`60c0a75`](https://github.com/embeddings-benchmark/mteb/commit/60c0a750454a2d920158a6d135ac2950bb8f8412))

## v1.36.23 (2025-03-17)

### Fix

* fix: Reduce logging and Warnings (#2349)

* Reduce logging and Warnings

* make lint

* format license to lowercase

* Address all comments

* Update mteb/leaderboard/app.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`99eb94b`](https://github.com/embeddings-benchmark/mteb/commit/99eb94beed6156fe1efa6af87925de31cbc7077f))

### Unknown

* fix leaderboard (#2385) ([`1bd844f`](https://github.com/embeddings-benchmark/mteb/commit/1bd844f4cf9d7abe01dc0091ca54844cc7562e71))

* Correct -1 to No information in Zero shot (#2381) ([`6fddbb0`](https://github.com/embeddings-benchmark/mteb/commit/6fddbb0bb929c5b42af14e9b7660bd1f49629bc1))

* Update tasks table ([`f31dc32`](https://github.com/embeddings-benchmark/mteb/commit/f31dc32b55ba0d72e8e10f9fab3dad226e137303))

* correct MIEB dataset stats (#2374)

* correct stats

* update Any2AnyMultiChoice qrels stats compute logic

* final correction ([`773211b`](https://github.com/embeddings-benchmark/mteb/commit/773211bb4ece58abc8bb6b1bbbf97bccf35b1559))

* Rename dunzhang and Jasper models to NovaResearch (#2373)

* Rename dunzhang and Jasper models to NovaResearch

* rename model in tests

* correct reference link ([`e34b139`](https://github.com/embeddings-benchmark/mteb/commit/e34b1394a4b5386675313f5177ca9a52213699d5))

* add-Data Korean Clustering dataset (KLUE-modified) (#2283)

* add PatentFnBClustering.py

* do make lint and revise

* rollback Makefile

* Update mteb/tasks/Clustering/kor/PatentFnBClustering.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* klue_mrc_domain

* make lint

* klue_modified_clustering_dataset

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`efeb1c9`](https://github.com/embeddings-benchmark/mteb/commit/efeb1c9b75fa3392cb09efa9ef9baf5a74e21525))

## v1.36.22 (2025-03-13)

### Fix

* fix: Ensure MIRACL pass trust_remote_code (#2346)

* fix: Add `trust_remote_code` to MIRACLRetrieval

* fix: Correctly pass trust remote code to Miracl

* fix ([`75961a0`](https://github.com/embeddings-benchmark/mteb/commit/75961a0d0b47fc2305cf0cdd6bc9dbe54db489e9))

* fix: Correctly pass trust remote code to Miracl ([`d6d8552`](https://github.com/embeddings-benchmark/mteb/commit/d6d8552c664ec530eb4ea87fa4d35d8a57c8bfef))

* fix: Add `trust_remote_code` to MIRACLRetrieval ([`fc329ba`](https://github.com/embeddings-benchmark/mteb/commit/fc329ba869e7773ff70c349a662860a0f068e125))

### Unknown

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`eadc38d`](https://github.com/embeddings-benchmark/mteb/commit/eadc38d27930d1c90f9c1586d0f26c3138405071))

* Merge branch &#39;fix-miracl&#39; ([`7576b57`](https://github.com/embeddings-benchmark/mteb/commit/7576b572921100cd878558a45f98977ad86270a0))

## v1.36.21 (2025-03-13)

### Fix

* fix: Add `trust_remote_code` to MIRACLRetrieval (#2344) ([`2d45653`](https://github.com/embeddings-benchmark/mteb/commit/2d4565308329e64d56db5486302791e1bf59da30))

## v1.36.20 (2025-03-12)

### Fix

* fix: Add WebFAQ bitext mining tasks (#2326)

* Add WebFAQ bitext mining tasks

Signed-off-by: Michael Dinzinger &lt;michael.dinzinger@uni-passau.de&gt;

* Lower number of language pairs in WebFAQBitextMining

Signed-off-by: Michael Dinzinger &lt;michael.dinzinger@uni-passau.de&gt;

---------

Signed-off-by: Michael Dinzinger &lt;michael.dinzinger@uni-passau.de&gt; ([`04cfe4d`](https://github.com/embeddings-benchmark/mteb/commit/04cfe4df42fb60804d61945ddef8bcfbaac9e065))

### Unknown

* Update tasks table ([`d716408`](https://github.com/embeddings-benchmark/mteb/commit/d7164082ec0b88c6186d43a8f4262f8b5c94fab4))

## v1.36.19 (2025-03-11)

### Documentation

* docs: fix typos ([`849efbb`](https://github.com/embeddings-benchmark/mteb/commit/849efbb0126f1471bf1ee15b5c9ab54711ff94e2))

### Fix

* fix: Add ModelMeta rubert-mini-frida, BERTA (#2330)

* Add rubert-mini-frida model meta

* Add BERTA model meta ([`ae83b5f`](https://github.com/embeddings-benchmark/mteb/commit/ae83b5f4b67790f07ba6c5bd9a21f7c893b63292))

## v1.36.18 (2025-03-11)

### Fix

* fix: add annotation models for stella zh (#2277)

* fix: add annotation models for stella zh

Additionally fixed a few annotation errors

* format

* Update mteb/models/stella_models.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`034da4d`](https://github.com/embeddings-benchmark/mteb/commit/034da4d7ebc9a01b549355d1717e734560cc2c13))

## v1.36.17 (2025-03-11)

### Fix

* fix: remove SyntaxWarnings in py312 (#2325)

* fix: Resolve conflicting dependencies

These errors where discovered when trying to install the package using `uv`.

We have a problem with salesforce-lavis, which is not compatible with the current set of dependencies.

* fix: Remove syntax warnings occuring in python 3.12

```
Python 3.12.0 (main, Oct  2 2023, 20:56:14) [Clang 16.0.3 ] on darwin
Type &#34;help&#34;, &#34;copyright&#34;, &#34;credits&#34; or &#34;license&#34; for more information.
&gt;&gt;&gt; import mteb # no syntax warnings
&gt;&gt;&gt;
``` ([`fc176ad`](https://github.com/embeddings-benchmark/mteb/commit/fc176ad3df466ccb4a31a0f9b90aad1de96ca87a))

## v1.36.16 (2025-03-11)

### Fix

* fix: Resolve conflicting dependencies (#2323)

These errors where discovered when trying to install the package using `uv`.

We have a problem with salesforce-lavis, which is not compatible with the current set of dependencies. ([`8f6bf45`](https://github.com/embeddings-benchmark/mteb/commit/8f6bf4558c834cfe2e0bae2bae0b7458d60ae869))

### Unknown

* Added VDR Model (#2290)

* Added VDR Model

* change custom wrapper to SentenceTransformer Wrapper

* remove kwargs and add TODO for Image Modality

* Update mteb/models/vdr_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`7965aad`](https://github.com/embeddings-benchmark/mteb/commit/7965aad10e2fe6270adbf62efbd4119c03fc2277))

## v1.36.15 (2025-03-11)

### Fix

* fix: Update voyage name to include Org. (#2322) ([`746b411`](https://github.com/embeddings-benchmark/mteb/commit/746b411c4d76a6e8596379b01e05fea05179c95b))

## v1.36.14 (2025-03-10)

### Ci

* ci: Add pre-commit hook (#2194)

* make dev life nicer - pre-commit hooks

* add pre-commit to install

* update precommit

* update ruff pre-commit

* lint

* lint

---------

Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt; ([`5b30d84`](https://github.com/embeddings-benchmark/mteb/commit/5b30d84c72c16efa9bf1e9ff5162d401799ab995))

### Fix

* fix: bug in voyage implementation (#2304)

* fix: Fix bug in voyage implementation

&#34;passage&#34; is not a valid input for the voyage API. Remapped to &#34;document&#34;.

* Update mteb/models/voyage_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`6193db1`](https://github.com/embeddings-benchmark/mteb/commit/6193db16cd95232ef742248b8fb374ca108365d7))

### Unknown

* Update tasks table ([`5e3915e`](https://github.com/embeddings-benchmark/mteb/commit/5e3915e8c9e416fbc86d41c6054aceefa77c60cc))

## v1.36.13 (2025-03-09)

### Fix

* fix: Add `ModelMeta` license &amp; custom validations (#2293)

* license validation

* move licenses

* update imports

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`5dce601`](https://github.com/embeddings-benchmark/mteb/commit/5dce60125e56b1719d33f4c4a3e4a35ea7da7bff))

## v1.36.12 (2025-03-09)

### Fix

* fix: Added Filter Modality (#2262)

* Added Filter Modality

* resolve suggestions

* make lint

* make sure test pass

* make lint

* added exclusive_modality_filter and unit tests

* Integrate tests on overview.py

* Update tests/test_overview.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* added task related to image modality

* Update mteb/abstasks/AbsTask.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/abstasks/AbsTask.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* update overview..py

* make lint

* update documentation

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`f840f7d`](https://github.com/embeddings-benchmark/mteb/commit/f840f7d51fce640d37507f2457636db3c535b05a))

## v1.36.11 (2025-03-08)

### Ci

* ci: run test_dataset_on_hf separately (#2201)

* dont run test_dataset_on_hf in every pr

* lint

* Update call pytest test_datasets

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update tests/test_tasks/test_all_abstasks.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* not datasets for test

* run dataset loading test for push or pull_request

* apply feedback

---------

Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`55b9a0e`](https://github.com/embeddings-benchmark/mteb/commit/55b9a0efef5198c37fd39af2b225b721dbba1b2f))

### Fix

* fix: Run remaining MIEB desc stats (#2288)

* run Vidore

* GLDv2

* run the rest

---------

Co-authored-by: Isaac Chung &lt;isaac@hn496lf4f9.lan&gt; ([`e628bce`](https://github.com/embeddings-benchmark/mteb/commit/e628bceb5dd05cf9a71c69cee94cf17b9da64c9c))

### Unknown

* Update tasks table ([`dd7008d`](https://github.com/embeddings-benchmark/mteb/commit/dd7008dc2145838fed26f7128036505b35c93de7))

* update link (#2281) ([`9513f15`](https://github.com/embeddings-benchmark/mteb/commit/9513f1546bb650684847c7354a7aaed0f18c3aa4))

* add gemini-embedding-exp-03-07 (#2279)

* add gemini-embedding-exp-03-07

* remove space for lint

* lint fix ([`fb1b04c`](https://github.com/embeddings-benchmark/mteb/commit/fb1b04c47823e92d6ebb90d638ab75a59b34baeb))

## v1.36.10 (2025-03-07)

### Fix

* fix: Formatting issue in Performance Plot (#2237)

* Formatting issue in Performance Plot

* make lint

* added function for better code readability ([`c456111`](https://github.com/embeddings-benchmark/mteb/commit/c456111b98a1e0e4be13f739ce360404f2a74461))

## v1.36.9 (2025-03-07)

### Documentation

* docs: Update description of EURLex (#2231) ([`3a9d271`](https://github.com/embeddings-benchmark/mteb/commit/3a9d271e9cacfd4c4a3072f09a08630008f44b11))

### Fix

* fix: Add WebFAQ Retrieval dataset (#2236)

* Add WebFAQ Retrieval dataset

Signed-off-by: Michael Dinzinger &lt;michael.dinzinger@uni-passau.de&gt;

* Small change WebFAQRetrieval.py

Signed-off-by: Michael Dinzinger &lt;michael.dinzinger@uni-passau.de&gt;

* Add remaining languages to WebFAQ Retrieval task

Signed-off-by: Michael Dinzinger &lt;michael.dinzinger@uni-passau.de&gt;

* Add descriptive stats

Signed-off-by: Michael Dinzinger &lt;michael.dinzinger@uni-passau.de&gt;

---------

Signed-off-by: Michael Dinzinger &lt;michael.dinzinger@uni-passau.de&gt; ([`9d6e1a9`](https://github.com/embeddings-benchmark/mteb/commit/9d6e1a9ed97d29789f87017f4d51c23cd7aa6213))

### Unknown

* Update tasks table ([`a67c4d0`](https://github.com/embeddings-benchmark/mteb/commit/a67c4d0773483218eecc6014f0c244b7f049389d))

* Add Arabic-Triplet-Matryoshka-V2 model metadata to MTEB (#2270)

* Add Arabic-Triplet-Matryoshka-V2 model metadata to MTEB

* Update memory_usage_mb with correct calculated value

* Update mteb/models/Arabic_Triplet_Matryoshka_V2.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/Arabic_Triplet_Matryoshka_V2.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* remove comments

* added correct memory usage

* Update mteb/models/Arabic_Triplet_Matryoshka_V2.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Apply linter fixes with ruff

* Update mteb/models/Arabic_Triplet_Matryoshka_V2.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/Arabic_Triplet_Matryoshka_V2.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Add Arabic_Triplet_Matryoshka_V2 to overview.py

* Rename model file to ara_models.py and update imports

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`f964829`](https://github.com/embeddings-benchmark/mteb/commit/f96482924076cbe4a195e7bd1850ca79494a7c49))

* Fix `calculate_memory_usage_mb` in adding_a_model.md (#2271) ([`a4456ec`](https://github.com/embeddings-benchmark/mteb/commit/a4456ec1739f021df22b28982dff8a5883cd68d8))

* Update tasks table ([`d8e73e7`](https://github.com/embeddings-benchmark/mteb/commit/d8e73e7d67412f9ce91a6bef36067e4222934470))

* misc: Add rest of the vision centric and compositionality descriptive stats (#2267)

add the rest ([`43cb205`](https://github.com/embeddings-benchmark/mteb/commit/43cb205b67c3658c48422c57f6a9543f42376239))

* Update tasks table ([`e81d109`](https://github.com/embeddings-benchmark/mteb/commit/e81d1097e4cae5fef116764cb57e04343023c21e))

* misc: Run Any2AnyRetrieval descriptive stats (#2223)

* run a few datasets

* add a few more

* run more tasks

* add more datasets

* remove pdb

* remove newline

* add more datasets ([`40b89db`](https://github.com/embeddings-benchmark/mteb/commit/40b89dba5e3e3901098d7fe3da966f56e03f7cfe))

* Remove overlapping legends from radar chart (#2195)

* Remove overlapping legends from radar chart

* ensure graph is not blocked

* Overlapping legend issue of Radar Chart ([`6129282`](https://github.com/embeddings-benchmark/mteb/commit/612928248bb423226bfa54f67ff962f1526d8bae))

* Automatically add similar tasks to training_tasks (#2228)

* refactor dataset checking

* increase timeout

* increase timeout

* remove timeout

* start

* automatically find datasets

* update comment

* fix aggregate task metadata

* fixes

* lint

* rename

* update fetch check ([`7f7d3e8`](https://github.com/embeddings-benchmark/mteb/commit/7f7d3e8e3908f2ffbf6a68d9ca1f71607e3e9d77))

* Add comment to `voyage-3-m-exp` model (#2229)

* remove model size from voyage-3-m-exp model

* Update mteb/models/voyage_models.py

* Update mteb/models/voyage_models.py ([`a87927b`](https://github.com/embeddings-benchmark/mteb/commit/a87927bf6914b516b541dfb66a6da4236629ffe8))

## v1.36.8 (2025-03-03)

### Fix

* fix: Add training data annotations to uderver-bloom models (#2210)

* fix: Add training data annotations to uderver-bloom models

fixes #2193

* fix: add mixedbread

---------

Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt; ([`ee514cb`](https://github.com/embeddings-benchmark/mteb/commit/ee514cb0d491809f12d581d5f2a5a8c596a8269a))

### Unknown

* Update tasks table ([`cc47225`](https://github.com/embeddings-benchmark/mteb/commit/cc472258dfb70bc005a53f8a40b46df296101b39))

* Descriptive stats functions for Any2AnyMC and ImageTextPC (#2197)

* Add Any2AnyMC descriptive stats

* Add descriptive stats function for ImageTextPC

* add descriptive stats examples

* linter

* update multi choice descriptive stats ([`3e991bd`](https://github.com/embeddings-benchmark/mteb/commit/3e991bdf401b669c7f5d57baa5c172857cf3f9e8))

* Change `dataset on HF` test to use official api (#2213)

* refactor dataset checking

* increase timeout

* increase timeout

* remove timeout ([`c5fded2`](https://github.com/embeddings-benchmark/mteb/commit/c5fded2a2a461e8fe53bb8ded25f1523217383a5))

* Add LLM2CLIP (OpenAI variants) (#2222)

* model loading and get_text_embeddings

* add image_emb, fused_emb, and calc probs methods

* add b16 model

* add llm2clip_openai_l_14_224 (not working yet)

* got llm2clip_openai_l_14_224 working

* make lint

* add training sets and allow py files ([`4ee4e7c`](https://github.com/embeddings-benchmark/mteb/commit/4ee4e7c35adcbe151925939a6fc6dbf9a4ed0fed))

## v1.36.7 (2025-03-03)

### Fix

* fix: More training data annotations (#2220)

* Added training  data annotation for bge-gemma

* Added missing annotations for Voyage models

* Added training data for sts-multilingual-mpnet

* Added all mteb datasets to STS-multilingual training data ([`2dd1391`](https://github.com/embeddings-benchmark/mteb/commit/2dd13912b6e5c7c8be93aeb9f7dd873671309961))

## v1.36.6 (2025-03-03)

### Fix

* fix: Fixed leaderboard crash (#2221)

* Fixed leaderboard crash

* Fixed language selection error

* Ran linting ([`761a174`](https://github.com/embeddings-benchmark/mteb/commit/761a17451bdc6cbe5baeca0ccffe38db9f9a1696))

### Unknown

* add labse annotation (#2182)

* add labse annotation

* Update mteb/models/sentence_transformers_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`587892d`](https://github.com/embeddings-benchmark/mteb/commit/587892d1348761dad83c5ba9995038a8b34102d1))

* add similar datasets (#2205)

* add similar datasets

* add nano

* update is filled

* Update mteb/abstasks/TaskMetadata.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`7af37d4`](https://github.com/embeddings-benchmark/mteb/commit/7af37d4773e3fa0855f3f2414904f2d638f88859))

* add base models for e5 (#2183) ([`1c8d715`](https://github.com/embeddings-benchmark/mteb/commit/1c8d715bfca53935f884913297d5a13bd13387ec))

* use &#39;mteb.MTEB&#39; instead of &#39;MTEB&#39; for custom model (#2199) ([`29464ac`](https://github.com/embeddings-benchmark/mteb/commit/29464aca853c14a1eec66b3f553d1dafde8e7218))

* misc: Speed up qrel creation in any2anyretrieval (#2196)

* use numpy vectorized operations instead of row-by-row

* scores are int ([`7345235`](https://github.com/embeddings-benchmark/mteb/commit/7345235214c99fa7117fad477a136e6380a0de40))

## v1.36.5 (2025-02-28)

### Fix

* fix: Alphabetical ordering of tasks in dropdowns (#2191) ([`fee6fc0`](https://github.com/embeddings-benchmark/mteb/commit/fee6fc065508cae0a2d34dae478d5423bcd2e155))

## v1.36.4 (2025-02-28)

### Fix

* fix: update ru models annotation (#2181) ([`3325f7e`](https://github.com/embeddings-benchmark/mteb/commit/3325f7e661089df9e3ff6ca38786e855054f8df7))

## v1.36.3 (2025-02-28)

### Fix

* fix: Added training data for sentence-croissant (#2189) ([`0901cf6`](https://github.com/embeddings-benchmark/mteb/commit/0901cf68b0a7841f350a05a5c87345c557604fd8))

## v1.36.2 (2025-02-28)

### Fix

* fix: Added training data annotation for MMLW models (#2188)

* Added training data annotation for MMLW models

* Added GIST annotations Kenneth missed

* Added Stella en 400m training data&#39; ([`0307102`](https://github.com/embeddings-benchmark/mteb/commit/03071024e4e20845bf73809ad55711f71ef953a9))

* fix: Update MTEB(Scandinavian) to use new DanFEVER (#2180)

This also resolves the missing data in the leaderboard.

Fixes #2172 ([`7daf893`](https://github.com/embeddings-benchmark/mteb/commit/7daf89395b4ee04d5b2adda582e3bd82df0a0d47))

* fix: Added training data annotations to MXBAI (#2185) ([`1b23d4e`](https://github.com/embeddings-benchmark/mteb/commit/1b23d4e73191c54f9caac91ff41cd64835cc2a37))

### Unknown

* Added training data annotation for e5-base-4k (#2186) ([`43d15f1`](https://github.com/embeddings-benchmark/mteb/commit/43d15f1bef747389109648dc5eac5c8f36c7facc))

## v1.36.1 (2025-02-27)

### Fix

* fix: Add more training data annotations (#2178)

* redo to voyage to only training data

* Add training data annotation for Kalm embeddings #2168

* Add correct training data annotations to Stella #2164

* removed fiqa PL as it does not exist

* remove ArxivClusteringS2S.v2 as it does not exist

* Add training data annotation for GIST embedding #2166

* fix max tokens for kalm models #2162

* remove eli 5

* fix: add training data for Bilingual Embeddings

fixes #2167 ([`1959c73`](https://github.com/embeddings-benchmark/mteb/commit/1959c73bb1ce2791e1d171e4c40077079817efc3))

* fix: update training datasets and revision for jina models (#2179)

* feat: update training datasets and revision for jina models

* feat: update training datasets and revision for jina models ([`62b33f2`](https://github.com/embeddings-benchmark/mteb/commit/62b33f26c5550e2b9e9fcd78fe78c4fcb2f698aa))

## v1.36.0 (2025-02-27)

### Feature

* feat: Add MIEB and MIEB-lite as benchmarks (#2035)

* add mieb and mieb-lite to benchmarks

* add CompositionalityEvaluation and DocumentUnderstanding types

* add VisionCentric type

* add missing comma

* split STS17MultilingualVisualSTS and STSBenchmarkMultilingualSTS to eng and non-eng

* use aggregate task instead so we can name the subsets

* shorten names

* fix import

* alternative strategy to avoid using get_task

* follow other aggregate tasks and skip metadata test

* run LB without errors when selecting MIEB(-lite)

* add back the capability as taks type

* typo

* extend description

* split into mieb(eng) and mieb(multilingual)

* remove unneeded files

* remove aggtask additions for test

* edit descriptions based on screenshots

* shorten

* rename to Compositionality and include ImageCoDeT2IMultiChoice

* re-tag missing VisionCentric tasks

* re-tag rparis and roxford as retrieval and include fixes

* re-tag voc2007 as image cls

* make lint

* correct num task types in descriptions

* add one model to models_to_annotate

* add mieb reference models

* update task types

* relabel to multilingual retrieval task type to align with paper

* fix reference and bibtex

* edit task list to match with final list

* add back agg task to reproduce table column in paper

* fix filtering and import

* update tests

* mieb lite add back missing tasks

* fix metadata test

* multi should have all 4 variants

* fix task counts

* lite has 10 task types

* fix visualSTS-17 lang splits

* Aggregate task can now use subsets &amp; eval langs to filter TaskResults

* fix test and mark VisualSTS17 as multilingual

* fix tests

* add agg task running script

* add voyage meta

* fix citations

* capitalize

* add coarse/fine labels

---------

Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt; ([`dea231b`](https://github.com/embeddings-benchmark/mteb/commit/dea231ba7be4343c37f4b56f2df4d67cb005df23))

### Unknown

* Update tasks table ([`dbcbf54`](https://github.com/embeddings-benchmark/mteb/commit/dbcbf540ea3435bc6a2be1558f41e75483cad261))

## v1.35.2 (2025-02-26)

### Fix

* fix: Add Training data annotations (#2173)

* redo to voyage to only training data

* Add training data annotation for Kalm embeddings #2168

* Add correct training data annotations to Stella #2164

* removed fiqa PL as it does not exist

* remove ArxivClusteringS2S.v2 as it does not exist

* Add training data annotation for GIST embedding #2166

* fix max tokens for kalm models #2162

* remove eli 5 ([`6cc1822`](https://github.com/embeddings-benchmark/mteb/commit/6cc18224970de37201a1a9d861a5a5f849bc21c0))

### Unknown

* Update tasks table ([`331cded`](https://github.com/embeddings-benchmark/mteb/commit/331cded71efad7449fae52033d925002178873f9))

* Update FaMTEBRetrieval.py (#2171)

The URL pointed to the settings page instead of the main repo URL. Now it is fixed. ([`8afb78a`](https://github.com/embeddings-benchmark/mteb/commit/8afb78ab2aa702f23db38a4bc29bdd614d50d28d))

## v1.35.1 (2025-02-25)

### Fix

* fix: Incorrect annotations for Mistral-based embedding models (#2157)

Fixes #2155 ([`565e29c`](https://github.com/embeddings-benchmark/mteb/commit/565e29c2f58b0f18f3ee1f0fbffa4f0f8e8e3400))

### Unknown

* Added zero-shot percentages and different filtering scheme (#2153)

* Added zero-shot percentages and different filtering scheme

* Update mteb/model_meta.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`a7dc95a`](https://github.com/embeddings-benchmark/mteb/commit/a7dc95a13a0c4a19b5545c1aa9b2036c29af0dfc))

* Update tasks table ([`ef3f4f0`](https://github.com/embeddings-benchmark/mteb/commit/ef3f4f09860c13b44f0864fd91edc7ff2b2e96f6))

* misc: add Any2AnyRetrievalDescriptiveStatistics (#2139)

add Any2AnyRetrievalDescriptiveStatistics ([`bd2a67c`](https://github.com/embeddings-benchmark/mteb/commit/bd2a67c1be7219761bafcabd70ff789eed31f4f4))

## v1.35.0 (2025-02-24)

### Feature

* feat: Add Qodo-Embed-1-7B model metadata and rename existing model (#2146)

* feat: Add Qodo-Embed-1-7B model metadata and rename existing model

* lint

* fix revision

* update license name

---------

Co-authored-by: Tal Sheffer &lt;tal.s@codium.ai&gt; ([`0e624b2`](https://github.com/embeddings-benchmark/mteb/commit/0e624b26b168c62afc6e0bbc2c89071a6c80b118))

### Unknown

* Fix tokens num in cde models (#2148)

fix tokens ([`8e97d36`](https://github.com/embeddings-benchmark/mteb/commit/8e97d3658d7f25cc652859fe80cf3162b93aa77c))

## v1.34.30 (2025-02-24)

### Fix

* fix: Add annotations for Voyage exp (#2144)

* fix: Update NVIDIA-Embed training data

Added a few missing annotations for nvidia-embed

* fix update annotationf for voyage exp ([`8538e93`](https://github.com/embeddings-benchmark/mteb/commit/8538e9346f1193ec4f8ba6d00ab3c6d8c13d1884))

## v1.34.29 (2025-02-24)

### Fix

* fix: Update NVIDIA-Embed training data (#2143)

Added a few missing annotations for nvidia-embed ([`760fcaf`](https://github.com/embeddings-benchmark/mteb/commit/760fcaf8fdbcd9e01d896330b2cef906066435b1))

### Test

* test: fix dataset availability test (#2141)

This simplified the test and also make it a lot simpler. It also removed about 100 test cases which where all to the same API call. ([`0163342`](https://github.com/embeddings-benchmark/mteb/commit/0163342850c1f479c4bbc2eaceba4b188bcdeb7d))

### Unknown

* misc: merge summary retrieval into bitext mining (#2140)

merge summary retrieval into bitext mining ([`4389501`](https://github.com/embeddings-benchmark/mteb/commit/4389501e55c855988ae1a9da25cfa4b5b0ba0eb4))

* Qodo embed 1 1.5 b (#2137)

* feat: Add Qodo-Embed-1-1.5B model metadata

* fix: Add Qodo models to overview imports

* fix: Add adapted_from field to Qodo model metadata

* Update mteb/models/qodo_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* relint

---------

Co-authored-by: Tal Sheffer &lt;tal.s@codium.ai&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`17a120a`](https://github.com/embeddings-benchmark/mteb/commit/17a120a6a96e0c2c4f918a9a1ad21ddd64b035a4))

* add is_cross_encoder (#1869)

* add is_cross_encoder

* Update mteb/model_meta.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* change value

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`e6eb473`](https://github.com/embeddings-benchmark/mteb/commit/e6eb47395b7eaaec31e13567d855d7af04f80fbb))

## v1.34.28 (2025-02-21)

### Fix

* fix: Add 2 new Static Sentence Transformer models (#2112)

* Add 2 new Static Sentence Transformer models

* Add Tatoeba

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`e7735b2`](https://github.com/embeddings-benchmark/mteb/commit/e7735b25700a1810ac9e62e009e1b54482a30334))

### Unknown

* Update tasks table ([`de2e3e3`](https://github.com/embeddings-benchmark/mteb/commit/de2e3e378b901aa9c76cbc29e9a864cf16d20a2e))

* format ([`950e3ab`](https://github.com/embeddings-benchmark/mteb/commit/950e3abecd6d2f585206d973244300f19573cccc))

## v1.34.27 (2025-02-21)

### Documentation

* docs: Follow google docstring format (#2115)

Fixes #2113 ([`276840f`](https://github.com/embeddings-benchmark/mteb/commit/276840f83ccea159563423f4e8cbfe685603ccba))

### Fix

* fix: update e5 instruct training data (#2129)

update e5 training data ([`44cfa9b`](https://github.com/embeddings-benchmark/mteb/commit/44cfa9b4edc448aaf078b71b919f331633c3917a))

### Unknown

* fix voyage (#2127) ([`b032f98`](https://github.com/embeddings-benchmark/mteb/commit/b032f98263cf53770962e631467066de5c051825))

* fix InstructSentenceTransformer Model name (#2125)

fix params ([`463ca54`](https://github.com/embeddings-benchmark/mteb/commit/463ca54b1ec7e3f87298136eda9fb98000dbff42))

* Update leaderboard_refresh.yaml (#2121) ([`f3e4a9a`](https://github.com/embeddings-benchmark/mteb/commit/f3e4a9a6af10522b00c42c6cb6a17cf13705f464))

## v1.34.26 (2025-02-20)

### Fix

* fix: Upgrade ruff to be gradio compatible (#2111)

* fix: update ruff to be gradio compatible (&gt;=0.9.3)

* format

* fix: upgrade ruff to latests (same as gradio compatible) ([`fb14e0c`](https://github.com/embeddings-benchmark/mteb/commit/fb14e0c652e06d5c730856d9e6ed2769bcd4d223))

## v1.34.25 (2025-02-20)

### Fix

* fix: add training data to BGE-m3-custom-fr (#2110)

This ensure that is it correctly filtered as non-zero-shot ([`cb42f4a`](https://github.com/embeddings-benchmark/mteb/commit/cb42f4a5cfa0a62fe89b6d8da00b5e27c94cb072))

## v1.34.24 (2025-02-20)

### Fix

* fix: Add codesage-large-v2 (#2090)

* Add codesage-large-v2

* Address comments

* Add training dataset

* Fix issues

* Format code

* Remove unnecessary wrapper ([`c052bbb`](https://github.com/embeddings-benchmark/mteb/commit/c052bbb98a826ce2da35859178a2868620afa61d))

## v1.34.23 (2025-02-20)

### Documentation

* docs: Fix typos &amp; refine text (#2102)

* Update app.py

* Fix typos ([`caa0b77`](https://github.com/embeddings-benchmark/mteb/commit/caa0b77e4c21310a64f480cbd710c62810deb134))

### Fix

* fix: add warning about task category conversion (#2108)

add warning about task category conversion ([`6a71485`](https://github.com/embeddings-benchmark/mteb/commit/6a714858e75a2a8fd2ec749c0ebe8866fe234037))

### Unknown

* Update tasks table ([`6e0c87a`](https://github.com/embeddings-benchmark/mteb/commit/6e0c87a4d484124ce81096419cdd0427823bde28))

* misc: Run Zeroshot Classification Descriptive Stats (#2105)

* add most datasets

* add birdsnap and imgnet1k

* add scimmir and sun397

* add uck101 zs ([`56a7b1a`](https://github.com/embeddings-benchmark/mteb/commit/56a7b1ae78709bdfe108da88d65acfc08cdae78d))

* Add model inf-retriever-v1-1.5b (#2106)

Add inf-retriever-v1-1.5b model ([`c69b8c3`](https://github.com/embeddings-benchmark/mteb/commit/c69b8c318390d294f979b1add1c68186ec4b8355))

## v1.34.22 (2025-02-19)

### Fix

* fix: Update links (#2098)

* Fix link

* Fix link ([`6b9f945`](https://github.com/embeddings-benchmark/mteb/commit/6b9f945183ceb01c7bc330fe9cddc132491012fb))

* fix: Updated model annotations for GTE, e5, gritlm, and SFR models (#2101)

Reported with references to paper + qoutes. ([`e0b364b`](https://github.com/embeddings-benchmark/mteb/commit/e0b364b5961e392e7662bfab9bf5ddb460b4943f))

### Unknown

* Update tasks table ([`9ca55f0`](https://github.com/embeddings-benchmark/mteb/commit/9ca55f055943c44cadf654d6b49cc67b88b45d3d))

* misc: Add Any2TextMutipleChoice Descriptive Statistics (#2095)

* add Any2TextMutipleChoiceDescriptiveStatistics

* run on all tasks ([`0371102`](https://github.com/embeddings-benchmark/mteb/commit/0371102c5288cf7246d990db42d3d129aa1af02a))

* Added gtr-t5-base/large/xl/xxl metadata to mteb (#2092)

* Added GTR Models to codebase

* Linted gtr models file.

* Added gtr-base/large/xl/xxl to sentence_transformers_models.py

* Added memory_usage_mb and training_datasets

* Reformatted training dataset names

* Reformatted training dataset names

* Reformatted training dataset names

---------

Co-authored-by: sufen &lt;sufenf@gmail.com&gt; ([`bbfbc45`](https://github.com/embeddings-benchmark/mteb/commit/bbfbc45a168cf7617d10c021d97b5beafde04dc1))

## v1.34.21 (2025-02-18)

### Fix

* fix: Add back task filtering by modalities (#2080)

* add back task filtering by modalities

* add unit test

* check if task modalities is a subset of model modalities and fix tests

* add model_modalities_more_than_task_modalities case ([`3deb7ea`](https://github.com/embeddings-benchmark/mteb/commit/3deb7eaf3d57752f625abf26d561b45ab0c47d98))

### Unknown

* merge gme models (#2089) ([`1b1d327`](https://github.com/embeddings-benchmark/mteb/commit/1b1d327ee62eaea7a2ff44b9f1a16039a77e208d))

## v1.34.20 (2025-02-17)

### Fix

* fix: Missing fixes for #2086 - change MultilingualSentiment split from test to validation in CMTEB (#2088)

* fix: Fixed previous incorrect specification of splits for CMTEB ( MTEB(cmn, v1) )

Fixes #2064

* change MultilingualSentiment split from test to validation in CMTEB ([`6637ff9`](https://github.com/embeddings-benchmark/mteb/commit/6637ff95945b12a61594d09eafe88c82d3dfe4e4))

* fix: Smarter leaderboard caching with cachetools (#2085)

* Added smarter caching to callbacks

* Added cachetools as a dependency

* Ran linting

* Removed debugging print statement

* Bumped Gradio version

* Dependency fixes

* Dependency fixes

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`1006770`](https://github.com/embeddings-benchmark/mteb/commit/1006770c098869d5c9db2e1b3b13c2c190c34a26))

### Unknown

* Remove duplicated string in docstring of TaskMetadata class (#2087)

* Remove duplicated string in docstring of TaskMetadata class

* Remove duplicated dataset field ([`c6e5123`](https://github.com/embeddings-benchmark/mteb/commit/c6e51230a9a65b9e5c25bae54e8d4b2c8095c7f8))

## v1.34.19 (2025-02-17)

### Fix

* fix: Fixed previous incorrect specification of splits for CMTEB ( MTEB(cmn, v1) ) (#2086)

Fixes #2064 ([`12d9b96`](https://github.com/embeddings-benchmark/mteb/commit/12d9b96842d64a159dba39013b2a121e7b436f9b))

## v1.34.18 (2025-02-17)

### Fix

* fix: Freeze model/rank columns in leaderboard (#2044)

* fix: freeze model/rank columns in leaderboard

* freezing zero-shot column

* update min gradio version to 5.16.0 in pyproject.toml

---------

Co-authored-by: Shikhar Shiromani &lt;sshiromani@sshiromani-mlt.client.nvidia.com&gt; ([`07562f4`](https://github.com/embeddings-benchmark/mteb/commit/07562f4d27c8319249c2a28ff9903ad5bf3b4173))

## v1.34.17 (2025-02-17)

### Fix

* fix: Ensure voyage model uses different naming scheme (#2083)

* fix: Added make command for running leaderboard locally

* fix: Ensure voyage models doesn&#39;t re-use the name ([`b14963f`](https://github.com/embeddings-benchmark/mteb/commit/b14963fe6ace93ca9c1e7e066577f7e44250f823))

## v1.34.16 (2025-02-17)

### Fix

* fix: add missing `e5` training datasets (#2065)

add missing training datasets ([`efe2578`](https://github.com/embeddings-benchmark/mteb/commit/efe2578c06265419d6ea613108d156bb4f124f8f))

## v1.34.15 (2025-02-17)

### Ci

* ci: Rerun tests that fail due to networking issues. (#2029)

* fix: rerun tests that fail - Networking

* update tests to use tmp_path

* set versions for dev dependencies

* add pytest options to pyproject.toml

* add rerun json.decoder.JSONDecodeError

* remove JSONDecodeError from pyproject.toml

* add huggingface_hub.errors.HfHubHTTPError

* add huggingface_hub.errors.LocalEntryNotFoundError
https://github.com/embeddings-benchmark/mteb/actions/runs/13298535701/job/37139767443?pr=2044

* FileNotFoundError
https://github.com/embeddings-benchmark/mteb/actions/runs/13302915091/job/37147507251?pr=2029

* add doc to pytest rerun

---------

Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt; ([`efaa990`](https://github.com/embeddings-benchmark/mteb/commit/efaa990b6c7a4916c3349bda4204b2b323927966))

### Fix

* fix: generate metadata (#2063)

* fix: generate metadata

* use logging not print for script

* lint

* add iso639 to dev pyproject

* fix import

* add memory_usage_mb

* set version for iso639

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`26360a0`](https://github.com/embeddings-benchmark/mteb/commit/26360a0b856d97cf8b589218365288bdf55ae791))

### Unknown

* Update tasks table ([`3dbdeb1`](https://github.com/embeddings-benchmark/mteb/commit/3dbdeb1f2664e3502ef68bcc84bd05f8d7c0c342))

* misc: Add all image classification descriptive stats (#2073)

* add most image classification descr stats

* revert changes to encoder

* add stats

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`04c9993`](https://github.com/embeddings-benchmark/mteb/commit/04c9993f3c5478f76253141ec1b0170522d821a2))

* misc: update model names to adjust for adding to results repo (#2074)

* update model names to adjust for adding to results repo

* update model meta script ([`50cc1c9`](https://github.com/embeddings-benchmark/mteb/commit/50cc1c995765dacc820d19f632bdea2f5fbef260))

* Update tasks table ([`dbda3c5`](https://github.com/embeddings-benchmark/mteb/commit/dbda3c59024c4042c2d3e37c61a5e2ee16e4e8ed))

* Add datasets for a benchmark newly introduced for &#34;Engineering&#34; domain (#1911)

* adding clustering tasks (built-bench-clustering S2S &amp; P2P)

* updated built-bench-clustering tasks

* Updated BuiltBenchClustering tasks

* Added &#34;Engineering&#34; as new domain to TaskMetadata.py
* Updated tasks table in docs
* Updated task metadata for BuiltBenchClustering S2S and P2P

* updated metadata for clustering tasks

* Add/update BuiltBench tasks

- Add BuiltBenchRetrieval task
- Add BuiltBenchReranking task
- Update metadata for BuiltBenchClusterinP2P
- Update metadata for BuiltBenchClusterinS2S

* update BuiltBench benchmark

* Update mteb/benchmarks/benchmarks.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/tasks/Clustering/eng/BuiltBenchClusteringS2S.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/tasks/Clustering/eng/BuiltBenchClusteringP2P.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/benchmarks/benchmarks.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Fix formatting via ruff

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`5f4b593`](https://github.com/embeddings-benchmark/mteb/commit/5f4b593416ca8615f128a04844b50eb2dd4c09b9))

## v1.34.14 (2025-02-14)

### Fix

* fix: Updating paper scripts (#1958)

* change reference revisions to align with paper

* Update author list

* Added code for main results table

* updated minor changes

* added external as a &#34;no_revision_available&#34; case

* revert unintended changes

* format ([`c6829d3`](https://github.com/embeddings-benchmark/mteb/commit/c6829d34d7a324bb1f3754d39dd52756921d6a9f))

* fix: Add climate fever v2 (#1873)

* Updated ClimateFEVER dataset with new version

* Adds Fill in the empty metadata.

* Updates the date tuple

* Update class name

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update domains

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update task_subtypes

* Update annotations_creators for the first version

* Update date

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update task subtypes

* Update path

* Update description

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Mina Parham &lt;minaparham@Keatext.local&gt; ([`8604e07`](https://github.com/embeddings-benchmark/mteb/commit/8604e079fd5bc6adac2d2050713dcceaeee5932d))

* fix: Added gte models (#1539)

* fix: Added gte models

* fix: Add mixbai models (#1540)

for #1515 ([`76e05dd`](https://github.com/embeddings-benchmark/mteb/commit/76e05ddb0006620eaf0b8850c5fb37bb74b943e1))

### Unknown

* Update tasks table ([`11ced79`](https://github.com/embeddings-benchmark/mteb/commit/11ced79009a190f02a285743476745ca40d3d987))

* Update tasks table ([`479fa20`](https://github.com/embeddings-benchmark/mteb/commit/479fa206a9d2a1c3401fccd93786ac493769db56))

* misc: Add VisualSTS descriptive stats (#2062)

* add visualsts stats

* add last dataset ([`3cf7b15`](https://github.com/embeddings-benchmark/mteb/commit/3cf7b158047498b516c46197a25c06d0d7004fa1))

* Rename MIEB task classes with duplicated names (#2061)

fix class names ([`bef4046`](https://github.com/embeddings-benchmark/mteb/commit/bef4046b51fc24b3e0648d30307efb2ea0d89163))

* Update tasks table ([`e090330`](https://github.com/embeddings-benchmark/mteb/commit/e090330a6bbcf595d13ff682703cad524007b65e))

* misc: Add ZS and multilabel image classification descriptive stats implementation (#2059)

* add image clustering descirptive stats and run

* finish off last one

* remove script

* add ImageMultilabelClassificationDescriptiveStatistics

* add VOC2007

* add zeroshot and mnist example ([`20df284`](https://github.com/embeddings-benchmark/mteb/commit/20df284af80d1623c0feb546e70a95d858e32dd8))

* Add giga embeddings (#1741)

* add gigaembeddings

* use jasper

* fix name

* create sentence_transformer instruct wrapper

* apply instruction template

* fix jasper

* update meta ([`02d2583`](https://github.com/embeddings-benchmark/mteb/commit/02d258307099782d233c92e7764e490a98c62903))

## v1.34.13 (2025-02-13)

### Fix

* fix: Update embed_dim for  jina models (#2058)

see https://github.com/embeddings-benchmark/results/pull/117 ([`50b8e7b`](https://github.com/embeddings-benchmark/mteb/commit/50b8e7ba10c9a33d2febbc25be8b69893d0b50e6))

### Unknown

* Update tasks table ([`48ef6f4`](https://github.com/embeddings-benchmark/mteb/commit/48ef6f4d2351042b1f5397ea1d2e28f58df2ecc0))

* misc: Add image clustering descriptive stats implementation (#2057)

* add image clustering descirptive stats and run
* finish off last one
* remove script ([`eb32719`](https://github.com/embeddings-benchmark/mteb/commit/eb32719210a05ab33cb0d33319b9aeafb6455a91))

## v1.34.12 (2025-02-13)

### Fix

* fix: Add BRIGHT (long) and fix bug in TaskResult.filter_and_validate() (#2041)

* fix: Add BRIGHT Long

Fixes #1978

* fix: Add BRIGHT(long)

* fix bug in task results

* updated bright

* updated tests for TaskResults ([`3537223`](https://github.com/embeddings-benchmark/mteb/commit/35372238b1f345ecf1422cb967186d8059213d07))

* fix: Add column descriptions to leaderboard (#2039)

* fix: Add column descriptions to leaderboard

* removed existing overlap ([`01fd6fb`](https://github.com/embeddings-benchmark/mteb/commit/01fd6fbb2a7a2f54543a4b2a41ac96fd90cc61b2))

### Unknown

* Update tasks table ([`fadba48`](https://github.com/embeddings-benchmark/mteb/commit/fadba483340e12cd1ccf15acd47b038f844f2b9b))

* misc: Add image classification descriptive stats implementation (#2045)

* add ImageClassificationDescriptiveStatistics

* add MNIST descriptive stats

* use tuples instead

* add label count and update docstrings

* update MNIST example ([`9556f99`](https://github.com/embeddings-benchmark/mteb/commit/9556f99d6a2a12e665aadfe282708a7401de09a0))

## v1.34.11 (2025-02-12)

### Fix

* fix: add Voyage-code-3 (#2040) ([`0b37966`](https://github.com/embeddings-benchmark/mteb/commit/0b3796658768cf4c213f83246112d5dbad9ac341))

## v1.34.10 (2025-02-12)

### Documentation

* docs: Fix README code rendering (#2037)

Fix README code rendering ([`1b04130`](https://github.com/embeddings-benchmark/mteb/commit/1b041303bcf56708a0eb9080db6c67099d3fe3f6))

### Fix

* fix: Add versioning to MTEB benchmarks (#2024)

* Add versioning to MTEB benchmarks

- Following suggestion made in #2001 I added version to MTEB benchmarks
- changed the name of the MTEB(Chinese) to MTEB(cmn, v1). Though we could go for MTEB(Chinese, v1) assuming it is a group (also covering chinese other than mandarin)
- change the name of FaMTEB(fas, beta) to MTEB(fas)
- did a minor formatting of imports due to a circular import error
- moved the Benchmark object out of the file with the benchmarks
  - this is still &gt;1000 lines so we could split it up to &#34;external_benchmarks&#34;, &#34;monolingual_benchmarks&#34;, &#34;domain_specific_benchmarks&#34;, &#34;multilingual_benchmarks&#34;

Fixes #2001

* format

* update tests

* updated for backward compatibility

* ibid

* Update mteb/benchmarks/get_benchmark.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/benchmarks/get_benchmark.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* add missing import

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`65f3407`](https://github.com/embeddings-benchmark/mteb/commit/65f3407e91100b6176052e2e5137f8e88c4eaece))

## v1.34.9 (2025-02-12)

### Fix

* fix: Add SONAR metadata and resolve missing models (#2014)

* Add SONAR metadata

Add SONAR metadat, but without an implementation

Fixes #1981

* fix: Add SONAR metadata

Fixes #1981

* minor edits

* reduced logging serverity of no model_meta.json

* resolve missing models

by ensuring that &#34;Unknown&#34; number of parameters is not filtered.

Should resolve:
#1979
#1976

This seems to have been caused by the restructering of calls on the leaderboard.

* format

* resolve missing models

by ensuring that &#34;Unknown&#34; number of parameters is not filtered.

Should resolve:
#1979
#1976

This seems to have been caused by the `MAX_MODEL_SIZE/MIN_MODEL_SIZE` args.

* format

* format

* added memory usage

* fixed None checks

* consistently refer to tasks as tasks not as datasets

adresses #2026

* minor

* removed used arg

* revert fix of not allowing None in model name ([`92b74b6`](https://github.com/embeddings-benchmark/mteb/commit/92b74b66e41e747eb6251ca87c21ebe071f1d83e))

* fix: Added script for generating and saving a local leaderboard (#2015)

* Added script for making a local leaderboard

* Updated variable

* Update scripts/make_leaderboard.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Resolved comments

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`477bea5`](https://github.com/embeddings-benchmark/mteb/commit/477bea5777f39b429e9a2509f5d1344754648ca0))

### Unknown

* Add SFR-Embedding-Code-2B_R (#2032)

* Add SFR-Embedding-Code-2B_R(#2019)

* make lint

* Added HF repo name for adapted_from parameter

* replace instruct_wrapper ([`0caea67`](https://github.com/embeddings-benchmark/mteb/commit/0caea6704ede3e3f1414912db3450fe04eb38711))

* Add FRIDA model meta (#2031)

* add FRIDA to models

* update prompts ([`f3c71b8`](https://github.com/embeddings-benchmark/mteb/commit/f3c71b8520c926037b7f846c1dbafeb8c1ada055))

## v1.34.8 (2025-02-10)

### Documentation

* docs: update MTEB eng classic benchmark description  (#2006)

* Simplify text

* Clarify

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`7917646`](https://github.com/embeddings-benchmark/mteb/commit/7917646c4a4dc3642f08815f18dde9064daffe39))

* docs: ModelMeta docstrings Typos (#2017)

* Update model_meta.py

* Update mteb/model_meta.py

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`42cf6a0`](https://github.com/embeddings-benchmark/mteb/commit/42cf6a02378663ceafda33d5eec28957805bf596))

* docs: Update adding_a_model.md (#2018)

Update adding_a_model.md ([`e6e21dc`](https://github.com/embeddings-benchmark/mteb/commit/e6e21dcfa56e0af357546a847367f80b8df173c3))

### Fix

* fix: Add Persian-Specific Models (#2021)

* Add new models

* Add training datasets info

---------

Co-authored-by: mehran &lt;mehan.sarmadi16@gmail.com&gt; ([`1588b9a`](https://github.com/embeddings-benchmark/mteb/commit/1588b9ac31b7a84d1e34ef0325c0c10b0b0e8db5))

### Unknown

* Adding sentence-transformer-xxl model to mteb (#2023)

* add sentence transformer xxl

* update datasets

* make lint, and rm public training code

* add all sentence-transformer models ([`f7a81e3`](https://github.com/embeddings-benchmark/mteb/commit/f7a81e3ffa7953edfa1714fa77093aefb0d143f6))

* add model memory usage (#1934)

* add model memory usage

* lint

* update

* calculate memory usage based on file size

* calculate memory usage

* add memory usage for MIEB models

* add last model usage

* add memory_usage_mb to overview

* fix rerank

* update memory usage

* update memory usage ([`e46539a`](https://github.com/embeddings-benchmark/mteb/commit/e46539a1c60bccba5fbffa8b7f6a938d9a6a9712))

## v1.34.7 (2025-02-07)

### Fix

* fix: BEIR-NL metadata mistake (#2010)

Update SCIDOCSNLRetrieval.py ([`b1ac052`](https://github.com/embeddings-benchmark/mteb/commit/b1ac0529cdb41e0052191bf2c8f68c7fb874bc21))

### Unknown

* Update tasks table ([`64f256e`](https://github.com/embeddings-benchmark/mteb/commit/64f256e4f494b8981ad36208d29f04b6d45cd433))

## v1.34.6 (2025-02-07)

### Fix

* fix: Update faq of on leaderboard (#2004)

Simplify ([`4fe4c99`](https://github.com/embeddings-benchmark/mteb/commit/4fe4c998be33aa369af9d13fe71b628d6dc14a84))

## v1.34.5 (2025-02-07)

### Fix

* fix: training data for gritlm (#1932)

* Fix training data

* Fix data

* Fix data

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`d810e4e`](https://github.com/embeddings-benchmark/mteb/commit/d810e4eef72c5bf8e26a91355e240584224a80cb))

### Unknown

* Sort benchmarks and add temp. reference to old leaderboard (#1993)

* fix: Added description and resolved bug in rangeslider

addresses #1987
fixes #1954

* format

* remove certificate

* Sorted benchmarks #1984 ([`3887d83`](https://github.com/embeddings-benchmark/mteb/commit/3887d83d89b46539769ebca24c827a663a388091))

* Add gte-modernbert-base (#1845)

* Update gte_models.py

* Update gte_models train data

* Update gte_models.py

* Update gte_models.py

* Update gte_models.py

* Update gte_models.py

* Update mteb/models/gte_models.py

* Update gte_models.py

* Update gte_models.py

* Update gte_models.py

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`e2c44ed`](https://github.com/embeddings-benchmark/mteb/commit/e2c44edb89772fdd6119488642edc7b25fc6699c))

* CI clean up: Remove MMTEB points check (#1994)

Fixes #1992 ([`fb6bade`](https://github.com/embeddings-benchmark/mteb/commit/fb6badecec31ddcacabdf45d1e38813858b279c4))

## v1.34.4 (2025-02-06)

### Fix

* fix: Added description and resolved bug in rangeslider (#1990)

* fix: Added description and resolved bug in rangeslider

addresses #1987
fixes #1954

* format

* remove certificate ([`8583383`](https://github.com/embeddings-benchmark/mteb/commit/85833830bf1f816af06b68339196c665dda1d1b0))

## v1.34.3 (2025-02-06)

### Fix

* fix: Meta information ru_sentence_models (#1991)

cointegrated/rubert-tiny
sergeyzh/rubert-tiny-turbo
sergeyzh/LaBSE-ru-turbo ([`370b26c`](https://github.com/embeddings-benchmark/mteb/commit/370b26ccec1a0ab8c1029635b4350d6a316bc1a4))

### Unknown

* Fix HagridRetrieval load_dataset &#34;trust_remote_code&#34; (#1989) ([`9618505`](https://github.com/embeddings-benchmark/mteb/commit/9618505d673bc1c530c8f31ff2e0ea461f578726))

* Add mini-gte model (#1906)

* add mini-gte model

* fix formatting

* Update mteb/models/qtack_models.py

add adapted from metadata

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* add datasets to mini-gte

* linting for qtack_models.py

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`1520979`](https://github.com/embeddings-benchmark/mteb/commit/1520979d6248a6fcfb759819848a1563e03595dd))

## v1.34.2 (2025-02-05)

### Fix

* fix: leaderboard and benchmark.py inconstiencies  (#1956)

* fix: fix task types in MIEB

* fix: French leaderboard inconsistencies

fixes #1919

* Fixes  #1917 ([`64c17b6`](https://github.com/embeddings-benchmark/mteb/commit/64c17b6e2ddc8c28f4c08c8ac2e09f5112d71e83))

### Unknown

* Fix: added link for text-embedding-005 and other google models (#1962)

Add reference link for text-embedding-005, text-embedding-004 and text-multilingual-embedding-002 ([`2a8c25a`](https://github.com/embeddings-benchmark/mteb/commit/2a8c25ac6072cb621661c30b7fe48e46afd6b5a3))

* Update tasks table ([`fc6696f`](https://github.com/embeddings-benchmark/mteb/commit/fc6696f17aa2a3119977bd880b429eaf03593ee4))

* Merge MIEB into main ðŸŽ‰ (#1968)

* mieb ZeroshotClassification

* mieb docs

* mieb implementation demo

* model meta; abstask column names; linear probe clf

* model meta; abstask column names; linear probe clf

* fix: update naming as candidate_labels

* Update README.md

* Update README.md

* i2tretrieval

* test load data ignore i2tretrieval

* [MIEB] Add image clustering (#1088)

* make lint
* wip
* add TinyImageNet and run
* type hints
* add accuracy
* lint

* remove unused &amp; fix typos

* T2I Retrieval

* Any2AnyRetrieval

* fix tests from merge

* [MIEB] Add image text pair classification and tests (#1099)

* add ImageTextPairClassification abstask and evaluator

* dataset transform into sequence of images for each sample

* fix processing logic; list of list images compatability

* lint and docstrings

* make lint

* fix failing tests in TaskMetadata

* add tests for mieb

* skip gated repo

---------

Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;

* [MIEB] Add image classification and zero shot classification tasks (#1101)

* fix task metadata

* use overrideable column names

* add CIFAR datasets

* add caltech101 dataset

* add FGVC aircraft dataset

* add food 101 dataset

* add OxfordPets dataset

* remove comments

* correct cifar100 path

* update cifar100 classification results

* cifar zero shot results

* add caltech101 zero shot

* matching CLIP paper implementation

* add aircraft and food zero shot

* add oxford pets zero shot

* [MIEB] Add CIFAR clustering (#1104)

add CIFAR clustering

* [MIEB] Add more image classification and zero shot classification datasets (#1103)

* update category to i2t

* add MNIST linear probe and zero shot

* add FER2013 linear probe and zero shot

* add stanford cars linear probe and zero shot

* add birdsnap linear probe and zero shot

* add eurosat linear probe and zero shot

* lint

* correct eurosat zero shot labels

* add abstask for image multilable and voc2007

* make lint

* [MIEB] Add more image classification and zero shot datasets (#1105)

* add STL10 linear probe and zero shot

* add RESISC45 linear probe and zeor shot

* add Describable textures linear probe and zero shot

* fix spacing lint

* add SUN397 linear probe and zero shot

* correct SUN397 zero shot captions

* add baai bge vista

* add e5-v

* linting

* memory issues for image linear probe &amp; zeroshot

* kknn linear probe arguments

* del comments

* Add some classification and ZeroShot classification tasks (#1107)

* Add Country211 classification task

* Add imagenet1k classification task

* Add UCF101 classification task

* Add PatchCamelyon Classification task

* Add GTSRB classification task

* Add GSTRB Zero Shot Classification

* Add country211 zero shot classification

* Add results for classification tasks

* Add zero shot classification tasks

* Add PatchCamelyon tasks and results

* Add linting

* Add results and fix prompts for zero shot

* Add results

* Add results and linting

* fix dependency &amp; clip mock test

* [MIEB] Add jina clip (#1120)

* add jina clip and mscoco i2t and t2i results

* make lint

* [MIEB] Update `mieb` with the `main` branch and some fixes (#1126)

* fix instruction retrival (#1072)

* fix instruction retrival

* fix test

* add points

* make nested results

* add test

* skip instruction test

* fix instruction passes

* fix unions

* move do_length_ablation

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update points table

* fix: fix bug-causing spelling error in function name of e5-mistral-instruct (#1106)

found bug

* 1.12.85

Automatically generated by python-semantic-release

* fix: MultilingualSentimentClassification (#1109)

* Update points table

* fix: Avoid spaces in dataset name for CQADupstack and ignore speed tasks

* 1.12.86

Automatically generated by python-semantic-release

* fix: Ensure that MLSUMClusteringP2P.v2 use the fast implementation as was intended (#1112)

* fix: Ensure that MLSUMClusteringP2P.v2 use the fast implementation as was intended

* fix: fixed formatting for cli

* docs: improve searchability in the advanced usage documentation

* 1.12.87

Automatically generated by python-semantic-release

* docs: improve searchability in the advanced usage documentation (#1113)

* docs: improve searchability in the advanced usage documentation

* docs: update based on corrections

* fix: export type for `mteb create_meta` (#1114)

* fix export type

* fix dataset version too

* 1.12.88

Automatically generated by python-semantic-release

* fix: Simplify models implementations (#1085)

* Merge

* Adapt

* Simplify

* Check for rev again

* Rmv cmmnt

* Simplify

* simplify

* Rmv comment

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Use logging; change try except; add info

* Lint

* Rmv results

* Update rev

* format

* Simplify models; Allow instructions

* Jobs

* Fix merge

* Format

* Adapt models

* fix: ensure that e5 ignores the NQ

* format

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* 1.12.89

Automatically generated by python-semantic-release

* fix: nomic models using prefix correctly (#1125)

* fix: nomic models using prefix correctly

* chore: remove comment

* fix: handling in case not torch tensor

* Fix typo

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* 1.12.90

Automatically generated by python-semantic-release

* refactor vista model wrapper to contain lib import

* python 38 type hints

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: anpalmak2003 &lt;73543260+anpalmak2003@users.noreply.github.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: Zach Nussbaum &lt;zanussbaum@gmail.com&gt;
Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;

* image memoery issues for all retrieval Abstasks

* Add CLEVR and SciMMIR Image-Text Understanding tasks (#1127)

* Add CLEVER and SciMMIR

* Update metadata

* remove useless comment

* Add linting

* fix typo and tests

* Add CLEVR count task

* add linting

* add fashion200k &amp; fashionIQ test passed

* clip text max seq truncation

* add WebQA, NIGHTS, OVEN

* any2any retrieval chunk encoding

* add nomic vision model; any2any topk bug

* add cv recall

* add InfoSeek; VisualNews

* [MIEB] Add Stanford Cars i2i Retrieval (#1147)

* wip

* add results

* make lint

* change back the order

* [MIEB] Add CUB200 i2i retrieval (#1154)

* add cub200 and results

* add skip_first_result

* skipped self and rerun results

* consolidate i2t and t2i to any2any

* remove abstask and evaluators

* remove references from test

* tu-add berlin sketch retrieval

* XM3600; XFlickr30kCO; mutilingual

* wit multilingual retrieval t2i

* correct multilingual t2i meta

* meta

* add dinov2 model; 4 sizes

* cls evaluator channel bug fix

* add ALIGN model

* add FORBI2IRetrieval

* forb &amp; tuberlin new revision

* disable tokenization parallelism

* add hateful meme retrieval i2tt2i

* add memotion retrieval t2ii2t

* add SciMMIR Retrieval i2tt2i

* ruff update

* Visual STS Abstask&amp;evaluator

* add visual STS17

* add visual STS 12-16

* [mieb] Add blip and blip2 models, and ImageNetDog15Clustering task (#1226)

* wip: start adding BLIP models

* add other blip variants

* wip: add blip2_models.py

* make lint

* wip: implement blip2 wrapper

* feat: add blip2 models, still mismatched names

* fix: remove projections from image and text embeddings

* make lint

* wip: add coco BLIP2

* fix: BLIP2 better zero-shot classification without text_proj and vision_proj

* tidy blip2

* add imagenet-dog-15 dataset

* tidy and lint

* remove unused import

* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator

* add imagenet-10 clustering task

* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering

* [mieb] add 3 compositionality evaluation tasks (#1229)

* linting &amp; update unavailable dataset path

* add aro visual relation&amp;attribution; sugarcrepe

* correct reference

* add SOPI2IRetrieval dataset/task (#1232)

* wip: start adding BLIP models

* add other blip variants

* wip: add blip2_models.py

* make lint

* wip: implement blip2 wrapper

* feat: add blip2 models, still mismatched names

* fix: remove projections from image and text embeddings

* make lint

* wip: add coco BLIP2

* fix: BLIP2 better zero-shot classification without text_proj and vision_proj

* tidy blip2

* add imagenet-dog-15 dataset

* tidy and lint

* remove unused import

* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator

* add imagenet-10 clustering task

* add SOPI2IRetrieval

* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering

* add SOPI2IRetrieval results for clip 32

* add results for clip vit 32/SOPI2IRetrieval

* resolve conflict

* change reference

* Image text pair cls (#1233)

* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets

* fix meta data

* fix validate points

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Add RP2kI2IRetrieval and METI2IRetrieval (#1239)

* wip: start adding BLIP models

* add other blip variants

* wip: add blip2_models.py

* make lint

* wip: implement blip2 wrapper

* feat: add blip2 models, still mismatched names

* fix: remove projections from image and text embeddings

* make lint

* wip: add coco BLIP2

* fix: BLIP2 better zero-shot classification without text_proj and vision_proj

* tidy blip2

* add imagenet-dog-15 dataset

* tidy and lint

* remove unused import

* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator

* add imagenet-10 clustering task

* add SOPI2IRetrieval

* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering

* add SOPI2IRetrieval results for clip 32

* add results for clip vit 32/SOPI2IRetrieval

* resolve conflict

* add RP2kI2IRetrieval dataset

* add RP2kI2IRetrieval results with clip-vit-base-patch32

* update image retrieval __init__.py

* add RP2kI2IRetrieval and METI2IRetrieval

* add METI2IRetreival

* add SOP results

* make lign

* new revision for METI2IRetrieval

* make lint

* reset corpus chunk size

* remove wrong classification import

* add Flickr30k T2I and I2T

* add Flickr30k T2I retriebal

* reduced-size MET revision

* fix: add Flickr30k T2I

* make lint

* [MIEB] Adding DataComp CLIP models (#1283)

* adding data comp CLIP models

* update model and caltech101 results

* make lint

* [mieb] Any2TextMultipleChoice Abstask&amp;Evaluator &amp; four tasks in CV-bench (#1287)

* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets

* fix meta data

* fix validate points

* CV-Bench

* evaluator args comment

* fix

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* [mieb] adding 10 tasks (#1290)

* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets

* add vidore benchmark 10 tasks

* fix reference

* fix old metadata

* fix meta

* [mieb] Adding MOCOv3 models (#1293)

* add moco models first try

* add as a timm model

* add large model results

* make lint

* [mieb] Add more Any2AnyRetrieval datasets (#1285)

* wip: start adding BLIP models

* add other blip variants

* wip: add blip2_models.py

* make lint

* wip: implement blip2 wrapper

* feat: add blip2 models, still mismatched names

* fix: remove projections from image and text embeddings

* make lint

* wip: add coco BLIP2

* fix: BLIP2 better zero-shot classification without text_proj and vision_proj

* tidy blip2

* add imagenet-dog-15 dataset

* tidy and lint

* remove unused import

* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator

* add imagenet-10 clustering task

* add SOPI2IRetrieval

* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering

* add SOPI2IRetrieval results for clip 32

* add results for clip vit 32/SOPI2IRetrieval

* resolve conflict

* add RP2kI2IRetrieval dataset

* add RP2kI2IRetrieval results with clip-vit-base-patch32

* update image retrieval __init__.py

* add RP2kI2IRetrieval and METI2IRetrieval

* add METI2IRetreival

* add SOP results

* make lign

* new revision for METI2IRetrieval

* make lint

* reset corpus chunk size

* remove wrong classification import

* add Flickr30k T2I and I2T

* add Flickr30k T2I retriebal

* reduced-size MET revision

* fix: add Flickr30k T2I

* make lint

* add two landmark datasets and results

* add Sketchy i2i retrieval

* add task metadata

* add BLINKIT2IRetrieval dataset

* add BLINKIT2TRetrieval

* add ImageCoDeT2IRetrieval

* make lint

* add vizwiz retrieval and results

* fix vizwiz duplicate texts

* add new vizwiz results

* add VQA2 results

* add GLD v2 I2T retrieval

* add gld v2 i2i retrieval

* make lint

* remove GLDv2I2IRetrieval

* [mieb] Add any2any multiple choice evaluator and abstask (and one task) (#1301)

* wip: start adding BLIP models

* add other blip variants

* wip: add blip2_models.py

* make lint

* wip: implement blip2 wrapper

* feat: add blip2 models, still mismatched names

* fix: remove projections from image and text embeddings

* make lint

* wip: add coco BLIP2

* fix: BLIP2 better zero-shot classification without text_proj and vision_proj

* tidy blip2

* add imagenet-dog-15 dataset

* tidy and lint

* remove unused import

* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator

* add imagenet-10 clustering task

* add SOPI2IRetrieval

* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering

* add SOPI2IRetrieval results for clip 32

* add results for clip vit 32/SOPI2IRetrieval

* resolve conflict

* add RP2kI2IRetrieval dataset

* add RP2kI2IRetrieval results with clip-vit-base-patch32

* update image retrieval __init__.py

* add RP2kI2IRetrieval and METI2IRetrieval

* add METI2IRetreival

* add SOP results

* make lign

* new revision for METI2IRetrieval

* make lint

* reset corpus chunk size

* remove wrong classification import

* add Flickr30k T2I and I2T

* add Flickr30k T2I retriebal

* reduced-size MET revision

* fix: add Flickr30k T2I

* make lint

* add two landmark datasets and results

* add Sketchy i2i retrieval

* add task metadata

* add BLINKIT2IRetrieval dataset

* add BLINKIT2TRetrieval

* add ImageCoDeT2IRetrieval

* make lint

* add vizwiz retrieval and results

* fix vizwiz duplicate texts

* add new vizwiz results

* add VQA2 results

* add GLD v2 I2T retrieval

* add gld v2 i2i retrieval

* make lint

* add AbsTaskAny2AnyMultiChoice

* make lint

* remove GLDv2I2IRetrieval

* exclude AbsTaskAny2AnyMultiChoice from test_load_data

* [mieb] Fix FORB dataset (#1306)

* correct format

* update results

* add more results

* add more results

* [mieb] run tasks fix (#1302)

* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets

* fix e5v&amp;vista

* task type fix for running tasks

* fix wrong meta

* run mieb script

* script

* lint

* align

* [mieb] split RParisI2IRetrieval and ROxfordI2IRetrieval into easy, medium and hard versions (#1305)

* wip: start adding BLIP models

* add other blip variants

* wip: add blip2_models.py

* make lint

* wip: implement blip2 wrapper

* feat: add blip2 models, still mismatched names

* fix: remove projections from image and text embeddings

* make lint

* wip: add coco BLIP2

* fix: BLIP2 better zero-shot classification without text_proj and vision_proj

* tidy blip2

* add imagenet-dog-15 dataset

* tidy and lint

* remove unused import

* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator

* add imagenet-10 clustering task

* add SOPI2IRetrieval

* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering

* add SOPI2IRetrieval results for clip 32

* add results for clip vit 32/SOPI2IRetrieval

* resolve conflict

* add RP2kI2IRetrieval dataset

* add RP2kI2IRetrieval results with clip-vit-base-patch32

* update image retrieval __init__.py

* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets

* add RP2kI2IRetrieval and METI2IRetrieval

* add METI2IRetreival

* add SOP results

* make lign

* new revision for METI2IRetrieval

* make lint

* reset corpus chunk size

* remove wrong classification import

* add Flickr30k T2I and I2T

* add Flickr30k T2I retriebal

* reduced-size MET revision

* fix: add Flickr30k T2I

* make lint

* add two landmark datasets and results

* add Sketchy i2i retrieval

* add task metadata

* add BLINKIT2IRetrieval dataset

* add BLINKIT2TRetrieval

* add ImageCoDeT2IRetrieval

* make lint

* add vizwiz retrieval and results

* fix vizwiz duplicate texts

* add new vizwiz results

* add VQA2 results

* add GLD v2 I2T retrieval

* add gld v2 i2i retrieval

* make lint

* add AbsTaskAny2AnyMultiChoice

* make lint

* remove GLDv2I2IRetrieval

* exclude AbsTaskAny2AnyMultiChoice from test_load_data

* fix e5v&amp;vista

* remove duplicate corpus entries from BLINKIT2TRetreival dataset

* task type fix for running tasks

* update BLINKIT2T metadata

* fix wrong meta

* run mieb script

* split ROxford, RParis into easy, medium and hard

* make lint

---------

Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;

* [mieb] run tasks small fix (#1310)

* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets

* fix e5v&amp;vista

* task type fix for running tasks

* fix wrong meta

* run mieb script

* script

* lint

* align

* fix

* linting

* [mieb] Add VLM2vec (#1323)

* wip vlm2vec model

* making i2t classification work wit Calteh101

* test vlm2vec on other task types

* move peft into class

* feat: Merge main into MIEB (#1329)

* fix: OpenAI BadRequestError by limiting input dimensions to 2048 elemâ€¦ (#1203)

* fix: OpenAI BadRequestError by limiting input dimensions to 2048 elements (#1201)

Fix OpenAI BadRequestError by limiting input dimensions to 2048 elements

- Ensure the &#39;sentences&#39; list passed to OpenAI API does not exceed 2048 elements
- Reference: OpenAI&#39;s Embedding API documentation on input limits

Co-authored-by: Ali Shiraee &lt;ShiraeA@basfad.basf.net&gt;

* fix ruff formatting

* Added minor test fixes to ensure reproducility across systems

* Ensure that tmp.json is not created within repo when running tests

* format

* fixes path issues

* Rerun CI

---------

Co-authored-by: HSILA &lt;a.shiraee@gmail.com&gt;
Co-authored-by: Ali Shiraee &lt;ShiraeA@basfad.basf.net&gt;

* fix: Ensure STS pearson and spearman does not use the p-value only the correlation (#1207)

Fixes #1206

* 1.14.16

Automatically generated by python-semantic-release

* fix: Normalize licenses including casing, uses of &#34;-&#34; etc.

* fix: Normalize licenses including casing, uses of &#34;-&#34; etc. (#1210)

* fix: Normalize licenses including casing, uses of &#34;-&#34; etc.

* fix tests

* 1.14.17

Automatically generated by python-semantic-release

* fix: Normalize benchmarks no only include task objects and added getter for benchmarks (#1208)

* Normalize benchmarks to only include tasks

- Force benchmarks to only include tasks. This fixes a few bugs where benchmarks can reference a task which is not implemented
- implements `mteb.get_benchmark`, which makes it easier to fetch benchmarks
- Added tests + updated docs

A few outstanding issues:

I would like `mteb.MTEB(benchmark)` to always reproduce the benchmark. Currently this is not possible as MTEB(eng) required the split to be specified. A solution it to allow &#34;eval_splits) to be specified when initializing a task and then pass it on to the `load_data()`. This way we can write the following:

`mteb.get_tasks(tasks=[...], eval_splits=[&#34;test&#34;], ...)`

I would also love the aggregation to be a part of the benchmark (such that it is clear how it should be aggregated). This is especially relevant for MTEB(eng) as it average the CQAD datasets before creating the global average. This way we can also create a result object for the benchmark itself. A complimenting solution for this is to allow nested benchmarks.

* fix error in tests

* format

* Added corrections based on review

* added example and formatted

* 1.14.18

Automatically generated by python-semantic-release

* docs: Fix broken links in docs (#1212)

* Added fixes for broken links in adding_a_dataset and adding_a_model docs.

* Updated link name

* Mismatch of the category of AmazonPolarityClassification (#1220)

Fixes #1219

* Update tasks table

* fix: Ensure that results are returned even when hitting cache (#1215)

Fixes #1122

* 1.14.19

Automatically generated by python-semantic-release

* fix: Allow benchmark to specify eval_splits (#1217)

* fix: Allow benchmark to specify eval_splits

This PR allow for benchmarks to specify specific eval. splits. This allow us to fully specify a benchmark within the benchmark object.

To do this it add the following:
- added eval_splits to the Abstask object, which default to metadata.eval_splits
- use the task.eval_splits unless overwritten in mteb.MTEB.run
- added eval_splits arg to mteb.get_tasks, which filter the tasks based on splits
- updated documentation
  - renamed the &#34;Advanced Usage&#34; to &#34;Usage Documentation&#34; to make it more accicible
- added tests where relevant

* Added correction based on feedback

* 1.14.20

Automatically generated by python-semantic-release

* Update points table

* Update points table

* docs: clarify adding a model (#1222)

* fix: Add RepLLaMA style models (#1223)

* init commit

* working and reproducing

* lint

* update hashes

* warning

* add pyproject

* Update points table

* 1.14.21

Automatically generated by python-semantic-release

* docs: Update points (#1228)

* Fix case

* Fix casing

* Fix case

* Fix case

* Create 971.jsonl

* Update contrib

* Add contributors

* Update points table

* docs: Add MTEB(code) dataset (#1237)

* docs: Add MTEB(code) dataset

* Fix linting

* Update points table

* Update of my affiliation (#1242)

Update points.md

* Add contributor (#1243)

* fix: @mrshu&#39;s name in `points.md` (#1246)

* Use the diacritic character to be inline with Slovak spelling.

Signed-off-by: mr.Shu &lt;mr@shu.io&gt;

* docs: Create benchmarks overview table (#1245)

* fix get_benchmarks method

* add create benchmark script

* make lint

* 1.14.22

Automatically generated by python-semantic-release

* docs: Update affiliation (#1247)

Update points.md

* Added author-information

* Add final author list

* Update points table

* docs: Added coordination point for Jimmy Lee  (#1253)

docs: Added coordination point for Jimmy lee for his work on the coordination of Crystina and Nandan

* Update points table

* fix: Add multilingual Benchmark (#1252)

* fix: Add multilingual bench

* Update mteb/benchmarks/benchmarks.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* format

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* 1.14.23

Automatically generated by python-semantic-release

* docs: Small point changes &amp; more contributors (#1254)

* Update points.md

* Fix format

* Fix attribution

* Update points table

* fix: Downsample large retrieval datasets (#1236)

* most tasks

* lint

* fix other issues

* refactor

* lint and docs

* add polish

* keep case sensitive mteb paths

* add potential points

* fix points

* fix test about metadata

* update tasks and stats

* lint

* Update points table

* Update tasks table

* 1.14.24

Automatically generated by python-semantic-release

* fix: Get meta from CrossEncoder (#1255)

* remove indent after return

* handle cross encoders for model meta

* make lint

* update filename since we now have model name

* 1.14.25

Automatically generated by python-semantic-release

* fix: Add listing all available benchmarks CLI option (#1256)

* add benchmarks.md in README

* add cli option

* add benchmark cli test case

* correct typo

* 1.14.26

Automatically generated by python-semantic-release

* docs: Update affiliation (#1248)

* Update points.md

* Update points.md

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* docs: Update mteb(eng) calculation (#1258)

* Update mteb(eng) calculation

* Fixed citations

* Update MTEB(eng) + MTEB(multilingual)

* feat: leverage SentenceTransformers&#39; query/passage specific prompts (#1221)

* feat: leverage SentenceTransformer models&#39; query/passage specific prompts

* refactor: remove E5Wrapper

fix: wrong e5 revisions

* fix: default prompt_type to None

* fix: e4ce987 revision no longer exists for multilingual-e5-small on the Hub

* fix: keep `prompt_name` in kwargs when model doesn&#39;t have a `prompts` attr

* feat: use Enum for `prompt_type`

* docs: specify how to use prompts with Sentence Transformers

* feat: readd arctic models due to metadata

* 1.15.0

Automatically generated by python-semantic-release

* fix: Add Touche2020v3 and JMTEB (#1262)

* add datasets

* fix metrics

* add Touche2020v3

* fix metadata

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* upd name and supress

* add benchmark class

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update tasks table

* 1.15.1

Automatically generated by python-semantic-release

* fix: Select benchmarks CLI option (#1261)

* add test case for a list of Benchmarks

* add selecting benchmarks CLI option

* typos

* use a separate attribute for benchmarks

* try fixing tests

* should accept string as well

* revert filename change

* use Benchmark and avoid circular import

* fix: derive `results_directory` path from `results_repo` name (#1275)

fix: don&#39;t hardcode repo name when downloading results

* 1.15.2

Automatically generated by python-semantic-release

* fix: sorting benchmark tasks by MTEB, then alphabetical (#1271)

* sorted

* fixed formatting

* efficiency changes

* fix test

* make lint

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* 1.15.3

Automatically generated by python-semantic-release

* ci: Removed 3.8 dependency (#1281)

Changes include:
- remove 3.8 from tests (added 3.11 and 3.12)
- changed other CI to 3.9
- updated lint rules to use 3.8

* Update points table

* fix: Allow Numpy &gt;=2.0 (#1264)

Allow Numpy &gt;=2.0

* 1.15.4

Automatically generated by python-semantic-release

* docs: points for paper writing (#1286)

* Create 1004.jsonl

* Create 1006.jsonl

* Update docs/mmteb/points/1004.jsonl

* Update docs/mmteb/points/1006.jsonl

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update points table

* Update points table

* Update points table

* docs: Fix a link in the README (#1289)

* Fix a link in the README

And fix some typos.

* Update README.md

* Update points table

* fix: Update benchmarks (#1288)

* make benchmark var name uppercase

* update touche to v3

* add MIRACLRetrievalHardNegatives to multilingual

* add mteb(indic)

* add eu benchmark

* 1.15.5

Automatically generated by python-semantic-release

* fix: Allow numpy&lt;2.0.0 (#1291)

* 1.15.6

Automatically generated by python-semantic-release

* fix: Add metadata dict to QBQTC in C-MTEB (#1292)

* fix QBQTC in C-MTEB

* make lint

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* 1.15.7

Automatically generated by python-semantic-release

* fix: Remove non-existent eval split of CMNLI (#1294)

fix eval_splits of CMNLI

* 1.15.8

Automatically generated by python-semantic-release

* Leaderboard (#1235)

* Add leaderboard dev

* Renamed MTEBResults to TaskResult

* Moved model and model meta loading utilities into overview.py

* Added get_model_metas to retrieve filtered metadata for models

* Restructured results object and made it into a class instead of a dict

* Added utilities for filtering models on BenchmarkResults objects

* Added to_table utility function to BenchmarkResults

* Added serialization utilities to BenchmarkResults

* Attempted fixing tests

* Added get_model_metas to __init__

* Added get_benchmarks to __init__ and made it return all benchmarks by default

* Added get_benchmarks to __init__

* Made tasks hashable

* Added task filtering based on task objects on BenchmarkResults

* Added BenchmarkResults to __init__

* Added additional arguments to get_scores on two classes

* Made get_scores smarter on BenchmarkResult

* Added basic multilingual benchmark

* Modified benchmark to be able to easily access results

* Added useful properties and filtering functions to BenchmarkResults

* Added minimal functioning example

* Added smarter table, task-list updating and tried fixing dropdown scrolling

* Made restrict_results into a private function

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Removed old leaderboard scripts

* Hardcoded max and min model size

* Removed redundant utils file

* Ran linting

* added leaderboard dependencies as optional

* Fixed union type error on Python 3.9

* Removed references to Dict in task aggregation

* Fixed name errors in _restrict_task_results

* Fixed _restrict_task_results

* Made hf_subsets={&#39;default&#39;} when the task is monolingual in _restric_task_results

* Task dropdown now gets filtered based on the other criteria

* Ran linting again

* Introduced hotfix for reranking test

* Added BenchmarkResults to __all__ in __init__

* Fixed validate_and_filter_scores method, and replaced _restric_task_results with it

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* feat: Use prompts instead of encode_corpus and encode_queries (#1278)

* add prompt per task type

* fix prompt

* upd test

* lint

* fix test

* fix DeprecatedSummarizationEvaluator

* fix prompts

* add test

* lint

* logger info

* use task type only in model_encode

* lint

* update interface

* add prompt types to docs

* fix test

* mock tasks

* mock task registry

* remove last task_type

* fix tests

* lint

* fix test

* fix

* use wrapper and new prompts

* fix tests

* lint

* fix test

* remove conftest

* validate task to prompt_name

* override model prompts

* task to prompt name optional

* fix tests

* fix models

* remove task_to_prompt_name

* remove from mteb __init__

* update docs

* load existing model prompts if model_prompts is None

* fix

* lint

* change wrapper loader

* add wrapper class

* lint

* add wrapper file

* update logging

* upd logging

* refactor reranking

* lint

* remove prints

* 1.16.0

Automatically generated by python-semantic-release

* fix: Add Retrieval SK Quad dataset for Slovak search evaluation (#1276)

* Add Retrieval SK Quad dataset for Slovak search evaluation

This commit introduces the Retrieval SK Quad dataset, designed to assess Slovak search performance. The dataset is derived from SK-QuAD and includes questions with their best answers categorized post-annotation. This addition provides a significant resource for advancing Slovak language search evaluation and supporting further research and development.

* Add Retrieval SK Quad dataset for Slovak search evaluation 2

Added the requested changes on the SKQuadRetrieval.py file

* add task to init

* add missing task metadata

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Update tasks table

* 1.16.1

Automatically generated by python-semantic-release

* fix: Add Slovak Hate Speech and Offensive Language Dataset (#1274)

* Add Slovak Hate Speech and Offensive Language
Dataset

This commit introduces the Slovak Hate Speech and Offensive Language Database to MTEB. The dataset includes posts from a social network, annotated by humans for hate speech and offensive content. Additionally, the corresponding task has been added to the tasks.md table to reflect this update.

* Add Slovak Hate Speech and Offensive Language Dataset
- Updated __init__.py to include the new SlovakHateSpeechClassification task.
- Modified SlovakHateSpeechClassification.py as per review suggestions to enhance functionality and readability.

* Did requested changes:
- Updated __init__.py to include the new SlovakHateSpeechClassification task.
- Modified SlovakHateSpeechClassification.py as per review suggestions to enhance functionality and readability.

* resolve linting issues by running `make lint`

* Update tasks table

* WIP: Leaderboard UI improvements (#1312)

* Fixed typos in task_results

* Fixed typos in task_results

* Added Tailwind, reorganized layout and fixed scrolling

* Ran linting

* 1.16.2

Automatically generated by python-semantic-release

* fix: remove duplicate multilingual

* 1.16.3

Automatically generated by python-semantic-release

* fix: Re-upload dataset to hub to avoid using script upload (#1322)

* fix dataset upload

* add linting

* Update tasks table

* 1.16.4

Automatically generated by python-semantic-release

* fix: Add implementations of common reranker models (#1309)

* init

* revert

* revert

* add metadata

* lint

* add reqs

* change to float16

* benchmark lint fix

* 1.16.5

Automatically generated by python-semantic-release

* Add multilingual mFollowIR dataset (#1308)

* add mFollowIR

* paper name

* edit warning-&gt;info

* convert to parquet

* lint

* Update tasks table

* Cache the embeddings when requested (#1307)

* add caching

* update test to use close

* change from json to pkl

* fix for window

* cleanup on Windows again

* infer dimension

* move cachewrapper

* add wrapper

* fix

* updates

* fix tests

* fix lint

* lint

* add test

* WIP: Leaderboard UI improvements (#1320)

* Fixed typos in task_results

* Fixed typos in task_results

* Added Tailwind, reorganized layout and fixed scrolling

* Ran linting

* Removed faux benchmark

* Updated layout

* Changed table number format

* Table highlights highest values by making them bold

* Added rank to table, removed organization from model_name

* Added mean rank to table

* Ran linting

* feat: Update metadata for all models (#1316)

* Added model meta

* format

* fixed metadata

* Metadata update for voyage models

* Update mteb/models/cohere_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/cohere_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Added corrections from review

* fix spelling error

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* resolved bugs from pytest --collect-only

* Avoid wrapping all models with the SentenceTransformerWrapper

* Added normalize_embeddings_to_numpy to ensure standard embeddings during evaluations

* fixed moved on correction from @Samoed

* conditionally set .predict method on SentenceTransformerWrapper

---------

Signed-off-by: mr.Shu &lt;mr@shu.io&gt;
Co-authored-by: HSILA &lt;a.shiraee@gmail.com&gt;
Co-authored-by: Ali Shiraee &lt;ShiraeA@basfad.basf.net&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Thomas van Dongen &lt;thomas123@live.nl&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: Orion Weller &lt;31665361+orionw@users.noreply.github.com&gt;
Co-authored-by: John Yang &lt;byjohnyang@gmail.com&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: Marek Å uppa &lt;mrshu@users.noreply.github.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Xa9aX ãƒ„ &lt;mishradiganta91@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel@buad.es&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel.buades@clinia.com&gt;
Co-authored-by: Sathvik Nallamalli &lt;sathviknallamalli@gmail.com&gt;
Co-authored-by: Michael Graczyk &lt;michael@mgraczyk.com&gt;
Co-authored-by: Mariya Hendriksen &lt;35101262+mariyahendriksen@users.noreply.github.com&gt;
Co-authored-by: Santiago Castro &lt;bryant1410@gmail.com&gt;
Co-authored-by: Joey Xia &lt;77958037+ZiyiXia@users.noreply.github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
Co-authored-by: Oliver &lt;oliver.pejic@students.fhnw.ch&gt;

* [mieb] Add OpenCLIP models (#1335)

* add open clip models

* Update __init__.py

* lint

* fix model overview

* update jina clip

---------

Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
Co-authored-by: gowitheflow-1998 &lt;chenghao.xiao@durham.ac.uk&gt;

* [mieb] new version with downsampled train split to 32 per class (#1327)

* new version with downsampled train split to 32 per class

* force load truncated image file

* make lint

* add open clip models

* Update __init__.py

* lint

* fix model overview

* fix ImageCLS undersample; run birdsnap

* make lint

* make lint

---------

Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
Co-authored-by: gowitheflow-1998 &lt;chenghao.xiao@durham.ac.uk&gt;

* [mieb] Fix Jina CLIP (#1349)

fix jina clip v1

* fix: Add clevr license (#1356)

* Add BLINK as multi-choice tasks (#1348)

* wip: start adding BLIP models

* add other blip variants

* wip: add blip2_models.py

* make lint

* wip: implement blip2 wrapper

* feat: add blip2 models, still mismatched names

* fix: remove projections from image and text embeddings

* make lint

* wip: add coco BLIP2

* fix: BLIP2 better zero-shot classification without text_proj and vision_proj

* tidy blip2

* add imagenet-dog-15 dataset

* tidy and lint

* remove unused import

* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator

* add imagenet-10 clustering task

* add SOPI2IRetrieval

* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering

* add SOPI2IRetrieval results for clip 32

* add results for clip vit 32/SOPI2IRetrieval

* resolve conflict

* add RP2kI2IRetrieval dataset

* add RP2kI2IRetrieval results with clip-vit-base-patch32

* update image retrieval __init__.py

* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets

* add RP2kI2IRetrieval and METI2IRetrieval

* add METI2IRetreival

* add SOP results

* make lign

* new revision for METI2IRetrieval

* make lint

* reset corpus chunk size

* remove wrong classification import

* add Flickr30k T2I and I2T

* add Flickr30k T2I retriebal

* reduced-size MET revision

* fix: add Flickr30k T2I

* make lint

* add two landmark datasets and results

* add Sketchy i2i retrieval

* add task metadata

* add BLINKIT2IRetrieval dataset

* add BLINKIT2TRetrieval

* add ImageCoDeT2IRetrieval

* make lint

* add vizwiz retrieval and results

* fix vizwiz duplicate texts

* add new vizwiz results

* add VQA2 results

* add GLD v2 I2T retrieval

* add gld v2 i2i retrieval

* make lint

* add AbsTaskAny2AnyMultiChoice

* make lint

* remove GLDv2I2IRetrieval

* exclude AbsTaskAny2AnyMultiChoice from test_load_data

* fix e5v&amp;vista

* remove duplicate corpus entries from BLINKIT2TRetreival dataset

* task type fix for running tasks

* update BLINKIT2T metadata

* fix wrong meta

* run mieb script

* split ROxford, RParis into easy, medium and hard

* make lint

* add BLINK as multi choice tasks

* fix: license metadata in wrong format

---------

Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;

* [mieb] add Eva CLIP models (#1369)

* add Eva CLIP models

* make lint

* [mieb] add siglip, cohere multimodal &amp; some fixes for final run (#1357)

* fix dataset type error

* fix clustering metrics

* add siglip &amp; cohere

* update mieb run script

* cohere-v import

* fix

* api key name

* [mieb] fixes for final run (#1374)

* e5_v device arg

* dataloader num_workers

* vista doc

* vista doc

* run mieb

* fix

* Update run_vista.md

* [mieb] Fix torch no grad (#1378)

Fix torch no grad

* [mieb] Fix vlm2vec (#1380)

* fix vlm2vec return dtype

* make lint

* [mieb] Remove null entries from corpus of ROxford, RParis (#1371)

* wip: start adding BLIP models

* add other blip variants

* wip: add blip2_models.py

* make lint

* wip: implement blip2 wrapper

* feat: add blip2 models, still mismatched names

* fix: remove projections from image and text embeddings

* make lint

* wip: add coco BLIP2

* fix: BLIP2 better zero-shot classification without text_proj and vision_proj

* tidy blip2

* add imagenet-dog-15 dataset

* tidy and lint

* remove unused import

* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator

* add imagenet-10 clustering task

* add SOPI2IRetrieval

* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering

* add SOPI2IRetrieval results for clip 32

* add results for clip vit 32/SOPI2IRetrieval

* resolve conflict

* add RP2kI2IRetrieval dataset

* add RP2kI2IRetrieval results with clip-vit-base-patch32

* update image retrieval __init__.py

* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets

* add RP2kI2IRetrieval and METI2IRetrieval

* add METI2IRetreival

* add SOP results

* make lign

* new revision for METI2IRetrieval

* make lint

* reset corpus chunk size

* remove wrong classification import

* add Flickr30k T2I and I2T

* add Flickr30k T2I retriebal

* reduced-size MET revision

* fix: add Flickr30k T2I

* make lint

* add two landmark datasets and results

* add Sketchy i2i retrieval

* add task metadata

* add BLINKIT2IRetrieval dataset

* add BLINKIT2TRetrieval

* add ImageCoDeT2IRetrieval

* make lint

* add vizwiz retrieval and results

* fix vizwiz duplicate texts

* add new vizwiz results

* add VQA2 results

* add GLD v2 I2T retrieval

* add gld v2 i2i retrieval

* make lint

* add AbsTaskAny2AnyMultiChoice

* make lint

* remove GLDv2I2IRetrieval

* exclude AbsTaskAny2AnyMultiChoice from test_load_data

* fix e5v&amp;vista

* remove duplicate corpus entries from BLINKIT2TRetreival dataset

* task type fix for running tasks

* update BLINKIT2T metadata

* fix wrong meta

* run mieb script

* split ROxford, RParis into easy, medium and hard

* make lint

* add BLINK as multi choice tasks

* fix: license metadata in wrong format

* remove null examples from corpus of ROxford and RParis

---------

Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;

* [mieb] fixes (#1390)

* Fix torch no grad

* simplify

* make lint

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* [MIEB] Remove non-existent method for blip (#1394)

remove non-existent method for blip

* [mieb] fix ALIGN; update Winoground revision id; update run script (#1391)

* fix align &amp; winoground

* lint

* Convert task category to i2i for tasks that only calls image encode

* update categories should include img cls, clustering, and multi label clf

* no op

* no op

* make lint

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* [mieb] Fix open clip for cv bench count (#1397)

fix shape mismatch

* [mieb] Update subtasks of BLINKIT2TMultiChoice and BLINKIT2IMultiChoice (#1403)

* wip: start adding BLIP models

* add other blip variants

* wip: add blip2_models.py

* make lint

* wip: implement blip2 wrapper

* feat: add blip2 models, still mismatched names

* fix: remove projections from image and text embeddings

* make lint

* wip: add coco BLIP2

* fix: BLIP2 better zero-shot classification without text_proj and vision_proj

* tidy blip2

* add imagenet-dog-15 dataset

* tidy and lint

* remove unused import

* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator

* add imagenet-10 clustering task

* add SOPI2IRetrieval

* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering

* add SOPI2IRetrieval results for clip 32

* add results for clip vit 32/SOPI2IRetrieval

* resolve conflict

* add RP2kI2IRetrieval dataset

* add RP2kI2IRetrieval results with clip-vit-base-patch32

* update image retrieval __init__.py

* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets

* add RP2kI2IRetrieval and METI2IRetrieval

* add METI2IRetreival

* add SOP results

* make lign

* new revision for METI2IRetrieval

* make lint

* reset corpus chunk size

* remove wrong classification import

* add Flickr30k T2I and I2T

* add Flickr30k T2I retriebal

* reduced-size MET revision

* fix: add Flickr30k T2I

* make lint

* add two landmark datasets and results

* add Sketchy i2i retrieval

* add task metadata

* add BLINKIT2IRetrieval dataset

* add BLINKIT2TRetrieval

* add ImageCoDeT2IRetrieval

* make lint

* add vizwiz retrieval and results

* fix vizwiz duplicate texts

* add new vizwiz results

* add VQA2 results

* add GLD v2 I2T retrieval

* add gld v2 i2i retrieval

* make lint

* add AbsTaskAny2AnyMultiChoice

* make lint

* remove GLDv2I2IRetrieval

* exclude AbsTaskAny2AnyMultiChoice from test_load_data

* fix e5v&amp;vista

* remove duplicate corpus entries from BLINKIT2TRetreival dataset

* task type fix for running tasks

* update BLINKIT2T metadata

* fix wrong meta

* run mieb script

* split ROxford, RParis into easy, medium and hard

* make lint

* add BLINK as multi choice tasks

* fix: license metadata in wrong format

* remove null examples from corpus of ROxford and RParis

* fix: add/remove subtasks from BLINKIT2IMultiChoice and BLINKIT2TMultiChoice

* update blink metadata

* add updated BLINK results

---------

Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;

* [mieb] Fix EVA CLIP for CV Bench (#1414)

* unsqueeze after preprocess

* make lint

* [mieb] Add calculate probs for vlm2vec (#1418)

* add method

* make lint

* [mieb] Fix siglip bug &amp; add retrieval datasets (#1424)

* fix siglip

* add edis&amp;gld-v2 i2i

* results

* siglip updated results

* fix siglip non-dataloader tasks

* [mieb] use Logistic Regression classifier for AbsTaskImageMultilabelClassification (#1420)

* use moc-lr classifier

* set n_experiments=5

* run dinov2 and some laion models

* add dinov2-giant results

* [mieb] mieb scripts (siglip rerun &amp; linear probing ablation &amp; params count) (#1429)

* mieb scripts

* lint

* [MIEB] Change Flickr30k to test split (#1449)

* wip: start adding BLIP models

* add other blip variants

* wip: add blip2_models.py

* make lint

* wip: implement blip2 wrapper

* feat: add blip2 models, still mismatched names

* fix: remove projections from image and text embeddings

* make lint

* wip: add coco BLIP2

* fix: BLIP2 better zero-shot classification without text_proj and vision_proj

* tidy blip2

* add imagenet-dog-15 dataset

* tidy and lint

* remove unused import

* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator

* add imagenet-10 clustering task

* add SOPI2IRetrieval

* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering

* add SOPI2IRetrieval results for clip 32

* add results for clip vit 32/SOPI2IRetrieval

* resolve conflict

* add RP2kI2IRetrieval dataset

* add RP2kI2IRetrieval results with clip-vit-base-patch32

* update image retrieval __init__.py

* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets

* add RP2kI2IRetrieval and METI2IRetrieval

* add METI2IRetreival

* add SOP results

* make lign

* new revision for METI2IRetrieval

* make lint

* reset corpus chunk size

* remove wrong classification import

* add Flickr30k T2I and I2T

* add Flickr30k T2I retriebal

* reduced-size MET revision

* fix: add Flickr30k T2I

* make lint

* add two landmark datasets and results

* add Sketchy i2i retrieval

* add task metadata

* add BLINKIT2IRetrieval dataset

* add BLINKIT2TRetrieval

* add ImageCoDeT2IRetrieval

* make lint

* add vizwiz retrieval and results

* fix vizwiz duplicate texts

* add new vizwiz results

* add VQA2 results

* add GLD v2 I2T retrieval

* add gld v2 i2i retrieval

* make lint

* add AbsTaskAny2AnyMultiChoice

* make lint

* remove GLDv2I2IRetrieval

* exclude AbsTaskAny2AnyMultiChoice from test_load_data

* fix e5v&amp;vista

* remove duplicate corpus entries from BLINKIT2TRetreival dataset

* task type fix for running tasks

* update BLINKIT2T metadata

* fix wrong meta

* run mieb script

* split ROxford, RParis into easy, medium and hard

* make lint

* add BLINK as multi choice tasks

* fix: license metadata in wrong format

* remove null examples from corpus of ROxford and RParis

* fix: add/remove subtasks from BLINKIT2IMultiChoice and BLINKIT2TMultiChoice

* update blink metadata

* add updated BLINK results

* merge upstream mieb

* change Flickr30k to test split

* change flickr to test split

---------

Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;

* [mieb] Fix VLM2vec dtype (#1462)

* propagate dtype

* fix fuse embeddings using list of PIL images

* [mieb] run script for missing results (#1472)

* task type fix

* scripts

* [mieb] Fix Moco model on CIFAR10Clustering (#1487)

Fix Moco model on CIFAR10Clustering

* [mieb] Fix Flickr30k I2T and T2I (#1505)

* remake flickr30k it2 and t2i

* add openai clip vit-b32 b16 and jina-clip results

* make lint

* [MIEB] add missing siglip models  (#1533)

* add udpates
* lint errors

* fix typo (#1535)

* add udpates
* lint errors
* fix small typo

* [mieb] Fix numbers of CIRR, Fashion200k, FashionIQ, Flickr30k, MSCOCO data statistics (#1544)

fix numbers

* Discussing a standard for ImageEncoders

* Add Voyage&#39;s multimodal embedding (#1555)

* add voyage multimodal &amp; ran 17 tasks

* lint

* typo

* clean

* [mieb] update script for final re-run (#1576)

* mieb final runs

* lint

* fix: no longer using same query text for all of BLINKIT2TMultiChoice (#1572)

* fix: no longer using same query text for all of BLINKIT2TMultiChoice

* fix: remove blink subtask

* fix: remove subtask from blink it2i

* fix: align BLINK retrieval to multi choice

* add ROxford and RParis I2I multi choice

* add retrieval metrics to multi choice evaluator

* fix: remove wrong negatives from revisiting multichoice datasets

* fix revisiting datasets

* add new results for revisiting multichoice

* [MIEB] Make multimodal models compatible to `task_name` and `prompt_type` (#1583)

* 1. Make `get_xxx_embeddings` follow `encode`.
2. `ImageDataset.transform` could be `None`.

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Fix arguments

* Try to fix tests

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* fix image encoder (#1596)

* format

* fixed tests

* lint

* [mieb] voyage-v: add exponential backoff and other error handling (#1610)

* add voyage multimodal &amp; ran 17 tasks

* lint

* typo

* clean

* exponential backoff tmp

* downsize large images for voyage api call

* voyage error handling

* lint

* add more results

* make tenacity optional

* lint

* log

* [MIEB] Fix `get_fused_emebddings` (#1612)

* Fix fused

* fix vlm2vec

* Fix lint

* [MIEB] Add new multimodal retrieval tasks (#1611)

* Add new tasks
* Fix score type

* [MIEB] Switch to ViDoRe BEIR version (#1607)

* Fix ViDoRe corpus

* fix lint

* ViDoRe beir version

* Extend MIEB test coverage (#1629)

* add one task from each image AbsTask to test grid

* add visual sts to test grid

* [mieb] Task filtering by modality supported by models (#1633)

* fix function signature for moco loader

* filter out tasks by model modalities

* correct conditions

* add model meta to relevant models

* use modalities instead and separate out constants

* [MIEB] Fix VISTA model (#1638)

Fix vista

* Warn (#1639)

* [mieb] model task modalities matching logic (#1640)

fixing task &amp; model modalities matching logic

* [mieb] Use mock abstask classes (#1648)

* rename to downsampled_dataset_transform

* add mock tasks for mieb

* wip getting to 57%

* make lint

* update mock classes to improve coverage

* omit mock tasks from some tests

* [MIEB] Add code for GME models (#1635)

* Add GME

* Fix infoseek prompts

* Merge instructions

* fix: add version check e5-v in mieb (#1723)

* add version check for e5v model

* Update e5_v.py

* make lint

* fix: change comparison to bigger than (#1743)

change comparison to bigger than

* docs: Rework MIEB docs (#1802)

* combine mieb docs and move to main docs folder

* make flow more coherent

* tidy up

* skip AfriSentiLID for now #1785

* fix typo: exclude MIEB mock tests

* update vista doc

* Apply suggestions from code review

---------

Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;

* [mieb] Remove results-mieb folder (#1815)

remove results-mieb folder

* [mieb] fixing lrap computation for multi-label classification (#1834)

multi-label cls lrap computation fix

* [mieb] Merge from main (#1853)

* Update tasks table
* 1.19.0
Automatically generated by python-semantic-release
* fix: Add the_ugly_duckling.txt for speedtask to Python wheel (#1402)
Add the_ugly_duckling.txt for speedtask to Python wheel
* 1.19.1
Automatically generated by python-semantic-release
* fix: Added the necessary trust_remote_code (#1406)
* 1.19.2
Automatically generated by python-semantic-release
* docs: Update recommendation for pushing results (#1401)
fix: Update recommendation for pushing results
* docs: Fix a typo in README (#1430)
Fix typo in readme
* fix: add logging for RetrievalEvaluator NaN values for similarity scores (#1398)
Fixes #1389
* 1.19.3
Automatically generated by python-semantic-release
* fix: make samples_per_label a task attribute (#1419)
make samples_per_label a task attr
* fix: Add Korean AutoRAGRetrieval (#1388)
* feat: add AutoRAG Korean embedding retrieval benchmark
* fix: run --- ðŸ§¹ Running linters ---
ruff format . 			# running ruff formatting
716 files left unchanged
ruff check . --fix  	# running ruff linting
All checks passed!
* fix: add metadata for AutoRAGRetrieval
* change link for markers_bm
* add AutoRAGRetrieval to init.py and update metadata
* add precise metadata
* update metadata: description and license
* delete descriptive_stats in AutoRAGRetrieval.py and run calculate_matadata_metrics.py
* fix: Add missing benchmarks in benchmarks.py (#1431)
Fixes #1423
* Update tasks table
* 1.19.4
Automatically generated by python-semantic-release
* Leaderboard 2.0: added performance x n_parameters plot + more benchmark info (#1437)
* Added elementary speed/performance plot
* Refactored table formatting code
* Bumped Gradio version
* Added more general info to benchmark description markdown block
* Adjusted margin an range on plot
* Made hover information easier to read on plot
* Made range scaling dynamic in plot
* Moved citation next to benchmark description
* Made titles in benchmark info bold
* Leaderboard: Fixed code benchmarks (#1441)
* fixed code benchmarks
* fix: Made n_parameters formatting smarter and more robust
* fix: changed jina-embeddings-v3 number of parameters from 572K to 572M
* fix: Fixed use_instuctions typo in model overview
* fix: Fixed sentence-transformer compatibility switch
* Ran linting
* Added all languages, tasks, types and domains to options
* Removed resetting options when a new benchmark is selected
* All results now get displayed, but models that haven&#39;t been run on everything get nan values in the table
* fix: Count unique texts, data leaks in calculate metrics (#1438)
* add more stat
* add more stat
* update statistics
* fix: update task metadata to allow for null (#1448)
* Update tasks table
* 1.19.5
Automatically generated by python-semantic-release
* Fix: Made data parsing in the leaderboard figure more robust (#1450)
Bugfixes with data parsing in main figure
* Fixed task loading (#1451)
* Fixed task result loading from disk
* Fixed task result loading from disk
* fix: publish (#1452)
* 1.19.6
Automatically generated by python-semantic-release
* fix: Fix load external results with `None` mteb_version (#1453)
* fix
* lint
* 1.19.7
Automatically generated by python-semantic-release
* WIP: Polishing up leaderboard UI (#1461)
* fix: Removed column wrapping on the table, so that it remains readable
* Added disclaimer to figure
* fix: Added links to task info table, switched out license with metric
* fix: loading pre 1.11.0 (#1460)
* small fix
* fix: fix
* 1.19.8
Automatically generated by python-semantic-release
* fix: swap touche2020 to maintain compatibility (#1469)
swap touche2020 for parity
* 1.19.9
Automatically generated by python-semantic-release
* docs: Add sum per language for task counts (#1468)
* add sum per lang
* add sort by sum option
* make lint
* fix: pinned datasets to &lt;3.0.0 (#1470)
* 1.19.10
Automatically generated by python-semantic-release
* feat: add CUREv1 retrieval dataset (#1459)
* feat: add CUREv1 dataset
---------
Co-authored-by: nadshe &lt;nadia.sheikh@clinia.com&gt;
Co-authored-by: olivierr42 &lt;olivier.rousseau@clinia.com&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel@buad.es&gt;
* feat: add missing domains to medical tasks
* feat: modify benchmark tasks
* chore: benchmark naming
---------
Co-authored-by: nadshe &lt;nadia.sheikh@clinia.com&gt;
Co-authored-by: olivierr42 &lt;olivier.rousseau@clinia.com&gt;
* Update tasks table
* 1.20.0
Automatically generated by python-semantic-release
* fix: check if `model` attr of model exists (#1499)
* check if model attr of model exists
* lint
* Fix retrieval evaluator
* 1.20.1
Automatically generated by python-semantic-release
* fix: Leaderboard demo data loading (#1507)
* Made get_scores error tolerant
* Added join_revisions, made get_scores failsafe
* Fetching metadata fixed fr HF models
* Added failsafe metadata fetching to leaderboard code
* Added revision joining to leaderboard app
* fix
* Only show models that have metadata, when filter_models is called
* Ran linting
* 1.20.2
Automatically generated by python-semantic-release
* fix: leaderboard only shows models that have ModelMeta (#1508)
Filtering for models that have metadata
* 1.20.3
Automatically generated by python-semantic-release
* fix: align readme with current mteb (#1493)
* align readme with current mteb
* align with mieb branch
* fix test
* 1.20.4
Automatically generated by python-semantic-release
* docs: Add lang family mapping and map to task table (#1486)
* add lang family mapping and map to task table
* make lint
* add back some unclassified lang codes
* Update tasks table
* fix: Ensure that models match the names on embedding-benchmarks/results (#1519)
* 1.20.5
Automatically generated by python-semantic-release
* fix: Adding missing metadata on models and mathcing names up with the results repo (#1528)
* Added Voyage 3 models
* Added correct metadata to Cohere models and matched names with the results repo
* 1.20.6
Automatically generated by python-semantic-release
* feat: Evaluate missing splits (#1525)
* fix: evaluate missing splits (#1268)
* implement partial evaluation for missing splits
* lint
* requested changes done from scratch
* test for missing split evaluation added
* uncomment test
* lint
* avoid circular import
* use TaskResult
* skip tests for now
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* got test_all_splits_evaluated passing
* tests passing
* address review comments
* make lint
* handle None cases for kg_co2_emissions
* use new results info
---------
Co-authored-by: Thivyanth &lt;thivyanth2004@gmail.com&gt;
* 1.21.0
Automatically generated by python-semantic-release
* fix: Correct typos superseeded -&gt; superseded (#1532)
fix typo -&gt; superseded
* 1.21.1
Automatically generated by python-semantic-release
* fix: Task load data error for SICK-BR-STS and XStance (#1534)
* fix task load data for two tasks
* correct dataset keys
* 1.21.2
Automatically generated by python-semantic-release
* fix: Proprietary models now get correctly shown in leaderboard (#1530)
* Fixed showing proprietary models in leaderboard
* Added links to all OpenAI models
* Fixed table formatting issues
* Bumped Gradio version
* 1.21.3
Automatically generated by python-semantic-release
* docs: Add Model Meta parameters and metadata (#1536)
* add multi_qa_MiniLM_L6_cos_v1 model meta
* add all_mpnet_base_v2
* add parameters to model meta
* make lint
* add extra params to meta
* fix: add more model meta (jina, e5) (#1537)
* add e5 model meta
* address review comments
* 1.21.4
Automatically generated by python-semantic-release
* Add cohere models (#1538)
* fix: bug cohere names
* format
* fix: add nomic models (#1543)
#1515
* fix: Added all-minilm-l12-v2 (#1542)
#1515
* fix: Added arctic models (#1541)
#1515
* fix: add sentence trimming to OpenAIWrapper (#1526)
* fix: add sentence trimming to OpenAIWrapper
* fix: import tiktoken library inside encode function
* fix: check tokenizer library installed and update ModelMeta to pass tokenizer_name
* fix: pass tokenizer_name, max_tokens to loader
* fix: make tokenizer_name None for default
* fix: delete changes for ModelMeta
* fix: fix revision to 2 for OpenAI models
* fix: add docstring for OpenAIWrapper
* fix: lint
* feat: add openai optional dependency set
* fix: add sleep for too many requests
* fix: add lint
* fix: delete evaluate file
* 1.21.5
Automatically generated by python-semantic-release
* fix: Fixed metadata errors (#1547)
* 1.21.6
Automatically generated by python-semantic-release
* fix: remove curev1 from multlingual (#1552)
Seems like it was added here:
https://github.com/embeddings-benchmark/mteb/commit/1cc6c9e0fe62ca4e77708b641823fa1a121f048b
* 1.21.7
Automatically generated by python-semantic-release
* fix: Add Model2vec (#1546)
* Added Model2Vec wrapper
* Added Model2vec models
* Added model2vec models to registry
* Added model2vec as a dependency
* Ran linting
* Update mteb/models/model2vec_models.py
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update mteb/models/model2vec_models.py
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Added adapted_from and superseeded_by to model2vec models.
* Added missing import
* Moved pyproject.toml to optional dependencies
* Fixed typos
* Added import error and changed model to model_name
* Added Numpy to frameworks
* Added Numpy to frameworks
* Corrected false info on model2vec models
* Replaced np.inf with maxint
* Update mteb/models/model2vec_models.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Added option to have infinite max tokens, added it to Model2vec
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Made result loading more permissive, changed eval splits for HotPotQA and DBPedia (#1554)
* Removed train and dev from eval splits on HotpotQA
* Removed dev from eval splits on DBPedia
* Made task_results validation more permissive
* Readded exception in get_score
* Ran linting
* 1.21.8
Automatically generated by python-semantic-release
* docs: Correction of SICK-R metadata (#1558)
* Correction of SICK-R metadata
* Correction of SICK-R metadata
---------
Co-authored-by: rposwiata &lt;rposwiata@opi.org.pl&gt;
* feat(google_models): fix issues and add support for `text-embedding-005` and `text-multilingual-embedding-002` (#1562)
* fix: google_models batching and prompt
* feat: add text-embedding-005 and text-multilingual-embedding-002
* chore: `make lint` errors
* fix: address PR comments
* 1.22.0
Automatically generated by python-semantic-release
* fix(bm25s): search implementation (#1566)
fix: bm25s implementation
* 1.22.1
Automatically generated by python-semantic-release
* docs: Fix dependency library name for bm25s (#1568)
* fix: bm25s implementation
* correct library name
---------
Co-authored-by: Daniel Buades Marcos &lt;daniel.buades@clinia.com&gt;
* fix: Add training dataset to model meta (#1561)
* fix: Add training dataset to model meta
Adresses #1556
* Added docs
* format
* feat: (cohere_models) cohere_task_type issue, batch requests and tqdm for visualization (#1564)
* feat: batch requests to cohere models
* fix: use correct task_type
* feat: use tqdm with openai
* fix: explicitely set `show_progress_bar` to False
* fix(publichealth-qa):  ignore rows with `None` values in `question` or `answer` (#1565)
* 1.23.0
Automatically generated by python-semantic-release
* fix: Added metadata for miscellaneous models (#1557)
* Added script for generating metadata, and metadata for the listed models
* Added misc models to overview
* Fixed misc metas
* Removed unnecessary imports
* Added logic to retrieve base model information
* Added base models to misc meta
* Added superseded_by to sentence-croissant models
* Added training datasets to mis models
* 1.23.1
Automatically generated by python-semantic-release
* fix: Added radar chart displaying capabilities on task types (#1570)
* Added radar chart displaying capabilities on task types
* Fixed table aggregation in leaderboard
* Spelled out why instructionretrieval is excluded
* 1.23.2
Automatically generated by python-semantic-release
* feat: add new arctic v2.0 models (#1574)
* feat: add new arctic v2.0 models
* chore: make lint
* 1.24.0
Automatically generated by python-semantic-release
* fix: Add namaa MrTydi reranking dataset (#1573)
* Add dataset class and file requirements
* pass tests
* make lint changes
* adjust meta data and remove load_data
---------
Co-authored-by: Omar Elshehy &lt;omarelshehy@Omars-MacBook-Pro.local&gt;
* Update tasks table
* 1.24.1
Automatically generated by python-semantic-release
* fix: Eval langs not correctly passed to monolingual tasks (#1587)
* fix SouthAfricanLangClassification.py
* add check for langs
* lint
* 1.24.2
Automatically generated by python-semantic-release
* feat: Add ColBert (#1563)
* feat: add max_sim operator for IR tasks to support multi-vector models
* docs: add doc for Model2VecWrapper.__init__(...)
* feat: add ColBERTWrapper to models &amp; add ColBERTv2
* fix: resolve issues
* fix: resolve issues
* Update README.md
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
* Update README.md
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update README.md
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update mteb/evaluation/evaluators/RetrievalEvaluator.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update README.md
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* README.md: rm subset
* doc: update example for Late Interaction
* get colbert running without errors
* fix: pass is_query to pylate
* fix: max_sim add pad_sequence
* feat: integrate Jinja templates for ColBERTv2 and add model prompt handling
* feat: add revision &amp; prompt_name
* doc: pad_sequence
* rm TODO jina colbert v2
* doc: warning: higher resource usage for MaxSim
---------
Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* 1.25.0
Automatically generated by python-semantic-release
* doc: colbert add score_function &amp; doc section (#1592)
* doc: colbert add score_function &amp; doc section
* doc: Update README.md
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* doc: Update README.md
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
---------
Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Feat: add support for scoring function (#1594)
* add support for scoring function
* lint
* move similarity to wrapper
* remove score function
* lint
* remove from InstructionRetrievalEvaluator
* Update mteb/evaluation/evaluators/RetrievalEvaluator.py
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* remove score function from README.md
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Add new models nvidia, gte, linq (#1436)
* Add new models nvidia, gte, linq
* add warning for gte-Qwen and nvidia models re: instruction used in docs as well
---------
Co-authored-by: isaac-chung &lt;chungisaac1217@gmail.com&gt;
* Leaderboard: Refined plots (#1601)
* Added embedding size guide to performance-size plot, removed shading on radar chart
* Changed plot names to something more descriptive
* Made plots failsafe
* fix: Leaderboard refinements (#1603)
* Added explanation of aggregate measures
* Added download button to result tables
* Task info gets sorted by task name
* Added custom, shareable links for each benchmark
* Moved explanation of aggregate metrics to the summary tab
* 1.25.1
Automatically generated by python-semantic-release
* Feat: Use similarity scores if available (#1602)
* Use similarity scores if available
* lint
* Add NanoBEIR Datasets (#1588)
* add NanoClimateFeverRetrieval task, still requires some debugging
* move task to correct place in init file
* add all Nano datasets and results
* format code
* Update mteb/tasks/Retrieval/eng/tempCodeRunnerFile.py
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
* pin revision to commit and add datasets to benchmark.py
* create new benchmark for NanoBEIR
* add revision when loading datasets
* lint
---------
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: isaac-chung &lt;chungisaac1217@gmail.com&gt;
* Update tasks table
* Feat: Evaluate missing languages (#1584)
* init
* fix tests
* update mock retrieval
* update tests
* use subsets instead of langs
* Apply suggestions from code review
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* fix tests
* add to readme
* rename subset in readme
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Add IBM Granite Embedding Models (#1613)
* add IBM granite embedding models
* lint formatting
* add adapted_from and superseded_by to ModelMeta
* fix: disable co2_tracker for API models (#1614)
* 1.25.2
Automatically generated by python-semantic-release
* fix: set `use_instructions` to True in models using prompts (#1616)
feat: set `use_instructions` to True in models using prompts
* 1.25.3
Automatically generated by python-semantic-release
* fix: override existing results (#1617)
* fix override existing results
* lint
* fix tests
* add tests with overwrite
* lint
* update tests
* lint
* update
* lint
* 1.25.4
Automatically generated by python-semantic-release
* add MSMARCO eval split in MTEB English (classic) benchmark (#1620)
* add MSMARCO eval split in MTEB English (classic) benchmark
Fixes #1608
* Add co-author
Co-authored-by: aashka-trivedi &lt;aashka.trivedi@gmail.com&gt;
---------
Co-authored-by: aashka-trivedi &lt;aashka.trivedi@gmail.com&gt;
* fix: GermanDPR Dataset Causes Cross-Encoder Failure Due to Unexpected dict (#1621)
Fixes #1609
* fix: properly add mteb_model_meta to model object (#1623)
* 1.25.5
Automatically generated by python-semantic-release
* Feat: Add jasper (#1591)
* init jasper
* init jasper
* add to overview
* add to overview
* remove some params
* fix max length
* return sdpa
* add dtype
* add dtype
* fix convert_to_tensor
* change to encode
* return whitespace processing
* explicitly add instructions
* move seq length
* try float
* fix max_seq_length
* add prompt validation to format instruction
* don&#39;t use instructions only to s2p
* fix: Update results_to_dataframe to use BenchmarkResults class (#1628)
* 1.25.6
Automatically generated by python-semantic-release
* Speed up test_save_predictions (#1631)
* fix: Correction of discrepancies for gte-Qweb model (#1637)
* 1.25.7
Automatically generated by python-semantic-release
* fix: output_folder for co2 evaluation (#1642)
* 1.25.8
Automatically generated by python-semantic-release
* fix: add missing benchmark to benchmarks.py (#1641)
add missing benchmark
* 1.25.9
Automatically generated by python-semantic-release
* fix: Cast all Model2Vec outputs as floats (#1667)
cast all outputs as floats
* 1.25.10
Automatically generated by python-semantic-release
* fix: Update gritlm kwargs (#1643)
* Fix kwarg
* format
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* 1.25.11
Automatically generated by python-semantic-release
* fix: Use batch size kwargs for openai APIs (#1668)
Fixes #1645
* 1.25.12
Automatically generated by python-semantic-release
* fix: Pass trust_remote_code=True to CPM model (#1669)
Fixes #1651
* 1.25.13
Automatically generated by python-semantic-release
* fix: Updated metadata for CPM (#1670)
* fix: Pass trust_remote_code=True to CPM model
Fixes #1651
* fix: Updated metadata for cpm
* 1.25.14
Automatically generated by python-semantic-release
* fix: remove model as a parameter for MulticlassClassification (#1666)
remove model parameter
* fix: Use prompts instead of prompt names for voyage (#1665)
* fix prompt names
* lint
* change input type
* 1.25.15
Automatically generated by python-semantic-release
* fix: Update BUCC dataset revision (#1674)
* trust remote code
* Update revision
* 1.25.16
Automatically generated by python-semantic-release
* fix: Add warning for non-retrieval tasks when using bm25s (#1678)
* clean up install instruction
* add check for bm25s and skip non-retrieval tasks
* add versions
* 1.25.17
Automatically generated by python-semantic-release
* fix: add check for key error in loader (#1675)
* add check for key error
* make KeyError everywhere
* update error
* 1.25.18
Automatically generated by python-semantic-release
* fix: trust remote code for snowflake-arctic-embed-m-v2.0 (#1682)
trust remote code
* 1.25.19
Automatically generated by python-semantic-release
* fix: nomic tensor return (#1683)
* fix nomic tensor return
* add typehint
* 1.25.20
Automatically generated by python-semantic-release
* feat: add `avsolatorio/NoInstruct-small-Embedding-v0` (#1677)
add no_instruct
* fix: arg name for openbmb/MiniCPM-Embedding (#1691)
fix name
* 1.26.0
Automatically generated by python-semantic-release
* fix: add trust_remote_code to Snowflake/snowflake-arctic-embed-m-long (#1695)
trust remote code
* fix: add revision for jinaai/jina-embeddings-v2-small-en (#1692)
add revision
* 1.26.1
Automatically generated by python-semantic-release
* fix: update model loader to trust remote code (#1697)
update model loader
* 1.26.2
Automatically generated by python-semantic-release
* fix: nomic prompts (#1685)
* fix nomic prompts
* fix variable model name
* pass prompts to model
* use sentence transformer wrapper
* update prompts
* lint
* update prompts
* update list for classification
* fix: NanoBeir (#1687)
* fix nano beir
* lint
* 1.26.3
Automatically generated by python-semantic-release
* Update RerankingEvaluator.py (#1702)
* fix: Register MicroLlama Text Embedding (#1644)
Register MicroLlama Text Embedding
* fix: GermanDPR (#1703)
* fix GermanDPR
* lint
* 1.26.4
Automatically generated by python-semantic-release
* Fix: minicpmv2 (#1705)
* updmini cpm
* flash_attn implementation
* remove flash attn
* ci: Refresh the v2 leaderboard daily (#1711)
* Create leaderboard_refresh.yaml
* Shorten and fix
* factory reset instead of normal
* Fix: typos in adding a model (#1722)
* fix: rollback BUCC revision (#1706)
* fix bucc
* fix logger
* upd evaluator
* add comment
* lint
* 1.26.5
Automatically generated by python-semantic-release
* fix: Added zero shot tag to benchmark (#1710)
* Added method for determining whether a model is zero shot
* Added .items() where intended
* Added filtering functions for zero shot models
* Added zero-shot filtering button and error message when table is empty.:
* Ran linting
* Fixed docstring linting error
* is_zero_shot returns None when no training data is specified
* Added zero-shot emoji column to leaderboard
* Added explanation for zero shot column
* Added soft and hard zero-shot buttons
* Added training data annotations to 24 models from HuggingFace Hub
* 1.26.6
Automatically generated by python-semantic-release
* feat: reduce logging for load_results()
- redacts missing subsets to avoid 100+ subsets printed
- reduce to logging.info
- removed splits that are commonly never evaluated on and thus also the errors for them being missing
The second part removed quite a few warnings (4930 to XX)
It also seems like the splits were accidentally included in some of the MMTEB benchmark.
This will remove those splits from those benchmarks (which are all in beta). We will have to recompute the tables for the paper though (we should do that anyway)
Other potential thing to consider:
- Scifact is included in MTEB(Medical). I have removed the &#34;train&#34; split from it as I think that was a mistake. (checked other dataset in benchmark)
Here is a count of the current top errors:
```py
{
    &#34;MassiveScenarioClassification: Missing splits {&#39;validation&#39;}&#34;: 238,  # included in e.g. mteb(fra)
    &#34;MassiveIntentClassification: Missing splits {&#39;validation&#39;}&#34;: 237, # included in e.g. mteb(fra)
    &#34;MassiveScenarioClassification: Missing subsets {&#39;af&#39;, &#39;da&#39;, ...} for split test&#34;: 230,
    &#34;AmazonReviewsClassification: Missing splits {&#39;validation&#39;}&#34;: 229, # included in e.g. mteb(deu)
    &#34;MassiveIntentClassification: Missing subsets {&#39;af&#39;, &#39;da&#39;, ...} for split test&#34;: 228,
    &#34;STS22: Missing subsets {&#39;fr-pl&#39;, &#39;de-en&#39;, ...} for split test&#34;: 223,
    &#34;AmazonReviewsClassification: Missing subsets {&#39;es&#39;, &#39;ja&#39;, ...} for split test&#34;: 196,
    &#34;MTOPDomainClassification: Missing splits {&#39;validation&#39;}&#34;: 195, # included in mteb(fra)
    &#34;MTOPIntentClassification: Missing splits {&#39;validation&#39;}&#34;: 194, # included in mteb(fra)
    &#34;AmazonCounterfactualClassification: Missing splits {&#39;validation&#39;}&#34;: 189, # included in mteb(deu)
    &#34;MTOPDomainClassification: Missing subsets {&#39;es&#39;, &#39;th&#39;, ...} for split test&#34;: 165,
    &#34;STS17: Missing subsets {&#39;en-ar&#39;, &#39;es-es&#39;, ...} for split test&#34;: 164,
    &#34;MTOPIntentClassification: Missing subsets {&#39;es&#39;, &#39;th&#39;, ...} for split test&#34;: 164,
    &#34;AmazonCounterfactualClassification: Missing subsets {&#39;de&#39;, &#39;ja&#39;, ...} for split test&#34;: 148,
}
```
* 1.27.0
Automatically generated by python-semantic-release
* feat: Add nomic modern bert (#1684)
* add nomic modern bert
* use SentenceTransformerWrapper
* use SentenceTransformerWrapper
* try nomic wrapper
* update
* use all prompts
* pass prompts
* use fp16
* lint
* change to version
* remove commented code
* fix: allow kwargs in init for RerankingWrapper (#1676)
* allow kwargs in init
* fix retrieval
* convert corpus_in_pair to list
* 1.28.0
Automatically generated by python-semantic-release
* Fixed result loading on leaderboard (#1739)
* Only main_score gets loaded for leaderboard thereby avoiding OOM errors
* Fixed plot failing because of missing embedding dimensions
* Ran linting
* test: Add script to test model loading below n_parameters threshold (#1698)
* add model loading test for models below 2B params
* add failure message to include model namne
* use the real get_model_meta
* use cache folder
* teardown per function
* fix directory removal
* write to file
* wip loading from before
* wip
* Rename model_loading_testing.py to model_loading.py
* Delete tests/test_models/test_model_loading.py
* checks for models below 2B
* try not using cache folder
* update script with scan_cache_dir and add args
* add github CI: detect changed model files and run model loading test
* install all model dependencies
* dependecy installations and move file location
* should trigger a model load test in CI
* find correct commit for diff
* explicity fetch base branch
* add make command
* try to run in python instead and add pytest
* fix attribute error and add read mode
* separate script calling
* let pip install be cached and specify repo path
* check ancestry
* add cache and rebase
* try to merge instead of rebase
* try without merge base
* check if file exists first
* Apply suggestions from code review
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update .github/workflows/model_loading.yml
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* address review comments to run test once from CI and not pytest
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* fix: Leaderboard Speedup (#1745)
* Added get_scores_fast
* Made leaderboard faster with smarter dependency graph and event management and caching
* Changed print to logger.info
* 1.28.1
Automatically generated by python-semantic-release
* fix: Fixed task_type aggregation on leaderboard (#1746)
* Fixed task_type aggregation in leaderboard
* Fixed an error due to unneccesary indentation in get_score
* 1.28.2
Automatically generated by python-semantic-release
* fix: Fixed definition of zero-shot in ModelMeta (#1747)
* Corrected zero_shot definition to be based on task names, not dataset path
* 1.28.3
Automatically generated by python-semantic-release
* fix: fixes implementation of similarity() (#1748)
* fix(#1594): fixes implementation of similarity()
* fix: add similarity to SentenceTransformerWrapper
---------
Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
* 1.28.4
Automatically generated by python-semantic-release
* fix: Leaderboard: `K` instead of `M` (#1761)
Fixes #1752
* other: add script for leaderboard compare (#1758)
* add script
* remove changes
* remove changes
* add comment
* lint
* order like in benchmark object
* round results
* 1.28.5
Automatically generated by python-semantic-release
* fix: added annotations for training data (#1742)
* fix: Added annotations for arctic embed models
* added google and bge
* added cohere
* Added e5
* added bge based model2vec
* annotated oAI
* format and update annotations
* 1.28.6
Automatically generated by python-semantic-release
* fix: update max tokens for OpenAI (#1772)
update max tokens
* ci: skip AfriSentiLID for now (#1785)
* skip AfriSentiLID for now
* skip relevant test case instead
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* 1.28.7
Automatically generated by python-semantic-release
* ci: fix model loading test (#1775)
* pass base branch into the make command as an arg
* test a file that has custom wrapper
* what about overview
* just dont check overview
* revert instance check
* explicitly omit overview and init
* remove test change
* try on a lot of models
* revert test model file
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* feat: Update task filtering, fixing bug which included cross-lingual tasks in overly many benchmarks (#1787)
* feat: Update task filtering, fixing bug on MTEB
- Updated task filtering adding exclusive_language_filter and hf_subset
- fix bug in MTEB where cross-lingual splits were included
- added missing language filtering to MTEB(europe, beta) and MTEB(indic, beta)
The following code outlines the problems:
```py
import mteb
from mteb.benchmarks import MTEB_ENG_CLASSIC
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
# was eq. to:
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;])
task.hf_subsets
# correct filtering to English datasets:
# [&#39;en&#39;, &#39;de-en&#39;, &#39;es-en&#39;, &#39;pl-en&#39;, &#39;zh-en&#39;]
# However it should be:
# [&#39;en&#39;]
# with the changes it is:
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
task.hf_subsets
# [&#39;en&#39;]
# eq. to
task = mteb.get_task(&#34;STS22&#34;, hf_subsets=[&#34;en&#34;])
# which you can also obtain using the exclusive_language_filter (though not if there was multiple english splits):
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;], exclusive_language_filter=True)
```
* format
* remove &#34;en-ext&#34; from AmazonCounterfactualClassification
* fixed mteb(deu)
* fix: simplify in a few areas
* 1.29.0
Automatically generated by python-semantic-release
* fix: Added C-MTEB (#1786)
Added C-MTEB
* 1.29.1
Automatically generated by python-semantic-release
* docs: Add contact to MMTEB benchmarks (#1796)
* Add myself to MMTEB benchmarks
* lint
* fix: loading pre 11 (#1798)
* fix loading pre 11
* add similarity
* lint
* run all task types
* 1.29.2
Automatically generated by python-semantic-release
* fix: allow to load no revision available (#1801)
* fix allow to load no revision available
* lint
* add require_model_meta to leaderboard
* lint
* 1.29.3
Automatically generated by python-semantic-release
* fix: Zero shot and aggregation on Leaderboard (#1810)
* Made join_revision filter out no_revision_available when other revisions have been run on the task
* Fixed zero-shot filtering
* Fixed aggregation of task types
* Ran linting
* fix: Added `ModelMeta` for BGE, GTE Chinese and multilingual models (#1811)
* Added BGE Chinese and multilingual-gemma models
* Added GTE multilingual and Chinese models
* Fixed date format
* 1.29.4
Automatically generated by python-semantic-release
* fix: Add additional contacts (#1817)
add contacts from #1790
* Update points table
* 1.29.5
Automatically generated by python-semantic-release
* fix: Added more Chinese models&#39; `ModelMeta` (#1814)
* Added Multilingual USE models
* Added Moka models
* Added dmeta models
* Added jina-zh
* Added  piccolo models
* 1.29.6
Automatically generated by python-semantic-release
* Add model inf-retriever-v1 (#1744)
* feat(models): add infly/inf-retriever-v1 model metadata- Add inf_models.py file with metadata for infly/inf-retriever-v1 model
- Update overview.py to include inf_models in model imports
* Reformat code
* Update inf-retriever-v1 ModelMeta
* Fill more information for inf-retriever-v1
* Add license information for inf-retriever-v1
---------
Co-authored-by: Samuel Yang &lt;samuelyang150@gmail.com&gt;
* ci: only return 1 model_name per file (#1818)
* only return 1 model_name per file
* fix args parse
* revert test change
* fix: add bge-m3 `ModelMeta` (#1821)
add bge
* 1.29.7
Automatically generated by python-semantic-release
* fix: Added Chinese Stella models (#1824)
Added Chinese Stella models
* fix: bm25s (#1827)
Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
* fix: Added way more training dataset annotations (#1765)
* fix: Leaderboard: `K` instead of `M`
Fixes #1752
* format
* fixed existing annotations to refer to task name instead of hf dataset
* added annotation to nvidia
* added voyage
* added uae annotations
* Added stella annotations
* sentence trf models
* added salesforce and e5
* jina
* bge + model2vec
* added llm2vec annotations
* add jasper
* format
* format
* Updated annotations and moved jina models
* fix: add even more training dataset annotations (#1793)
* fix: update max tokens for OpenAI (#1772)
update max tokens
* ci: skip AfriSentiLID for now (#1785)
* skip AfriSentiLID for now
* skip relevant test case instead
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* 1.28.7
Automatically generated by python-semantic-release
* ci: fix model loading test (#1775)
* pass base branch into the make command as an arg
* test a file that has custom wrapper
* what about overview
* just dont check overview
* revert instance check
* explicitly omit overview and init
* remove test change
* try on a lot of models
* revert test model file
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* feat: Update task filtering, fixing bug which included cross-lingual tasks in overly many benchmarks (#1787)
* feat: Update task filtering, fixing bug on MTEB
- Updated task filtering adding exclusive_language_filter and hf_subset
- fix bug in MTEB where cross-lingual splits were included
- added missing language filtering to MTEB(europe, beta) and MTEB(indic, beta)
The following code outlines the problems:
```py
import mteb
from mteb.benchmarks import MTEB_ENG_CLASSIC
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
# was eq. to:
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;])
task.hf_subsets
# correct filtering to English datasets:
# [&#39;en&#39;, &#39;de-en&#39;, &#39;es-en&#39;, &#39;pl-en&#39;, &#39;zh-en&#39;]
# However it should be:
# [&#39;en&#39;]
# with the changes it is:
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
task.hf_subsets
# [&#39;en&#39;]
# eq. to
task = mteb.get_task(&#34;STS22&#34;, hf_subsets=[&#34;en&#34;])
# which you can also obtain using the exclusive_language_filter (though not if there was multiple english splits):
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;], exclusive_language_filter=True)
```
* format
* remove &#34;en-ext&#34; from AmazonCounterfactualClassification
* fixed mteb(deu)
* fix: simplify in a few areas
* fix: Add gritlm
* 1.29.0
Automatically generated by python-semantic-release
* fix: Added more annotations!
* fix: Added C-MTEB (#1786)
Added C-MTEB
* 1.29.1
Automatically generated by python-semantic-release
* docs: Add contact to MMTEB benchmarks (#1796)
* Add myself to MMTEB benchmarks
* lint
* fix: loading pre 11 (#1798)
* fix loading pre 11
* add similarity
* lint
* run all task types
* 1.29.2
Automatically generated by python-semantic-release
* fix: allow to load no revision available (#1801)
* fix allow to load no revision available
* lint
* add require_model_meta to leaderboard
* lint
* 1.29.3
Automatically generated by python-semantic-release
---------
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
---------
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
* fix: Added Misc Chinese models (#1819)
* Added moka and piccolo models to overview file
* Added Text2Vec models
* Added various Chinese embedding models
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* 1.29.8
Automatically generated by python-semantic-release
* fix: Fixed eval split for MultilingualSentiment in C-MTEB (#1804)
* Fixed eval split for MultilingualSentiment in C-MTEB
* FIxed splits for atec, bq and stsb in C-MTEB
* 1.29.9
Automatically generated by python-semantic-release
* fix: subsets to run (#1830)
* fix split evals
* add test
* lint
* fix moka
* add assert
* fix: Remove default params, `public_training_data` and `memory usage` in `ModelMeta` (#1794)
* fix: Leaderboard: `K` instead of `M`
Fixes #1752
* format
* fixed existing annotations to refer to task name instead of hf dataset
* added annotation to nvidia
* added voyage
* added uae annotations
* Added stella annotations
* sentence trf models
* added salesforce and e5
* jina
* bge + model2vec
* added llm2vec annotations
* add jasper
* format
* format
* Updated annotations and moved jina models
* make models parameters needed to be filled
* fix tests
* remove comments
* remove model meta from test
* fix model meta from split
* fix: add even more training dataset annotations (#1793)
* fix: update max tokens for OpenAI (#1772)
update max tokens
* ci: skip AfriSentiLID for now (#1785)
* skip AfriSentiLID for now
* skip relevant test case instead
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* 1.28.7
Automatically generated by python-semantic-release
* ci: fix model loading test (#1775)
* pass base branch into the make command as an arg
* test a file that has custom wrapper
* what about overview
* just dont check overview
* revert instance check
* explicitly omit overview and init
* remove test change
* try on a lot of models
* revert test model file
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* feat: Update task filtering, fixing bug which included cross-lingual tasks in overly many benchmarks (#1787)
* feat: Update task filtering, fixing bug on MTEB
- Updated task filtering adding exclusive_language_filter and hf_subset
- fix bug in MTEB where cross-lingual splits were included
- added missing language filtering to MTEB(europe, beta) and MTEB(indic, beta)
The following code outlines the problems:
```py
import mteb
from mteb.benchmarks import MTEB_ENG_CLASSIC
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
# was eq. to:
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;])
task.hf_subsets
# correct filtering to English datasets:
# [&#39;en&#39;, &#39;de-en&#39;, &#39;es-en&#39;, &#39;pl-en&#39;, &#39;zh-en&#39;]
# However it should be:
# [&#39;en&#39;]
# with the changes it is:
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
task.hf_subsets
# [&#39;en&#39;]
# eq. to
task = mteb.get_task(&#34;STS22&#34;, hf_subsets=[&#34;en&#34;])
# which you can also obtain using the exclusive_language_filter (though not if there was multiple english splits):
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;], exclusive_language_filter=True)
```
* format
* remove &#34;en-ext&#34; from AmazonCounterfactualClassification
* fixed mteb(deu)
* fix: simplify in a few areas
* fix: Add gritlm
* 1.29.0
Automatically generated by python-semantic-release
* fix: Added more annotations!
* fix: Added C-MTEB (#1786)
Added C-MTEB
* 1.29.1
Automatically generated by python-semantic-release
* docs: Add contact to MMTEB benchmarks (#1796)
* Add myself to MMTEB benchmarks
* lint
* fix: loading pre 11 (#1798)
* fix loading pre 11
* add similarity
* lint
* run all task types
* 1.29.2
Automatically generated by python-semantic-release
* fix: allow to load no revision available (#1801)
* fix allow to load no revision available
* lint
* add require_model_meta to leaderboard
* lint
* 1.29.3
Automatically generated by python-semantic-release
---------
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
* fig merges
* update models info
* change public_training_code to str
* change `public_training_code=False` to None
* remove annotations
* remove annotations
* remove changed annotations
* remove changed annotations
* remove `public_training_data` and `memory usage`
* make framework not optional
* make framework non-optional
* empty frameworks
* add framework
* fix tests
* Update mteb/models/overview.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
* 1.29.10
Automatically generated by python-semantic-release
* fix: Add reported annotation and re-added public_training_data (#1846)
* fix: Add additional dataset annotations
* fix: readded public training data
* update voyage annotations
* 1.29.11
Automatically generated by python-semantic-release
* fix: Leaderboard Refinements (#1849)
* Added better descriptions to benchmarks and removed beta tags
* Fixed zero-shot filtering on app loading
* Added zero-shot definition in an accordion
* NaN values are now filled with blank
* Added type hints to filter_models
* 1.29.12
Automatically generated by python-semantic-release
* rest of the merge conflicts
* fix merge conflicts
* fill in model meta defaults
* fix ModeMeta modalities
* fix metadata pydantic errors;
* assert model.model instead since it is a wrapper
* fix: Fixed leaderboard search bar (#1852)
Fixed leaderboard search bar
* 1.29.13
Automatically generated by python-semantic-release
* fix: Hotfixed public_training_data type annotation (#1857)
Fixed public_training_data flag type to include boolean, as this is how all models are annotated
* fix: Fix zeta alpha mistral (#1736)
* fix zeta alpha mistral
* update use_instructions
* update training datasets
* Update mteb/models/e5_instruct.py
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* update float
* Update mteb/models/e5_instruct.py
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Add more annotations (#1833)
* apply additions from #1794
* add annotations for rumodels
* add nomic training data
* fix metadata
* update rest of model meta
* fix bge reranker
* 1.29.14
Automatically generated by python-semantic-release
* fix: Adding missing model meta (#1856)
* Added CDE models
* Added bge-en-icl
* Updated CDE to bge_full_data
* Fixed public_training_data flag type to include boolean, as this is how all models are annotated
* Added public training data link instead of bool to CDE and BGE
* Added GME models
* Changed Torch to PyTorch
* Added metadata on LENS models
* Added ember_v1
* Added metadata for amazon titan
* Removed GME implementation
* fix Encoder class
---------
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Helena Kloosterman &lt;helena.kloosterman@intel.com&gt;
Co-authored-by: Alexey Vatolin &lt;vatolinalex@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Elias H &lt;40372306+eherra@users.noreply.github.com&gt;
Co-authored-by: Youngjoon Jang &lt;82500463+yjoonjang@users.noreply.github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Napuh &lt;55241721+Napuh@users.noreply.github.com&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel.buades@clinia.com&gt;
Co-authored-by: nadshe &lt;nadia.sheikh@clinia.com&gt;
Co-authored-by: olivierr42 &lt;olivier.rousseau@clinia.com&gt;
Co-authored-by: Thivyanth &lt;thivyanth2004@gmail.com&gt;
Co-authored-by: RafaÅ‚ PoÅ›wiata &lt;rafalposwiata@gmail.com&gt;
Co-authored-by: Omar Elshehy &lt;41394057+omarelshehy@users.noreply.github.com&gt;
Co-authored-by: Omar Elshehy &lt;omarelshehy@Omars-MacBook-Pro.local&gt;
Co-authored-by: Sam &lt;40773225+sam-hey@users.noreply.github.com&gt;
Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
Co-authored-by: KGupta10 &lt;92774828+KGupta10@users.noreply.github.com&gt;
Co-authored-by: Aashka Trivedi &lt;aashka.trivedi@gmail.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
Co-authored-by: Ken Wang &lt;wangxiaotian2007@gmail.com&gt;
Co-authored-by: Orion Weller &lt;31665361+orionw@users.noreply.github.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: Samuel Yang &lt;yangjun2@mail.ustc.edu.cn&gt;
Co-authored-by: Samuel Yang &lt;samuelyang150@gmail.com&gt;

* [mieb] Fill in align model meta (#1863)

* add align model meta

* trigger ci

* fix meta

* [mieb] Fill in clip and open clip model meta (#1876)

* add clip and open clip model meta

* fix training_datasets

* [mieb] Fill in blip model meta (#1874)

* add blip and blip 2 model meta

* fix references

* fix training datasets

* [mieb] Fill in cohere_v and dinov2 model meta (#1880)

fill in cohere_v and dino model meta

* [mieb] Fill in e5v and eva clip model meta (#1885)

* add e5v model meta

* add some eva_clip2 meta

* add the rest of meta

* [mieb] Fill out gme v and jina clip model meta (#1887)

* add gme_v model meta
* fill in jina clip meta
* jina clip v1 training data
* correct type
* cosmetic fix
* handle case where name is a variable and not a string
* Update mteb/models/gme_v_models.py
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
---------
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* [mieb] Fill in mocov3 and nomic vision model meta (#1890)

* add moco model meta

* add nomic v model meta

* add training dataset for nomic

* [mieb] Fill in siglip model meta (#1894)

add siglip model meta

* [mieb] Fill in vista vlm2vec voyage v model meta (#1903)

* add vista model meta

* add vlm2vec model meta

* add more meta

* [mieb] merge from main once more (#1942)

* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* 1.31.4
Automatically generated by python-semantic-release
* Update tasks table
* fix: Limited plotly version to be less than 6.0.0 (#1902)
Limited plotly version to be less than 6.0.0
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* update stella/jasper metainfo (#1896)
update stella meta
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* 1.31.5
Automatically generated by python-semantic-release
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Feat: Add FaMTEB (Farsi/Persian Text Embedding Benchmark) (#1843)
* Add Summary Retrieval Task
* Add FaMTEBClassification
* Add FaMTEBClustering
* Add FaMTEBPairClassification
* Add FaMTEBRetrieval and BEIRFA and FaMTEBSTS
* Add FaMTEBSummaryRetrieval
* Add FaMTEB to benchmarks
* fix benchmark names
* temporary fix metadata
* Fix dataset revisions
* Update SummaryRetrievalEvaluator.py
* Update task files
* Update task files
* add data domain and subtask description
* Update AbsTaskSummaryRetrieval and FaMTEBSummaryRetrieval
* Update AbsTaskSummaryRetrieval
* Add mock task
* Update AbsTaskSummaryRetrieval
* Update AbsTaskSummaryRetrieval
* make lint
* Refactor SummaryRetrieval to subclass BitextMining
* Add aggregated datasets
---------
Co-authored-by: mehran &lt;mehan.sarmadi16@gmail.com&gt;
Co-authored-by: e.zeinivand &lt;zeinivand@ymail.com&gt;
Co-authored-by: Erfun76 &lt;59398902+Erfun76@users.noreply.github.com&gt;
* Update tasks table
* Docs: update docs according to current state (#1870)
* update docs
* Apply suggestions from code review
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* update readme
* Update README.md
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update tasks table
* Update tasks table
* Update tasks table
* Adding a banner to the new MMTEB leaderboard (#1908)
* Adding a banner to the new MMTEB leaderboard
* linting
* Update mteb/leaderboard/app.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* adding reference to mteb arena
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* fix: Filling missing metadata for leaderboard release (#1895)
* Update ArxivClusteringS2S.py
* fill some metadat for retrieval
* fill in the reste of missing metadata
* fix metadata
* fix climatefever metadata
* fix: Added CQADupstack annotations
* removed annotation for non-exisitant task
* format
* Added financial to other financial dataset
* Moved ArguAna annotation to derivate datasets
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* 1.31.6
Automatically generated by python-semantic-release
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* fix: remove SummaryRetrieval as a type (#1915)
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* fix: revert rename and add to description (#1918)
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* docs: Add sort to domains for task metadata (#1922)
Tests currently go into an infinite loop. This should prevent that.
* Update tasks table
* 1.31.7
Automatically generated by python-semantic-release
* docs: Updated citation for mteb(scandinavian) (#1914)
fix: Updated citation for mteb(scandinavian)
* fix: Add datasets in CodeRAG-Bench (#1595)
* add three out of four datasets in CodeRAG-Bench
* add verified CodeRAGStackoverflowPostsRetrieval dataset
* clean up code and make some comments
* fixed lint errors
* addressed comments about code-rag datasets: fixed grammar and remove unnessary code and loop
* roll back files which is not supposed to change
* fixed the comments in split_by_first_newline() and make the methods private by adding a underscore prefix
* refactor to use common args
* update task descriptions
* add entry in benchmarks
* correct the alphanumeric order for the dataset
* add  in tasks.md
* add  in tasks.md
* update task metadata
* update importing path
* fix lint errors
* correct CodeRAG task metadata description field and id for stackoverflow-posts
* fix error in test
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update tasks table
* 1.31.8
Automatically generated by python-semantic-release
* Leaderboard: Acks (#1930)
Add acs
* omit instructions.py
---------
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Mehran Sarmadi &lt;128898167+mehran-sarmadi@users.noreply.github.com&gt;
Co-authored-by: mehran &lt;mehan.sarmadi16@gmail.com&gt;
Co-authored-by: e.zeinivand &lt;zeinivand@ymail.com&gt;
Co-authored-by: Erfun76 &lt;59398902+Erfun76@users.noreply.github.com&gt;
Co-authored-by: Wissam Siblini &lt;36303760+wissam-sib@users.noreply.github.com&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Pengfei He &lt;hepengfe@gmail.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* fix merge conflict error in task metadata

* remove old file

* add mieb to readme

* add comments to mieb task categories

* remove commented out code

* use logger.info in abstasks

* add blip2 dependency to pyproject

* remove test code

* fix #1960

---------

Signed-off-by: mr.Shu &lt;mr@shu.io&gt;
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: anpalmak2003 &lt;73543260+anpalmak2003@users.noreply.github.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: Zach Nussbaum &lt;zanussbaum@gmail.com&gt;
Co-authored-by: Jamie-Stirling &lt;36764530+Jamie-Stirling@users.noreply.github.com&gt;
Co-authored-by: HSILA &lt;a.shiraee@gmail.com&gt;
Co-authored-by: Ali Shiraee &lt;ShiraeA@basfad.basf.net&gt;
Co-authored-by: Thomas van Dongen &lt;thomas123@live.nl&gt;
Co-authored-by: Orion Weller &lt;31665361+orionw@users.noreply.github.com&gt;
Co-authored-by: John Yang &lt;byjohnyang@gmail.com&gt;
Co-authored-by: Marek Å uppa &lt;mrshu@users.noreply.github.com&gt;
Co-authored-by: Xa9aX ãƒ„ &lt;mishradiganta91@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel@buad.es&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel.buades@clinia.com&gt;
Co-authored-by: Sathvik Nallamalli &lt;sathviknallamalli@gmail.com&gt;
Co-authored-by: Michael Graczyk &lt;michael@mgraczyk.com&gt;
Co-authored-by: Mariya Hendriksen &lt;35101262+mariyahendriksen@users.noreply.github.com&gt;
Co-authored-by: Santiago Castro &lt;bryant1410@gmail.com&gt;
Co-authored-by: Joey Xia &lt;77958037+ZiyiXia@users.noreply.github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
Co-authored-by: Oliver &lt;oliver.pejic@students.fhnw.ch&gt;
Co-authored-by: gowitheflow-1998 &lt;chenghao.xiao@durham.ac.uk&gt;
Co-authored-by: Saiteja Utpala &lt;73220310+SaitejaUtpala@users.noreply.github.com&gt;
Co-authored-by: Xin Zhang &lt;izhx404@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt; ([`bc05a9d`](https://github.com/embeddings-benchmark/mteb/commit/bc05a9d39b60210fb676518faeab055aa1b5448d))

## v1.34.1 (2025-02-05)

### Documentation

* docs: Add instruction for running leaderboard (#1925)

* fix: Add instruction for running leaderboard

@x-tabdeveloping should we rename it from demo to app?

Fixes #1923

* Update README.md ([`d87d17e`](https://github.com/embeddings-benchmark/mteb/commit/d87d17e690b2d3e072e854d671965f7324eb3fe7))

### Fix

* fix: Changed callback for slider, accounted for None input (#1969)

Changed callback for slider, accounted for None input ([`4232427`](https://github.com/embeddings-benchmark/mteb/commit/4232427c61c3f0db474666134f00bbfe163a981c))

### Unknown

* Fix: Corrected model size for UAE (#1965) ([`a37e559`](https://github.com/embeddings-benchmark/mteb/commit/a37e559145a62b7e55413e402ce209df746d4f3f))

* Revert &#34;feat: Merge MIEB into main ðŸŽ‰ &#34; (#1957)

* Revert &#34;feat: Merge MIEB into main ðŸŽ‰  (#1944)&#34;

This reverts commit 6d63d0668552946bad5924092aa5864cfe442c93.

* Update extract_model_names.py

* make lint

* trigger CI

* make lint ([`2c62d21`](https://github.com/embeddings-benchmark/mteb/commit/2c62d219c2028c66171e6544fc4a6b00540cdf73))

* misc: add warnings (#1945)

* add warnings

* update warns

* add warning to metadata dict

* Update mteb/evaluation/MTEB.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`195e688`](https://github.com/embeddings-benchmark/mteb/commit/195e688485c6fc81e46d92e9c679e323f52acbf5))

* misc: lint main (#1961)

* lint main

* try 3.10

* make lint ([`cde11ae`](https://github.com/embeddings-benchmark/mteb/commit/cde11aede07557ff99ac99e8938ad68c457cd6de))

* Update ModelMeta of inf-retriever-v1 (#1964)

Update inf-retriever-v1 of bf16 version and max_tokens ([`c22f14d`](https://github.com/embeddings-benchmark/mteb/commit/c22f14dedae6394c59f41d447fe67b8dda3a7ddb))

## v1.34.0 (2025-02-04)

### Feature

* feat: Add new benchmark BEIR-NL  (#1909)

* BEIR-NL datasets

* BEIR-NL added to benchmarks

* BEIR-NL annotations_creators changed to derived

* BEIR-NL sample_creation clarified

* Update mteb/tasks/Retrieval/nld/MMARCONLRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Retrieval/nld/FEVERNLRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Retrieval/nld/ClimateFEVERNLRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* descriptions of models are changed to include BEIR-NL

* dates for BEIR-NL fixed

* more metadata annotations for BEIR-NL

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`de8f384`](https://github.com/embeddings-benchmark/mteb/commit/de8f384e11fdde2b960a9fda6ed574ca496bfdd5))

### Unknown

* Update tasks table ([`d162645`](https://github.com/embeddings-benchmark/mteb/commit/d162645abe2226fc14db21fb414e76e8210f0475))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`3036c05`](https://github.com/embeddings-benchmark/mteb/commit/3036c050726a77cd65537244bfd25e635c280027))

## v1.33.1 (2025-02-04)

### Fix

* fix: fix task types in MIEB (#1952) ([`a21f0b7`](https://github.com/embeddings-benchmark/mteb/commit/a21f0b74df99c23e3fec72cd5d577710e2391a60))

* fix: fix task types in MIEB ([`f43b661`](https://github.com/embeddings-benchmark/mteb/commit/f43b661c41a3e1bbe0628af9cf38382b4ca21fa4))

## v1.33.0 (2025-02-04)

### Feature

* feat: Merge MIEB into main ðŸŽ‰  (#1944)

* mieb ZeroshotClassification
* mieb docs
* mieb implementation demo
* model meta; abstask column names; linear probe clf
* model meta; abstask column names; linear probe clf
* fix: update naming as candidate_labels
* Update README.md
* Update README.md
* i2tretrieval
* test load data ignore i2tretrieval
* [MIEB] Add image clustering (#1088)
* make lint
* wip
* add TinyImageNet and run
* type hints
* add accuracy
* lint
* remove unused &amp; fix typos
* T2I Retrieval
* Any2AnyRetrieval
* fix tests from merge
* [MIEB] Add image text pair classification and tests (#1099)
* add ImageTextPairClassification abstask and evaluator
* dataset transform into sequence of images for each sample
* fix processing logic; list of list images compatability
* lint and docstrings
* make lint
* fix failing tests in TaskMetadata
* add tests for mieb
* skip gated repo
---------
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
* [MIEB] Add image classification and zero shot classification tasks (#1101)
* fix task metadata
* use overrideable column names
* add CIFAR datasets
* add caltech101 dataset
* add FGVC aircraft dataset
* add food 101 dataset
* add OxfordPets dataset
* remove comments
* correct cifar100 path
* update cifar100 classification results
* cifar zero shot results
* add caltech101 zero shot
* matching CLIP paper implementation
* add aircraft and food zero shot
* add oxford pets zero shot
* [MIEB] Add CIFAR clustering (#1104)
add CIFAR clustering
* [MIEB] Add more image classification and zero shot classification datasets (#1103)
* update category to i2t
* add MNIST linear probe and zero shot
* add FER2013 linear probe and zero shot
* add stanford cars linear probe and zero shot
* add birdsnap linear probe and zero shot
* add eurosat linear probe and zero shot
* lint
* correct eurosat zero shot labels
* add abstask for image multilable and voc2007
* make lint
* [MIEB] Add more image classification and zero shot datasets (#1105)
* add STL10 linear probe and zero shot
* add RESISC45 linear probe and zeor shot
* add Describable textures linear probe and zero shot
* fix spacing lint
* add SUN397 linear probe and zero shot
* correct SUN397 zero shot captions
* add baai bge vista
* add e5-v
* linting
* memory issues for image linear probe &amp; zeroshot
* kknn linear probe arguments
* del comments
* Add some classification and ZeroShot classification tasks (#1107)
* Add Country211 classification task
* Add imagenet1k classification task
* Add UCF101 classification task
* Add PatchCamelyon Classification task
* Add GTSRB classification task
* Add GSTRB Zero Shot Classification
* Add country211 zero shot classification
* Add results for classification tasks
* Add zero shot classification tasks
* Add PatchCamelyon tasks and results
* Add linting
* Add results and fix prompts for zero shot
* Add results
* Add results and linting
* fix dependency &amp; clip mock test
* [MIEB] Add jina clip (#1120)
* add jina clip and mscoco i2t and t2i results
* make lint
* [MIEB] Update `mieb` with the `main` branch and some fixes (#1126)
* fix instruction retrival (#1072)
* fix instruction retrival
* fix test
* add points
* make nested results
* add test
* skip instruction test
* fix instruction passes
* fix unions
* move do_length_ablation
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update points table
* fix: fix bug-causing spelling error in function name of e5-mistral-instruct (#1106)
found bug
* 1.12.85
Automatically generated by python-semantic-release
* fix: MultilingualSentimentClassification (#1109)
* Update points table
* fix: Avoid spaces in dataset name for CQADupstack and ignore speed tasks
* 1.12.86
Automatically generated by python-semantic-release
* fix: Ensure that MLSUMClusteringP2P.v2 use the fast implementation as was intended (#1112)
* fix: Ensure that MLSUMClusteringP2P.v2 use the fast implementation as was intended
* fix: fixed formatting for cli
* docs: improve searchability in the advanced usage documentation
* 1.12.87
Automatically generated by python-semantic-release
* docs: improve searchability in the advanced usage documentation (#1113)
* docs: improve searchability in the advanced usage documentation
* docs: update based on corrections
* fix: export type for `mteb create_meta` (#1114)
* fix export type
* fix dataset version too
* 1.12.88
Automatically generated by python-semantic-release
* fix: Simplify models implementations (#1085)
* Merge
* Adapt
* Simplify
* Check for rev again
* Rmv cmmnt
* Simplify
* simplify
* Rmv comment
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Use logging; change try except; add info
* Lint
* Rmv results
* Update rev
* format
* Simplify models; Allow instructions
* Jobs
* Fix merge
* Format
* Adapt models
* fix: ensure that e5 ignores the NQ
* format
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* 1.12.89
Automatically generated by python-semantic-release
* fix: nomic models using prefix correctly (#1125)
* fix: nomic models using prefix correctly
* chore: remove comment
* fix: handling in case not torch tensor
* Fix typo
---------
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
* 1.12.90
Automatically generated by python-semantic-release
* refactor vista model wrapper to contain lib import
* python 38 type hints
---------
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: anpalmak2003 &lt;73543260+anpalmak2003@users.noreply.github.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: Zach Nussbaum &lt;zanussbaum@gmail.com&gt;
Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
* image memoery issues for all retrieval Abstasks
* Add CLEVR and SciMMIR Image-Text Understanding tasks (#1127)
* Add CLEVER and SciMMIR
* Update metadata
* remove useless comment
* Add linting
* fix typo and tests
* Add CLEVR count task
* add linting
* add fashion200k &amp; fashionIQ test passed
* clip text max seq truncation
* add WebQA, NIGHTS, OVEN
* any2any retrieval chunk encoding
* add nomic vision model; any2any topk bug
* add cv recall
* add InfoSeek; VisualNews
* [MIEB] Add Stanford Cars i2i Retrieval (#1147)
* wip
* add results
* make lint
* change back the order
* [MIEB] Add CUB200 i2i retrieval (#1154)
* add cub200 and results
* add skip_first_result
* skipped self and rerun results
* consolidate i2t and t2i to any2any
* remove abstask and evaluators
* remove references from test
* tu-add berlin sketch retrieval
* XM3600; XFlickr30kCO; mutilingual
* wit multilingual retrieval t2i
* correct multilingual t2i meta
* meta
* add dinov2 model; 4 sizes
* cls evaluator channel bug fix
* add ALIGN model
* add FORBI2IRetrieval
* forb &amp; tuberlin new revision
* disable tokenization parallelism
* add hateful meme retrieval i2tt2i
* add memotion retrieval t2ii2t
* add SciMMIR Retrieval i2tt2i
* ruff update
* Visual STS Abstask&amp;evaluator
* add visual STS17
* add visual STS 12-16
* [mieb] Add blip and blip2 models, and ImageNetDog15Clustering task (#1226)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* [mieb] add 3 compositionality evaluation tasks (#1229)
* linting &amp; update unavailable dataset path
* add aro visual relation&amp;attribution; sugarcrepe
* correct reference
* add SOPI2IRetrieval dataset/task (#1232)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* change reference
* Image text pair cls (#1233)
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* fix meta data
* fix validate points
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Add RP2kI2IRetrieval and METI2IRetrieval (#1239)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* [MIEB] Adding DataComp CLIP models (#1283)
* adding data comp CLIP models
* update model and caltech101 results
* make lint
* [mieb] Any2TextMultipleChoice Abstask&amp;Evaluator &amp; four tasks in CV-bench (#1287)
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* fix meta data
* fix validate points
* CV-Bench
* evaluator args comment
* fix
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* [mieb] adding 10 tasks (#1290)
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* add vidore benchmark 10 tasks
* fix reference
* fix old metadata
* fix meta
* [mieb] Adding MOCOv3 models (#1293)
* add moco models first try
* add as a timm model
* add large model results
* make lint
* [mieb] Add more Any2AnyRetrieval datasets (#1285)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* add two landmark datasets and results
* add Sketchy i2i retrieval
* add task metadata
* add BLINKIT2IRetrieval dataset
* add BLINKIT2TRetrieval
* add ImageCoDeT2IRetrieval
* make lint
* add vizwiz retrieval and results
* fix vizwiz duplicate texts
* add new vizwiz results
* add VQA2 results
* add GLD v2 I2T retrieval
* add gld v2 i2i retrieval
* make lint
* remove GLDv2I2IRetrieval
* [mieb] Add any2any multiple choice evaluator and abstask (and one task) (#1301)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* add two landmark datasets and results
* add Sketchy i2i retrieval
* add task metadata
* add BLINKIT2IRetrieval dataset
* add BLINKIT2TRetrieval
* add ImageCoDeT2IRetrieval
* make lint
* add vizwiz retrieval and results
* fix vizwiz duplicate texts
* add new vizwiz results
* add VQA2 results
* add GLD v2 I2T retrieval
* add gld v2 i2i retrieval
* make lint
* add AbsTaskAny2AnyMultiChoice
* make lint
* remove GLDv2I2IRetrieval
* exclude AbsTaskAny2AnyMultiChoice from test_load_data
* [mieb] Fix FORB dataset (#1306)
* correct format
* update results
* add more results
* add more results
* [mieb] run tasks fix (#1302)
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* fix e5v&amp;vista
* task type fix for running tasks
* fix wrong meta
* run mieb script
* script
* lint
* align
* [mieb] split RParisI2IRetrieval and ROxfordI2IRetrieval into easy, medium and hard versions (#1305)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* add two landmark datasets and results
* add Sketchy i2i retrieval
* add task metadata
* add BLINKIT2IRetrieval dataset
* add BLINKIT2TRetrieval
* add ImageCoDeT2IRetrieval
* make lint
* add vizwiz retrieval and results
* fix vizwiz duplicate texts
* add new vizwiz results
* add VQA2 results
* add GLD v2 I2T retrieval
* add gld v2 i2i retrieval
* make lint
* add AbsTaskAny2AnyMultiChoice
* make lint
* remove GLDv2I2IRetrieval
* exclude AbsTaskAny2AnyMultiChoice from test_load_data
* fix e5v&amp;vista
* remove duplicate corpus entries from BLINKIT2TRetreival dataset
* task type fix for running tasks
* update BLINKIT2T metadata
* fix wrong meta
* run mieb script
* split ROxford, RParis into easy, medium and hard
* make lint
---------
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
* [mieb] run tasks small fix (#1310)
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* fix e5v&amp;vista
* task type fix for running tasks
* fix wrong meta
* run mieb script
* script
* lint
* align
* fix
* linting
* [mieb] Add VLM2vec (#1323)
* wip vlm2vec model
* making i2t classification work wit Calteh101
* test vlm2vec on other task types
* move peft into class
* feat: Merge main into MIEB (#1329)
* fix: OpenAI BadRequestError by limiting input dimensions to 2048 elemâ€¦ (#1203)
* fix: OpenAI BadRequestError by limiting input dimensions to 2048 elements (#1201)
Fix OpenAI BadRequestError by limiting input dimensions to 2048 elements
- Ensure the &#39;sentences&#39; list passed to OpenAI API does not exceed 2048 elements
- Reference: OpenAI&#39;s Embedding API documentation on input limits
Co-authored-by: Ali Shiraee &lt;ShiraeA@basfad.basf.net&gt;
* fix ruff formatting
* Added minor test fixes to ensure reproducility across systems
* Ensure that tmp.json is not created within repo when running tests
* format
* fixes path issues
* Rerun CI
---------
Co-authored-by: HSILA &lt;a.shiraee@gmail.com&gt;
Co-authored-by: Ali Shiraee &lt;ShiraeA@basfad.basf.net&gt;
* fix: Ensure STS pearson and spearman does not use the p-value only the correlation (#1207)
Fixes #1206
* 1.14.16
Automatically generated by python-semantic-release
* fix: Normalize licenses including casing, uses of &#34;-&#34; etc.
* fix: Normalize licenses including casing, uses of &#34;-&#34; etc. (#1210)
* fix: Normalize licenses including casing, uses of &#34;-&#34; etc.
* fix tests
* 1.14.17
Automatically generated by python-semantic-release
* fix: Normalize benchmarks no only include task objects and added getter for benchmarks (#1208)
* Normalize benchmarks to only include tasks
- Force benchmarks to only include tasks. This fixes a few bugs where benchmarks can reference a task which is not implemented
- implements `mteb.get_benchmark`, which makes it easier to fetch benchmarks
- Added tests + updated docs
A few outstanding issues:
I would like `mteb.MTEB(benchmark)` to always reproduce the benchmark. Currently this is not possible as MTEB(eng) required the split to be specified. A solution it to allow &#34;eval_splits) to be specified when initializing a task and then pass it on to the `load_data()`. This way we can write the following:
`mteb.get_tasks(tasks=[...], eval_splits=[&#34;test&#34;], ...)`
I would also love the aggregation to be a part of the benchmark (such that it is clear how it should be aggregated). This is especially relevant for MTEB(eng) as it average the CQAD datasets before creating the global average. This way we can also create a result object for the benchmark itself. A complimenting solution for this is to allow nested benchmarks.
* fix error in tests
* format
* Added corrections based on review
* added example and formatted
* 1.14.18
Automatically generated by python-semantic-release
* docs: Fix broken links in docs (#1212)
* Added fixes for broken links in adding_a_dataset and adding_a_model docs.
* Updated link name
* Mismatch of the category of AmazonPolarityClassification (#1220)
Fixes #1219
* Update tasks table
* fix: Ensure that results are returned even when hitting cache (#1215)
Fixes #1122
* 1.14.19
Automatically generated by python-semantic-release
* fix: Allow benchmark to specify eval_splits (#1217)
* fix: Allow benchmark to specify eval_splits
This PR allow for benchmarks to specify specific eval. splits. This allow us to fully specify a benchmark within the benchmark object.
To do this it add the following:
- added eval_splits to the Abstask object, which default to metadata.eval_splits
- use the task.eval_splits unless overwritten in mteb.MTEB.run
- added eval_splits arg to mteb.get_tasks, which filter the tasks based on splits
- updated documentation
  - renamed the &#34;Advanced Usage&#34; to &#34;Usage Documentation&#34; to make it more accicible
- added tests where relevant
* Added correction based on feedback
* 1.14.20
Automatically generated by python-semantic-release
* Update points table
* Update points table
* docs: clarify adding a model (#1222)
* fix: Add RepLLaMA style models (#1223)
* init commit
* working and reproducing
* lint
* update hashes
* warning
* add pyproject
* Update points table
* 1.14.21
Automatically generated by python-semantic-release
* docs: Update points (#1228)
* Fix case
* Fix casing
* Fix case
* Fix case
* Create 971.jsonl
* Update contrib
* Add contributors
* Update points table
* docs: Add MTEB(code) dataset (#1237)
* docs: Add MTEB(code) dataset
* Fix linting
* Update points table
* Update of my affiliation (#1242)
Update points.md
* Add contributor (#1243)
* fix: @mrshu&#39;s name in `points.md` (#1246)
* Use the diacritic character to be inline with Slovak spelling.
Signed-off-by: mr.Shu &lt;mr@shu.io&gt;
* docs: Create benchmarks overview table (#1245)
* fix get_benchmarks method
* add create benchmark script
* make lint
* 1.14.22
Automatically generated by python-semantic-release
* docs: Update affiliation (#1247)
Update points.md
* Added author-information
* Add final author list
* Update points table
* docs: Added coordination point for Jimmy Lee  (#1253)
docs: Added coordination point for Jimmy lee for his work on the coordination of Crystina and Nandan
* Update points table
* fix: Add multilingual Benchmark (#1252)
* fix: Add multilingual bench
* Update mteb/benchmarks/benchmarks.py
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
* format
---------
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
* 1.14.23
Automatically generated by python-semantic-release
* docs: Small point changes &amp; more contributors (#1254)
* Update points.md
* Fix format
* Fix attribution
* Update points table
* fix: Downsample large retrieval datasets (#1236)
* most tasks
* lint
* fix other issues
* refactor
* lint and docs
* add polish
* keep case sensitive mteb paths
* add potential points
* fix points
* fix test about metadata
* update tasks and stats
* lint
* Update points table
* Update tasks table
* 1.14.24
Automatically generated by python-semantic-release
* fix: Get meta from CrossEncoder (#1255)
* remove indent after return
* handle cross encoders for model meta
* make lint
* update filename since we now have model name
* 1.14.25
Automatically generated by python-semantic-release
* fix: Add listing all available benchmarks CLI option (#1256)
* add benchmarks.md in README
* add cli option
* add benchmark cli test case
* correct typo
* 1.14.26
Automatically generated by python-semantic-release
* docs: Update affiliation (#1248)
* Update points.md
* Update points.md
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* docs: Update mteb(eng) calculation (#1258)
* Update mteb(eng) calculation
* Fixed citations
* Update MTEB(eng) + MTEB(multilingual)
* feat: leverage SentenceTransformers&#39; query/passage specific prompts (#1221)
* feat: leverage SentenceTransformer models&#39; query/passage specific prompts
* refactor: remove E5Wrapper
fix: wrong e5 revisions
* fix: default prompt_type to None
* fix: e4ce987 revision no longer exists for multilingual-e5-small on the Hub
* fix: keep `prompt_name` in kwargs when model doesn&#39;t have a `prompts` attr
* feat: use Enum for `prompt_type`
* docs: specify how to use prompts with Sentence Transformers
* feat: readd arctic models due to metadata
* 1.15.0
Automatically generated by python-semantic-release
* fix: Add Touche2020v3 and JMTEB (#1262)
* add datasets
* fix metrics
* add Touche2020v3
* fix metadata
* Apply suggestions from code review
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* upd name and supress
* add benchmark class
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update tasks table
* 1.15.1
Automatically generated by python-semantic-release
* fix: Select benchmarks CLI option (#1261)
* add test case for a list of Benchmarks
* add selecting benchmarks CLI option
* typos
* use a separate attribute for benchmarks
* try fixing tests
* should accept string as well
* revert filename change
* use Benchmark and avoid circular import
* fix: derive `results_directory` path from `results_repo` name (#1275)
fix: don&#39;t hardcode repo name when downloading results
* 1.15.2
Automatically generated by python-semantic-release
* fix: sorting benchmark tasks by MTEB, then alphabetical (#1271)
* sorted
* fixed formatting
* efficiency changes
* fix test
* make lint
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* 1.15.3
Automatically generated by python-semantic-release
* ci: Removed 3.8 dependency (#1281)
Changes include:
- remove 3.8 from tests (added 3.11 and 3.12)
- changed other CI to 3.9
- updated lint rules to use 3.8
* Update points table
* fix: Allow Numpy &gt;=2.0 (#1264)
Allow Numpy &gt;=2.0
* 1.15.4
Automatically generated by python-semantic-release
* docs: points for paper writing (#1286)
* Create 1004.jsonl
* Create 1006.jsonl
* Update docs/mmteb/points/1004.jsonl
* Update docs/mmteb/points/1006.jsonl
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update points table
* Update points table
* Update points table
* docs: Fix a link in the README (#1289)
* Fix a link in the README
And fix some typos.
* Update README.md
* Update points table
* fix: Update benchmarks (#1288)
* make benchmark var name uppercase
* update touche to v3
* add MIRACLRetrievalHardNegatives to multilingual
* add mteb(indic)
* add eu benchmark
* 1.15.5
Automatically generated by python-semantic-release
* fix: Allow numpy&lt;2.0.0 (#1291)
* 1.15.6
Automatically generated by python-semantic-release
* fix: Add metadata dict to QBQTC in C-MTEB (#1292)
* fix QBQTC in C-MTEB
* make lint
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* 1.15.7
Automatically generated by python-semantic-release
* fix: Remove non-existent eval split of CMNLI (#1294)
fix eval_splits of CMNLI
* 1.15.8
Automatically generated by python-semantic-release
* Leaderboard (#1235)
* Add leaderboard dev
* Renamed MTEBResults to TaskResult
* Moved model and model meta loading utilities into overview.py
* Added get_model_metas to retrieve filtered metadata for models
* Restructured results object and made it into a class instead of a dict
* Added utilities for filtering models on BenchmarkResults objects
* Added to_table utility function to BenchmarkResults
* Added serialization utilities to BenchmarkResults
* Attempted fixing tests
* Added get_model_metas to __init__
* Added get_benchmarks to __init__ and made it return all benchmarks by default
* Added get_benchmarks to __init__
* Made tasks hashable
* Added task filtering based on task objects on BenchmarkResults
* Added BenchmarkResults to __init__
* Added additional arguments to get_scores on two classes
* Made get_scores smarter on BenchmarkResult
* Added basic multilingual benchmark
* Modified benchmark to be able to easily access results
* Added useful properties and filtering functions to BenchmarkResults
* Added minimal functioning example
* Added smarter table, task-list updating and tried fixing dropdown scrolling
* Made restrict_results into a private function
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Removed old leaderboard scripts
* Hardcoded max and min model size
* Removed redundant utils file
* Ran linting
* added leaderboard dependencies as optional
* Fixed union type error on Python 3.9
* Removed references to Dict in task aggregation
* Fixed name errors in _restrict_task_results
* Fixed _restrict_task_results
* Made hf_subsets={&#39;default&#39;} when the task is monolingual in _restric_task_results
* Task dropdown now gets filtered based on the other criteria
* Ran linting again
* Introduced hotfix for reranking test
* Added BenchmarkResults to __all__ in __init__
* Fixed validate_and_filter_scores method, and replaced _restric_task_results with it
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* feat: Use prompts instead of encode_corpus and encode_queries (#1278)
* add prompt per task type
* fix prompt
* upd test
* lint
* fix test
* fix DeprecatedSummarizationEvaluator
* fix prompts
* add test
* lint
* logger info
* use task type only in model_encode
* lint
* update interface
* add prompt types to docs
* fix test
* mock tasks
* mock task registry
* remove last task_type
* fix tests
* lint
* fix test
* fix
* use wrapper and new prompts
* fix tests
* lint
* fix test
* remove conftest
* validate task to prompt_name
* override model prompts
* task to prompt name optional
* fix tests
* fix models
* remove task_to_prompt_name
* remove from mteb __init__
* update docs
* load existing model prompts if model_prompts is None
* fix
* lint
* change wrapper loader
* add wrapper class
* lint
* add wrapper file
* update logging
* upd logging
* refactor reranking
* lint
* remove prints
* 1.16.0
Automatically generated by python-semantic-release
* fix: Add Retrieval SK Quad dataset for Slovak search evaluation (#1276)
* Add Retrieval SK Quad dataset for Slovak search evaluation
This commit introduces the Retrieval SK Quad dataset, designed to assess Slovak search performance. The dataset is derived from SK-QuAD and includes questions with their best answers categorized post-annotation. This addition provides a significant resource for advancing Slovak language search evaluation and supporting further research and development.
* Add Retrieval SK Quad dataset for Slovak search evaluation 2
Added the requested changes on the SKQuadRetrieval.py file
* add task to init
* add missing task metadata
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update tasks table
* 1.16.1
Automatically generated by python-semantic-release
* fix: Add Slovak Hate Speech and Offensive Language Dataset (#1274)
* Add Slovak Hate Speech and Offensive Language
Dataset
This commit introduces the Slovak Hate Speech and Offensive Language Database to MTEB. The dataset includes posts from a social network, annotated by humans for hate speech and offensive content. Additionally, the corresponding task has been added to the tasks.md table to reflect this update.
* Add Slovak Hate Speech and Offensive Language Dataset
- Updated __init__.py to include the new SlovakHateSpeechClassification task.
- Modified SlovakHateSpeechClassification.py as per review suggestions to enhance functionality and readability.
* Did requested changes:
- Updated __init__.py to include the new SlovakHateSpeechClassification task.
- Modified SlovakHateSpeechClassification.py as per review suggestions to enhance functionality and readability.
* resolve linting issues by running `make lint`
* Update tasks table
* WIP: Leaderboard UI improvements (#1312)
* Fixed typos in task_results
* Fixed typos in task_results
* Added Tailwind, reorganized layout and fixed scrolling
* Ran linting
* 1.16.2
Automatically generated by python-semantic-release
* fix: remove duplicate multilingual
* 1.16.3
Automatically generated by python-semantic-release
* fix: Re-upload dataset to hub to avoid using script upload (#1322)
* fix dataset upload
* add linting
* Update tasks table
* 1.16.4
Automatically generated by python-semantic-release
* fix: Add implementations of common reranker models (#1309)
* init
* revert
* revert
* add metadata
* lint
* add reqs
* change to float16
* benchmark lint fix
* 1.16.5
Automatically generated by python-semantic-release
* Add multilingual mFollowIR dataset (#1308)
* add mFollowIR
* paper name
* edit warning-&gt;info
* convert to parquet
* lint
* Update tasks table
* Cache the embeddings when requested (#1307)
* add caching
* update test to use close
* change from json to pkl
* fix for window
* cleanup on Windows again
* infer dimension
* move cachewrapper
* add wrapper
* fix
* updates
* fix tests
* fix lint
* lint
* add test
* WIP: Leaderboard UI improvements (#1320)
* Fixed typos in task_results
* Fixed typos in task_results
* Added Tailwind, reorganized layout and fixed scrolling
* Ran linting
* Removed faux benchmark
* Updated layout
* Changed table number format
* Table highlights highest values by making them bold
* Added rank to table, removed organization from model_name
* Added mean rank to table
* Ran linting
* feat: Update metadata for all models (#1316)
* Added model meta
* format
* fixed metadata
* Metadata update for voyage models
* Update mteb/models/cohere_models.py
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
* Update mteb/models/cohere_models.py
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
* Added corrections from review
* fix spelling error
---------
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
* resolved bugs from pytest --collect-only
* Avoid wrapping all models with the SentenceTransformerWrapper
* Added normalize_embeddings_to_numpy to ensure standard embeddings during evaluations
* fixed moved on correction from @Samoed
* conditionally set .predict method on SentenceTransformerWrapper
---------
Signed-off-by: mr.Shu &lt;mr@shu.io&gt;
Co-authored-by: HSILA &lt;a.shiraee@gmail.com&gt;
Co-authored-by: Ali Shiraee &lt;ShiraeA@basfad.basf.net&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Thomas van Dongen &lt;thomas123@live.nl&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: Orion Weller &lt;31665361+orionw@users.noreply.github.com&gt;
Co-authored-by: John Yang &lt;byjohnyang@gmail.com&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: Marek Å uppa &lt;mrshu@users.noreply.github.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Xa9aX ãƒ„ &lt;mishradiganta91@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel@buad.es&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel.buades@clinia.com&gt;
Co-authored-by: Sathvik Nallamalli &lt;sathviknallamalli@gmail.com&gt;
Co-authored-by: Michael Graczyk &lt;michael@mgraczyk.com&gt;
Co-authored-by: Mariya Hendriksen &lt;35101262+mariyahendriksen@users.noreply.github.com&gt;
Co-authored-by: Santiago Castro &lt;bryant1410@gmail.com&gt;
Co-authored-by: Joey Xia &lt;77958037+ZiyiXia@users.noreply.github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
Co-authored-by: Oliver &lt;oliver.pejic@students.fhnw.ch&gt;
* [mieb] Add OpenCLIP models (#1335)
* add open clip models
* Update __init__.py
* lint
* fix model overview
* update jina clip
---------
Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
Co-authored-by: gowitheflow-1998 &lt;chenghao.xiao@durham.ac.uk&gt;
* [mieb] new version with downsampled train split to 32 per class (#1327)
* new version with downsampled train split to 32 per class
* force load truncated image file
* make lint
* add open clip models
* Update __init__.py
* lint
* fix model overview
* fix ImageCLS undersample; run birdsnap
* make lint
* make lint
---------
Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
Co-authored-by: gowitheflow-1998 &lt;chenghao.xiao@durham.ac.uk&gt;
* [mieb] Fix Jina CLIP (#1349)
fix jina clip v1
* fix: Add clevr license (#1356)
* Add BLINK as multi-choice tasks (#1348)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* add two landmark datasets and results
* add Sketchy i2i retrieval
* add task metadata
* add BLINKIT2IRetrieval dataset
* add BLINKIT2TRetrieval
* add ImageCoDeT2IRetrieval
* make lint
* add vizwiz retrieval and results
* fix vizwiz duplicate texts
* add new vizwiz results
* add VQA2 results
* add GLD v2 I2T retrieval
* add gld v2 i2i retrieval
* make lint
* add AbsTaskAny2AnyMultiChoice
* make lint
* remove GLDv2I2IRetrieval
* exclude AbsTaskAny2AnyMultiChoice from test_load_data
* fix e5v&amp;vista
* remove duplicate corpus entries from BLINKIT2TRetreival dataset
* task type fix for running tasks
* update BLINKIT2T metadata
* fix wrong meta
* run mieb script
* split ROxford, RParis into easy, medium and hard
* make lint
* add BLINK as multi choice tasks
* fix: license metadata in wrong format
---------
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
* [mieb] add Eva CLIP models (#1369)
* add Eva CLIP models
* make lint
* [mieb] add siglip, cohere multimodal &amp; some fixes for final run (#1357)
* fix dataset type error
* fix clustering metrics
* add siglip &amp; cohere
* update mieb run script
* cohere-v import
* fix
* api key name
* [mieb] fixes for final run (#1374)
* e5_v device arg
* dataloader num_workers
* vista doc
* vista doc
* run mieb
* fix
* Update run_vista.md
* [mieb] Fix torch no grad (#1378)
Fix torch no grad
* [mieb] Fix vlm2vec (#1380)
* fix vlm2vec return dtype
* make lint
* [mieb] Remove null entries from corpus of ROxford, RParis (#1371)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* add two landmark datasets and results
* add Sketchy i2i retrieval
* add task metadata
* add BLINKIT2IRetrieval dataset
* add BLINKIT2TRetrieval
* add ImageCoDeT2IRetrieval
* make lint
* add vizwiz retrieval and results
* fix vizwiz duplicate texts
* add new vizwiz results
* add VQA2 results
* add GLD v2 I2T retrieval
* add gld v2 i2i retrieval
* make lint
* add AbsTaskAny2AnyMultiChoice
* make lint
* remove GLDv2I2IRetrieval
* exclude AbsTaskAny2AnyMultiChoice from test_load_data
* fix e5v&amp;vista
* remove duplicate corpus entries from BLINKIT2TRetreival dataset
* task type fix for running tasks
* update BLINKIT2T metadata
* fix wrong meta
* run mieb script
* split ROxford, RParis into easy, medium and hard
* make lint
* add BLINK as multi choice tasks
* fix: license metadata in wrong format
* remove null examples from corpus of ROxford and RParis
---------
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
* [mieb] fixes (#1390)
* Fix torch no grad
* simplify
* make lint
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* [MIEB] Remove non-existent method for blip (#1394)
remove non-existent method for blip
* [mieb] fix ALIGN; update Winoground revision id; update run script (#1391)
* fix align &amp; winoground
* lint
* Convert task category to i2i for tasks that only calls image encode
* update categories should include img cls, clustering, and multi label clf
* no op
* no op
* make lint
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* [mieb] Fix open clip for cv bench count (#1397)
fix shape mismatch
* [mieb] Update subtasks of BLINKIT2TMultiChoice and BLINKIT2IMultiChoice (#1403)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* add two landmark datasets and results
* add Sketchy i2i retrieval
* add task metadata
* add BLINKIT2IRetrieval dataset
* add BLINKIT2TRetrieval
* add ImageCoDeT2IRetrieval
* make lint
* add vizwiz retrieval and results
* fix vizwiz duplicate texts
* add new vizwiz results
* add VQA2 results
* add GLD v2 I2T retrieval
* add gld v2 i2i retrieval
* make lint
* add AbsTaskAny2AnyMultiChoice
* make lint
* remove GLDv2I2IRetrieval
* exclude AbsTaskAny2AnyMultiChoice from test_load_data
* fix e5v&amp;vista
* remove duplicate corpus entries from BLINKIT2TRetreival dataset
* task type fix for running tasks
* update BLINKIT2T metadata
* fix wrong meta
* run mieb script
* split ROxford, RParis into easy, medium and hard
* make lint
* add BLINK as multi choice tasks
* fix: license metadata in wrong format
* remove null examples from corpus of ROxford and RParis
* fix: add/remove subtasks from BLINKIT2IMultiChoice and BLINKIT2TMultiChoice
* update blink metadata
* add updated BLINK results
---------
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
* [mieb] Fix EVA CLIP for CV Bench (#1414)
* unsqueeze after preprocess
* make lint
* [mieb] Add calculate probs for vlm2vec (#1418)
* add method
* make lint
* [mieb] Fix siglip bug &amp; add retrieval datasets (#1424)
* fix siglip
* add edis&amp;gld-v2 i2i
* results
* siglip updated results
* fix siglip non-dataloader tasks
* [mieb] use Logistic Regression classifier for AbsTaskImageMultilabelClassification (#1420)
* use moc-lr classifier
* set n_experiments=5
* run dinov2 and some laion models
* add dinov2-giant results
* [mieb] mieb scripts (siglip rerun &amp; linear probing ablation &amp; params count) (#1429)
* mieb scripts
* lint
* [MIEB] Change Flickr30k to test split (#1449)
* wip: start adding BLIP models
* add other blip variants
* wip: add blip2_models.py
* make lint
* wip: implement blip2 wrapper
* feat: add blip2 models, still mismatched names
* fix: remove projections from image and text embeddings
* make lint
* wip: add coco BLIP2
* fix: BLIP2 better zero-shot classification without text_proj and vision_proj
* tidy blip2
* add imagenet-dog-15 dataset
* tidy and lint
* remove unused import
* add cluster_accuracy, ari and nmi to Image.ClusteringEvaluator
* add imagenet-10 clustering task
* add SOPI2IRetrieval
* add results forclip on ImageNet10Clustering and ImageNetDog15Clustering
* add SOPI2IRetrieval results for clip 32
* add results for clip vit 32/SOPI2IRetrieval
* resolve conflict
* add RP2kI2IRetrieval dataset
* add RP2kI2IRetrieval results with clip-vit-base-patch32
* update image retrieval __init__.py
* fix ImageTextPair dataloading for large datasets; more compositionality evaluation datasets
* add RP2kI2IRetrieval and METI2IRetrieval
* add METI2IRetreival
* add SOP results
* make lign
* new revision for METI2IRetrieval
* make lint
* reset corpus chunk size
* remove wrong classification import
* add Flickr30k T2I and I2T
* add Flickr30k T2I retriebal
* reduced-size MET revision
* fix: add Flickr30k T2I
* make lint
* add two landmark datasets and results
* add Sketchy i2i retrieval
* add task metadata
* add BLINKIT2IRetrieval dataset
* add BLINKIT2TRetrieval
* add ImageCoDeT2IRetrieval
* make lint
* add vizwiz retrieval and results
* fix vizwiz duplicate texts
* add new vizwiz results
* add VQA2 results
* add GLD v2 I2T retrieval
* add gld v2 i2i retrieval
* make lint
* add AbsTaskAny2AnyMultiChoice
* make lint
* remove GLDv2I2IRetrieval
* exclude AbsTaskAny2AnyMultiChoice from test_load_data
* fix e5v&amp;vista
* remove duplicate corpus entries from BLINKIT2TRetreival dataset
* task type fix for running tasks
* update BLINKIT2T metadata
* fix wrong meta
* run mieb script
* split ROxford, RParis into easy, medium and hard
* make lint
* add BLINK as multi choice tasks
* fix: license metadata in wrong format
* remove null examples from corpus of ROxford and RParis
* fix: add/remove subtasks from BLINKIT2IMultiChoice and BLINKIT2TMultiChoice
* update blink metadata
* add updated BLINK results
* merge upstream mieb
* change Flickr30k to test split
* change flickr to test split
---------
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
* [mieb] Fix VLM2vec dtype (#1462)
* propagate dtype
* fix fuse embeddings using list of PIL images
* [mieb] run script for missing results (#1472)
* task type fix
* scripts
* [mieb] Fix Moco model on CIFAR10Clustering (#1487)
Fix Moco model on CIFAR10Clustering
* [mieb] Fix Flickr30k I2T and T2I (#1505)
* remake flickr30k it2 and t2i
* add openai clip vit-b32 b16 and jina-clip results
* make lint
* [MIEB] add missing siglip models  (#1533)
* add udpates
* lint errors
* fix typo (#1535)
* add udpates
* lint errors
* fix small typo
* [mieb] Fix numbers of CIRR, Fashion200k, FashionIQ, Flickr30k, MSCOCO data statistics (#1544)
fix numbers
* Discussing a standard for ImageEncoders
* Add Voyage&#39;s multimodal embedding (#1555)
* add voyage multimodal &amp; ran 17 tasks
* lint
* typo
* clean
* [mieb] update script for final re-run (#1576)
* mieb final runs
* lint
* fix: no longer using same query text for all of BLINKIT2TMultiChoice (#1572)
* fix: no longer using same query text for all of BLINKIT2TMultiChoice
* fix: remove blink subtask
* fix: remove subtask from blink it2i
* fix: align BLINK retrieval to multi choice
* add ROxford and RParis I2I multi choice
* add retrieval metrics to multi choice evaluator
* fix: remove wrong negatives from revisiting multichoice datasets
* fix revisiting datasets
* add new results for revisiting multichoice
* [MIEB] Make multimodal models compatible to `task_name` and `prompt_type` (#1583)
* 1. Make `get_xxx_embeddings` follow `encode`.
2. `ImageDataset.transform` could be `None`.
* Apply suggestions from code review
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Fix arguments
* Try to fix tests
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* fix image encoder (#1596)
* format
* fixed tests
* lint
* [mieb] voyage-v: add exponential backoff and other error handling (#1610)
* add voyage multimodal &amp; ran 17 tasks
* lint
* typo
* clean
* exponential backoff tmp
* downsize large images for voyage api call
* voyage error handling
* lint
* add more results
* make tenacity optional
* lint
* log
* [MIEB] Fix `get_fused_emebddings` (#1612)
* Fix fused
* fix vlm2vec
* Fix lint
* [MIEB] Add new multimodal retrieval tasks (#1611)
* Add new tasks
* Fix score type
* [MIEB] Switch to ViDoRe BEIR version (#1607)
* Fix ViDoRe corpus
* fix lint
* ViDoRe beir version
* Extend MIEB test coverage (#1629)
* add one task from each image AbsTask to test grid
* add visual sts to test grid
* [mieb] Task filtering by modality supported by models (#1633)
* fix function signature for moco loader
* filter out tasks by model modalities
* correct conditions
* add model meta to relevant models
* use modalities instead and separate out constants
* [MIEB] Fix VISTA model (#1638)
Fix vista
* Warn (#1639)
* [mieb] model task modalities matching logic (#1640)
fixing task &amp; model modalities matching logic
* [mieb] Use mock abstask classes (#1648)
* rename to downsampled_dataset_transform
* add mock tasks for mieb
* wip getting to 57%
* make lint
* update mock classes to improve coverage
* omit mock tasks from some tests
* [MIEB] Add code for GME models (#1635)
* Add GME
* Fix infoseek prompts
* Merge instructions
* fix: add version check e5-v in mieb (#1723)
* add version check for e5v model
* Update e5_v.py
* make lint
* fix: change comparison to bigger than (#1743)
change comparison to bigger than
* docs: Rework MIEB docs (#1802)
* combine mieb docs and move to main docs folder
* make flow more coherent
* tidy up
* skip AfriSentiLID for now #1785
* fix typo: exclude MIEB mock tests
* update vista doc
* Apply suggestions from code review
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* [mieb] Remove results-mieb folder (#1815)
remove results-mieb folder
* [mieb] fixing lrap computation for multi-label classification (#1834)
multi-label cls lrap computation fix
* [mieb] Merge from main (#1853)
* Update tasks table
* 1.19.0
Automatically generated by python-semantic-release
* fix: Add the_ugly_duckling.txt for speedtask to Python wheel (#1402)
Add the_ugly_duckling.txt for speedtask to Python wheel
* 1.19.1
Automatically generated by python-semantic-release
* fix: Added the necessary trust_remote_code (#1406)
* 1.19.2
Automatically generated by python-semantic-release
* docs: Update recommendation for pushing results (#1401)
fix: Update recommendation for pushing results
* docs: Fix a typo in README (#1430)
Fix typo in readme
* fix: add logging for RetrievalEvaluator NaN values for similarity scores (#1398)
Fixes #1389
* 1.19.3
Automatically generated by python-semantic-release
* fix: make samples_per_label a task attribute (#1419)
make samples_per_label a task attr
* fix: Add Korean AutoRAGRetrieval (#1388)
* feat: add AutoRAG Korean embedding retrieval benchmark
* fix: run --- ðŸ§¹ Running linters ---
ruff format . 			# running ruff formatting
716 files left unchanged
ruff check . --fix  	# running ruff linting
All checks passed!
* fix: add metadata for AutoRAGRetrieval
* change link for markers_bm
* add AutoRAGRetrieval to init.py and update metadata
* add precise metadata
* update metadata: description and license
* delete descriptive_stats in AutoRAGRetrieval.py and run calculate_matadata_metrics.py
* fix: Add missing benchmarks in benchmarks.py (#1431)
Fixes #1423
* Update tasks table
* 1.19.4
Automatically generated by python-semantic-release
* Leaderboard 2.0: added performance x n_parameters plot + more benchmark info (#1437)
* Added elementary speed/performance plot
* Refactored table formatting code
* Bumped Gradio version
* Added more general info to benchmark description markdown block
* Adjusted margin an range on plot
* Made hover information easier to read on plot
* Made range scaling dynamic in plot
* Moved citation next to benchmark description
* Made titles in benchmark info bold
* Leaderboard: Fixed code benchmarks (#1441)
* fixed code benchmarks
* fix: Made n_parameters formatting smarter and more robust
* fix: changed jina-embeddings-v3 number of parameters from 572K to 572M
* fix: Fixed use_instuctions typo in model overview
* fix: Fixed sentence-transformer compatibility switch
* Ran linting
* Added all languages, tasks, types and domains to options
* Removed resetting options when a new benchmark is selected
* All results now get displayed, but models that haven&#39;t been run on everything get nan values in the table
* fix: Count unique texts, data leaks in calculate metrics (#1438)
* add more stat
* add more stat
* update statistics
* fix: update task metadata to allow for null (#1448)
* Update tasks table
* 1.19.5
Automatically generated by python-semantic-release
* Fix: Made data parsing in the leaderboard figure more robust (#1450)
Bugfixes with data parsing in main figure
* Fixed task loading (#1451)
* Fixed task result loading from disk
* Fixed task result loading from disk
* fix: publish (#1452)
* 1.19.6
Automatically generated by python-semantic-release
* fix: Fix load external results with `None` mteb_version (#1453)
* fix
* lint
* 1.19.7
Automatically generated by python-semantic-release
* WIP: Polishing up leaderboard UI (#1461)
* fix: Removed column wrapping on the table, so that it remains readable
* Added disclaimer to figure
* fix: Added links to task info table, switched out license with metric
* fix: loading pre 1.11.0 (#1460)
* small fix
* fix: fix
* 1.19.8
Automatically generated by python-semantic-release
* fix: swap touche2020 to maintain compatibility (#1469)
swap touche2020 for parity
* 1.19.9
Automatically generated by python-semantic-release
* docs: Add sum per language for task counts (#1468)
* add sum per lang
* add sort by sum option
* make lint
* fix: pinned datasets to &lt;3.0.0 (#1470)
* 1.19.10
Automatically generated by python-semantic-release
* feat: add CUREv1 retrieval dataset (#1459)
* feat: add CUREv1 dataset
---------
Co-authored-by: nadshe &lt;nadia.sheikh@clinia.com&gt;
Co-authored-by: olivierr42 &lt;olivier.rousseau@clinia.com&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel@buad.es&gt;
* feat: add missing domains to medical tasks
* feat: modify benchmark tasks
* chore: benchmark naming
---------
Co-authored-by: nadshe &lt;nadia.sheikh@clinia.com&gt;
Co-authored-by: olivierr42 &lt;olivier.rousseau@clinia.com&gt;
* Update tasks table
* 1.20.0
Automatically generated by python-semantic-release
* fix: check if `model` attr of model exists (#1499)
* check if model attr of model exists
* lint
* Fix retrieval evaluator
* 1.20.1
Automatically generated by python-semantic-release
* fix: Leaderboard demo data loading (#1507)
* Made get_scores error tolerant
* Added join_revisions, made get_scores failsafe
* Fetching metadata fixed fr HF models
* Added failsafe metadata fetching to leaderboard code
* Added revision joining to leaderboard app
* fix
* Only show models that have metadata, when filter_models is called
* Ran linting
* 1.20.2
Automatically generated by python-semantic-release
* fix: leaderboard only shows models that have ModelMeta (#1508)
Filtering for models that have metadata
* 1.20.3
Automatically generated by python-semantic-release
* fix: align readme with current mteb (#1493)
* align readme with current mteb
* align with mieb branch
* fix test
* 1.20.4
Automatically generated by python-semantic-release
* docs: Add lang family mapping and map to task table (#1486)
* add lang family mapping and map to task table
* make lint
* add back some unclassified lang codes
* Update tasks table
* fix: Ensure that models match the names on embedding-benchmarks/results (#1519)
* 1.20.5
Automatically generated by python-semantic-release
* fix: Adding missing metadata on models and mathcing names up with the results repo (#1528)
* Added Voyage 3 models
* Added correct metadata to Cohere models and matched names with the results repo
* 1.20.6
Automatically generated by python-semantic-release
* feat: Evaluate missing splits (#1525)
* fix: evaluate missing splits (#1268)
* implement partial evaluation for missing splits
* lint
* requested changes done from scratch
* test for missing split evaluation added
* uncomment test
* lint
* avoid circular import
* use TaskResult
* skip tests for now
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* got test_all_splits_evaluated passing
* tests passing
* address review comments
* make lint
* handle None cases for kg_co2_emissions
* use new results info
---------
Co-authored-by: Thivyanth &lt;thivyanth2004@gmail.com&gt;
* 1.21.0
Automatically generated by python-semantic-release
* fix: Correct typos superseeded -&gt; superseded (#1532)
fix typo -&gt; superseded
* 1.21.1
Automatically generated by python-semantic-release
* fix: Task load data error for SICK-BR-STS and XStance (#1534)
* fix task load data for two tasks
* correct dataset keys
* 1.21.2
Automatically generated by python-semantic-release
* fix: Proprietary models now get correctly shown in leaderboard (#1530)
* Fixed showing proprietary models in leaderboard
* Added links to all OpenAI models
* Fixed table formatting issues
* Bumped Gradio version
* 1.21.3
Automatically generated by python-semantic-release
* docs: Add Model Meta parameters and metadata (#1536)
* add multi_qa_MiniLM_L6_cos_v1 model meta
* add all_mpnet_base_v2
* add parameters to model meta
* make lint
* add extra params to meta
* fix: add more model meta (jina, e5) (#1537)
* add e5 model meta
* address review comments
* 1.21.4
Automatically generated by python-semantic-release
* Add cohere models (#1538)
* fix: bug cohere names
* format
* fix: add nomic models (#1543)
#1515
* fix: Added all-minilm-l12-v2 (#1542)
#1515
* fix: Added arctic models (#1541)
#1515
* fix: add sentence trimming to OpenAIWrapper (#1526)
* fix: add sentence trimming to OpenAIWrapper
* fix: import tiktoken library inside encode function
* fix: check tokenizer library installed and update ModelMeta to pass tokenizer_name
* fix: pass tokenizer_name, max_tokens to loader
* fix: make tokenizer_name None for default
* fix: delete changes for ModelMeta
* fix: fix revision to 2 for OpenAI models
* fix: add docstring for OpenAIWrapper
* fix: lint
* feat: add openai optional dependency set
* fix: add sleep for too many requests
* fix: add lint
* fix: delete evaluate file
* 1.21.5
Automatically generated by python-semantic-release
* fix: Fixed metadata errors (#1547)
* 1.21.6
Automatically generated by python-semantic-release
* fix: remove curev1 from multlingual (#1552)
Seems like it was added here:
https://github.com/embeddings-benchmark/mteb/commit/1cc6c9e0fe62ca4e77708b641823fa1a121f048b
* 1.21.7
Automatically generated by python-semantic-release
* fix: Add Model2vec (#1546)
* Added Model2Vec wrapper
* Added Model2vec models
* Added model2vec models to registry
* Added model2vec as a dependency
* Ran linting
* Update mteb/models/model2vec_models.py
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update mteb/models/model2vec_models.py
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Added adapted_from and superseeded_by to model2vec models.
* Added missing import
* Moved pyproject.toml to optional dependencies
* Fixed typos
* Added import error and changed model to model_name
* Added Numpy to frameworks
* Added Numpy to frameworks
* Corrected false info on model2vec models
* Replaced np.inf with maxint
* Update mteb/models/model2vec_models.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Added option to have infinite max tokens, added it to Model2vec
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Made result loading more permissive, changed eval splits for HotPotQA and DBPedia (#1554)
* Removed train and dev from eval splits on HotpotQA
* Removed dev from eval splits on DBPedia
* Made task_results validation more permissive
* Readded exception in get_score
* Ran linting
* 1.21.8
Automatically generated by python-semantic-release
* docs: Correction of SICK-R metadata (#1558)
* Correction of SICK-R metadata
* Correction of SICK-R metadata
---------
Co-authored-by: rposwiata &lt;rposwiata@opi.org.pl&gt;
* feat(google_models): fix issues and add support for `text-embedding-005` and `text-multilingual-embedding-002` (#1562)
* fix: google_models batching and prompt
* feat: add text-embedding-005 and text-multilingual-embedding-002
* chore: `make lint` errors
* fix: address PR comments
* 1.22.0
Automatically generated by python-semantic-release
* fix(bm25s): search implementation (#1566)
fix: bm25s implementation
* 1.22.1
Automatically generated by python-semantic-release
* docs: Fix dependency library name for bm25s (#1568)
* fix: bm25s implementation
* correct library name
---------
Co-authored-by: Daniel Buades Marcos &lt;daniel.buades@clinia.com&gt;
* fix: Add training dataset to model meta (#1561)
* fix: Add training dataset to model meta
Adresses #1556
* Added docs
* format
* feat: (cohere_models) cohere_task_type issue, batch requests and tqdm for visualization (#1564)
* feat: batch requests to cohere models
* fix: use correct task_type
* feat: use tqdm with openai
* fix: explicitely set `show_progress_bar` to False
* fix(publichealth-qa):  ignore rows with `None` values in `question` or `answer` (#1565)
* 1.23.0
Automatically generated by python-semantic-release
* fix: Added metadata for miscellaneous models (#1557)
* Added script for generating metadata, and metadata for the listed models
* Added misc models to overview
* Fixed misc metas
* Removed unnecessary imports
* Added logic to retrieve base model information
* Added base models to misc meta
* Added superseded_by to sentence-croissant models
* Added training datasets to mis models
* 1.23.1
Automatically generated by python-semantic-release
* fix: Added radar chart displaying capabilities on task types (#1570)
* Added radar chart displaying capabilities on task types
* Fixed table aggregation in leaderboard
* Spelled out why instructionretrieval is excluded
* 1.23.2
Automatically generated by python-semantic-release
* feat: add new arctic v2.0 models (#1574)
* feat: add new arctic v2.0 models
* chore: make lint
* 1.24.0
Automatically generated by python-semantic-release
* fix: Add namaa MrTydi reranking dataset (#1573)
* Add dataset class and file requirements
* pass tests
* make lint changes
* adjust meta data and remove load_data
---------
Co-authored-by: Omar Elshehy &lt;omarelshehy@Omars-MacBook-Pro.local&gt;
* Update tasks table
* 1.24.1
Automatically generated by python-semantic-release
* fix: Eval langs not correctly passed to monolingual tasks (#1587)
* fix SouthAfricanLangClassification.py
* add check for langs
* lint
* 1.24.2
Automatically generated by python-semantic-release
* feat: Add ColBert (#1563)
* feat: add max_sim operator for IR tasks to support multi-vector models
* docs: add doc for Model2VecWrapper.__init__(...)
* feat: add ColBERTWrapper to models &amp; add ColBERTv2
* fix: resolve issues
* fix: resolve issues
* Update README.md
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
* Update README.md
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update README.md
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update mteb/evaluation/evaluators/RetrievalEvaluator.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update README.md
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* README.md: rm subset
* doc: update example for Late Interaction
* get colbert running without errors
* fix: pass is_query to pylate
* fix: max_sim add pad_sequence
* feat: integrate Jinja templates for ColBERTv2 and add model prompt handling
* feat: add revision &amp; prompt_name
* doc: pad_sequence
* rm TODO jina colbert v2
* doc: warning: higher resource usage for MaxSim
---------
Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* 1.25.0
Automatically generated by python-semantic-release
* doc: colbert add score_function &amp; doc section (#1592)
* doc: colbert add score_function &amp; doc section
* doc: Update README.md
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* doc: Update README.md
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
---------
Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Feat: add support for scoring function (#1594)
* add support for scoring function
* lint
* move similarity to wrapper
* remove score function
* lint
* remove from InstructionRetrievalEvaluator
* Update mteb/evaluation/evaluators/RetrievalEvaluator.py
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* remove score function from README.md
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Add new models nvidia, gte, linq (#1436)
* Add new models nvidia, gte, linq
* add warning for gte-Qwen and nvidia models re: instruction used in docs as well
---------
Co-authored-by: isaac-chung &lt;chungisaac1217@gmail.com&gt;
* Leaderboard: Refined plots (#1601)
* Added embedding size guide to performance-size plot, removed shading on radar chart
* Changed plot names to something more descriptive
* Made plots failsafe
* fix: Leaderboard refinements (#1603)
* Added explanation of aggregate measures
* Added download button to result tables
* Task info gets sorted by task name
* Added custom, shareable links for each benchmark
* Moved explanation of aggregate metrics to the summary tab
* 1.25.1
Automatically generated by python-semantic-release
* Feat: Use similarity scores if available (#1602)
* Use similarity scores if available
* lint
* Add NanoBEIR Datasets (#1588)
* add NanoClimateFeverRetrieval task, still requires some debugging
* move task to correct place in init file
* add all Nano datasets and results
* format code
* Update mteb/tasks/Retrieval/eng/tempCodeRunnerFile.py
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
* pin revision to commit and add datasets to benchmark.py
* create new benchmark for NanoBEIR
* add revision when loading datasets
* lint
---------
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: isaac-chung &lt;chungisaac1217@gmail.com&gt;
* Update tasks table
* Feat: Evaluate missing languages (#1584)
* init
* fix tests
* update mock retrieval
* update tests
* use subsets instead of langs
* Apply suggestions from code review
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* fix tests
* add to readme
* rename subset in readme
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Add IBM Granite Embedding Models (#1613)
* add IBM granite embedding models
* lint formatting
* add adapted_from and superseded_by to ModelMeta
* fix: disable co2_tracker for API models (#1614)
* 1.25.2
Automatically generated by python-semantic-release
* fix: set `use_instructions` to True in models using prompts (#1616)
feat: set `use_instructions` to True in models using prompts
* 1.25.3
Automatically generated by python-semantic-release
* fix: override existing results (#1617)
* fix override existing results
* lint
* fix tests
* add tests with overwrite
* lint
* update tests
* lint
* update
* lint
* 1.25.4
Automatically generated by python-semantic-release
* add MSMARCO eval split in MTEB English (classic) benchmark (#1620)
* add MSMARCO eval split in MTEB English (classic) benchmark
Fixes #1608
* Add co-author
Co-authored-by: aashka-trivedi &lt;aashka.trivedi@gmail.com&gt;
---------
Co-authored-by: aashka-trivedi &lt;aashka.trivedi@gmail.com&gt;
* fix: GermanDPR Dataset Causes Cross-Encoder Failure Due to Unexpected dict (#1621)
Fixes #1609
* fix: properly add mteb_model_meta to model object (#1623)
* 1.25.5
Automatically generated by python-semantic-release
* Feat: Add jasper (#1591)
* init jasper
* init jasper
* add to overview
* add to overview
* remove some params
* fix max length
* return sdpa
* add dtype
* add dtype
* fix convert_to_tensor
* change to encode
* return whitespace processing
* explicitly add instructions
* move seq length
* try float
* fix max_seq_length
* add prompt validation to format instruction
* don&#39;t use instructions only to s2p
* fix: Update results_to_dataframe to use BenchmarkResults class (#1628)
* 1.25.6
Automatically generated by python-semantic-release
* Speed up test_save_predictions (#1631)
* fix: Correction of discrepancies for gte-Qweb model (#1637)
* 1.25.7
Automatically generated by python-semantic-release
* fix: output_folder for co2 evaluation (#1642)
* 1.25.8
Automatically generated by python-semantic-release
* fix: add missing benchmark to benchmarks.py (#1641)
add missing benchmark
* 1.25.9
Automatically generated by python-semantic-release
* fix: Cast all Model2Vec outputs as floats (#1667)
cast all outputs as floats
* 1.25.10
Automatically generated by python-semantic-release
* fix: Update gritlm kwargs (#1643)
* Fix kwarg
* format
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* 1.25.11
Automatically generated by python-semantic-release
* fix: Use batch size kwargs for openai APIs (#1668)
Fixes #1645
* 1.25.12
Automatically generated by python-semantic-release
* fix: Pass trust_remote_code=True to CPM model (#1669)
Fixes #1651
* 1.25.13
Automatically generated by python-semantic-release
* fix: Updated metadata for CPM (#1670)
* fix: Pass trust_remote_code=True to CPM model
Fixes #1651
* fix: Updated metadata for cpm
* 1.25.14
Automatically generated by python-semantic-release
* fix: remove model as a parameter for MulticlassClassification (#1666)
remove model parameter
* fix: Use prompts instead of prompt names for voyage (#1665)
* fix prompt names
* lint
* change input type
* 1.25.15
Automatically generated by python-semantic-release
* fix: Update BUCC dataset revision (#1674)
* trust remote code
* Update revision
* 1.25.16
Automatically generated by python-semantic-release
* fix: Add warning for non-retrieval tasks when using bm25s (#1678)
* clean up install instruction
* add check for bm25s and skip non-retrieval tasks
* add versions
* 1.25.17
Automatically generated by python-semantic-release
* fix: add check for key error in loader (#1675)
* add check for key error
* make KeyError everywhere
* update error
* 1.25.18
Automatically generated by python-semantic-release
* fix: trust remote code for snowflake-arctic-embed-m-v2.0 (#1682)
trust remote code
* 1.25.19
Automatically generated by python-semantic-release
* fix: nomic tensor return (#1683)
* fix nomic tensor return
* add typehint
* 1.25.20
Automatically generated by python-semantic-release
* feat: add `avsolatorio/NoInstruct-small-Embedding-v0` (#1677)
add no_instruct
* fix: arg name for openbmb/MiniCPM-Embedding (#1691)
fix name
* 1.26.0
Automatically generated by python-semantic-release
* fix: add trust_remote_code to Snowflake/snowflake-arctic-embed-m-long (#1695)
trust remote code
* fix: add revision for jinaai/jina-embeddings-v2-small-en (#1692)
add revision
* 1.26.1
Automatically generated by python-semantic-release
* fix: update model loader to trust remote code (#1697)
update model loader
* 1.26.2
Automatically generated by python-semantic-release
* fix: nomic prompts (#1685)
* fix nomic prompts
* fix variable model name
* pass prompts to model
* use sentence transformer wrapper
* update prompts
* lint
* update prompts
* update list for classification
* fix: NanoBeir (#1687)
* fix nano beir
* lint
* 1.26.3
Automatically generated by python-semantic-release
* Update RerankingEvaluator.py (#1702)
* fix: Register MicroLlama Text Embedding (#1644)
Register MicroLlama Text Embedding
* fix: GermanDPR (#1703)
* fix GermanDPR
* lint
* 1.26.4
Automatically generated by python-semantic-release
* Fix: minicpmv2 (#1705)
* updmini cpm
* flash_attn implementation
* remove flash attn
* ci: Refresh the v2 leaderboard daily (#1711)
* Create leaderboard_refresh.yaml
* Shorten and fix
* factory reset instead of normal
* Fix: typos in adding a model (#1722)
* fix: rollback BUCC revision (#1706)
* fix bucc
* fix logger
* upd evaluator
* add comment
* lint
* 1.26.5
Automatically generated by python-semantic-release
* fix: Added zero shot tag to benchmark (#1710)
* Added method for determining whether a model is zero shot
* Added .items() where intended
* Added filtering functions for zero shot models
* Added zero-shot filtering button and error message when table is empty.:
* Ran linting
* Fixed docstring linting error
* is_zero_shot returns None when no training data is specified
* Added zero-shot emoji column to leaderboard
* Added explanation for zero shot column
* Added soft and hard zero-shot buttons
* Added training data annotations to 24 models from HuggingFace Hub
* 1.26.6
Automatically generated by python-semantic-release
* feat: reduce logging for load_results()
- redacts missing subsets to avoid 100+ subsets printed
- reduce to logging.info
- removed splits that are commonly never evaluated on and thus also the errors for them being missing
The second part removed quite a few warnings (4930 to XX)
It also seems like the splits were accidentally included in some of the MMTEB benchmark.
This will remove those splits from those benchmarks (which are all in beta). We will have to recompute the tables for the paper though (we should do that anyway)
Other potential thing to consider:
- Scifact is included in MTEB(Medical). I have removed the &#34;train&#34; split from it as I think that was a mistake. (checked other dataset in benchmark)
Here is a count of the current top errors:
```py
{
    &#34;MassiveScenarioClassification: Missing splits {&#39;validation&#39;}&#34;: 238,  # included in e.g. mteb(fra)
    &#34;MassiveIntentClassification: Missing splits {&#39;validation&#39;}&#34;: 237, # included in e.g. mteb(fra)
    &#34;MassiveScenarioClassification: Missing subsets {&#39;af&#39;, &#39;da&#39;, ...} for split test&#34;: 230,
    &#34;AmazonReviewsClassification: Missing splits {&#39;validation&#39;}&#34;: 229, # included in e.g. mteb(deu)
    &#34;MassiveIntentClassification: Missing subsets {&#39;af&#39;, &#39;da&#39;, ...} for split test&#34;: 228,
    &#34;STS22: Missing subsets {&#39;fr-pl&#39;, &#39;de-en&#39;, ...} for split test&#34;: 223,
    &#34;AmazonReviewsClassification: Missing subsets {&#39;es&#39;, &#39;ja&#39;, ...} for split test&#34;: 196,
    &#34;MTOPDomainClassification: Missing splits {&#39;validation&#39;}&#34;: 195, # included in mteb(fra)
    &#34;MTOPIntentClassification: Missing splits {&#39;validation&#39;}&#34;: 194, # included in mteb(fra)
    &#34;AmazonCounterfactualClassification: Missing splits {&#39;validation&#39;}&#34;: 189, # included in mteb(deu)
    &#34;MTOPDomainClassification: Missing subsets {&#39;es&#39;, &#39;th&#39;, ...} for split test&#34;: 165,
    &#34;STS17: Missing subsets {&#39;en-ar&#39;, &#39;es-es&#39;, ...} for split test&#34;: 164,
    &#34;MTOPIntentClassification: Missing subsets {&#39;es&#39;, &#39;th&#39;, ...} for split test&#34;: 164,
    &#34;AmazonCounterfactualClassification: Missing subsets {&#39;de&#39;, &#39;ja&#39;, ...} for split test&#34;: 148,
}
```
* 1.27.0
Automatically generated by python-semantic-release
* feat: Add nomic modern bert (#1684)
* add nomic modern bert
* use SentenceTransformerWrapper
* use SentenceTransformerWrapper
* try nomic wrapper
* update
* use all prompts
* pass prompts
* use fp16
* lint
* change to version
* remove commented code
* fix: allow kwargs in init for RerankingWrapper (#1676)
* allow kwargs in init
* fix retrieval
* convert corpus_in_pair to list
* 1.28.0
Automatically generated by python-semantic-release
* Fixed result loading on leaderboard (#1739)
* Only main_score gets loaded for leaderboard thereby avoiding OOM errors
* Fixed plot failing because of missing embedding dimensions
* Ran linting
* test: Add script to test model loading below n_parameters threshold (#1698)
* add model loading test for models below 2B params
* add failure message to include model namne
* use the real get_model_meta
* use cache folder
* teardown per function
* fix directory removal
* write to file
* wip loading from before
* wip
* Rename model_loading_testing.py to model_loading.py
* Delete tests/test_models/test_model_loading.py
* checks for models below 2B
* try not using cache folder
* update script with scan_cache_dir and add args
* add github CI: detect changed model files and run model loading test
* install all model dependencies
* dependecy installations and move file location
* should trigger a model load test in CI
* find correct commit for diff
* explicity fetch base branch
* add make command
* try to run in python instead and add pytest
* fix attribute error and add read mode
* separate script calling
* let pip install be cached and specify repo path
* check ancestry
* add cache and rebase
* try to merge instead of rebase
* try without merge base
* check if file exists first
* Apply suggestions from code review
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update .github/workflows/model_loading.yml
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* address review comments to run test once from CI and not pytest
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* fix: Leaderboard Speedup (#1745)
* Added get_scores_fast
* Made leaderboard faster with smarter dependency graph and event management and caching
* Changed print to logger.info
* 1.28.1
Automatically generated by python-semantic-release
* fix: Fixed task_type aggregation on leaderboard (#1746)
* Fixed task_type aggregation in leaderboard
* Fixed an error due to unneccesary indentation in get_score
* 1.28.2
Automatically generated by python-semantic-release
* fix: Fixed definition of zero-shot in ModelMeta (#1747)
* Corrected zero_shot definition to be based on task names, not dataset path
* 1.28.3
Automatically generated by python-semantic-release
* fix: fixes implementation of similarity() (#1748)
* fix(#1594): fixes implementation of similarity()
* fix: add similarity to SentenceTransformerWrapper
---------
Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
* 1.28.4
Automatically generated by python-semantic-release
* fix: Leaderboard: `K` instead of `M` (#1761)
Fixes #1752
* other: add script for leaderboard compare (#1758)
* add script
* remove changes
* remove changes
* add comment
* lint
* order like in benchmark object
* round results
* 1.28.5
Automatically generated by python-semantic-release
* fix: added annotations for training data (#1742)
* fix: Added annotations for arctic embed models
* added google and bge
* added cohere
* Added e5
* added bge based model2vec
* annotated oAI
* format and update annotations
* 1.28.6
Automatically generated by python-semantic-release
* fix: update max tokens for OpenAI (#1772)
update max tokens
* ci: skip AfriSentiLID for now (#1785)
* skip AfriSentiLID for now
* skip relevant test case instead
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* 1.28.7
Automatically generated by python-semantic-release
* ci: fix model loading test (#1775)
* pass base branch into the make command as an arg
* test a file that has custom wrapper
* what about overview
* just dont check overview
* revert instance check
* explicitly omit overview and init
* remove test change
* try on a lot of models
* revert test model file
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* feat: Update task filtering, fixing bug which included cross-lingual tasks in overly many benchmarks (#1787)
* feat: Update task filtering, fixing bug on MTEB
- Updated task filtering adding exclusive_language_filter and hf_subset
- fix bug in MTEB where cross-lingual splits were included
- added missing language filtering to MTEB(europe, beta) and MTEB(indic, beta)
The following code outlines the problems:
```py
import mteb
from mteb.benchmarks import MTEB_ENG_CLASSIC
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
# was eq. to:
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;])
task.hf_subsets
# correct filtering to English datasets:
# [&#39;en&#39;, &#39;de-en&#39;, &#39;es-en&#39;, &#39;pl-en&#39;, &#39;zh-en&#39;]
# However it should be:
# [&#39;en&#39;]
# with the changes it is:
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
task.hf_subsets
# [&#39;en&#39;]
# eq. to
task = mteb.get_task(&#34;STS22&#34;, hf_subsets=[&#34;en&#34;])
# which you can also obtain using the exclusive_language_filter (though not if there was multiple english splits):
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;], exclusive_language_filter=True)
```
* format
* remove &#34;en-ext&#34; from AmazonCounterfactualClassification
* fixed mteb(deu)
* fix: simplify in a few areas
* 1.29.0
Automatically generated by python-semantic-release
* fix: Added C-MTEB (#1786)
Added C-MTEB
* 1.29.1
Automatically generated by python-semantic-release
* docs: Add contact to MMTEB benchmarks (#1796)
* Add myself to MMTEB benchmarks
* lint
* fix: loading pre 11 (#1798)
* fix loading pre 11
* add similarity
* lint
* run all task types
* 1.29.2
Automatically generated by python-semantic-release
* fix: allow to load no revision available (#1801)
* fix allow to load no revision available
* lint
* add require_model_meta to leaderboard
* lint
* 1.29.3
Automatically generated by python-semantic-release
* fix: Zero shot and aggregation on Leaderboard (#1810)
* Made join_revision filter out no_revision_available when other revisions have been run on the task
* Fixed zero-shot filtering
* Fixed aggregation of task types
* Ran linting
* fix: Added `ModelMeta` for BGE, GTE Chinese and multilingual models (#1811)
* Added BGE Chinese and multilingual-gemma models
* Added GTE multilingual and Chinese models
* Fixed date format
* 1.29.4
Automatically generated by python-semantic-release
* fix: Add additional contacts (#1817)
add contacts from #1790
* Update points table
* 1.29.5
Automatically generated by python-semantic-release
* fix: Added more Chinese models&#39; `ModelMeta` (#1814)
* Added Multilingual USE models
* Added Moka models
* Added dmeta models
* Added jina-zh
* Added  piccolo models
* 1.29.6
Automatically generated by python-semantic-release
* Add model inf-retriever-v1 (#1744)
* feat(models): add infly/inf-retriever-v1 model metadata- Add inf_models.py file with metadata for infly/inf-retriever-v1 model
- Update overview.py to include inf_models in model imports
* Reformat code
* Update inf-retriever-v1 ModelMeta
* Fill more information for inf-retriever-v1
* Add license information for inf-retriever-v1
---------
Co-authored-by: Samuel Yang &lt;samuelyang150@gmail.com&gt;
* ci: only return 1 model_name per file (#1818)
* only return 1 model_name per file
* fix args parse
* revert test change
* fix: add bge-m3 `ModelMeta` (#1821)
add bge
* 1.29.7
Automatically generated by python-semantic-release
* fix: Added Chinese Stella models (#1824)
Added Chinese Stella models
* fix: bm25s (#1827)
Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
* fix: Added way more training dataset annotations (#1765)
* fix: Leaderboard: `K` instead of `M`
Fixes #1752
* format
* fixed existing annotations to refer to task name instead of hf dataset
* added annotation to nvidia
* added voyage
* added uae annotations
* Added stella annotations
* sentence trf models
* added salesforce and e5
* jina
* bge + model2vec
* added llm2vec annotations
* add jasper
* format
* format
* Updated annotations and moved jina models
* fix: add even more training dataset annotations (#1793)
* fix: update max tokens for OpenAI (#1772)
update max tokens
* ci: skip AfriSentiLID for now (#1785)
* skip AfriSentiLID for now
* skip relevant test case instead
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* 1.28.7
Automatically generated by python-semantic-release
* ci: fix model loading test (#1775)
* pass base branch into the make command as an arg
* test a file that has custom wrapper
* what about overview
* just dont check overview
* revert instance check
* explicitly omit overview and init
* remove test change
* try on a lot of models
* revert test model file
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* feat: Update task filtering, fixing bug which included cross-lingual tasks in overly many benchmarks (#1787)
* feat: Update task filtering, fixing bug on MTEB
- Updated task filtering adding exclusive_language_filter and hf_subset
- fix bug in MTEB where cross-lingual splits were included
- added missing language filtering to MTEB(europe, beta) and MTEB(indic, beta)
The following code outlines the problems:
```py
import mteb
from mteb.benchmarks import MTEB_ENG_CLASSIC
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
# was eq. to:
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;])
task.hf_subsets
# correct filtering to English datasets:
# [&#39;en&#39;, &#39;de-en&#39;, &#39;es-en&#39;, &#39;pl-en&#39;, &#39;zh-en&#39;]
# However it should be:
# [&#39;en&#39;]
# with the changes it is:
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
task.hf_subsets
# [&#39;en&#39;]
# eq. to
task = mteb.get_task(&#34;STS22&#34;, hf_subsets=[&#34;en&#34;])
# which you can also obtain using the exclusive_language_filter (though not if there was multiple english splits):
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;], exclusive_language_filter=True)
```
* format
* remove &#34;en-ext&#34; from AmazonCounterfactualClassification
* fixed mteb(deu)
* fix: simplify in a few areas
* fix: Add gritlm
* 1.29.0
Automatically generated by python-semantic-release
* fix: Added more annotations!
* fix: Added C-MTEB (#1786)
Added C-MTEB
* 1.29.1
Automatically generated by python-semantic-release
* docs: Add contact to MMTEB benchmarks (#1796)
* Add myself to MMTEB benchmarks
* lint
* fix: loading pre 11 (#1798)
* fix loading pre 11
* add similarity
* lint
* run all task types
* 1.29.2
Automatically generated by python-semantic-release
* fix: allow to load no revision available (#1801)
* fix allow to load no revision available
* lint
* add require_model_meta to leaderboard
* lint
* 1.29.3
Automatically generated by python-semantic-release
---------
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
---------
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
* fix: Added Misc Chinese models (#1819)
* Added moka and piccolo models to overview file
* Added Text2Vec models
* Added various Chinese embedding models
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* 1.29.8
Automatically generated by python-semantic-release
* fix: Fixed eval split for MultilingualSentiment in C-MTEB (#1804)
* Fixed eval split for MultilingualSentiment in C-MTEB
* FIxed splits for atec, bq and stsb in C-MTEB
* 1.29.9
Automatically generated by python-semantic-release
* fix: subsets to run (#1830)
* fix split evals
* add test
* lint
* fix moka
* add assert
* fix: Remove default params, `public_training_data` and `memory usage` in `ModelMeta` (#1794)
* fix: Leaderboard: `K` instead of `M`
Fixes #1752
* format
* fixed existing annotations to refer to task name instead of hf dataset
* added annotation to nvidia
* added voyage
* added uae annotations
* Added stella annotations
* sentence trf models
* added salesforce and e5
* jina
* bge + model2vec
* added llm2vec annotations
* add jasper
* format
* format
* Updated annotations and moved jina models
* make models parameters needed to be filled
* fix tests
* remove comments
* remove model meta from test
* fix model meta from split
* fix: add even more training dataset annotations (#1793)
* fix: update max tokens for OpenAI (#1772)
update max tokens
* ci: skip AfriSentiLID for now (#1785)
* skip AfriSentiLID for now
* skip relevant test case instead
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* 1.28.7
Automatically generated by python-semantic-release
* ci: fix model loading test (#1775)
* pass base branch into the make command as an arg
* test a file that has custom wrapper
* what about overview
* just dont check overview
* revert instance check
* explicitly omit overview and init
* remove test change
* try on a lot of models
* revert test model file
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* feat: Update task filtering, fixing bug which included cross-lingual tasks in overly many benchmarks (#1787)
* feat: Update task filtering, fixing bug on MTEB
- Updated task filtering adding exclusive_language_filter and hf_subset
- fix bug in MTEB where cross-lingual splits were included
- added missing language filtering to MTEB(europe, beta) and MTEB(indic, beta)
The following code outlines the problems:
```py
import mteb
from mteb.benchmarks import MTEB_ENG_CLASSIC
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
# was eq. to:
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;])
task.hf_subsets
# correct filtering to English datasets:
# [&#39;en&#39;, &#39;de-en&#39;, &#39;es-en&#39;, &#39;pl-en&#39;, &#39;zh-en&#39;]
# However it should be:
# [&#39;en&#39;]
# with the changes it is:
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
task.hf_subsets
# [&#39;en&#39;]
# eq. to
task = mteb.get_task(&#34;STS22&#34;, hf_subsets=[&#34;en&#34;])
# which you can also obtain using the exclusive_language_filter (though not if there was multiple english splits):
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;], exclusive_language_filter=True)
```
* format
* remove &#34;en-ext&#34; from AmazonCounterfactualClassification
* fixed mteb(deu)
* fix: simplify in a few areas
* fix: Add gritlm
* 1.29.0
Automatically generated by python-semantic-release
* fix: Added more annotations!
* fix: Added C-MTEB (#1786)
Added C-MTEB
* 1.29.1
Automatically generated by python-semantic-release
* docs: Add contact to MMTEB benchmarks (#1796)
* Add myself to MMTEB benchmarks
* lint
* fix: loading pre 11 (#1798)
* fix loading pre 11
* add similarity
* lint
* run all task types
* 1.29.2
Automatically generated by python-semantic-release
* fix: allow to load no revision available (#1801)
* fix allow to load no revision available
* lint
* add require_model_meta to leaderboard
* lint
* 1.29.3
Automatically generated by python-semantic-release
---------
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
* fig merges
* update models info
* change public_training_code to str
* change `public_training_code=False` to None
* remove annotations
* remove annotations
* remove changed annotations
* remove changed annotations
* remove `public_training_data` and `memory usage`
* make framework not optional
* make framework non-optional
* empty frameworks
* add framework
* fix tests
* Update mteb/models/overview.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
* 1.29.10
Automatically generated by python-semantic-release
* fix: Add reported annotation and re-added public_training_data (#1846)
* fix: Add additional dataset annotations
* fix: readded public training data
* update voyage annotations
* 1.29.11
Automatically generated by python-semantic-release
* fix: Leaderboard Refinements (#1849)
* Added better descriptions to benchmarks and removed beta tags
* Fixed zero-shot filtering on app loading
* Added zero-shot definition in an accordion
* NaN values are now filled with blank
* Added type hints to filter_models
* 1.29.12
Automatically generated by python-semantic-release
* rest of the merge conflicts
* fix merge conflicts
* fill in model meta defaults
* fix ModeMeta modalities
* fix metadata pydantic errors;
* assert model.model instead since it is a wrapper
* fix: Fixed leaderboard search bar (#1852)
Fixed leaderboard search bar
* 1.29.13
Automatically generated by python-semantic-release
* fix: Hotfixed public_training_data type annotation (#1857)
Fixed public_training_data flag type to include boolean, as this is how all models are annotated
* fix: Fix zeta alpha mistral (#1736)
* fix zeta alpha mistral
* update use_instructions
* update training datasets
* Update mteb/models/e5_instruct.py
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* update float
* Update mteb/models/e5_instruct.py
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Add more annotations (#1833)
* apply additions from #1794
* add annotations for rumodels
* add nomic training data
* fix metadata
* update rest of model meta
* fix bge reranker
* 1.29.14
Automatically generated by python-semantic-release
* fix: Adding missing model meta (#1856)
* Added CDE models
* Added bge-en-icl
* Updated CDE to bge_full_data
* Fixed public_training_data flag type to include boolean, as this is how all models are annotated
* Added public training data link instead of bool to CDE and BGE
* Added GME models
* Changed Torch to PyTorch
* Added metadata on LENS models
* Added ember_v1
* Added metadata for amazon titan
* Removed GME implementation
* fix Encoder class
---------
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Helena Kloosterman &lt;helena.kloosterman@intel.com&gt;
Co-authored-by: Alexey Vatolin &lt;vatolinalex@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Elias H &lt;40372306+eherra@users.noreply.github.com&gt;
Co-authored-by: Youngjoon Jang &lt;82500463+yjoonjang@users.noreply.github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Napuh &lt;55241721+Napuh@users.noreply.github.com&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel.buades@clinia.com&gt;
Co-authored-by: nadshe &lt;nadia.sheikh@clinia.com&gt;
Co-authored-by: olivierr42 &lt;olivier.rousseau@clinia.com&gt;
Co-authored-by: Thivyanth &lt;thivyanth2004@gmail.com&gt;
Co-authored-by: RafaÅ‚ PoÅ›wiata &lt;rafalposwiata@gmail.com&gt;
Co-authored-by: Omar Elshehy &lt;41394057+omarelshehy@users.noreply.github.com&gt;
Co-authored-by: Omar Elshehy &lt;omarelshehy@Omars-MacBook-Pro.local&gt;
Co-authored-by: Sam &lt;40773225+sam-hey@users.noreply.github.com&gt;
Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
Co-authored-by: KGupta10 &lt;92774828+KGupta10@users.noreply.github.com&gt;
Co-authored-by: Aashka Trivedi &lt;aashka.trivedi@gmail.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
Co-authored-by: Ken Wang &lt;wangxiaotian2007@gmail.com&gt;
Co-authored-by: Orion Weller &lt;31665361+orionw@users.noreply.github.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: Samuel Yang &lt;yangjun2@mail.ustc.edu.cn&gt;
Co-authored-by: Samuel Yang &lt;samuelyang150@gmail.com&gt;
* [mieb] Fill in align model meta (#1863)
* add align model meta
* trigger ci
* fix meta
* [mieb] Fill in clip and open clip model meta (#1876)
* add clip and open clip model meta
* fix training_datasets
* [mieb] Fill in blip model meta (#1874)
* add blip and blip 2 model meta
* fix references
* fix training datasets
* [mieb] Fill in cohere_v and dinov2 model meta (#1880)
fill in cohere_v and dino model meta
* [mieb] Fill in e5v and eva clip model meta (#1885)
* add e5v model meta
* add some eva_clip2 meta
* add the rest of meta
* [mieb] Fill out gme v and jina clip model meta (#1887)
* add gme_v model meta
* fill in jina clip meta
* jina clip v1 training data
* correct type
* cosmetic fix
* handle case where name is a variable and not a string
* Update mteb/models/gme_v_models.py
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
---------
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
* [mieb] Fill in mocov3 and nomic vision model meta (#1890)
* add moco model meta
* add nomic v model meta
* add training dataset for nomic
* [mieb] Fill in siglip model meta (#1894)
add siglip model meta
* [mieb] Fill in vista vlm2vec voyage v model meta (#1903)
* add vista model meta
* add vlm2vec model meta
* add more meta
* [mieb] merge from main once more (#1942)
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* 1.31.4
Automatically generated by python-semantic-release
* Update tasks table
* fix: Limited plotly version to be less than 6.0.0 (#1902)
Limited plotly version to be less than 6.0.0
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* update stella/jasper metainfo (#1896)
update stella meta
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* 1.31.5
Automatically generated by python-semantic-release
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Feat: Add FaMTEB (Farsi/Persian Text Embedding Benchmark) (#1843)
* Add Summary Retrieval Task
* Add FaMTEBClassification
* Add FaMTEBClustering
* Add FaMTEBPairClassification
* Add FaMTEBRetrieval and BEIRFA and FaMTEBSTS
* Add FaMTEBSummaryRetrieval
* Add FaMTEB to benchmarks
* fix benchmark names
* temporary fix metadata
* Fix dataset revisions
* Update SummaryRetrievalEvaluator.py
* Update task files
* Update task files
* add data domain and subtask description
* Update AbsTaskSummaryRetrieval and FaMTEBSummaryRetrieval
* Update AbsTaskSummaryRetrieval
* Add mock task
* Update AbsTaskSummaryRetrieval
* Update AbsTaskSummaryRetrieval
* make lint
* Refactor SummaryRetrieval to subclass BitextMining
* Add aggregated datasets
---------
Co-authored-by: mehran &lt;mehan.sarmadi16@gmail.com&gt;
Co-authored-by: e.zeinivand &lt;zeinivand@ymail.com&gt;
Co-authored-by: Erfun76 &lt;59398902+Erfun76@users.noreply.github.com&gt;
* Update tasks table
* Docs: update docs according to current state (#1870)
* update docs
* Apply suggestions from code review
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* update readme
* Update README.md
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update tasks table
* Update tasks table
* Update tasks table
* Adding a banner to the new MMTEB leaderboard (#1908)
* Adding a banner to the new MMTEB leaderboard
* linting
* Update mteb/leaderboard/app.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* adding reference to mteb arena
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* fix: Filling missing metadata for leaderboard release (#1895)
* Update ArxivClusteringS2S.py
* fill some metadat for retrieval
* fill in the reste of missing metadata
* fix metadata
* fix climatefever metadata
* fix: Added CQADupstack annotations
* removed annotation for non-exisitant task
* format
* Added financial to other financial dataset
* Moved ArguAna annotation to derivate datasets
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* 1.31.6
Automatically generated by python-semantic-release
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* fix: remove SummaryRetrieval as a type (#1915)
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* fix: revert rename and add to description (#1918)
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* Update tasks table
* docs: Add sort to domains for task metadata (#1922)
Tests currently go into an infinite loop. This should prevent that.
* Update tasks table
* 1.31.7
Automatically generated by python-semantic-release
* docs: Updated citation for mteb(scandinavian) (#1914)
fix: Updated citation for mteb(scandinavian)
* fix: Add datasets in CodeRAG-Bench (#1595)
* add three out of four datasets in CodeRAG-Bench
* add verified CodeRAGStackoverflowPostsRetrieval dataset
* clean up code and make some comments
* fixed lint errors
* addressed comments about code-rag datasets: fixed grammar and remove unnessary code and loop
* roll back files which is not supposed to change
* fixed the comments in split_by_first_newline() and make the methods private by adding a underscore prefix
* refactor to use common args
* update task descriptions
* add entry in benchmarks
* correct the alphanumeric order for the dataset
* add  in tasks.md
* add  in tasks.md
* update task metadata
* update importing path
* fix lint errors
* correct CodeRAG task metadata description field and id for stackoverflow-posts
* fix error in test
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update tasks table
* 1.31.8
Automatically generated by python-semantic-release
* Leaderboard: Acks (#1930)
Add acs
* omit instructions.py
---------
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Mehran Sarmadi &lt;128898167+mehran-sarmadi@users.noreply.github.com&gt;
Co-authored-by: mehran &lt;mehan.sarmadi16@gmail.com&gt;
Co-authored-by: e.zeinivand &lt;zeinivand@ymail.com&gt;
Co-authored-by: Erfun76 &lt;59398902+Erfun76@users.noreply.github.com&gt;
Co-authored-by: Wissam Siblini &lt;36303760+wissam-sib@users.noreply.github.com&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Pengfei He &lt;hepengfe@gmail.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
* fix merge conflict error in task metadata
* remove old file
* add mieb to readme
* add comments to mieb task categories
* remove commented out code
* use logger.info in abstasks
* add blip2 dependency to pyproject
* remove test code
---------
Signed-off-by: mr.Shu &lt;mr@shu.io&gt;
Co-authored-by: gowitheflow-1998 &lt;jsbs54@durham.ac.uk&gt;
Co-authored-by: chenghao xiao &lt;85804993+gowitheflow-1998@users.noreply.github.com&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: github-actions[bot] &lt;github-actions[bot]@users.noreply.github.com&gt;
Co-authored-by: anpalmak2003 &lt;73543260+anpalmak2003@users.noreply.github.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: Zach Nussbaum &lt;zanussbaum@gmail.com&gt;
Co-authored-by: Jamie-Stirling &lt;36764530+Jamie-Stirling@users.noreply.github.com&gt;
Co-authored-by: HSILA &lt;a.shiraee@gmail.com&gt;
Co-authored-by: Ali Shiraee &lt;ShiraeA@basfad.basf.net&gt;
Co-authored-by: Thomas van Dongen &lt;thomas123@live.nl&gt;
Co-authored-by: Orion Weller &lt;31665361+orionw@users.noreply.github.com&gt;
Co-authored-by: John Yang &lt;byjohnyang@gmail.com&gt;
Co-authored-by: Marek Å uppa &lt;mrshu@users.noreply.github.com&gt;
Co-authored-by: Xa9aX ãƒ„ &lt;mishradiganta91@gmail.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel@buad.es&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel.buades@clinia.com&gt;
Co-authored-by: Sathvik Nallamalli &lt;sathviknallamalli@gmail.com&gt;
Co-authored-by: Michael Graczyk &lt;michael@mgraczyk.com&gt;
Co-authored-by: Mariya Hendriksen &lt;35101262+mariyahendriksen@users.noreply.github.com&gt;
Co-authored-by: Santiago Castro &lt;bryant1410@gmail.com&gt;
Co-authored-by: Joey Xia &lt;77958037+ZiyiXia@users.noreply.github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
Co-authored-by: Oliver &lt;oliver.pejic@students.fhnw.ch&gt;
Co-authored-by: gowitheflow-1998 &lt;chenghao.xiao@durham.ac.uk&gt;
Co-authored-by: Saiteja Utpala &lt;73220310+SaitejaUtpala@users.noreply.github.com&gt;
Co-authored-by: Xin Zhang &lt;izhx404@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt; ([`6d63d06`](https://github.com/embeddings-benchmark/mteb/commit/6d63d0668552946bad5924092aa5864cfe442c93))

### Unknown

* Fixed join_revisions if results are empty (#1949) ([`c81827d`](https://github.com/embeddings-benchmark/mteb/commit/c81827d9e97faf00a5a20f806a5d4a262d434802))

## v1.32.0 (2025-02-04)

### Feature

* feat: add beir (#1933)

add beir ([`7ef3a90`](https://github.com/embeddings-benchmark/mteb/commit/7ef3a906245c460a0e98c0a85e4861312e3742ed))

### Unknown

* Updated links in MTEB(eng) and eng,classic (#1948) ([`3cf2bed`](https://github.com/embeddings-benchmark/mteb/commit/3cf2bed0589299e28edf9e2545d1993b95a31ba1))

* misc: add bgev1 models (#1928)

* add bgev1 models

* add bge-*-en

* fix naming ([`e16acf8`](https://github.com/embeddings-benchmark/mteb/commit/e16acf8c7239eb2be9633b3df5fcd9a96b21a52a))

* misc: add warning for save_suffix removal from AbsTask (#1940)

add warning for param removal ([`07c489d`](https://github.com/embeddings-benchmark/mteb/commit/07c489d378cf1084d24e7e0bf391882ccbe460c3))

* Leaderboard: Acks (#1930)

Add acs ([`476afc7`](https://github.com/embeddings-benchmark/mteb/commit/476afc73584f09946f90a77455546d83f8a7c444))

## v1.31.8 (2025-02-01)

### Documentation

* docs: Updated citation for mteb(scandinavian) (#1914)

fix: Updated citation for mteb(scandinavian) ([`f3526fc`](https://github.com/embeddings-benchmark/mteb/commit/f3526fc0b83cfb25989ec9ad405995bcad19b35d))

### Fix

* fix: Add datasets in CodeRAG-Bench (#1595)

* add three out of four datasets in CodeRAG-Bench
* add verified CodeRAGStackoverflowPostsRetrieval dataset
* clean up code and make some comments
* fixed lint errors
* addressed comments about code-rag datasets: fixed grammar and remove unnessary code and loop
* roll back files which is not supposed to change
* fixed the comments in split_by_first_newline() and make the methods private by adding a underscore prefix
* refactor to use common args
* update task descriptions
* add entry in benchmarks
* correct the alphanumeric order for the dataset
* add  in tasks.md
* add  in tasks.md
* update task metadata
* update importing path
* fix lint errors
* correct CodeRAG task metadata description field and id for stackoverflow-posts
* fix error in test
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`9c762da`](https://github.com/embeddings-benchmark/mteb/commit/9c762da0332009375dc4d5a42aa770bd68d309a4))

### Unknown

* Update tasks table ([`57db0f9`](https://github.com/embeddings-benchmark/mteb/commit/57db0f9492928c4653d37b1699cb86223c894517))

## v1.31.7 (2025-02-01)

### Documentation

* docs: Add sort to domains for task metadata (#1922)

Tests currently go into an infinite loop. This should prevent that. ([`6f673ba`](https://github.com/embeddings-benchmark/mteb/commit/6f673ba0350a73c3b0bd39a22c704b36640ef1ff))

### Fix

* fix: revert rename and add to description (#1918) ([`75ff333`](https://github.com/embeddings-benchmark/mteb/commit/75ff333d60f1e93dcb645dbccbdc868dc5bb9420))

* fix: remove SummaryRetrieval as a type (#1915) ([`21d32f0`](https://github.com/embeddings-benchmark/mteb/commit/21d32f0b96135fc8f95ce6fd7e513109274a806b))

### Unknown

* Update tasks table ([`14616dc`](https://github.com/embeddings-benchmark/mteb/commit/14616dc2a8fcad80ce0394806223a9ddd54457e8))

* Update tasks table ([`e932dfc`](https://github.com/embeddings-benchmark/mteb/commit/e932dfc3096374117a20c0a03ec7da06eaa9f745))

* Update tasks table ([`6072eae`](https://github.com/embeddings-benchmark/mteb/commit/6072eaeb8aa011edcf435ae7c80e2165210d37d6))

* Update tasks table ([`2b95d66`](https://github.com/embeddings-benchmark/mteb/commit/2b95d66bc1ba4012aa097f94ecaefa74f4663f4f))

* Update tasks table ([`e344a2e`](https://github.com/embeddings-benchmark/mteb/commit/e344a2ebd4db22e278a3f7db81347ebfa31d1544))

* Update tasks table ([`597b8fc`](https://github.com/embeddings-benchmark/mteb/commit/597b8fceaca83e8481018954a197905af8893b61))

* Update tasks table ([`a420249`](https://github.com/embeddings-benchmark/mteb/commit/a420249ad20ff69cde6705ee3dd483e9b9ea57f3))

* Update tasks table ([`4be5352`](https://github.com/embeddings-benchmark/mteb/commit/4be535282293b25d028cd491201e6a14bca9d361))

* Update tasks table ([`7474c97`](https://github.com/embeddings-benchmark/mteb/commit/7474c97fed493abc12aa83f29dac21c996e57c85))

* Update tasks table ([`9146cc3`](https://github.com/embeddings-benchmark/mteb/commit/9146cc3ad979e5d9b9bf22e7b9b08e0a0f7b3e61))

* Update tasks table ([`8cdb25a`](https://github.com/embeddings-benchmark/mteb/commit/8cdb25a54b548699d0ddc4583ff22186d461892b))

* Update tasks table ([`4294389`](https://github.com/embeddings-benchmark/mteb/commit/429438973aea73505a2282a2d1a2f823e6ad31d7))

* Update tasks table ([`c275b10`](https://github.com/embeddings-benchmark/mteb/commit/c275b10b693d2d3c84d0808a7db81156e51cc182))

* Update tasks table ([`0ae0417`](https://github.com/embeddings-benchmark/mteb/commit/0ae0417933655cb81917f46ea6a78e1b05dc86fc))

* Update tasks table ([`974ff3c`](https://github.com/embeddings-benchmark/mteb/commit/974ff3ca6b73e7ad34dde05fe9e49d223998f029))

* Update tasks table ([`0cd396e`](https://github.com/embeddings-benchmark/mteb/commit/0cd396e3505130b4a10afdd083723b1222746e47))

* Update tasks table ([`de3a1f9`](https://github.com/embeddings-benchmark/mteb/commit/de3a1f9bdc5ebe9e89d1e477f508144d037d8f0e))

* Update tasks table ([`996c522`](https://github.com/embeddings-benchmark/mteb/commit/996c5228d03b8086e733ed10afd92102b4982010))

* Update tasks table ([`2b5f320`](https://github.com/embeddings-benchmark/mteb/commit/2b5f320ebf8a36d643e42dd03c18a2f829a608a3))

* Update tasks table ([`e183458`](https://github.com/embeddings-benchmark/mteb/commit/e183458d17b031adc4887a1f60e0e9b8c10708a5))

* Update tasks table ([`df3ef70`](https://github.com/embeddings-benchmark/mteb/commit/df3ef70de53677d00ad76383273bc56ade3b6a1d))

* Update tasks table ([`f42d5d0`](https://github.com/embeddings-benchmark/mteb/commit/f42d5d024b4f291d49ccf0cba5106df061642c7a))

* Update tasks table ([`0ac5bf2`](https://github.com/embeddings-benchmark/mteb/commit/0ac5bf223559f7fd1441bdd224010d9aa4dfa827))

* Update tasks table ([`52c000d`](https://github.com/embeddings-benchmark/mteb/commit/52c000d638ab70b1b1b03ae0b7e14d7813c67a46))

* Update tasks table ([`0e8a539`](https://github.com/embeddings-benchmark/mteb/commit/0e8a539a191394af6f0379c438757a1c775ca0ea))

* Update tasks table ([`bf3256a`](https://github.com/embeddings-benchmark/mteb/commit/bf3256a58a5061ee3bbd429fe12147d7f50f04de))

* Update tasks table ([`53f4e2e`](https://github.com/embeddings-benchmark/mteb/commit/53f4e2e53f9f3df5d749b1e3fff125004762577c))

* Update tasks table ([`ea6c1a2`](https://github.com/embeddings-benchmark/mteb/commit/ea6c1a2b81ff15612d5e25ff1983d67886640df0))

* Update tasks table ([`dafbb80`](https://github.com/embeddings-benchmark/mteb/commit/dafbb8088cc043e8bc6eba7f6bd355a0d649d151))

* Update tasks table ([`745e2e6`](https://github.com/embeddings-benchmark/mteb/commit/745e2e6edddfcc8a838aff3c5b1f00608c75c56e))

* Update tasks table ([`d6ff9d0`](https://github.com/embeddings-benchmark/mteb/commit/d6ff9d0b8496dcfdd82486fa5d18361f0cc6e4c9))

* Update tasks table ([`e5ae84f`](https://github.com/embeddings-benchmark/mteb/commit/e5ae84f974b6eb38386680afb46e461526709007))

* Update tasks table ([`c72a4ba`](https://github.com/embeddings-benchmark/mteb/commit/c72a4baf2ebe33e2db6035894224a73dd0862c68))

* Update tasks table ([`471ea4c`](https://github.com/embeddings-benchmark/mteb/commit/471ea4ced5a13f78e9a2c0949441dcf51654cd36))

* Update tasks table ([`887ebf2`](https://github.com/embeddings-benchmark/mteb/commit/887ebf27f859c31f431bb314343e2922258df5b9))

* Update tasks table ([`54d1bd1`](https://github.com/embeddings-benchmark/mteb/commit/54d1bd1574779977e55f0b9ba51f3a047b443713))

* Update tasks table ([`f1ea61a`](https://github.com/embeddings-benchmark/mteb/commit/f1ea61a7374434ded6cf06fb377a05efab1249b6))

* Update tasks table ([`6cb089f`](https://github.com/embeddings-benchmark/mteb/commit/6cb089f84f99db873b7476883187f066ce56999a))

* Update tasks table ([`6d051da`](https://github.com/embeddings-benchmark/mteb/commit/6d051da9a498689f7c3f0eb9be8b92e5abc22924))

* Update tasks table ([`2756d67`](https://github.com/embeddings-benchmark/mteb/commit/2756d67e98ef413b640f7e0380fce611f53625d0))

* Update tasks table ([`e823bd7`](https://github.com/embeddings-benchmark/mteb/commit/e823bd768de8857a2e42d396ee0949c14cb2d0fa))

* Update tasks table ([`c3ea285`](https://github.com/embeddings-benchmark/mteb/commit/c3ea285750c9a6744e16d0ca4ef7aade3875e880))

* Update tasks table ([`a9be716`](https://github.com/embeddings-benchmark/mteb/commit/a9be71659f5f050bf1dde5e0b23897474721d82e))

* Update tasks table ([`c01563d`](https://github.com/embeddings-benchmark/mteb/commit/c01563d461e8195c71af421cd4cb151776291dbc))

* Update tasks table ([`d57f988`](https://github.com/embeddings-benchmark/mteb/commit/d57f988fcc854b2623a04abde64688a80488ec35))

* Update tasks table ([`2850833`](https://github.com/embeddings-benchmark/mteb/commit/2850833c3823d5a2c1b83e56ac4c2fc16ede1a04))

* Update tasks table ([`13fd52e`](https://github.com/embeddings-benchmark/mteb/commit/13fd52eea8103f7c2677f2f29b8bdba617092e11))

* Update tasks table ([`ff4e7c6`](https://github.com/embeddings-benchmark/mteb/commit/ff4e7c62d59fb92d61ed3baa3b7ce7527cb0c6e4))

* Update tasks table ([`26ffe3a`](https://github.com/embeddings-benchmark/mteb/commit/26ffe3aabfc6ff2fa25fdfaa972ce0056105dd65))

* Update tasks table ([`b61de5d`](https://github.com/embeddings-benchmark/mteb/commit/b61de5d54b71136e945baa0e69c1210b3fb1106b))

* Update tasks table ([`5c2cbfc`](https://github.com/embeddings-benchmark/mteb/commit/5c2cbfc621341032ba8fbc2c93a070817c66f1fa))

* Update tasks table ([`2e34cc7`](https://github.com/embeddings-benchmark/mteb/commit/2e34cc72224206fb0a318cca70e22817aa279e18))

* Update tasks table ([`96f3aff`](https://github.com/embeddings-benchmark/mteb/commit/96f3aff6f86c09012601ef01d68f9c0888b17d8e))

* Update tasks table ([`d9ba681`](https://github.com/embeddings-benchmark/mteb/commit/d9ba6813da9309d20c6e1043d36d8a188cf8e79e))

* Update tasks table ([`9641319`](https://github.com/embeddings-benchmark/mteb/commit/96413197195503997517a0ea10197f57ae9822da))

* Update tasks table ([`ad1deff`](https://github.com/embeddings-benchmark/mteb/commit/ad1deffef122123c8681736eb5b01c6f977d16ef))

* Update tasks table ([`1f7971f`](https://github.com/embeddings-benchmark/mteb/commit/1f7971f98e02cfae01d67d9764b04d6b93c3754c))

* Update tasks table ([`88a2fe1`](https://github.com/embeddings-benchmark/mteb/commit/88a2fe1ee4259b411e1b3aeab52acb3c90e97c3a))

* Update tasks table ([`03b2380`](https://github.com/embeddings-benchmark/mteb/commit/03b23806b6de0d5c915e64c086cb9749cd2445b1))

* Update tasks table ([`d9c9b9e`](https://github.com/embeddings-benchmark/mteb/commit/d9c9b9e157f3ec0dd14f41973bc22f0d49343217))

* Update tasks table ([`635ed80`](https://github.com/embeddings-benchmark/mteb/commit/635ed802dcd46817d5d9c5cdbaff048d25268452))

* Update tasks table ([`f70a994`](https://github.com/embeddings-benchmark/mteb/commit/f70a994b3839fe276d880e76fd25494367dfadd7))

* Update tasks table ([`a6c2841`](https://github.com/embeddings-benchmark/mteb/commit/a6c284163e5ce4f30276a9f0ed0248d56d3126f9))

* Update tasks table ([`37ef436`](https://github.com/embeddings-benchmark/mteb/commit/37ef436f20bbbbe9b0d3f1fb2d6f662a886eb387))

* Update tasks table ([`2b4a467`](https://github.com/embeddings-benchmark/mteb/commit/2b4a467125ed86c169749f8546e812fc46a56706))

* Update tasks table ([`3231736`](https://github.com/embeddings-benchmark/mteb/commit/32317369a9579952089a44e5c9e876bfebf9390e))

* Update tasks table ([`d2e1361`](https://github.com/embeddings-benchmark/mteb/commit/d2e1361ff8fcfce7a2fa1285f57a3aac0fc14a08))

* Update tasks table ([`7258174`](https://github.com/embeddings-benchmark/mteb/commit/7258174c40a45a0f47be297579ad4c1ac0111d1d))

* Update tasks table ([`2cb0c3a`](https://github.com/embeddings-benchmark/mteb/commit/2cb0c3a19334d6f75531ed829338168b6325a7ec))

* Update tasks table ([`6c0070a`](https://github.com/embeddings-benchmark/mteb/commit/6c0070a4e420fcaf0f38b5674ae0029d3e9ec992))

* Update tasks table ([`4b88d1c`](https://github.com/embeddings-benchmark/mteb/commit/4b88d1c568bf58d73b2610ff21209437bbc7e001))

* Update tasks table ([`42bea66`](https://github.com/embeddings-benchmark/mteb/commit/42bea66a5560bd6499a32209e45c3d98a909b400))

* Update tasks table ([`e4329f0`](https://github.com/embeddings-benchmark/mteb/commit/e4329f0f424bebe768031440f18a747a2d377e55))

* Update tasks table ([`ec2cf13`](https://github.com/embeddings-benchmark/mteb/commit/ec2cf139b492a9023d765cc6ee2051942035a8e2))

* Update tasks table ([`7184a29`](https://github.com/embeddings-benchmark/mteb/commit/7184a29a5d1af2b4e9f05cc0b030141fb2e59629))

* Update tasks table ([`1a60580`](https://github.com/embeddings-benchmark/mteb/commit/1a60580daec655ee7ae4fb5e66de92a40b16cb52))

* Update tasks table ([`da378de`](https://github.com/embeddings-benchmark/mteb/commit/da378de49241d5436e22c4ad16a551cc18333fa4))

* Update tasks table ([`33ce26a`](https://github.com/embeddings-benchmark/mteb/commit/33ce26af98314500859908898632303eac309f1f))

* Update tasks table ([`4977c93`](https://github.com/embeddings-benchmark/mteb/commit/4977c93085fa210f4de6f26f05f63ca154d90fc0))

* Update tasks table ([`4e8288d`](https://github.com/embeddings-benchmark/mteb/commit/4e8288d5a6080ab7571e97a3978dae88fc65aa19))

* Update tasks table ([`8ffa6cf`](https://github.com/embeddings-benchmark/mteb/commit/8ffa6cf8ddb105711e38ed6106c1120d6d6f5188))

* Update tasks table ([`07a02c5`](https://github.com/embeddings-benchmark/mteb/commit/07a02c54c66275905201437c1e7a4780305e837e))

* Update tasks table ([`3c86eee`](https://github.com/embeddings-benchmark/mteb/commit/3c86eeef173e5b0a3361c58ab03f75ea1806b9f1))

* Update tasks table ([`eb837f1`](https://github.com/embeddings-benchmark/mteb/commit/eb837f16c4e283eda968961f646b6f2276a7c2b7))

* Update tasks table ([`8baee52`](https://github.com/embeddings-benchmark/mteb/commit/8baee527993de867fe020b11bce9e92f7875aa7c))

* Update tasks table ([`51a314c`](https://github.com/embeddings-benchmark/mteb/commit/51a314ce12fbbcf71268d3dea40c052034da293c))

* Update tasks table ([`813e711`](https://github.com/embeddings-benchmark/mteb/commit/813e7117b380311cd54b4e1818e0347fa033263c))

* Update tasks table ([`8aa5a69`](https://github.com/embeddings-benchmark/mteb/commit/8aa5a699c6524c3dd5ac431593fdf60f11e89b73))

* Update tasks table ([`9e4166f`](https://github.com/embeddings-benchmark/mteb/commit/9e4166f9696462fdb6755d370b0317a4a3665672))

* Update tasks table ([`be4f0da`](https://github.com/embeddings-benchmark/mteb/commit/be4f0dae24f41b6615b42d6e8e3e550a29d5f032))

* Update tasks table ([`b58a615`](https://github.com/embeddings-benchmark/mteb/commit/b58a615474abbad48282f63ee0fd2f80f4856037))

* Update tasks table ([`dea83b1`](https://github.com/embeddings-benchmark/mteb/commit/dea83b16c0938e64359ea2f8011cf9c0ad5bcf95))

* Update tasks table ([`1791fc8`](https://github.com/embeddings-benchmark/mteb/commit/1791fc840b90c757ebbe297a4f4c249b561e8218))

* Update tasks table ([`5f2e277`](https://github.com/embeddings-benchmark/mteb/commit/5f2e277804c8c6e649b2ba32f4768ea116897ce8))

* Update tasks table ([`11c2452`](https://github.com/embeddings-benchmark/mteb/commit/11c24527776eead78ec34288fb9ab455631eb2f6))

* Update tasks table ([`0ed6c34`](https://github.com/embeddings-benchmark/mteb/commit/0ed6c34387a7de9df2354fcd8ee7a34cde75f756))

* Update tasks table ([`03ffb4a`](https://github.com/embeddings-benchmark/mteb/commit/03ffb4abc9f8f71aba3bdefedb9baf1908d0fbac))

* Update tasks table ([`5651f6f`](https://github.com/embeddings-benchmark/mteb/commit/5651f6f526d8fca95cc07b12bea97f7a484d95e6))

* Update tasks table ([`e1926ea`](https://github.com/embeddings-benchmark/mteb/commit/e1926ea0adfcc54e125a42de00e44f598691502a))

* Update tasks table ([`1d08e42`](https://github.com/embeddings-benchmark/mteb/commit/1d08e42547dcae1fbbe47c4ae0d018bc699426c6))

* Update tasks table ([`e8b37f7`](https://github.com/embeddings-benchmark/mteb/commit/e8b37f75ad4c04972192045ab9b6cf3ed67cca09))

* Update tasks table ([`fc940e5`](https://github.com/embeddings-benchmark/mteb/commit/fc940e5450732d2e75a9547860eb47011177e2fc))

* Update tasks table ([`d949520`](https://github.com/embeddings-benchmark/mteb/commit/d9495200d865bc5e8bf74674b327040093960bdc))

* Update tasks table ([`50bfeaf`](https://github.com/embeddings-benchmark/mteb/commit/50bfeaf4cbf96ad17bd90d8138c3730ec228161c))

* Update tasks table ([`8866cc2`](https://github.com/embeddings-benchmark/mteb/commit/8866cc2ec8f9cf3b1cd551880ee688423bac4c1e))

* Update tasks table ([`b3eb993`](https://github.com/embeddings-benchmark/mteb/commit/b3eb993bb88edfab95067fe085dbd7df6ef4c3d8))

* Update tasks table ([`74551ca`](https://github.com/embeddings-benchmark/mteb/commit/74551ca2a7dcc20bad5c2bf73e04ebe282e7be1a))

* Update tasks table ([`4cd6ad0`](https://github.com/embeddings-benchmark/mteb/commit/4cd6ad0b18b7b2a3c35e5485eaa612ab717455e9))

* Update tasks table ([`b384dae`](https://github.com/embeddings-benchmark/mteb/commit/b384daea7ba6c1c4660afc21f101009de4197c43))

* Update tasks table ([`9e9f2d1`](https://github.com/embeddings-benchmark/mteb/commit/9e9f2d1ea870025e9e90161ec426389d31c7b254))

* Update tasks table ([`2a9fb4b`](https://github.com/embeddings-benchmark/mteb/commit/2a9fb4b9ddd170e386ab14d5bb3e8769cf86c732))

* Update tasks table ([`cdd121a`](https://github.com/embeddings-benchmark/mteb/commit/cdd121a131eaf39004f1dff3dae0428ccb144f06))

* Update tasks table ([`fe6e2cd`](https://github.com/embeddings-benchmark/mteb/commit/fe6e2cda3c67d8000353f9f8cd015317a613c7b1))

* Update tasks table ([`d2de690`](https://github.com/embeddings-benchmark/mteb/commit/d2de690273b78ba070c9809b65f0df09dcd5924b))

* Update tasks table ([`b60080d`](https://github.com/embeddings-benchmark/mteb/commit/b60080d7bfc6e6c3c67fde41bb0c212bb5ef92cd))

* Update tasks table ([`92d5d17`](https://github.com/embeddings-benchmark/mteb/commit/92d5d17a3c1081a40bd286e896f4e3b9b21159ca))

* Update tasks table ([`3f09026`](https://github.com/embeddings-benchmark/mteb/commit/3f090265663d387bde206652a176608132302df6))

* Update tasks table ([`20a16fb`](https://github.com/embeddings-benchmark/mteb/commit/20a16fb7d1ae8afb28a47cb8d03f609faabde7e8))

* Update tasks table ([`9661751`](https://github.com/embeddings-benchmark/mteb/commit/9661751f96ee2bdfe79c008993c928e3b6e34cc2))

* Update tasks table ([`fd57157`](https://github.com/embeddings-benchmark/mteb/commit/fd57157c12901ff06bde53a7ae9493473419d98a))

* Update tasks table ([`d6752c0`](https://github.com/embeddings-benchmark/mteb/commit/d6752c0f6a2b6faa676e601d2ec7f55f090fad9a))

* Update tasks table ([`d4eaa91`](https://github.com/embeddings-benchmark/mteb/commit/d4eaa9155231076546a47072d58c152684ab5c6d))

* Update tasks table ([`6dd2734`](https://github.com/embeddings-benchmark/mteb/commit/6dd2734c55863e0bb1a46793f8a905db91dbc30e))

* Update tasks table ([`d44d893`](https://github.com/embeddings-benchmark/mteb/commit/d44d893da6f264f9c8c57bdba5e476aef2a96d60))

* Update tasks table ([`03941bd`](https://github.com/embeddings-benchmark/mteb/commit/03941bd8c5481c1e0762faae50d43d32c0bd836f))

* Update tasks table ([`ef3fe1b`](https://github.com/embeddings-benchmark/mteb/commit/ef3fe1bc353f0144dc0a1bac37e41aecbd9acead))

* Update tasks table ([`eb80d8b`](https://github.com/embeddings-benchmark/mteb/commit/eb80d8bf1041ee9527548235ef7d9a498348c7ab))

* Update tasks table ([`4e2167a`](https://github.com/embeddings-benchmark/mteb/commit/4e2167a2b0730d2298f61b3aeb709a8cdf02fef8))

* Update tasks table ([`44fc1ae`](https://github.com/embeddings-benchmark/mteb/commit/44fc1ae4da329fc267473ce82c0e9a027ca2fe29))

* Update tasks table ([`579f946`](https://github.com/embeddings-benchmark/mteb/commit/579f946f788f6cbd76cce30c10eea3088b98aa97))

* Update tasks table ([`605f571`](https://github.com/embeddings-benchmark/mteb/commit/605f571a44349e90d1e571c2371d4fd828c1a773))

* Update tasks table ([`ebaa650`](https://github.com/embeddings-benchmark/mteb/commit/ebaa650e988ccafd4da27681da582afd521156ac))

* Update tasks table ([`50f2598`](https://github.com/embeddings-benchmark/mteb/commit/50f2598d69627c0d30fa2399e2a0603fa06cf650))

* Update tasks table ([`2191e83`](https://github.com/embeddings-benchmark/mteb/commit/2191e83f5d1f755e580d8b16643ed62b3b36495a))

* Update tasks table ([`4cc0fee`](https://github.com/embeddings-benchmark/mteb/commit/4cc0fee1e1df3d2713d1085c459fe1e91707a871))

* Update tasks table ([`1c24ef3`](https://github.com/embeddings-benchmark/mteb/commit/1c24ef3fd6db45593c61671966de30e587bdc8a5))

* Update tasks table ([`b755b79`](https://github.com/embeddings-benchmark/mteb/commit/b755b796111e71b24f546f552fd4a675667a5be5))

* Update tasks table ([`da7092c`](https://github.com/embeddings-benchmark/mteb/commit/da7092c9bf671b4b5cace15d613ef2c1c43db056))

* Update tasks table ([`fb90fa9`](https://github.com/embeddings-benchmark/mteb/commit/fb90fa92b2c075d537184048f1bbbff90d888397))

* Update tasks table ([`ba68e07`](https://github.com/embeddings-benchmark/mteb/commit/ba68e0780639a67af52b966c0e478ee45fc8329f))

* Update tasks table ([`28cf270`](https://github.com/embeddings-benchmark/mteb/commit/28cf2704c9ae3194b70ecfb8ce798dac0cf9dbe5))

* Update tasks table ([`9a2665b`](https://github.com/embeddings-benchmark/mteb/commit/9a2665bf3ec84a7c5c88301c1b50230a7931d661))

* Update tasks table ([`2d9a472`](https://github.com/embeddings-benchmark/mteb/commit/2d9a472f412c57de978dc9bf1d656003930a7e13))

* Update tasks table ([`fffce31`](https://github.com/embeddings-benchmark/mteb/commit/fffce31636ba66f65274f079d9a6188261bdf8b4))

* Update tasks table ([`0f7206b`](https://github.com/embeddings-benchmark/mteb/commit/0f7206b682bc750910c0a8bb1c6291da2dbd5f73))

* Update tasks table ([`3c57df3`](https://github.com/embeddings-benchmark/mteb/commit/3c57df3d7cba844c6875bc16c763ecf4bc287b1d))

* Update tasks table ([`616733d`](https://github.com/embeddings-benchmark/mteb/commit/616733d4a0862a7e4be5cd4f9946e4bab0e82d25))

* Update tasks table ([`acb3778`](https://github.com/embeddings-benchmark/mteb/commit/acb37786ec6da7eb92d924f97dd2c783b0e4d1ac))

* Update tasks table ([`750a9a9`](https://github.com/embeddings-benchmark/mteb/commit/750a9a91bb2887c78fcfb51d2088d2b5e0c287e2))

* Update tasks table ([`55cf386`](https://github.com/embeddings-benchmark/mteb/commit/55cf386ac30745c94650477c75b7730c0af3704b))

* Update tasks table ([`2156389`](https://github.com/embeddings-benchmark/mteb/commit/2156389e46e4fc4e592a1c35410eefb36f4ee8cf))

* Update tasks table ([`4a15db1`](https://github.com/embeddings-benchmark/mteb/commit/4a15db1ef23e4a765088a306f7fa7d6e73815fae))

* Update tasks table ([`baab628`](https://github.com/embeddings-benchmark/mteb/commit/baab628fe669afd5d4274c9cab2a231a1eee08be))

* Update tasks table ([`10d4604`](https://github.com/embeddings-benchmark/mteb/commit/10d4604e85e60886d0c6ca1b28bd7ede0c020737))

* Update tasks table ([`1b1efa7`](https://github.com/embeddings-benchmark/mteb/commit/1b1efa77ee4087e51a56f534855ca6a7e1392076))

* Update tasks table ([`803e973`](https://github.com/embeddings-benchmark/mteb/commit/803e97374880c0f491956c8852cdd3249a7b712e))

* Update tasks table ([`f539d9a`](https://github.com/embeddings-benchmark/mteb/commit/f539d9a92cc47e9aa9b9a28ef3926b4cc6f17bf2))

* Update tasks table ([`1faa897`](https://github.com/embeddings-benchmark/mteb/commit/1faa897a10fbaaede801737f9d1a906edb8ccbbd))

* Update tasks table ([`58d5248`](https://github.com/embeddings-benchmark/mteb/commit/58d5248bca4ae7b197bc45ddce6435f9f5a812e2))

* Update tasks table ([`0a073df`](https://github.com/embeddings-benchmark/mteb/commit/0a073dff01b47794ba94088b6eb6d49502bd5c68))

* Update tasks table ([`4d30059`](https://github.com/embeddings-benchmark/mteb/commit/4d30059eac4a6e7d55e2f5784955108a2e17f2c5))

* Update tasks table ([`253a499`](https://github.com/embeddings-benchmark/mteb/commit/253a499eb4bef243b715afd9502a28ab9198d763))

* Update tasks table ([`e29348c`](https://github.com/embeddings-benchmark/mteb/commit/e29348ca49ce31cc8a59e11eb2ae32d04e8ac200))

* Update tasks table ([`47c63c3`](https://github.com/embeddings-benchmark/mteb/commit/47c63c3a555915e1a5cb032866178c351e58db89))

* Update tasks table ([`1275f93`](https://github.com/embeddings-benchmark/mteb/commit/1275f932348004542fcecd9daf3b59b19e3c5f2c))

* Update tasks table ([`257578c`](https://github.com/embeddings-benchmark/mteb/commit/257578c544d723f915cd546d91b20519741b90d9))

* Update tasks table ([`93d631f`](https://github.com/embeddings-benchmark/mteb/commit/93d631f59895a9079da1ba86de965dd6b72bde39))

* Update tasks table ([`490b59c`](https://github.com/embeddings-benchmark/mteb/commit/490b59cc5eeb82ba0ec2c26959129502c42b141c))

## v1.31.6 (2025-01-30)

### Fix

* fix: Filling missing metadata for leaderboard release (#1895)

* Update ArxivClusteringS2S.py

* fill some metadat for retrieval

* fill in the reste of missing metadata

* fix metadata

* fix climatefever metadata

* fix: Added CQADupstack annotations

* removed annotation for non-exisitant task

* format

* Added financial to other financial dataset

* Moved ArguAna annotation to derivate datasets

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`938e90f`](https://github.com/embeddings-benchmark/mteb/commit/938e90f58714c525157d968a278ae3b07fc7b20a))

### Unknown

* Update tasks table ([`12ad5bd`](https://github.com/embeddings-benchmark/mteb/commit/12ad5bd4e0c606f73a2aab5b8e66f11f53fb5d35))

* Update tasks table ([`9076213`](https://github.com/embeddings-benchmark/mteb/commit/9076213f35f0662bc98efe646849d58b910e2b41))

* Update tasks table ([`4bb4ec6`](https://github.com/embeddings-benchmark/mteb/commit/4bb4ec645adf0a51d02d12e41b4ab26b19681041))

* Update tasks table ([`d510ddb`](https://github.com/embeddings-benchmark/mteb/commit/d510ddba80fb5396e0b3457aa2d608fc4f1006ea))

* Update tasks table ([`e35c8dd`](https://github.com/embeddings-benchmark/mteb/commit/e35c8dd71fe1431d583304ece365a31b5b4dc404))

* Update tasks table ([`9a6275e`](https://github.com/embeddings-benchmark/mteb/commit/9a6275eb540f6c97e659497bde09d9ee1765a704))

* Update tasks table ([`d9ab239`](https://github.com/embeddings-benchmark/mteb/commit/d9ab239460a60f7592f6fc61b58994440accd68b))

* Update tasks table ([`21b60f5`](https://github.com/embeddings-benchmark/mteb/commit/21b60f578940d29b89c4b60da4cb049ec780d3d9))

* Update tasks table ([`c46cb8b`](https://github.com/embeddings-benchmark/mteb/commit/c46cb8b1df5850e921a3704046b71354cfc80ad6))

* Update tasks table ([`0bbc4c7`](https://github.com/embeddings-benchmark/mteb/commit/0bbc4c701e8655abc95c3da74f1955126cba11d7))

* Update tasks table ([`3123d1c`](https://github.com/embeddings-benchmark/mteb/commit/3123d1cf3681cbd9f8bb99c496c571cde6c0f79d))

* Update tasks table ([`f7438b8`](https://github.com/embeddings-benchmark/mteb/commit/f7438b88745d3846721ddda34f70e45d4d661a70))

* Update tasks table ([`51faf65`](https://github.com/embeddings-benchmark/mteb/commit/51faf65040535ae6475a42d481c8431d73c0afe5))

* Update tasks table ([`1b76261`](https://github.com/embeddings-benchmark/mteb/commit/1b76261192bc14f2d13d58177bf2495d3d7154e1))

* Update tasks table ([`67f8a79`](https://github.com/embeddings-benchmark/mteb/commit/67f8a79f2589380bc690ce69aec372a71bd16bb7))

* Update tasks table ([`933f4af`](https://github.com/embeddings-benchmark/mteb/commit/933f4af9c3b2dde8983f29e78026e3bc36ee0e2a))

* Update tasks table ([`599849b`](https://github.com/embeddings-benchmark/mteb/commit/599849b47408dfb52f669aa14d39ca70e3673f69))

* Update tasks table ([`ff4ae8d`](https://github.com/embeddings-benchmark/mteb/commit/ff4ae8dc4c41acf0aaf80cb0ab0a641d8833fba9))

* Update tasks table ([`780a7d3`](https://github.com/embeddings-benchmark/mteb/commit/780a7d3179b96a6b1d8b89f344f09854af889f39))

* Update tasks table ([`c34ef64`](https://github.com/embeddings-benchmark/mteb/commit/c34ef6473ca8516d7de7cf59ec3ebcf502ecb69a))

* Update tasks table ([`b23597c`](https://github.com/embeddings-benchmark/mteb/commit/b23597c9b7d97b14c6292f1d4e1013b0b91192a6))

* Update tasks table ([`1030888`](https://github.com/embeddings-benchmark/mteb/commit/1030888fe108ee286bf4eb062f1ab054c8488d9a))

* Update tasks table ([`913112a`](https://github.com/embeddings-benchmark/mteb/commit/913112a3f3474281020e8092ce84d02d6c2a897c))

* Update tasks table ([`25a6f17`](https://github.com/embeddings-benchmark/mteb/commit/25a6f17fe4807cf1834ec2f2e113ae86f09960fe))

* Update tasks table ([`e07ffe8`](https://github.com/embeddings-benchmark/mteb/commit/e07ffe8d4502d99609286e262cc954346f60b427))

* Update tasks table ([`b78525d`](https://github.com/embeddings-benchmark/mteb/commit/b78525d05bca45a10a77fe1c9474fd94747a3667))

* Update tasks table ([`6989fd5`](https://github.com/embeddings-benchmark/mteb/commit/6989fd5f036e0d0c08c542e5458546e0a64ea03e))

* Update tasks table ([`b7e412d`](https://github.com/embeddings-benchmark/mteb/commit/b7e412d5e29912305c0ef1dd0b34b8aeef7af8c7))

* Update tasks table ([`2e817b0`](https://github.com/embeddings-benchmark/mteb/commit/2e817b03c0e863543091581096392e8d9ccd0025))

* Update tasks table ([`28ad172`](https://github.com/embeddings-benchmark/mteb/commit/28ad1723b5750f5b22b28783e1e57e38508f5498))

* Update tasks table ([`2850a97`](https://github.com/embeddings-benchmark/mteb/commit/2850a9706752d0cf341f674614a46880da6bea65))

* Update tasks table ([`77681bf`](https://github.com/embeddings-benchmark/mteb/commit/77681bf0900bed8b29688ade2a310b4ea7142e61))

* Adding a banner to the new MMTEB leaderboard (#1908)

* Adding a banner to the new MMTEB leaderboard

* linting

* Update mteb/leaderboard/app.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* adding reference to mteb arena

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`d0bb5b9`](https://github.com/embeddings-benchmark/mteb/commit/d0bb5b9753f36de826f45b956990d422757f24be))

* Update tasks table ([`f258cfc`](https://github.com/embeddings-benchmark/mteb/commit/f258cfc96063531aeb2a4e1e13a1e21b43ad04d2))

* Update tasks table ([`6cc0560`](https://github.com/embeddings-benchmark/mteb/commit/6cc0560305caf82d9a3bc876ee2d57bedb08cb0d))

* Update tasks table ([`7996458`](https://github.com/embeddings-benchmark/mteb/commit/7996458822e8f8f8de05e4c3a43c609e026b25b1))

* Docs: update docs according to current state (#1870)

* update docs

* Apply suggestions from code review

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* update readme

* Update README.md

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`7e5d6c8`](https://github.com/embeddings-benchmark/mteb/commit/7e5d6c81daa2512b1c257e645cd0de122184acc0))

* Update tasks table ([`0a59704`](https://github.com/embeddings-benchmark/mteb/commit/0a59704cb3711f01be8f211cee005033b7aadb20))

* Feat: Add FaMTEB (Farsi/Persian Text Embedding Benchmark) (#1843)

* Add Summary Retrieval Task

* Add FaMTEBClassification

* Add FaMTEBClustering

* Add FaMTEBPairClassification

* Add FaMTEBRetrieval and BEIRFA and FaMTEBSTS

* Add FaMTEBSummaryRetrieval

* Add FaMTEB to benchmarks

* fix benchmark names

* temporary fix metadata

* Fix dataset revisions

* Update SummaryRetrievalEvaluator.py

* Update task files

* Update task files

* add data domain and subtask description

* Update AbsTaskSummaryRetrieval and FaMTEBSummaryRetrieval

* Update AbsTaskSummaryRetrieval

* Add mock task

* Update AbsTaskSummaryRetrieval

* Update AbsTaskSummaryRetrieval

* make lint

* Refactor SummaryRetrieval to subclass BitextMining

* Add aggregated datasets

---------

Co-authored-by: mehran &lt;mehan.sarmadi16@gmail.com&gt;
Co-authored-by: e.zeinivand &lt;zeinivand@ymail.com&gt;
Co-authored-by: Erfun76 &lt;59398902+Erfun76@users.noreply.github.com&gt; ([`f3404b4`](https://github.com/embeddings-benchmark/mteb/commit/f3404b4b13377431c6d251926f13e338bc9f9b65))

* Update tasks table ([`35b2c09`](https://github.com/embeddings-benchmark/mteb/commit/35b2c09e800f956ced87c643dd9afbe248dfb834))

* Update tasks table ([`d44f9c3`](https://github.com/embeddings-benchmark/mteb/commit/d44f9c3fa814165e6110dd5d3cd8c340d37ee405))

* Update tasks table ([`0a57880`](https://github.com/embeddings-benchmark/mteb/commit/0a57880faeeb944a17004152c36dded85bcb218b))

* Update tasks table ([`e04218c`](https://github.com/embeddings-benchmark/mteb/commit/e04218cbf376ccb04965da6b7860f4cfe696efba))

## v1.31.5 (2025-01-29)

### Fix

* fix: Limited plotly version to be less than 6.0.0 (#1902)

Limited plotly version to be less than 6.0.0 ([`cec0ed4`](https://github.com/embeddings-benchmark/mteb/commit/cec0ed472fc762722bce24dfde6cb331f7006dee))

### Unknown

* Update tasks table ([`42c175f`](https://github.com/embeddings-benchmark/mteb/commit/42c175f110a6190e08736332ebbb03c48991d8e7))

* Update tasks table ([`a5d1538`](https://github.com/embeddings-benchmark/mteb/commit/a5d1538f58c688d42a5d2388540a023e12f332e8))

* Update tasks table ([`ef929f8`](https://github.com/embeddings-benchmark/mteb/commit/ef929f86a91d6361828c6786246b0c255bea4068))

* Update tasks table ([`d6deab1`](https://github.com/embeddings-benchmark/mteb/commit/d6deab116274cad0889929cb00beb31a5999664e))

* Update tasks table ([`1c84c1c`](https://github.com/embeddings-benchmark/mteb/commit/1c84c1cb103eae8654b7c482f22efe6a80aa9900))

* Update tasks table ([`cc1e899`](https://github.com/embeddings-benchmark/mteb/commit/cc1e899229336253a253b381a2c2767f8213dd8a))

* update stella/jasper metainfo (#1896)

update stella meta ([`976bdd5`](https://github.com/embeddings-benchmark/mteb/commit/976bdd5682584fb892935d69efbcda315fd6364e))

* Update tasks table ([`0861254`](https://github.com/embeddings-benchmark/mteb/commit/086125475e647a6a4cb43bed863dd494671f34a0))

* Update tasks table ([`a764fd7`](https://github.com/embeddings-benchmark/mteb/commit/a764fd7ea2c1a9f1cb72a5dd21b67bbab6b14bad))

* Update tasks table ([`93f23c4`](https://github.com/embeddings-benchmark/mteb/commit/93f23c41fd3544499f00c95ea2b03a1e8e1c6d21))

* Update tasks table ([`da08617`](https://github.com/embeddings-benchmark/mteb/commit/da0861794b3a0a2b47bddead9e1134ea05e83e11))

* Update tasks table ([`251142e`](https://github.com/embeddings-benchmark/mteb/commit/251142ecdd3633985df07721482d38bac1d5896f))

* Update tasks table ([`d005797`](https://github.com/embeddings-benchmark/mteb/commit/d005797a765d4f031f5720146b0bc92ecdb8b5dd))

* Update tasks table ([`d8bf18b`](https://github.com/embeddings-benchmark/mteb/commit/d8bf18b2f4605fca6455c4761bc3235789ce6371))

* Update tasks table ([`a91d268`](https://github.com/embeddings-benchmark/mteb/commit/a91d268014a8ce0a8791838a4c2709e32229a315))

* Update tasks table ([`092688d`](https://github.com/embeddings-benchmark/mteb/commit/092688df377e9dbb9080170f1462ef09a3818fbd))

## v1.31.4 (2025-01-29)

### Fix

* fix: Allow aggregated tasks within benchmarks (#1771)

* fix: Allow aggregated tasks within benchmarks

Fixes #1231

* feat: Update task filtering, fixing bug on MTEB

- Updated task filtering adding exclusive_language_filter and hf_subset
- fix bug in MTEB where cross-lingual splits were included
- added missing language filtering to MTEB(europe, beta) and MTEB(indic, beta)

The following code outlines the problems:

```py
import mteb
from mteb.benchmarks import MTEB_ENG_CLASSIC

task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
# was eq. to:
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;])
task.hf_subsets
# correct filtering to English datasets:
# [&#39;en&#39;, &#39;de-en&#39;, &#39;es-en&#39;, &#39;pl-en&#39;, &#39;zh-en&#39;]
# However it should be:
# [&#39;en&#39;]

# with the changes it is:
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
task.hf_subsets
# [&#39;en&#39;]
# eq. to
task = mteb.get_task(&#34;STS22&#34;, hf_subsets=[&#34;en&#34;])
# which you can also obtain using the exclusive_language_filter (though not if there was multiple english splits):
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;], exclusive_language_filter=True)
```

* format

* remove &#34;en-ext&#34; from AmazonCounterfactualClassification

* fixed mteb(deu)

* fix: simplify in a few areas

* wip

* tmp

* sav

* Allow aggregated tasks within benchmarks
Fixes #1231

* ensure correct formatting of eval_langs

* ignore aggregate dataset

* clean up dummy cases

* add to mteb(eng, classic)

* format

* clean up

* Allow aggregated tasks within benchmarks
Fixes #1231

* added fixed from comments

* fix merge

* format

* Updated task type

* Added minor fix for dummy tasks ([`8fb59a4`](https://github.com/embeddings-benchmark/mteb/commit/8fb59a49b00e7932abec42c045c1cc068c7eba41))

### Unknown

* Update tasks table ([`3ee0785`](https://github.com/embeddings-benchmark/mteb/commit/3ee07855c30b4419b4bf2fab934f2282141eaa9a))

* Update tasks table ([`02f8ad5`](https://github.com/embeddings-benchmark/mteb/commit/02f8ad57a847c39bc1cdf1bdf7fbae3868ba0e5d))

* Update tasks table ([`c77c82c`](https://github.com/embeddings-benchmark/mteb/commit/c77c82c0647e5f24d3035639da8a393193d08461))

* Update tasks table ([`e8b8ac0`](https://github.com/embeddings-benchmark/mteb/commit/e8b8ac08952c4569fd3b8cff3218e3ee9e3f25e2))

* Update tasks table ([`50f305f`](https://github.com/embeddings-benchmark/mteb/commit/50f305fcb286969bcda9a110a4a9236c5f8a7157))

* Update tasks table ([`2689cb8`](https://github.com/embeddings-benchmark/mteb/commit/2689cb84f40d2ac936942ea1590aec7dc5f63825))

* Update tasks table ([`24d5373`](https://github.com/embeddings-benchmark/mteb/commit/24d5373d5da6ffdd90085629c2da8192e1de935a))

* Update tasks table ([`e487eff`](https://github.com/embeddings-benchmark/mteb/commit/e487eff88f6a3460ae553b5fbef8bb552cfea92d))

* Update tasks table ([`8bc101f`](https://github.com/embeddings-benchmark/mteb/commit/8bc101f9e6933a197a272a3189c92d85bc9b00bd))

* Update tasks table ([`cebf5b6`](https://github.com/embeddings-benchmark/mteb/commit/cebf5b6d81981662af05762c8dffdb1a9bd5bf1a))

* Update tasks table ([`1ead72f`](https://github.com/embeddings-benchmark/mteb/commit/1ead72f3f03d3c858aca69216d031f95e64140dc))

* Update tasks table ([`d939627`](https://github.com/embeddings-benchmark/mteb/commit/d939627d27273b7b740e8ade5287f074aa6c0303))

## v1.31.3 (2025-01-28)

### Fix

* fix: External results are preferred when only they have the needed splits (#1893)

join_revisions now prefers task_results where the scores are not empty ([`2a41730`](https://github.com/embeddings-benchmark/mteb/commit/2a4173046a4b64c38c99132417abe60590dc0381))

## v1.31.2 (2025-01-28)

### Fix

* fix: update voyage exp metadata (#1888)

* fix: update voyage exp metadata

* aded number of parameters ([`e623771`](https://github.com/embeddings-benchmark/mteb/commit/e6237714a1e340a0e07a8f121030e0277a8d5634))

## v1.31.1 (2025-01-26)

### Fix

* fix: fix jina v1, 2 models (#1872)

fix jina models ([`1d66089`](https://github.com/embeddings-benchmark/mteb/commit/1d660892288d02379e67a59b94523410497ee20b))

### Unknown

* doc: update pr template (#1871)

* doc: update pr template

* group testing &amp;  add: do not delete

---------

Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt; ([`95714d0`](https://github.com/embeddings-benchmark/mteb/commit/95714d06da6a06969e92526262d57f718e840c21))

## v1.31.0 (2025-01-25)

### Feature

* feat: add instruct wrapper (#1768)

* add instruct wrapper

* use get_task_instruction

* add logging messages

* apply based on PromptType

* update description

* change example model

* move nvembed

* Update mteb/models/instruct_wrapper.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* update docstrings

* add instruction to docs

* Apply suggestions from code review

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* lint

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`ee0f15a`](https://github.com/embeddings-benchmark/mteb/commit/ee0f15ad03313d3a030c6f21ae6aafd9bc95bbb0))

## v1.30.0 (2025-01-25)

### Feature

* feat: Integrating ChemTEB (#1708)

* Add SMILES, AI Paraphrase and Inter-Source Paragraphs PairClassification Tasks

* Add chemical subsets of NQ and HotpotQA datasets as Retrieval tasks

* Add PubChem Synonyms PairClassification task

* Update task __init__ for previously added tasks

* Add nomic-bert loader

* Add a script to run the evaluation pipeline for chemical-related tasks

* Add 15 Wikipedia article classification tasks

* Add PairClassification and BitextMining tasks for Coconut SMILES

* Fix naming of some Classification and PairClassification tasks

* Fix some classification tasks naming issues

* Integrate WANDB with benchmarking script

* Update .gitignore

* Fix `nomic_models.py` issue with retrieval tasks, similar to issue #1115 in original repo

* Add one chemical model and some SentenceTransformer models

* Fix a naming issue for SentenceTransformer models

* Add OpenAI, bge-m3 and matscibert models

* Add PubChem SMILES Bitext Mining tasks

* Change metric namings to be more descriptive

* Add English e5 and bge v1 models, all the sizes

* Add two Wikipedia Clustering tasks

* Add a try-except in evaluation script to skip faulty models during the benchmark.

* Add bge v1.5 models and clustering score extraction to json parser

* Add Amazon Titan embedding models

* Add Cohere Bedrock models

* Add two SDS Classification tasks

* Add SDS Classification tasks to classification init and chem_eval

* Add a retrieval dataset, update dataset names and revisions

* Update revision for the CoconutRetrieval dataset: handle duplicate SMILES (documents)

* Update `CoconutSMILES2FormulaPC` task

* Change CoconutRetrieval dataset to a smaller one

* Update some models
- Integrate models added in ChemTEB (such as amazon, cohere bedrock and nomic bert) with latest modeling format in mteb.
- Update the metadata for the mentioned models

* Fix a typo
`open_weights` argument is repeated twice

* Update ChemTEB tasks
- Rename some tasks for better readability.
- Merge some BitextMining and PairClassification tasks into a single task with subsets (`PubChemSMILESBitextMining` and `PubChemSMILESPC`)
- Add a new multilingual task (`PubChemWikiPairClassification`) consisting of 12 languages.
- Update dataset paths, revisions and metadata for most tasks.
- Add a `Chemistry` domain to `TaskMetadata`

* Remove unnecessary files and tasks for MTEB

* Update some ChemTEB tasks
- Move `PubChemSMILESBitextMining` to `eng` folder
- Add citations for tasks involving SDS, NQ, Hotpot, PubChem data
- Update Clustering tasks `category`
- Change `main_score` for `PubChemAISentenceParaphrasePC`

* Create ChemTEB benchmark

* Remove `CoconutRetrieval`

* Update tasks and benchmarks tables with ChemTEB

* Mention ChemTEB in readme

* Fix some issues, update task metadata, lint
- `eval_langs` fixed
- Dataset path was fixed for two datasets
- Metadata was completed for all tasks, mainly following fields: `date`, `task_subtypes`, `dialect`, `sample_creation`
- ruff lint
- rename `nomic_bert_models.py` to `nomic_bert_model.py` and update it.

* Remove `nomic_bert_model.py` as it is now compatible with SentenceTransformer.

* Remove `WikipediaAIParagraphsParaphrasePC` task due to being trivial.

* Merge `amazon_models` and `cohere_bedrock_models.py` into `bedrock_models.py`

* Remove unnecessary `load_data` for some tasks.

* Update `bedrock_models.py`, `openai_models.py` and two dataset revisions
- Text should be truncated for amazon text embedding models.
- `text-embedding-ada-002` returns null embeddings for some inputs with 8192 tokens.
- Two datasets are updated, dropping very long samples (len &gt; 99th percentile)

* Add a layer of dynamic truncation for amazon models in `bedrock_models.py`

* Replace `metadata_dict` with `self.metadata` in `PubChemSMILESPC.py`

* fix model meta for bedrock models

* Add reference comment to original Cohere API implementation ([`4d66434`](https://github.com/embeddings-benchmark/mteb/commit/4d66434c80050ace3b927f3fc1829b8dd377f78a))

### Unknown

* Update points table ([`223bf32`](https://github.com/embeddings-benchmark/mteb/commit/223bf324c213f222785bbf2db88e30c8069c610b))

## v1.29.16 (2025-01-22)

### Fix

* fix: Added correct training data annotation to LENS (#1859)

Added correct training data annotation to LENS ([`e775436`](https://github.com/embeddings-benchmark/mteb/commit/e77543694ae16716c4420dd0b79c0d9f33a938db))

## v1.29.15 (2025-01-22)

### Fix

* fix: Adding missing model meta (#1856)

* Added CDE models

* Added bge-en-icl

* Updated CDE to bge_full_data

* Fixed public_training_data flag type to include boolean, as this is how all models are annotated

* Added public training data link instead of bool to CDE and BGE

* Added GME models

* Changed Torch to PyTorch

* Added metadata on LENS models

* Added ember_v1

* Added metadata for amazon titan

* Removed GME implementation ([`692bd26`](https://github.com/embeddings-benchmark/mteb/commit/692bd265e731c934d8318c497b954e271540a6ab))

## v1.29.14 (2025-01-22)

### Fix

* fix: Fix zeta alpha mistral (#1736)

* fix zeta alpha mistral

* update use_instructions

* update training datasets

* Update mteb/models/e5_instruct.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* update float

* Update mteb/models/e5_instruct.py

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`4985da9`](https://github.com/embeddings-benchmark/mteb/commit/4985da94cbc4c1368debab737fa8195f6bb91ce2))

* fix: Hotfixed public_training_data type annotation (#1857)

Fixed public_training_data flag type to include boolean, as this is how all models are annotated ([`4bd7328`](https://github.com/embeddings-benchmark/mteb/commit/4bd7328f1d43ff36564eb5941e7b32daf826f456))

### Unknown

* Add more annotations (#1833)

* apply additions from #1794

* add annotations for rumodels

* add nomic training data

* fix metadata

* update rest of model meta

* fix bge reranker ([`12ed9c5`](https://github.com/embeddings-benchmark/mteb/commit/12ed9c50debd83b7fd6f589373d1fd4539f2aa17))

## v1.29.13 (2025-01-22)

### Fix

* fix: Fixed leaderboard search bar (#1852)

Fixed leaderboard search bar ([`fe33061`](https://github.com/embeddings-benchmark/mteb/commit/fe330611b6e433096501d0d9814b2c644c33e984))

## v1.29.12 (2025-01-21)

### Fix

* fix: Leaderboard Refinements (#1849)

* Added better descriptions to benchmarks and removed beta tags

* Fixed zero-shot filtering on app loading

* Added zero-shot definition in an accordion

* NaN values are now filled with blank

* Added type hints to filter_models ([`a8cc887`](https://github.com/embeddings-benchmark/mteb/commit/a8cc88778623ee4e46c7c27ea5b5bc98e534165e))

## v1.29.11 (2025-01-21)

### Fix

* fix: Add reported annotation and re-added public_training_data (#1846)

* fix: Add additional dataset annotations

* fix: readded public training data

* update voyage annotations ([`a7a8144`](https://github.com/embeddings-benchmark/mteb/commit/a7a8144a6964641614c7d407e43c75ab5b7c40ca))

## v1.29.10 (2025-01-20)

### Fix

* fix: Remove default params, `public_training_data` and `memory usage` in `ModelMeta` (#1794)

* fix: Leaderboard: `K` instead of `M`
Fixes #1752
* format
* fixed existing annotations to refer to task name instead of hf dataset
* added annotation to nvidia
* added voyage
* added uae annotations
* Added stella annotations
* sentence trf models
* added salesforce and e5
* jina
* bge + model2vec
* added llm2vec annotations
* add jasper
* format
* format
* Updated annotations and moved jina models
* make models parameters needed to be filled
* fix tests
* remove comments
* remove model meta from test
* fix model meta from split
* fix: add even more training dataset annotations (#1793)
* fix: update max tokens for OpenAI (#1772)
update max tokens
* ci: skip AfriSentiLID for now (#1785)
* skip AfriSentiLID for now
* skip relevant test case instead
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* 1.28.7
Automatically generated by python-semantic-release
* ci: fix model loading test (#1775)
* pass base branch into the make command as an arg
* test a file that has custom wrapper
* what about overview
* just dont check overview
* revert instance check
* explicitly omit overview and init
* remove test change
* try on a lot of models
* revert test model file
---------
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
* feat: Update task filtering, fixing bug which included cross-lingual tasks in overly many benchmarks (#1787)
* feat: Update task filtering, fixing bug on MTEB
- Updated task filtering adding exclusive_language_filter and hf_subset
- fix bug in MTEB where cross-lingual splits were included
- added missing language filtering to MTEB(europe, beta) and MTEB(indic, beta)
The following code outlines the problems:
```py
import mteb
from mteb.benchmarks import MTEB_ENG_CLASSIC
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
# was eq. to:
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;])
task.hf_subsets
# correct filtering to English datasets:
# [&#39;en&#39;, &#39;de-en&#39;, &#39;es-en&#39;, &#39;pl-en&#39;, &#39;zh-en&#39;]
# However it should be:
# [&#39;en&#39;]
# with the changes it is:
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
task.hf_subsets
# [&#39;en&#39;]
# eq. to
task = mteb.get_task(&#34;STS22&#34;, hf_subsets=[&#34;en&#34;])
# which you can also obtain using the exclusive_language_filter (though not if there was multiple english splits):
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;], exclusive_language_filter=True)
```
* format
* remove &#34;en-ext&#34; from AmazonCounterfactualClassification
* fixed mteb(deu)
* fix: simplify in a few areas
* fix: Add gritlm
* 1.29.0
Automatically generated by python-semantic-release
* fix: Added more annotations!
* fix: Added C-MTEB (#1786)
Added C-MTEB
* 1.29.1
Automatically generated by python-semantic-release
* docs: Add contact to MMTEB benchmarks (#1796)
* Add myself to MMTEB benchmarks
* lint
* fix: loading pre 11 (#1798)
* fix loading pre 11
* add similarity
* lint
* run all task types
* 1.29.2
Automatically generated by python-semantic-release
* fix: allow to load no revision available (#1801)
* fix allow to load no revision available
* lint
* add require_model_meta to leaderboard
* lint
* 1.29.3
Automatically generated by python-semantic-release
---------
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;
* fig merges
* update models info
* change public_training_code to str
* change `public_training_code=False` to None
* remove annotations
* remove annotations
* remove changed annotations
* remove changed annotations
* remove `public_training_data` and `memory usage`
* make framework not optional
* make framework non-optional
* empty frameworks
* add framework
* fix tests
* Update mteb/models/overview.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt; ([`0a83e38`](https://github.com/embeddings-benchmark/mteb/commit/0a83e383efe41e86e51c0d4cdca18d9ed5d42821))

* fix: subsets to run (#1830)

* fix split evals
* add test
* lint
* fix moka
* add assert ([`8be6b2e`](https://github.com/embeddings-benchmark/mteb/commit/8be6b2e36abb005822e07c034484c245345f6eb2))

## v1.29.9 (2025-01-17)

### Fix

* fix: Fixed eval split for MultilingualSentiment in C-MTEB (#1804)

* Fixed eval split for MultilingualSentiment in C-MTEB

* FIxed splits for atec, bq and stsb in C-MTEB ([`96f639b`](https://github.com/embeddings-benchmark/mteb/commit/96f639bc34153caaac422a3a13e0d9f3626d65b9))

## v1.29.8 (2025-01-17)

### Fix

* fix: Added Misc Chinese models (#1819)

* Added moka and piccolo models to overview file

* Added Text2Vec models

* Added various Chinese embedding models

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`9823529`](https://github.com/embeddings-benchmark/mteb/commit/9823529282b131e7f24399eb0639fbc33280d148))

* fix: Added way more training dataset annotations (#1765)

* fix: Leaderboard: `K` instead of `M`
Fixes #1752

* format

* fixed existing annotations to refer to task name instead of hf dataset

* added annotation to nvidia

* added voyage

* added uae annotations

* Added stella annotations

* sentence trf models

* added salesforce and e5

* jina

* bge + model2vec

* added llm2vec annotations

* add jasper

* format

* format

* Updated annotations and moved jina models

* fix: add even more training dataset annotations (#1793)

* fix: update max tokens for OpenAI (#1772)

update max tokens

* ci: skip AfriSentiLID for now (#1785)

* skip AfriSentiLID for now

* skip relevant test case instead

---------

Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;

* 1.28.7

Automatically generated by python-semantic-release

* ci: fix model loading test (#1775)

* pass base branch into the make command as an arg

* test a file that has custom wrapper

* what about overview

* just dont check overview

* revert instance check

* explicitly omit overview and init

* remove test change

* try on a lot of models

* revert test model file

---------

Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;

* feat: Update task filtering, fixing bug which included cross-lingual tasks in overly many benchmarks (#1787)

* feat: Update task filtering, fixing bug on MTEB

- Updated task filtering adding exclusive_language_filter and hf_subset
- fix bug in MTEB where cross-lingual splits were included
- added missing language filtering to MTEB(europe, beta) and MTEB(indic, beta)

The following code outlines the problems:

```py
import mteb
from mteb.benchmarks import MTEB_ENG_CLASSIC

task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
# was eq. to:
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;])
task.hf_subsets
# correct filtering to English datasets:
# [&#39;en&#39;, &#39;de-en&#39;, &#39;es-en&#39;, &#39;pl-en&#39;, &#39;zh-en&#39;]
# However it should be:
# [&#39;en&#39;]

# with the changes it is:
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
task.hf_subsets
# [&#39;en&#39;]
# eq. to
task = mteb.get_task(&#34;STS22&#34;, hf_subsets=[&#34;en&#34;])
# which you can also obtain using the exclusive_language_filter (though not if there was multiple english splits):
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;], exclusive_language_filter=True)
```

* format

* remove &#34;en-ext&#34; from AmazonCounterfactualClassification

* fixed mteb(deu)

* fix: simplify in a few areas

* fix: Add gritlm

* 1.29.0

Automatically generated by python-semantic-release

* fix: Added more annotations!

* fix: Added C-MTEB (#1786)

Added C-MTEB

* 1.29.1

Automatically generated by python-semantic-release

* docs: Add contact to MMTEB benchmarks (#1796)

* Add myself to MMTEB benchmarks
* lint

* fix: loading pre 11 (#1798)

* fix loading pre 11

* add similarity

* lint

* run all task types

* 1.29.2

Automatically generated by python-semantic-release

* fix: allow to load no revision available (#1801)

* fix allow to load no revision available

* lint

* add require_model_meta to leaderboard

* lint

* 1.29.3

Automatically generated by python-semantic-release

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt;

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt; ([`3b2d074`](https://github.com/embeddings-benchmark/mteb/commit/3b2d074efbe9d665171071dab63796f3ae783802))

* fix: bm25s (#1827)

Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt; ([`96420a2`](https://github.com/embeddings-benchmark/mteb/commit/96420a2ad39a61aafb34630f5c6c5a50a3717fdc))

* fix: Added Chinese Stella models (#1824)

Added Chinese Stella models ([`74b495c`](https://github.com/embeddings-benchmark/mteb/commit/74b495cd197846af91d6425891d1f9156cd1db68))

## v1.29.7 (2025-01-16)

### Ci

* ci: only return 1 model_name per file (#1818)

* only return 1 model_name per file

* fix args parse

* revert test change ([`d7a7791`](https://github.com/embeddings-benchmark/mteb/commit/d7a77918cc0e8b8f03cbbe5199e8a0fe58e429d9))

### Fix

* fix: add bge-m3 `ModelMeta` (#1821)

add bge ([`4ac59bc`](https://github.com/embeddings-benchmark/mteb/commit/4ac59bcdfbed8604b05e067b8b7df79f47b0d7a7))

### Unknown

* Add model inf-retriever-v1 (#1744)

* feat(models): add infly/inf-retriever-v1 model metadata- Add inf_models.py file with metadata for infly/inf-retriever-v1 model
- Update overview.py to include inf_models in model imports

* Reformat code

* Update inf-retriever-v1 ModelMeta

* Fill more information for inf-retriever-v1

* Add license information for inf-retriever-v1

---------

Co-authored-by: Samuel Yang &lt;samuelyang150@gmail.com&gt; ([`60c4980`](https://github.com/embeddings-benchmark/mteb/commit/60c49804fe0bbf10a4dde7cc63a9002f5eee6d40))

## v1.29.6 (2025-01-15)

### Fix

* fix: Added more Chinese models&#39; `ModelMeta` (#1814)

* Added Multilingual USE models

* Added Moka models

* Added dmeta models

* Added jina-zh

* Added  piccolo models ([`748955c`](https://github.com/embeddings-benchmark/mteb/commit/748955c367b5c549f4b8d54945361f5bbc7184f6))

## v1.29.5 (2025-01-15)

### Fix

* fix: Add additional contacts (#1817)

add contacts from #1790 ([`c4ee9fe`](https://github.com/embeddings-benchmark/mteb/commit/c4ee9fe1ccffaea57b8bf21d42e4031386a95c01))

### Unknown

* Update points table ([`e3a3df8`](https://github.com/embeddings-benchmark/mteb/commit/e3a3df89b5749924bb45986460d25ec58f7f24e8))

## v1.29.4 (2025-01-15)

### Fix

* fix: Added `ModelMeta` for BGE, GTE Chinese and multilingual models (#1811)

* Added BGE Chinese and multilingual-gemma models

* Added GTE multilingual and Chinese models

* Fixed date format ([`3f5ee82`](https://github.com/embeddings-benchmark/mteb/commit/3f5ee82a5049eaf235a84fcfc9278f48adecfcb7))

* fix: Zero shot and aggregation on Leaderboard (#1810)

* Made join_revision filter out no_revision_available when other revisions have been run on the task

* Fixed zero-shot filtering

* Fixed aggregation of task types

* Ran linting ([`0acc166`](https://github.com/embeddings-benchmark/mteb/commit/0acc166d54294ce16dc4750a84ad4abd896ab92d))

## v1.29.3 (2025-01-14)

### Fix

* fix: allow to load no revision available (#1801)

* fix allow to load no revision available

* lint

* add require_model_meta to leaderboard

* lint ([`a202884`](https://github.com/embeddings-benchmark/mteb/commit/a2028840a6b4f77057761664edce8cae2edb64d1))

## v1.29.2 (2025-01-14)

### Documentation

* docs: Add contact to MMTEB benchmarks (#1796)

* Add myself to MMTEB benchmarks
* lint ([`e9e9118`](https://github.com/embeddings-benchmark/mteb/commit/e9e9118b9bf6cbda678c70d6776a8f290833eff3))

### Fix

* fix: loading pre 11 (#1798)

* fix loading pre 11

* add similarity

* lint

* run all task types ([`94103e6`](https://github.com/embeddings-benchmark/mteb/commit/94103e6a2e8156678c3858045286cbd50b5d49c5))

## v1.29.1 (2025-01-13)

### Fix

* fix: Added C-MTEB (#1786)

Added C-MTEB ([`3ba7e22`](https://github.com/embeddings-benchmark/mteb/commit/3ba7e22d52320166ec003cbd04c5f09bc0eefe24))

## v1.29.0 (2025-01-13)

### Ci

* ci: fix model loading test (#1775)

* pass base branch into the make command as an arg

* test a file that has custom wrapper

* what about overview

* just dont check overview

* revert instance check

* explicitly omit overview and init

* remove test change

* try on a lot of models

* revert test model file

---------

Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt; ([`9b117a8`](https://github.com/embeddings-benchmark/mteb/commit/9b117a8245a8c56470d99b8ca3d6b2f6b6819dd8))

### Feature

* feat: Update task filtering, fixing bug which included cross-lingual tasks in overly many benchmarks (#1787)

* feat: Update task filtering, fixing bug on MTEB

- Updated task filtering adding exclusive_language_filter and hf_subset
- fix bug in MTEB where cross-lingual splits were included
- added missing language filtering to MTEB(europe, beta) and MTEB(indic, beta)

The following code outlines the problems:

```py
import mteb
from mteb.benchmarks import MTEB_ENG_CLASSIC

task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
# was eq. to:
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;])
task.hf_subsets
# correct filtering to English datasets:
# [&#39;en&#39;, &#39;de-en&#39;, &#39;es-en&#39;, &#39;pl-en&#39;, &#39;zh-en&#39;]
# However it should be:
# [&#39;en&#39;]

# with the changes it is:
task = [t for t in MTEB_ENG_CLASSIC.tasks if t.metadata.name == &#34;STS22&#34;][0]
task.hf_subsets
# [&#39;en&#39;]
# eq. to
task = mteb.get_task(&#34;STS22&#34;, hf_subsets=[&#34;en&#34;])
# which you can also obtain using the exclusive_language_filter (though not if there was multiple english splits):
task = mteb.get_task(&#34;STS22&#34;, languages=[&#34;eng&#34;], exclusive_language_filter=True)
```

* format

* remove &#34;en-ext&#34; from AmazonCounterfactualClassification

* fixed mteb(deu)

* fix: simplify in a few areas ([`4a70e5d`](https://github.com/embeddings-benchmark/mteb/commit/4a70e5d8996a341097c81782b463b1822f9708fe))

## v1.28.7 (2025-01-13)

### Ci

* ci: skip AfriSentiLID for now (#1785)

* skip AfriSentiLID for now

* skip relevant test case instead

---------

Co-authored-by: Isaac Chung &lt;isaac.chung@team.wrike.com&gt; ([`71dbd61`](https://github.com/embeddings-benchmark/mteb/commit/71dbd61c2b1b82e3d19ed0a4914f59886d4f0007))

### Fix

* fix: update max tokens for OpenAI (#1772)

update max tokens ([`0c5c3a5`](https://github.com/embeddings-benchmark/mteb/commit/0c5c3a544bea7dcb4c6e6d75d612638171cf0332))

## v1.28.6 (2025-01-11)

### Fix

* fix: added annotations for training data (#1742)

* fix: Added annotations for arctic embed models

* added google and bge

* added cohere

* Added e5

* added bge based model2vec

* annotated oAI

* format and update annotations ([`3f093c8`](https://github.com/embeddings-benchmark/mteb/commit/3f093c86a5e4bccd31e8a9ed860d1a33bd64b391))

## v1.28.5 (2025-01-11)

### Fix

* fix: Leaderboard: `K` instead of `M` (#1761)

Fixes #1752 ([`972463e`](https://github.com/embeddings-benchmark/mteb/commit/972463e818b411609c4c60c070377e75c2987b4c))

### Unknown

* other: add script for leaderboard compare (#1758)

* add script

* remove changes

* remove changes

* add comment

* lint

* order like in benchmark object

* round results ([`8bc80aa`](https://github.com/embeddings-benchmark/mteb/commit/8bc80aa360cc40ce8fbdc209c609919272abf870))

## v1.28.4 (2025-01-10)

### Fix

* fix: fixes implementation of similarity() (#1748)

* fix(#1594): fixes implementation of similarity()

* fix: add similarity to SentenceTransformerWrapper

---------

Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt; ([`3fe9264`](https://github.com/embeddings-benchmark/mteb/commit/3fe92644fa53c0c8cedc92d17fb25f0012a26aab))

## v1.28.3 (2025-01-10)

### Fix

* fix: Fixed definition of zero-shot in ModelMeta (#1747)


* Corrected zero_shot definition to be based on task names, not dataset path ([`407e205`](https://github.com/embeddings-benchmark/mteb/commit/407e20541613018b61fda2f1ec6be0ef9741e194))

## v1.28.2 (2025-01-10)

### Fix

* fix: Fixed task_type aggregation on leaderboard (#1746)

* Fixed task_type aggregation in leaderboard

* Fixed an error due to unneccesary indentation in get_score ([`76bb070`](https://github.com/embeddings-benchmark/mteb/commit/76bb070f5966716010e399c6bf1c2278ce83a173))

## v1.28.1 (2025-01-10)

### Fix

* fix: Leaderboard Speedup (#1745)

* Added get_scores_fast

* Made leaderboard faster with smarter dependency graph and event management and caching

* Changed print to logger.info ([`9eff8ca`](https://github.com/embeddings-benchmark/mteb/commit/9eff8cae60e3fcf9346969dfbf7f548f3e27bc55))

### Test

* test: Add script to test model loading below n_parameters threshold (#1698)

* add model loading test for models below 2B params
* add failure message to include model namne
* use the real get_model_meta
* use cache folder
* teardown per function
* fix directory removal
* write to file
* wip loading from before
* wip
* Rename model_loading_testing.py to model_loading.py
* Delete tests/test_models/test_model_loading.py
* checks for models below 2B
* try not using cache folder
* update script with scan_cache_dir and add args
* add github CI: detect changed model files and run model loading test
* install all model dependencies
* dependecy installations and move file location
* should trigger a model load test in CI
* find correct commit for diff
* explicity fetch base branch
* add make command
* try to run in python instead and add pytest
* fix attribute error and add read mode
* separate script calling
* let pip install be cached and specify repo path
* check ancestry
* add cache and rebase
* try to merge instead of rebase
* try without merge base
* check if file exists first
* Apply suggestions from code review
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update .github/workflows/model_loading.yml
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* address review comments to run test once from CI and not pytest
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`8d033f3`](https://github.com/embeddings-benchmark/mteb/commit/8d033f39415cd00840a1e0f6305d453ca6032abf))

### Unknown

* Fixed result loading on leaderboard (#1739)

* Only main_score gets loaded for leaderboard thereby avoiding OOM errors

* Fixed plot failing because of missing embedding dimensions

* Ran linting ([`752d2b8`](https://github.com/embeddings-benchmark/mteb/commit/752d2b8013db501af11db851dd07a70931b266b0))

## v1.28.0 (2025-01-09)

### Feature

* feat: Add nomic modern bert (#1684)

* add nomic modern bert

* use SentenceTransformerWrapper

* use SentenceTransformerWrapper

* try nomic wrapper

* update

* use all prompts

* pass prompts

* use fp16

* lint

* change to version

* remove commented code ([`95f143a`](https://github.com/embeddings-benchmark/mteb/commit/95f143a075812e4c12d53c0893539db0379052d9))

### Fix

* fix: allow kwargs in init for RerankingWrapper (#1676)

* allow kwargs in init

* fix retrieval

* convert corpus_in_pair to list ([`f5962c6`](https://github.com/embeddings-benchmark/mteb/commit/f5962c6ff0197f38a39a06c1a14ad6d2bb7522f3))

## v1.27.0 (2025-01-08)

### Feature

* feat: reduce logging for load_results()

- redacts missing subsets to avoid 100+ subsets printed
- reduce to logging.info
- removed splits that are commonly never evaluated on and thus also the errors for them being missing

The second part removed quite a few warnings (4930 to XX)

It also seems like the splits were accidentally included in some of the MMTEB benchmark.

This will remove those splits from those benchmarks (which are all in beta). We will have to recompute the tables for the paper though (we should do that anyway)

Other potential thing to consider:

- Scifact is included in MTEB(Medical). I have removed the &#34;train&#34; split from it as I think that was a mistake. (checked other dataset in benchmark)

Here is a count of the current top errors:
```py
{
    &#34;MassiveScenarioClassification: Missing splits {&#39;validation&#39;}&#34;: 238,  # included in e.g. mteb(fra)
    &#34;MassiveIntentClassification: Missing splits {&#39;validation&#39;}&#34;: 237, # included in e.g. mteb(fra)
    &#34;MassiveScenarioClassification: Missing subsets {&#39;af&#39;, &#39;da&#39;, ...} for split test&#34;: 230,
    &#34;AmazonReviewsClassification: Missing splits {&#39;validation&#39;}&#34;: 229, # included in e.g. mteb(deu)
    &#34;MassiveIntentClassification: Missing subsets {&#39;af&#39;, &#39;da&#39;, ...} for split test&#34;: 228,
    &#34;STS22: Missing subsets {&#39;fr-pl&#39;, &#39;de-en&#39;, ...} for split test&#34;: 223,
    &#34;AmazonReviewsClassification: Missing subsets {&#39;es&#39;, &#39;ja&#39;, ...} for split test&#34;: 196,
    &#34;MTOPDomainClassification: Missing splits {&#39;validation&#39;}&#34;: 195, # included in mteb(fra)
    &#34;MTOPIntentClassification: Missing splits {&#39;validation&#39;}&#34;: 194, # included in mteb(fra)
    &#34;AmazonCounterfactualClassification: Missing splits {&#39;validation&#39;}&#34;: 189, # included in mteb(deu)
    &#34;MTOPDomainClassification: Missing subsets {&#39;es&#39;, &#39;th&#39;, ...} for split test&#34;: 165,
    &#34;STS17: Missing subsets {&#39;en-ar&#39;, &#39;es-es&#39;, ...} for split test&#34;: 164,
    &#34;MTOPIntentClassification: Missing subsets {&#39;es&#39;, &#39;th&#39;, ...} for split test&#34;: 164,
    &#34;AmazonCounterfactualClassification: Missing subsets {&#39;de&#39;, &#39;ja&#39;, ...} for split test&#34;: 148,
}
``` ([`7e16fa2`](https://github.com/embeddings-benchmark/mteb/commit/7e16fa2565b2058e12303a1feedbd0d4dea96a41))

## v1.26.6 (2025-01-08)

### Fix

* fix: Added zero shot tag to benchmark (#1710)

* Added method for determining whether a model is zero shot

* Added .items() where intended

* Added filtering functions for zero shot models

* Added zero-shot filtering button and error message when table is empty.:

* Ran linting

* Fixed docstring linting error

* is_zero_shot returns None when no training data is specified

* Added zero-shot emoji column to leaderboard

* Added explanation for zero shot column

* Added soft and hard zero-shot buttons

* Added training data annotations to 24 models from HuggingFace Hub ([`8702815`](https://github.com/embeddings-benchmark/mteb/commit/87028155f1f4d0b81156e9ff278dcab8a903e7a4))

## v1.26.5 (2025-01-08)

### Ci

* ci: Refresh the v2 leaderboard daily (#1711)

* Create leaderboard_refresh.yaml

* Shorten and fix

* factory reset instead of normal ([`25f4f61`](https://github.com/embeddings-benchmark/mteb/commit/25f4f618f1694d1155919c9771c551fa70b5049b))

### Fix

* fix: rollback BUCC revision (#1706)

* fix bucc
* fix logger
* upd evaluator
* add comment
* lint ([`9bcb52f`](https://github.com/embeddings-benchmark/mteb/commit/9bcb52ff6c6a13d3de03dc2f0cc95fd3a62d9170))

### Unknown

* Fix: typos in adding a model (#1722) ([`ab8805c`](https://github.com/embeddings-benchmark/mteb/commit/ab8805c612c178c30d6642770778b06324cbfbc1))

* Fix: minicpmv2 (#1705)

* updmini cpm

* flash_attn implementation

* remove flash attn ([`222bb35`](https://github.com/embeddings-benchmark/mteb/commit/222bb35ebfa0da4d8b620d78bcfd64729a37ab03))

## v1.26.4 (2025-01-04)

### Fix

* fix: GermanDPR (#1703)

* fix GermanDPR

* lint ([`753d08a`](https://github.com/embeddings-benchmark/mteb/commit/753d08a95dfdcdb3439510abff69e14304caa4e7))

* fix: Register MicroLlama Text Embedding (#1644)

Register MicroLlama Text Embedding ([`6d1d9f4`](https://github.com/embeddings-benchmark/mteb/commit/6d1d9f4191876829740b9bf7234ec62d31805d30))

### Unknown

* Update RerankingEvaluator.py (#1702) ([`0753aba`](https://github.com/embeddings-benchmark/mteb/commit/0753abaacb31989e00b8e00322254cce85903639))

## v1.26.3 (2025-01-03)

### Fix

* fix: NanoBeir (#1687)

* fix nano beir

* lint ([`cff7ed8`](https://github.com/embeddings-benchmark/mteb/commit/cff7ed887715f3f72c4de0793041c15205f87f04))

* fix: nomic prompts (#1685)

* fix nomic prompts

* fix variable model name

* pass prompts to model

* use sentence transformer wrapper

* update prompts

* lint

* update prompts

* update list for classification ([`808257c`](https://github.com/embeddings-benchmark/mteb/commit/808257c0311cf5ff54cf579412a43eb460fbc15b))

## v1.26.2 (2025-01-03)

### Fix

* fix: update model loader to trust remote code (#1697)

update model loader ([`43d74e1`](https://github.com/embeddings-benchmark/mteb/commit/43d74e158b6d3217e94e074b96ebe0649651ddf8))

## v1.26.1 (2025-01-03)

### Fix

* fix: add revision for jinaai/jina-embeddings-v2-small-en (#1692)

add revision ([`6bfc1f2`](https://github.com/embeddings-benchmark/mteb/commit/6bfc1f2a5655c66940e4cb515153bb910498b9b6))

### Unknown

*  fix: add trust_remote_code to Snowflake/snowflake-arctic-embed-m-long (#1695)

trust remote code ([`f4de307`](https://github.com/embeddings-benchmark/mteb/commit/f4de30737c6d862973a4512a33e5f1d269eea5af))

## v1.26.0 (2025-01-02)

### Feature

* feat: add `avsolatorio/NoInstruct-small-Embedding-v0` (#1677)

add no_instruct ([`ba1f022`](https://github.com/embeddings-benchmark/mteb/commit/ba1f022d5063ce8f4c5fec095b7cc5218372666a))

### Fix

* fix: arg name for openbmb/MiniCPM-Embedding (#1691)

fix name ([`4a496b9`](https://github.com/embeddings-benchmark/mteb/commit/4a496b9f1d179f30c39c2b4acc55752816e21048))

## v1.25.20 (2025-01-02)

### Fix

* fix: nomic tensor return (#1683)

* fix nomic tensor return

* add typehint ([`f5e6401`](https://github.com/embeddings-benchmark/mteb/commit/f5e64013e83033f9b2f60bf6f44bf373ab684ad9))

## v1.25.19 (2025-01-02)

### Fix

* fix: trust remote code for snowflake-arctic-embed-m-v2.0 (#1682)

trust remote code ([`7b1e67b`](https://github.com/embeddings-benchmark/mteb/commit/7b1e67bf6ce6ad880d7f34250778db12a3675ee2))

## v1.25.18 (2025-01-02)

### Fix

* fix: add check for key error in loader (#1675)

* add check for key error

* make KeyError everywhere

* update error ([`1aa08fd`](https://github.com/embeddings-benchmark/mteb/commit/1aa08fd41bce7a4372bf8aacde1db9e38a363719))

## v1.25.17 (2025-01-01)

### Fix

* fix: Add warning for non-retrieval tasks when using bm25s (#1678)

* clean up install instruction

* add check for bm25s and skip non-retrieval tasks

* add versions ([`c50f26c`](https://github.com/embeddings-benchmark/mteb/commit/c50f26c84dab23a065b3044fe614ceb282b7f792))

## v1.25.16 (2025-01-01)

### Fix

* fix: Update BUCC dataset revision (#1674)

* trust remote code

* Update revision ([`343edc4`](https://github.com/embeddings-benchmark/mteb/commit/343edc485a366a91925b893033abe76b2a300dcc))

## v1.25.15 (2025-01-01)

### Fix

* fix: Use prompts instead of prompt names for voyage (#1665)

* fix prompt names

* lint

* change input type ([`82e9949`](https://github.com/embeddings-benchmark/mteb/commit/82e9949828b83e30c3efb7ccd3268cf0762dc591))

* fix: remove model as a parameter for MulticlassClassification (#1666)

remove model parameter ([`5cfcc77`](https://github.com/embeddings-benchmark/mteb/commit/5cfcc77cc8eb45fd7ba15042117988843ed71ddc))

## v1.25.14 (2025-01-01)

### Fix

* fix: Updated metadata for CPM (#1670)

* fix: Pass trust_remote_code=True to CPM model

Fixes #1651

* fix: Updated metadata for cpm ([`f99a178`](https://github.com/embeddings-benchmark/mteb/commit/f99a178c2c085644d0adf64d37d162bc748d5be7))

## v1.25.13 (2025-01-01)

### Fix

* fix: Pass trust_remote_code=True to CPM model (#1669)

Fixes #1651 ([`f426159`](https://github.com/embeddings-benchmark/mteb/commit/f4261592066454f1b9b44f6bce59b0c1ea2e9ac7))

## v1.25.12 (2025-01-01)

### Fix

* fix: Use batch size kwargs for openai APIs (#1668)

Fixes #1645 ([`663653e`](https://github.com/embeddings-benchmark/mteb/commit/663653e1be56e885ef2b2b1ab0eb1c4ac01a1b52))

## v1.25.11 (2025-01-01)

### Fix

* fix: Update gritlm kwargs (#1643)

* Fix kwarg

* format

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`19cbf64`](https://github.com/embeddings-benchmark/mteb/commit/19cbf64d727e4980d80340fde55d3d7491924318))

## v1.25.10 (2025-01-01)

### Fix

* fix: Cast all Model2Vec outputs as floats (#1667)

cast all outputs as floats ([`fa0ed6b`](https://github.com/embeddings-benchmark/mteb/commit/fa0ed6b37c232f1832630eb15e96f2de6bf90a57))

## v1.25.9 (2024-12-30)

### Fix

* fix: add missing benchmark to benchmarks.py (#1641)

add missing benchmark ([`27eb549`](https://github.com/embeddings-benchmark/mteb/commit/27eb549d8445e1425dd0fec8cfff80892d20ba4e))

## v1.25.8 (2024-12-30)

### Fix

* fix: output_folder for co2 evaluation (#1642) ([`366b2ce`](https://github.com/embeddings-benchmark/mteb/commit/366b2cef74b0ccc5486799696a3d939cdf64c9c1))

## v1.25.7 (2024-12-29)

### Fix

* fix: Correction of discrepancies for gte-Qweb model (#1637) ([`2de61b1`](https://github.com/embeddings-benchmark/mteb/commit/2de61b104ce0433955815b977aba2dca4213e775))

### Unknown

* Speed up test_save_predictions (#1631) ([`1b06601`](https://github.com/embeddings-benchmark/mteb/commit/1b066019a8eaef102e74c395ac09422d3f0b0760))

## v1.25.6 (2024-12-24)

### Fix

* fix: Update results_to_dataframe to use BenchmarkResults class (#1628) ([`02ae4fa`](https://github.com/embeddings-benchmark/mteb/commit/02ae4fabc3c0a7d733728c2c645c9e472fca42bb))

### Unknown

* Feat: Add jasper (#1591)

* init jasper

* init jasper

* add to overview

* add to overview

* remove some params

* fix max length

* return sdpa

* add dtype

* add dtype

* fix convert_to_tensor

* change to encode

* return whitespace processing

* explicitly add instructions

* move seq length

* try float

* fix max_seq_length

* add prompt validation to format instruction

* don&#39;t use instructions only to s2p ([`ef5a068`](https://github.com/embeddings-benchmark/mteb/commit/ef5a068c82e51b82f7c2233581ea3e2b597a6a8b))

## v1.25.5 (2024-12-22)

### Fix

* fix: properly add mteb_model_meta to model object (#1623) ([`72a457e`](https://github.com/embeddings-benchmark/mteb/commit/72a457ebbc6ae7e758adf3720ba082606084b84d))

* fix: GermanDPR Dataset Causes Cross-Encoder Failure Due to Unexpected dict (#1621)

Fixes #1609 ([`748033e`](https://github.com/embeddings-benchmark/mteb/commit/748033ebd094896b2d40a47b0e88ae13bb7fbef8))

### Unknown

* add MSMARCO eval split in MTEB English (classic) benchmark (#1620)

* add MSMARCO eval split in MTEB English (classic) benchmark

Fixes #1608

* Add co-author

Co-authored-by: aashka-trivedi &lt;aashka.trivedi@gmail.com&gt;

---------

Co-authored-by: aashka-trivedi &lt;aashka.trivedi@gmail.com&gt; ([`e1b74f2`](https://github.com/embeddings-benchmark/mteb/commit/e1b74f229765544b62fb8e97d1c49c12e39870b3))

## v1.25.4 (2024-12-22)

### Fix

* fix: override existing results (#1617)

* fix override existing results

* lint

* fix tests

* add tests with overwrite

* lint

* update tests

* lint

* update

* lint ([`272adb1`](https://github.com/embeddings-benchmark/mteb/commit/272adb1691fb6a2f7863a16b2d32f0af4946c37f))

## v1.25.3 (2024-12-20)

### Fix

* fix: set `use_instructions` to True in models using prompts (#1616)

feat: set `use_instructions` to True in models using prompts ([`0c44482`](https://github.com/embeddings-benchmark/mteb/commit/0c444827f97bc558cbe5573714b3f4d9e7d745c0))

## v1.25.2 (2024-12-20)

### Fix

* fix: disable co2_tracker for API models (#1614) ([`7c8e094`](https://github.com/embeddings-benchmark/mteb/commit/7c8e094743c236a46d892f7cfa59529d64ef141b))

### Unknown

* Add IBM Granite Embedding Models (#1613)

* add IBM granite embedding models
* lint formatting
* add adapted_from and superseded_by to ModelMeta ([`ad05983`](https://github.com/embeddings-benchmark/mteb/commit/ad05983fc3e44afc9087328f010a06ceb83f6f7d))

* Feat: Evaluate missing languages (#1584)

* init
* fix tests
* update mock retrieval
* update tests
* use subsets instead of langs
* Apply suggestions from code review
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* fix tests
* add to readme
* rename subset in readme
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`48cb97d`](https://github.com/embeddings-benchmark/mteb/commit/48cb97d1e75cdf8260283d6628ac515141ed1e92))

* Update tasks table ([`9de7f20`](https://github.com/embeddings-benchmark/mteb/commit/9de7f20e091a674e984e6b89b099a5f31cd09cd7))

* Add NanoBEIR Datasets (#1588)

* add NanoClimateFeverRetrieval task, still requires some debugging
* move task to correct place in init file
* add all Nano datasets and results
* format code
* Update mteb/tasks/Retrieval/eng/tempCodeRunnerFile.py
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
* pin revision to commit and add datasets to benchmark.py
* create new benchmark for NanoBEIR
* add revision when loading datasets
* lint
---------
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: isaac-chung &lt;chungisaac1217@gmail.com&gt; ([`6731b94`](https://github.com/embeddings-benchmark/mteb/commit/6731b94d0c7b1bc3a01329d12b3c5b03520ae102))

* Feat: Use similarity scores if available (#1602)

* Use similarity scores if available

* lint ([`b81b584`](https://github.com/embeddings-benchmark/mteb/commit/b81b584ceb1bd8a42a676482edcc19c90de75cb1))

## v1.25.1 (2024-12-16)

### Fix

* fix: Leaderboard refinements (#1603)

* Added explanation of aggregate measures

* Added download button to result tables

* Task info gets sorted by task name

* Added custom, shareable links for each benchmark

* Moved explanation of aggregate metrics to the summary tab ([`6ecc86f`](https://github.com/embeddings-benchmark/mteb/commit/6ecc86ff2f6fc0ea83332cb9a454df8c7e178ddd))

### Unknown

* Leaderboard: Refined plots (#1601)

* Added embedding size guide to performance-size plot, removed shading on radar chart

* Changed plot names to something more descriptive

* Made plots failsafe ([`0c9e046`](https://github.com/embeddings-benchmark/mteb/commit/0c9e046eb1cc81b4780ef5c02e9e04f9a68521c4))

* Add new models nvidia, gte, linq (#1436)

* Add new models nvidia, gte, linq
* add warning for gte-Qwen and nvidia models re: instruction used in docs as well
---------
Co-authored-by: isaac-chung &lt;chungisaac1217@gmail.com&gt; ([`95d5ae5`](https://github.com/embeddings-benchmark/mteb/commit/95d5ae5897c0e8671dd6ba0bd9f8a7db1fb930be))

* Feat: add support for scoring function (#1594)

* add support for scoring function

* lint

* move similarity to wrapper

* remove score function

* lint

* remove from InstructionRetrievalEvaluator

* Update mteb/evaluation/evaluators/RetrievalEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* remove score function from README.md

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`8e6ee46`](https://github.com/embeddings-benchmark/mteb/commit/8e6ee46408ca359833033b81aeec2be132cbfa0d))

* doc: colbert add score_function &amp; doc section (#1592)

* doc: colbert add score_function &amp; doc section

* doc: Update README.md

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* doc: Update README.md

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

---------

Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`992b20b`](https://github.com/embeddings-benchmark/mteb/commit/992b20b7079bba96fee913181e28292757c0087b))

## v1.25.0 (2024-12-14)

### Feature

* feat: Add ColBert (#1563)

* feat: add max_sim operator for IR tasks to support multi-vector models

* docs: add doc for Model2VecWrapper.__init__(...)

* feat: add ColBERTWrapper to models &amp; add ColBERTv2

* fix: resolve issues

* fix: resolve issues

* Update README.md

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update README.md

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Update README.md

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Update mteb/evaluation/evaluators/RetrievalEvaluator.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Update README.md

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* README.md: rm subset

* doc: update example for Late Interaction

* get colbert running without errors

* fix: pass is_query to pylate

* fix: max_sim add pad_sequence

* feat: integrate Jinja templates for ColBERTv2 and add model prompt handling

* feat: add revision &amp; prompt_name

* doc: pad_sequence

* rm TODO jina colbert v2

* doc: warning: higher resource usage for MaxSim

---------

Co-authored-by: sam021313 &lt;40773225+sam021313@users.noreply.github.com&gt;
Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`fdfdaef`](https://github.com/embeddings-benchmark/mteb/commit/fdfdaeff8597707a70b79e1ff0b0cb5b63a97b01))

## v1.24.2 (2024-12-13)

### Fix

* fix: Eval langs not correctly passed to monolingual tasks (#1587)

* fix SouthAfricanLangClassification.py

* add check for langs

* lint ([`373db74`](https://github.com/embeddings-benchmark/mteb/commit/373db747d807c3f2597269ac9abf50291673764d))

## v1.24.1 (2024-12-11)

### Fix

* fix: Add namaa MrTydi reranking dataset (#1573)

* Add dataset class and file requirements

* pass tests

* make lint changes

* adjust meta data and remove load_data

---------

Co-authored-by: Omar Elshehy &lt;omarelshehy@Omars-MacBook-Pro.local&gt; ([`7b9b3c9`](https://github.com/embeddings-benchmark/mteb/commit/7b9b3c98a26506d64808bdfb082e1f853f3f4f71))

### Unknown

* Update tasks table ([`1101db7`](https://github.com/embeddings-benchmark/mteb/commit/1101db7936cf0199aa587c55b7b34a3cd569e6ce))

## v1.24.0 (2024-12-10)

### Feature

* feat: add new arctic v2.0 models (#1574)

* feat: add new arctic v2.0 models

* chore: make lint ([`53756ad`](https://github.com/embeddings-benchmark/mteb/commit/53756ad59d48c8fede1bd4a85a9ad3f1ba948cbb))

## v1.23.2 (2024-12-09)

### Fix

* fix: Added radar chart displaying capabilities on task types (#1570)

* Added radar chart displaying capabilities on task types

* Fixed table aggregation in leaderboard

* Spelled out why instructionretrieval is excluded ([`c49f838`](https://github.com/embeddings-benchmark/mteb/commit/c49f838c2cc4f557d325681bbd1d6cba62e9e1f7))

## v1.23.1 (2024-12-09)

### Fix

* fix: Added metadata for miscellaneous models (#1557)

* Added script for generating metadata, and metadata for the listed models

* Added misc models to overview

* Fixed misc metas

* Removed unnecessary imports

* Added logic to retrieve base model information

* Added base models to misc meta

* Added superseded_by to sentence-croissant models

* Added training datasets to mis models ([`ce8c175`](https://github.com/embeddings-benchmark/mteb/commit/ce8c17541e61ca259bf73f1b0d634a9cea3f93bd))

## v1.23.0 (2024-12-08)

### Documentation

* docs: Fix dependency library name for bm25s (#1568)

* fix: bm25s implementation

* correct library name

---------

Co-authored-by: Daniel Buades Marcos &lt;daniel.buades@clinia.com&gt; ([`03347eb`](https://github.com/embeddings-benchmark/mteb/commit/03347ebfe4809056e0fd2894fcae69dcdd2ed964))

### Feature

* feat: (cohere_models) cohere_task_type issue, batch requests and tqdm for visualization (#1564)

* feat: batch requests to cohere models

* fix: use correct task_type

* feat: use tqdm with openai

* fix: explicitely set `show_progress_bar` to False ([`1d21818`](https://github.com/embeddings-benchmark/mteb/commit/1d21818c3704d1866245c21b0f186ac18fa77b9f))

### Fix

* fix(publichealth-qa):  ignore rows with `None` values in `question` or `answer` (#1565) ([`68bd8ac`](https://github.com/embeddings-benchmark/mteb/commit/68bd8ac79b33e48942316b26f253db644b6763ad))

* fix: Add training dataset to model meta (#1561)

* fix: Add training dataset to model meta

Adresses #1556

* Added docs

* format ([`6489fca`](https://github.com/embeddings-benchmark/mteb/commit/6489fca1b47f60fd335e6ae644f89cb15fc5f943))

## v1.22.1 (2024-12-07)

### Fix

* fix(bm25s): search implementation (#1566)

fix: bm25s implementation ([`ac44e58`](https://github.com/embeddings-benchmark/mteb/commit/ac44e58d0a94b9f571f0ca41e004af31dcef3b1b))

## v1.22.0 (2024-12-07)

### Documentation

* docs: Correction of SICK-R metadata (#1558)

* Correction of SICK-R metadata
* Correction of SICK-R metadata
---------
Co-authored-by: rposwiata &lt;rposwiata@opi.org.pl&gt; ([`fc64791`](https://github.com/embeddings-benchmark/mteb/commit/fc64791943950f75ff58f522269f3329df341817))

### Feature

* feat(google_models): fix issues and add support for `text-embedding-005` and `text-multilingual-embedding-002` (#1562)

* fix: google_models batching and prompt
* feat: add text-embedding-005 and text-multilingual-embedding-002
* chore: `make lint` errors
* fix: address PR comments ([`611b6a1`](https://github.com/embeddings-benchmark/mteb/commit/611b6a175911d7a238f13439243e3c95652a2d85))

## v1.21.8 (2024-12-06)

### Fix

* fix: Add Model2vec (#1546)

* Added Model2Vec wrapper

* Added Model2vec models

* Added model2vec models to registry

* Added model2vec as a dependency

* Ran linting

* Update mteb/models/model2vec_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/models/model2vec_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Added adapted_from and superseeded_by to model2vec models.

* Added missing import

* Moved pyproject.toml to optional dependencies

* Fixed typos

* Added import error and changed model to model_name

* Added Numpy to frameworks

* Added Numpy to frameworks

* Corrected false info on model2vec models

* Replaced np.inf with maxint

* Update mteb/models/model2vec_models.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Added option to have infinite max tokens, added it to Model2vec

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`2ee8d44`](https://github.com/embeddings-benchmark/mteb/commit/2ee8d44e9ed994860ceae100fab186a209411f42))

### Unknown

* Made result loading more permissive, changed eval splits for HotPotQA and DBPedia (#1554)

* Removed train and dev from eval splits on HotpotQA

* Removed dev from eval splits on DBPedia

* Made task_results validation more permissive

* Readded exception in get_score

* Ran linting ([`2905813`](https://github.com/embeddings-benchmark/mteb/commit/29058133f8b0750ec0c66c48495c9028bd7e2616))

## v1.21.7 (2024-12-05)

### Fix

* fix: remove curev1 from multlingual (#1552)

Seems like it was added here:
https://github.com/embeddings-benchmark/mteb/commit/1cc6c9e0fe62ca4e77708b641823fa1a121f048b ([`279a4ee`](https://github.com/embeddings-benchmark/mteb/commit/279a4ee5fb6cec07c2d4e85800e51c975fa5a45d))

## v1.21.6 (2024-12-04)

### Fix

* fix: Fixed metadata errors (#1547) ([`a44a46c`](https://github.com/embeddings-benchmark/mteb/commit/a44a46c3541f4187e692e3a5dd81e3ec9ef9c4f3))

## v1.21.5 (2024-12-04)

### Fix

* fix: add sentence trimming to OpenAIWrapper (#1526)

* fix: add sentence trimming to OpenAIWrapper

* fix: import tiktoken library inside encode function

* fix: check tokenizer library installed and update ModelMeta to pass tokenizer_name

* fix: pass tokenizer_name, max_tokens to loader

* fix: make tokenizer_name None for default

* fix: delete changes for ModelMeta

* fix: fix revision to 2 for OpenAI models

* fix: add docstring for OpenAIWrapper

* fix: lint

* feat: add openai optional dependency set

* fix: add sleep for too many requests

* fix: add lint

* fix: delete evaluate file ([`37fdfa1`](https://github.com/embeddings-benchmark/mteb/commit/37fdfa1e4ef3d4247589ee52adfb2374bf1ee8a5))

* fix: Added arctic models (#1541)

#1515 ([`df11c38`](https://github.com/embeddings-benchmark/mteb/commit/df11c382eb79d6d1b4e9b9a350a14524808f645f))

* fix: Added all-minilm-l12-v2 (#1542)

#1515 ([`97ab272`](https://github.com/embeddings-benchmark/mteb/commit/97ab2721e5bb73bcf5ed6352366ab333234532f7))

* fix: add nomic models (#1543)

#1515 ([`5013df8`](https://github.com/embeddings-benchmark/mteb/commit/5013df813621c179f08b5db52450ac9acd18514d))

### Unknown

* Add cohere models (#1538)

* fix: bug cohere names

* format ([`c2f4c26`](https://github.com/embeddings-benchmark/mteb/commit/c2f4c2649114380345115e338a63b26880dd4963))

## v1.21.4 (2024-12-04)

### Documentation

* docs: Add Model Meta parameters and metadata (#1536)

* add multi_qa_MiniLM_L6_cos_v1 model meta
* add all_mpnet_base_v2
* add parameters to model meta
* make lint
* add extra params to meta ([`5fa7b7b`](https://github.com/embeddings-benchmark/mteb/commit/5fa7b7b1c450db2ff8a5402e38cce0046600b538))

### Fix

* fix: add more model meta (jina, e5) (#1537)

* add e5 model meta

* address review comments ([`36bab4d`](https://github.com/embeddings-benchmark/mteb/commit/36bab4d345686be0c5c91a2e67c051a286e369a3))

## v1.21.3 (2024-12-02)

### Fix

* fix: Proprietary models now get correctly shown in leaderboard (#1530)

* Fixed showing proprietary models in leaderboard

* Added links to all OpenAI models

* Fixed table formatting issues

* Bumped Gradio version ([`39349ff`](https://github.com/embeddings-benchmark/mteb/commit/39349ff4bc565bc60fa33adc0916c68eee4eb182))

## v1.21.2 (2024-12-01)

### Fix

* fix: Task load data error for SICK-BR-STS and XStance (#1534)

* fix task load data for two tasks

* correct dataset keys ([`5b6f20f`](https://github.com/embeddings-benchmark/mteb/commit/5b6f20fe6fbe7673480fbb8c36402ddbe7e203a2))

## v1.21.1 (2024-11-30)

### Fix

* fix: Correct typos superseeded -&gt; superseded (#1532)

fix typo -&gt; superseded ([`343b6e0`](https://github.com/embeddings-benchmark/mteb/commit/343b6e055f1fe6784f3fcf9d99e830101bb3e16f))

## v1.21.0 (2024-11-29)

### Feature

* feat: Evaluate missing splits (#1525)

* fix: evaluate missing splits (#1268)

* implement partial evaluation for missing splits

* lint

* requested changes done from scratch

* test for missing split evaluation added

* uncomment test

* lint

* avoid circular import

* use TaskResult

* skip tests for now

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* got test_all_splits_evaluated passing

* tests passing

* address review comments

* make lint

* handle None cases for kg_co2_emissions

* use new results info

---------

Co-authored-by: Thivyanth &lt;thivyanth2004@gmail.com&gt; ([`8e12250`](https://github.com/embeddings-benchmark/mteb/commit/8e1225047d4eed79484c00440fe3f801c512eca5))

## v1.20.6 (2024-11-29)

### Fix

* fix: Adding missing metadata on models and mathcing names up with the results repo (#1528)

* Added Voyage 3 models

* Added correct metadata to Cohere models and matched names with the results repo ([`b02ae82`](https://github.com/embeddings-benchmark/mteb/commit/b02ae826bd512d8c28afb185fa856ca76e90fc0b))

## v1.20.5 (2024-11-29)

### Documentation

* docs: Add lang family mapping and map to task table (#1486)

* add lang family mapping and map to task table

* make lint

* add back some unclassified lang codes ([`cfd43ac`](https://github.com/embeddings-benchmark/mteb/commit/cfd43aca70173b93a4d1163b1e6afd52eef41372))

### Fix

* fix: Ensure that models match the names on embedding-benchmarks/results (#1519) ([`e3d2b54`](https://github.com/embeddings-benchmark/mteb/commit/e3d2b548d8df716bd5ab8ef4f080d7cff82d51cf))

### Unknown

* Update tasks table ([`377a63d`](https://github.com/embeddings-benchmark/mteb/commit/377a63d01e19d42d1163c9cc92b26a11ca84bf5d))

## v1.20.4 (2024-11-27)

### Fix

* fix: align readme with current mteb (#1493)

* align readme with current mteb

* align with mieb branch

* fix test ([`942f212`](https://github.com/embeddings-benchmark/mteb/commit/942f2125dce5534a167416eefe322dcc71dcbcfe))

## v1.20.3 (2024-11-27)

### Fix

* fix: leaderboard only shows models that have ModelMeta (#1508)

Filtering for models that have metadata ([`35245d3`](https://github.com/embeddings-benchmark/mteb/commit/35245d36248c0105accaace879f4662def52f5c0))

## v1.20.2 (2024-11-27)

### Fix

* fix: Leaderboard demo data loading (#1507)

* Made get_scores error tolerant

* Added join_revisions, made get_scores failsafe

* Fetching metadata fixed fr HF models

* Added failsafe metadata fetching to leaderboard code

* Added revision joining to leaderboard app

* fix

* Only show models that have metadata, when filter_models is called

* Ran linting ([`0affa31`](https://github.com/embeddings-benchmark/mteb/commit/0affa31c23727889f56f4bb27da9154ce13ed67a))

## v1.20.1 (2024-11-26)

### Fix

* fix: check if `model` attr of model exists (#1499)

* check if model attr of model exists

* lint

* Fix retrieval evaluator ([`917ad7f`](https://github.com/embeddings-benchmark/mteb/commit/917ad7f23704edc974c407efda20edc71375041d))

## v1.20.0 (2024-11-21)

### Feature

* feat: add CUREv1 retrieval dataset (#1459)

* feat: add CUREv1 dataset

---------

Co-authored-by: nadshe &lt;nadia.sheikh@clinia.com&gt;
Co-authored-by: olivierr42 &lt;olivier.rousseau@clinia.com&gt;
Co-authored-by: Daniel Buades Marcos &lt;daniel@buad.es&gt;

* feat: add missing domains to medical tasks

* feat: modify benchmark tasks

* chore: benchmark naming

---------

Co-authored-by: nadshe &lt;nadia.sheikh@clinia.com&gt;
Co-authored-by: olivierr42 &lt;olivier.rousseau@clinia.com&gt; ([`1cc6c9e`](https://github.com/embeddings-benchmark/mteb/commit/1cc6c9e0fe62ca4e77708b641823fa1a121f048b))

### Unknown

* Update tasks table ([`4408717`](https://github.com/embeddings-benchmark/mteb/commit/440871739689a175d0e4a8c538ce428a4e27e350))

## v1.19.10 (2024-11-19)

### Documentation

* docs: Add sum per language for task counts (#1468)

* add sum per lang

* add sort by sum option

* make lint ([`2fb6fe7`](https://github.com/embeddings-benchmark/mteb/commit/2fb6fe764585f0cf6555d15ba9b2e18d4adddcf3))

### Fix

* fix: pinned datasets to &lt;3.0.0 (#1470) ([`fde124a`](https://github.com/embeddings-benchmark/mteb/commit/fde124a8a0894838aabca90b061191e74c33a82f))

## v1.19.9 (2024-11-17)

### Fix

* fix: swap touche2020 to maintain compatibility (#1469)

swap touche2020 for parity ([`9b2aece`](https://github.com/embeddings-benchmark/mteb/commit/9b2aecebe00e17b9db02d4fd3182df92222d680d))

## v1.19.8 (2024-11-15)

### Fix

* fix: loading pre 1.11.0 (#1460)

* small fix

* fix: fix ([`1b920ac`](https://github.com/embeddings-benchmark/mteb/commit/1b920ac06bb83eba9530c3ddd125e09fb146dc95))

### Unknown

* WIP: Polishing up leaderboard UI (#1461)

* fix: Removed column wrapping on the table, so that it remains readable

* Added disclaimer to figure

* fix: Added links to task info table, switched out license with metric ([`58c459b`](https://github.com/embeddings-benchmark/mteb/commit/58c459bcd3e1ee772624f723e86efb86e40db6cb))

## v1.19.7 (2024-11-14)

### Fix

* fix: Fix load external results with `None` mteb_version (#1453)

* fix

* lint ([`14d7523`](https://github.com/embeddings-benchmark/mteb/commit/14d7523850edae97cda2a7264f357da29e0ac867))

## v1.19.6 (2024-11-14)

### Fix

* fix: publish (#1452) ([`feb1ab7`](https://github.com/embeddings-benchmark/mteb/commit/feb1ab7652102696a4aa20a03dc98a7240274a20))

### Unknown

* Fixed task loading (#1451)

* Fixed task result loading from disk

* Fixed task result loading from disk ([`039d010`](https://github.com/embeddings-benchmark/mteb/commit/039d01088f457297a3a1929ff713cc3d55050453))

* Fix: Made data parsing in the leaderboard figure more robust (#1450)

Bugfixes with data parsing in main figure ([`4e86cea`](https://github.com/embeddings-benchmark/mteb/commit/4e86ceab8f11d5cacf38e5f959f846c962105e34))

## v1.19.5 (2024-11-14)

### Fix

* fix: update task metadata to allow for null (#1448) ([`04ac3f2`](https://github.com/embeddings-benchmark/mteb/commit/04ac3f21139db2ea50fdef4d91c345f61f229d44))

* fix: Count unique texts, data leaks in calculate metrics (#1438)

* add more stat

* add more stat

* update statistics ([`dd5d226`](https://github.com/embeddings-benchmark/mteb/commit/dd5d226f6a377fbf3f98f714323921539a418d83))

### Unknown

* Update tasks table ([`f6a49fe`](https://github.com/embeddings-benchmark/mteb/commit/f6a49fef74724bed1a7e19d6b895324ed25cff13))

* Leaderboard: Fixed code benchmarks (#1441)

* fixed code benchmarks

* fix: Made n_parameters formatting smarter and more robust

* fix: changed jina-embeddings-v3 number of parameters from 572K to 572M

* fix: Fixed use_instuctions typo in model overview

* fix: Fixed sentence-transformer compatibility switch

* Ran linting

* Added all languages, tasks, types and domains to options

* Removed resetting options when a new benchmark is selected

* All results now get displayed, but models that haven&#39;t been run on everything get nan values in the table ([`3a1a470`](https://github.com/embeddings-benchmark/mteb/commit/3a1a470c8e0ad7b8bce61c7f73a501d6716fce5a))

* Leaderboard 2.0: added performance x n_parameters plot + more benchmark info (#1437)

* Added elementary speed/performance plot

* Refactored table formatting code

* Bumped Gradio version

* Added more general info to benchmark description markdown block

* Adjusted margin an range on plot

* Made hover information easier to read on plot

* Made range scaling dynamic in plot

* Moved citation next to benchmark description

* Made titles in benchmark info bold ([`76c2112`](https://github.com/embeddings-benchmark/mteb/commit/76c21120f27b396fa1900fdf203c5079ad34b0d8))

## v1.19.4 (2024-11-11)

### Fix

* fix: Add missing benchmarks in benchmarks.py (#1431)

Fixes #1423 ([`a240ea0`](https://github.com/embeddings-benchmark/mteb/commit/a240ea099aac446702a3f7167fd0921f6eb4e259))

* fix: Add Korean AutoRAGRetrieval (#1388)

* feat: add AutoRAG Korean embedding retrieval benchmark

* fix: run --- ðŸ§¹ Running linters ---
ruff format . 			# running ruff formatting
716 files left unchanged
ruff check . --fix  	# running ruff linting
All checks passed!

* fix: add metadata for AutoRAGRetrieval

* change link for markers_bm

* add AutoRAGRetrieval to init.py and update metadata

* add precise metadata

* update metadata: description and license

* delete descriptive_stats in AutoRAGRetrieval.py and run calculate_matadata_metrics.py ([`f79d9ba`](https://github.com/embeddings-benchmark/mteb/commit/f79d9ba06c3d7a69c155bc1287c91bba6f41fa62))

* fix: make samples_per_label a task attribute (#1419)

make samples_per_label a task attr ([`7f1a1d3`](https://github.com/embeddings-benchmark/mteb/commit/7f1a1d33fdc515f39740d4f15b86b011280f1ee6))

### Unknown

* Update tasks table ([`d069aba`](https://github.com/embeddings-benchmark/mteb/commit/d069aba1a597f4a4e033148243abd7df0f62bfb7))

## v1.19.3 (2024-11-11)

### Documentation

* docs: Fix a typo in README (#1430)

Fix typo in readme ([`9681eb3`](https://github.com/embeddings-benchmark/mteb/commit/9681eb38c781ec9c9f1c5395f45cd30bf73ba3fa))

* docs: Update recommendation for pushing results (#1401)

fix: Update recommendation for pushing results ([`fccf034`](https://github.com/embeddings-benchmark/mteb/commit/fccf034bd78d74917f9d8fb6053e473fb03e86d8))

### Fix

* fix: add logging for RetrievalEvaluator NaN values for similarity scores (#1398)

Fixes #1389 ([`cc7a106`](https://github.com/embeddings-benchmark/mteb/commit/cc7a10666b7c151e9bff66dc50d1413579dac22a))

## v1.19.2 (2024-11-07)

### Fix

* fix: Added the necessary trust_remote_code (#1406) ([`fd8b283`](https://github.com/embeddings-benchmark/mteb/commit/fd8b283e41b555f648d7046e084bcde7af28baf5))

## v1.19.1 (2024-11-07)

### Fix

* fix: Add the_ugly_duckling.txt for speedtask to Python wheel (#1402)

Add the_ugly_duckling.txt for speedtask to Python wheel ([`b1a0ec6`](https://github.com/embeddings-benchmark/mteb/commit/b1a0ec67ffcd41bdb7085c8ee995214eb5c5cee6))

## v1.19.0 (2024-11-06)

### Feature

* feat: Standardize descriptive stats (#1375)

* init

* mock tests

* remove debug prints

* remove descriptive stats and move to n_samples

* fix typo

* fix create task table

* fix citations

* remove n_samples

* metadata per task

* add test

* reformat task table

* add n_samples property

* fix tests

* rename total_symbols to number_of_characters

* Update mteb/abstasks/AbsTaskRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* rename in tests

* lint

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`2854fa2`](https://github.com/embeddings-benchmark/mteb/commit/2854fa2149d301f6c654c492030d7b5dbf66964f))

### Unknown

* Update tasks table ([`537b974`](https://github.com/embeddings-benchmark/mteb/commit/537b974dfcbf958c7e6292dde9bb2f816342a20f))

## v1.18.9 (2024-11-06)

### Fix

* fix: Disable `rich` output with `verbosity=0` on `evaluation.run` (#1395)

* feat: verbose=0 now supress rich console output

* fix: removed unnecesary list comprenhension ([`1bb1ca3`](https://github.com/embeddings-benchmark/mteb/commit/1bb1ca34fbf220c07d67443ba37f49fa16291b04))

## v1.18.8 (2024-11-04)

### Fix

* fix: Update logging verbosity levels in MTEB (#1384)

* Fix verbosity handling in MTEB.py for consistent logging

* updates

* update docstrings

* linting code ([`35daf58`](https://github.com/embeddings-benchmark/mteb/commit/35daf58578870678eb08e3d6230ad516c01fec83))

## v1.18.7 (2024-11-04)

### Fix

* fix: Leaderboard UI improvements (#1370)

* Added elementary search bar with RegEx functionality

* Improved layout

* Table improvements, adjusted column width and added links

* Update benchmark filter description

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Added instructions on multiple search queries

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`92fe9cb`](https://github.com/embeddings-benchmark/mteb/commit/92fe9cbd6bde7800a987185f0e91bc23ad8c2eb6))

## v1.18.6 (2024-10-31)

### Fix

* fix: Integrate prompts to task metadata (#1300)

* init

* add DatasetDict

* add classification

* add clustering

* add pair classification

* add retrieval

* add all prompts

* start integrating prompts

* refactor instruct models

* lint

* fix test

* fix

* fix no prompt in prompt dict

* add more logging

* add more logging

* Apply suggestions from code review

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* fix code review

* fix use_instructions

* add log if instruction template not set

* fix metadata

* lint

* fix brazilian

* remove MetadataDatasetDict

* rollback test metadata

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`029d378`](https://github.com/embeddings-benchmark/mteb/commit/029d378b2c17d7e05a4c9c30a17966917cb83a33))

## v1.18.5 (2024-10-31)

### Fix

* fix: Speed up leaderboard by caching and skipping validation (#1365)

* Made loading and filtering faster by removing unnecessary validation

* Made select_tasks faster by removing validation

* Added caching to leaderboard

* Ran linting

* Added missing future import ([`f1bc375`](https://github.com/embeddings-benchmark/mteb/commit/f1bc3758d6e1cc91fbe22b26dcbd1cfe3b640f06))

## v1.18.4 (2024-10-30)

### Fix

* fix: make sure test is the default split for FEVER (#1361)

The other splits can still be run as long as they are specified. ([`d9626ab`](https://github.com/embeddings-benchmark/mteb/commit/d9626abbc5d438024a21e7f21a29d4741bb94188))

## v1.18.3 (2024-10-30)

### Fix

* fix: Update KorSarcasm to avoid trust-remote code (#1364) ([`756ba7e`](https://github.com/embeddings-benchmark/mteb/commit/756ba7e46e6daa8d1bff6b4d3db254296e37e7dc))

### Unknown

* Leaderboard updates: Model meta + task and benchmark info (#1345)

* Added benchmark description and citation to leaderboard

* Added model information to main table

* Fixed citation box

* Added table tab with task information

* Added button for benchmark link if specified

* Formatted model column in per_task table properly

* Implemented model filtering based on metadata

* Fixed maximum minimum model sizes

* Ran linting

* Replaced mean rank with borda rank in main table ([`298b0bd`](https://github.com/embeddings-benchmark/mteb/commit/298b0bde0c5dec52dc395f7786ba8397c757430a))

## v1.18.2 (2024-10-30)

### Fix

* fix: upload BrazilianToxicTweetsClassification to hf (#1352)

upload to hf ([`9c7a1c2`](https://github.com/embeddings-benchmark/mteb/commit/9c7a1c2a8f99966c2d98ec9efe7666ea8b5672a5))

## v1.18.1 (2024-10-30)

### Fix

* fix: Add jina, uae, stella models (#1319)

* add models

* fix

* fix

* fix prompt

* Update mteb/models/jina_models.py

Co-authored-by: Wang Bo &lt;bo.wang@jina.ai&gt;

* Update mteb/models/jina_models.py

Co-authored-by: Wang Bo &lt;bo.wang@jina.ai&gt;

* try reeval stella

* change to e5

* change to e5

* add metadata

* update languages

* Update mteb/models/jina_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* remove docstring

* remove trust remote

* update model meta

* Set minimal version

---------

Co-authored-by: Wang Bo &lt;bo.wang@jina.ai&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`0b846ff`](https://github.com/embeddings-benchmark/mteb/commit/0b846ff3ad8ec9f16342c913d81da74aa9ca0643))

* fix: remove accidentally commited file ([`16a333e`](https://github.com/embeddings-benchmark/mteb/commit/16a333ee3b9c1b26468a8b13d42e2697e0474a85))

## v1.18.0 (2024-10-28)

### Feature

* feat: update English benchmarks and mark MMTEB benchmarks as beta (#1341)

* feat: update English benchmarks and mark MMTEB benchmarks as beta

* Added summEvalv2

* Update docs with new MTEB_EN_MAIN rename ([`61371dd`](https://github.com/embeddings-benchmark/mteb/commit/61371dd2db8e3c3a5c7ecd4bb9afff973f7d01d8))

## v1.17.0 (2024-10-26)

### Feature

* feat: Update metadata for all models (#1316)

* Added model meta

* format

* fixed metadata

* Metadata update for voyage models

* Update mteb/models/cohere_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Update mteb/models/cohere_models.py

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt;

* Added corrections from review

* fix spelling error

---------

Co-authored-by: Roman Solomatin &lt;samoed.roman@gmail.com&gt; ([`f8fed9b`](https://github.com/embeddings-benchmark/mteb/commit/f8fed9b1567982d8dd590a3a08262537427fcf09))

### Unknown

* WIP: Leaderboard UI improvements (#1320)

* Fixed typos in task_results

* Fixed typos in task_results

* Added Tailwind, reorganized layout and fixed scrolling

* Ran linting

* Removed faux benchmark

* Updated layout

* Changed table number format

* Table highlights highest values by making them bold

* Added rank to table, removed organization from model_name

* Added mean rank to table

* Ran linting ([`5af36c5`](https://github.com/embeddings-benchmark/mteb/commit/5af36c515d8e98f1eabe35a11558b1317a93c0f8))

* Cache the embeddings when requested (#1307)

* add caching

* update test to use close

* change from json to pkl

* fix for window

* cleanup on Windows again

* infer dimension

* move cachewrapper

* add wrapper

* fix

* updates

* fix tests

* fix lint

* lint

* add test ([`650e8b8`](https://github.com/embeddings-benchmark/mteb/commit/650e8b89ba856b21869e3fa6d5921ed7d9ed8d07))

* Update tasks table ([`4a04042`](https://github.com/embeddings-benchmark/mteb/commit/4a040426c8744c851e877a923e940b30b9714b14))

* Add multilingual mFollowIR dataset (#1308)

* add mFollowIR

* paper name

* edit warning-&gt;info

* convert to parquet

* lint ([`b580b95`](https://github.com/embeddings-benchmark/mteb/commit/b580b95fc91a7e7e675d27c3ae9a9df64ddad169))

## v1.16.5 (2024-10-25)

### Fix

* fix: Add implementations of common reranker models (#1309)

* init

* revert

* revert

* add metadata

* lint

* add reqs

* change to float16

* benchmark lint fix ([`f5f90d3`](https://github.com/embeddings-benchmark/mteb/commit/f5f90d3df694b47a7ca81d46c95f1dd2b389ca06))

## v1.16.4 (2024-10-25)

### Fix

* fix: Re-upload dataset to hub to avoid using script upload (#1322)

* fix dataset upload

* add linting ([`f00a262`](https://github.com/embeddings-benchmark/mteb/commit/f00a2622821eeec68e191561ca9f2b346f0a5dc6))

### Unknown

* Update tasks table ([`e5b6c12`](https://github.com/embeddings-benchmark/mteb/commit/e5b6c12b2578c5421dce46df259c6327342b7681))

## v1.16.3 (2024-10-24)

### Fix

* fix: remove duplicate multilingual ([`2f14519`](https://github.com/embeddings-benchmark/mteb/commit/2f1451955da42070bf6aea4c317c4bc3da755a38))

## v1.16.2 (2024-10-24)

### Fix

* fix: Add Slovak Hate Speech and Offensive Language Dataset (#1274)

* Add Slovak Hate Speech and Offensive Language
Dataset

This commit introduces the Slovak Hate Speech and Offensive Language Database to MTEB. The dataset includes posts from a social network, annotated by humans for hate speech and offensive content. Additionally, the corresponding task has been added to the tasks.md table to reflect this update.

* Add Slovak Hate Speech and Offensive Language Dataset
- Updated __init__.py to include the new SlovakHateSpeechClassification task.
- Modified SlovakHateSpeechClassification.py as per review suggestions to enhance functionality and readability.

* Did requested changes:
- Updated __init__.py to include the new SlovakHateSpeechClassification task.
- Modified SlovakHateSpeechClassification.py as per review suggestions to enhance functionality and readability.

* resolve linting issues by running `make lint` ([`f3d8014`](https://github.com/embeddings-benchmark/mteb/commit/f3d8014fc91dfdf400ab7713683afe4cf785cabf))

### Unknown

* WIP: Leaderboard UI improvements (#1312)

* Fixed typos in task_results

* Fixed typos in task_results

* Added Tailwind, reorganized layout and fixed scrolling

* Ran linting ([`bd5ee9e`](https://github.com/embeddings-benchmark/mteb/commit/bd5ee9eca947a656f6ed0d83971615d53a85475a))

* Update tasks table ([`0d86753`](https://github.com/embeddings-benchmark/mteb/commit/0d8675338a0c99a606daa19bbc2a35d904b5c93f))

## v1.16.1 (2024-10-22)

### Fix

* fix: Add Retrieval SK Quad dataset for Slovak search evaluation (#1276)

* Add Retrieval SK Quad dataset for Slovak search evaluation

This commit introduces the Retrieval SK Quad dataset, designed to assess Slovak search performance. The dataset is derived from SK-QuAD and includes questions with their best answers categorized post-annotation. This addition provides a significant resource for advancing Slovak language search evaluation and supporting further research and development.

* Add Retrieval SK Quad dataset for Slovak search evaluation 2

Added the requested changes on the SKQuadRetrieval.py file

* add task to init

* add missing task metadata

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`fc53498`](https://github.com/embeddings-benchmark/mteb/commit/fc534980b27d3909eaa06943e60480fde41d926e))

### Unknown

* Update tasks table ([`95f012a`](https://github.com/embeddings-benchmark/mteb/commit/95f012ac7a43159e93f911053e9628b8e5c25436))

## v1.16.0 (2024-10-21)

### Feature

* feat: Use prompts instead of encode_corpus and encode_queries (#1278)

* add prompt per task type

* fix prompt

* upd test

* lint

* fix test

* fix DeprecatedSummarizationEvaluator

* fix prompts

* add test

* lint

* logger info

* use task type only in model_encode

* lint

* update interface

* add prompt types to docs

* fix test

* mock tasks

* mock task registry

* remove last task_type

* fix tests

* lint

* fix test

* fix

* use wrapper and new prompts

* fix tests

* lint

* fix test

* remove conftest

* validate task to prompt_name

* override model prompts

* task to prompt name optional

* fix tests

* fix models

* remove task_to_prompt_name

* remove from mteb __init__

* update docs

* load existing model prompts if model_prompts is None

* fix

* lint

* change wrapper loader

* add wrapper class

* lint

* add wrapper file

* update logging

* upd logging

* refactor reranking

* lint

* remove prints ([`2a61821`](https://github.com/embeddings-benchmark/mteb/commit/2a61821d9294eb5b0cb053e1e676c199f23be12b))

### Unknown

* Leaderboard (#1235)

* Add leaderboard dev

* Renamed MTEBResults to TaskResult

* Moved model and model meta loading utilities into overview.py

* Added get_model_metas to retrieve filtered metadata for models

* Restructured results object and made it into a class instead of a dict

* Added utilities for filtering models on BenchmarkResults objects

* Added to_table utility function to BenchmarkResults

* Added serialization utilities to BenchmarkResults

* Attempted fixing tests

* Added get_model_metas to __init__

* Added get_benchmarks to __init__ and made it return all benchmarks by default

* Added get_benchmarks to __init__

* Made tasks hashable

* Added task filtering based on task objects on BenchmarkResults

* Added BenchmarkResults to __init__

* Added additional arguments to get_scores on two classes

* Made get_scores smarter on BenchmarkResult

* Added basic multilingual benchmark

* Modified benchmark to be able to easily access results

* Added useful properties and filtering functions to BenchmarkResults

* Added minimal functioning example

* Added smarter table, task-list updating and tried fixing dropdown scrolling

* Made restrict_results into a private function

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Removed old leaderboard scripts

* Hardcoded max and min model size

* Removed redundant utils file

* Ran linting

* added leaderboard dependencies as optional

* Fixed union type error on Python 3.9

* Removed references to Dict in task aggregation

* Fixed name errors in _restrict_task_results

* Fixed _restrict_task_results

* Made hf_subsets={&#39;default&#39;} when the task is monolingual in _restric_task_results

* Task dropdown now gets filtered based on the other criteria

* Ran linting again

* Introduced hotfix for reranking test

* Added BenchmarkResults to __all__ in __init__

* Fixed validate_and_filter_scores method, and replaced _restric_task_results with it

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`094f922`](https://github.com/embeddings-benchmark/mteb/commit/094f9225973268fedae55b322eb9af7bb0ae2110))

## v1.15.8 (2024-10-20)

### Fix

* fix: Remove non-existent eval split of CMNLI (#1294)

fix eval_splits of CMNLI ([`5b4b262`](https://github.com/embeddings-benchmark/mteb/commit/5b4b262555d8c9d55aec4d178b68be33616c145d))

## v1.15.7 (2024-10-16)

### Fix

* fix: Add metadata dict to QBQTC in C-MTEB (#1292)

* fix QBQTC in C-MTEB

* make lint

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`4a88a1d`](https://github.com/embeddings-benchmark/mteb/commit/4a88a1d8b515efae58a06b687681a04598ae8db2))

## v1.15.6 (2024-10-14)

### Fix

* fix: Allow numpy&lt;2.0.0 (#1291) ([`60cef98`](https://github.com/embeddings-benchmark/mteb/commit/60cef9834045c372861d4700ac87b5e9753e94a3))

## v1.15.5 (2024-10-13)

### Documentation

* docs: Fix a link in the README (#1289)

* Fix a link in the README

And fix some typos.

* Update README.md ([`c1ebd6e`](https://github.com/embeddings-benchmark/mteb/commit/c1ebd6e84acdc790dd3190e854e1a46539c2c902))

* docs: points for paper writing (#1286)

* Create 1004.jsonl

* Create 1006.jsonl

* Update docs/mmteb/points/1004.jsonl

* Update docs/mmteb/points/1006.jsonl

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`426f4a1`](https://github.com/embeddings-benchmark/mteb/commit/426f4a136f579f264f3e60a6919ac7d68d265107))

### Fix

* fix: Update benchmarks (#1288)

* make benchmark var name uppercase

* update touche to v3

* add MIRACLRetrievalHardNegatives to multilingual

* add mteb(indic)

* add eu benchmark ([`f55a888`](https://github.com/embeddings-benchmark/mteb/commit/f55a888b8244798b0bd5763b8a09481d051fe935))

### Unknown

* Update points table ([`1123788`](https://github.com/embeddings-benchmark/mteb/commit/112378832ecb22f29169e4de283c1de1242b1576))

* Update points table ([`b1a6cae`](https://github.com/embeddings-benchmark/mteb/commit/b1a6caef3aa2f4733d890b3ef1057478676dca34))

* Update points table ([`c77ad6e`](https://github.com/embeddings-benchmark/mteb/commit/c77ad6ebeead9c5632a0804d47d1d16839f4f785))

* Update points table ([`73e829d`](https://github.com/embeddings-benchmark/mteb/commit/73e829dc59d326c1ee30171853d4eb5e972b6183))

## v1.15.4 (2024-10-07)

### Ci

* ci: Removed 3.8 dependency (#1281)

Changes include:
- remove 3.8 from tests (added 3.11 and 3.12)
- changed other CI to 3.9
- updated lint rules to use 3.8 ([`81081a3`](https://github.com/embeddings-benchmark/mteb/commit/81081a36b4f7b06b9eef28a488a4e68e3d4c912f))

### Fix

* fix: Allow Numpy &gt;=2.0 (#1264)

Allow Numpy &gt;=2.0 ([`b2318f5`](https://github.com/embeddings-benchmark/mteb/commit/b2318f5f900eaa6164f8414b9c51268b7b51ecd4))

### Unknown

* Update points table ([`53f43fe`](https://github.com/embeddings-benchmark/mteb/commit/53f43fee5082b015b275c642fcedf7337d5b4036))

## v1.15.3 (2024-10-06)

### Fix

* fix: sorting benchmark tasks by MTEB, then alphabetical (#1271)

* sorted

* fixed formatting

* efficiency changes

* fix test

* make lint

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`513ceaf`](https://github.com/embeddings-benchmark/mteb/commit/513ceaf58736662f676f4a03e55fe3449f8760fb))

## v1.15.2 (2024-10-03)

### Fix

* fix: derive `results_directory` path from `results_repo` name (#1275)

fix: don&#39;t hardcode repo name when downloading results ([`b589c29`](https://github.com/embeddings-benchmark/mteb/commit/b589c29ec3f5af2c962ce4539e0d3695ae8869c3))

* fix: Select benchmarks CLI option (#1261)

* add test case for a list of Benchmarks

* add selecting benchmarks CLI option

* typos

* use a separate attribute for benchmarks

* try fixing tests

* should accept string as well

* revert filename change

* use Benchmark and avoid circular import ([`e717d6e`](https://github.com/embeddings-benchmark/mteb/commit/e717d6ea2778d08ee09fd2ae14671aeba7eabd60))

## v1.15.1 (2024-10-03)

### Fix

* fix: Add Touche2020v3 and JMTEB (#1262)

* add datasets

* fix metrics

* add Touche2020v3

* fix metadata

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* upd name and supress

* add benchmark class

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`5074918`](https://github.com/embeddings-benchmark/mteb/commit/507491884b0bb9e4599594740bb9886ba7b9b2a7))

### Unknown

* Update tasks table ([`7a55c85`](https://github.com/embeddings-benchmark/mteb/commit/7a55c85cd4f5aab8ae36313f222778fdb4683216))

## v1.15.0 (2024-10-03)

### Documentation

* docs: Update mteb(eng) calculation (#1258)

* Update mteb(eng) calculation

* Fixed citations

* Update MTEB(eng) + MTEB(multilingual) ([`11518ed`](https://github.com/embeddings-benchmark/mteb/commit/11518edd03b916a63e84505592f0d1a32a058d49))

* docs: Update affiliation (#1248)

* Update points.md

* Update points.md

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`647c295`](https://github.com/embeddings-benchmark/mteb/commit/647c295c4dc178f902ab4633d4e1d6e8213487eb))

### Feature

* feat: leverage SentenceTransformers&#39; query/passage specific prompts (#1221)

* feat: leverage SentenceTransformer models&#39; query/passage specific prompts

* refactor: remove E5Wrapper

fix: wrong e5 revisions

* fix: default prompt_type to None

* fix: e4ce987 revision no longer exists for multilingual-e5-small on the Hub

* fix: keep `prompt_name` in kwargs when model doesn&#39;t have a `prompts` attr

* feat: use Enum for `prompt_type`

* docs: specify how to use prompts with Sentence Transformers

* feat: readd arctic models due to metadata ([`c809b84`](https://github.com/embeddings-benchmark/mteb/commit/c809b84d3c7b5bf6f5bca6bbbbdac313e9327d2e))

## v1.14.26 (2024-09-29)

### Fix

* fix: Add listing all available benchmarks CLI option (#1256)

* add benchmarks.md in README

* add cli option

* add benchmark cli test case

* correct typo ([`5e1e290`](https://github.com/embeddings-benchmark/mteb/commit/5e1e29064ac6bb49a09c3dbb5d655c0d2b5379e1))

## v1.14.25 (2024-09-29)

### Fix

* fix: Get meta from CrossEncoder (#1255)

* remove indent after return

* handle cross encoders for model meta

* make lint

* update filename since we now have model name ([`0ad5dad`](https://github.com/embeddings-benchmark/mteb/commit/0ad5dad6591ccbfbf3304525ea20fad9c2710cce))

## v1.14.24 (2024-09-28)

### Documentation

* docs: Small point changes &amp; more contributors (#1254)

* Update points.md

* Fix format

* Fix attribution ([`0d7664d`](https://github.com/embeddings-benchmark/mteb/commit/0d7664d22cf4eeedb5f84e162ab3aa0115dc7c7c))

### Fix

* fix: Downsample large retrieval datasets (#1236)

* most tasks

* lint

* fix other issues

* refactor

* lint and docs

* add polish

* keep case sensitive mteb paths

* add potential points

* fix points

* fix test about metadata

* update tasks and stats

* lint ([`b754f1a`](https://github.com/embeddings-benchmark/mteb/commit/b754f1a578cc6f6868f0666e7a0e2ac9158fe13c))

### Unknown

* Update tasks table ([`e875401`](https://github.com/embeddings-benchmark/mteb/commit/e8754010b6b47118d7d6553098b5e37860ec5414))

* Update points table ([`a155401`](https://github.com/embeddings-benchmark/mteb/commit/a15540116446c6e1d3e0878c92eda3483ae1584a))

* Update points table ([`55e18a8`](https://github.com/embeddings-benchmark/mteb/commit/55e18a80bd91474eff286042c538462c04e034d6))

## v1.14.23 (2024-09-28)

### Documentation

* docs: Added coordination point for Jimmy Lee  (#1253)

docs: Added coordination point for Jimmy lee for his work on the coordination of Crystina and Nandan ([`6b27ce0`](https://github.com/embeddings-benchmark/mteb/commit/6b27ce0a589e0e8f1370dacd414fa61cf882fb8c))

* docs: Update affiliation (#1247)

Update points.md ([`45de3ec`](https://github.com/embeddings-benchmark/mteb/commit/45de3eca1c2487573104e6facd113d2c40907a0f))

### Fix

* fix: Add multilingual Benchmark (#1252)

* fix: Add multilingual bench

* Update mteb/benchmarks/benchmarks.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* format

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`6a6259c`](https://github.com/embeddings-benchmark/mteb/commit/6a6259c39eda1d831073b7516ec158c617f782f3))

### Unknown

* Update points table ([`4dbf784`](https://github.com/embeddings-benchmark/mteb/commit/4dbf78447a67bd9a3b14fd50bdb1cb4466fe1f95))

* Update points table ([`35abd84`](https://github.com/embeddings-benchmark/mteb/commit/35abd8495faa10f165ca108ca84baecb60e365a6))

* Add final author list ([`9ac24b7`](https://github.com/embeddings-benchmark/mteb/commit/9ac24b7b27d6dc6daf0ded3f91bac1b30bc62769))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`8582244`](https://github.com/embeddings-benchmark/mteb/commit/8582244752e341c9a17e3121b7b82d4f82b7346b))

## v1.14.22 (2024-09-27)

### Documentation

* docs: Create benchmarks overview table (#1245)

* fix get_benchmarks method

* add create benchmark script

* make lint ([`fda9be1`](https://github.com/embeddings-benchmark/mteb/commit/fda9be1c085b5d83be58253e32e4aca8e4a2d594))

* docs: Add MTEB(code) dataset (#1237)

* docs: Add MTEB(code) dataset

* Fix linting ([`f808863`](https://github.com/embeddings-benchmark/mteb/commit/f808863f5e393fc472058539fb113efe47e0abf4))

* docs: Update points (#1228)

* Fix case

* Fix casing

* Fix case

* Fix case

* Create 971.jsonl

* Update contrib

* Add contributors ([`a636dc2`](https://github.com/embeddings-benchmark/mteb/commit/a636dc28e968e5689f465983cbdad40481893e6f))

### Fix

* fix: @mrshu&#39;s name in `points.md` (#1246)

* Use the diacritic character to be inline with Slovak spelling.

Signed-off-by: mr.Shu &lt;mr@shu.io&gt; ([`3c06694`](https://github.com/embeddings-benchmark/mteb/commit/3c06694cabb6f6b8d71543aace90f1086cf296e5))

### Unknown

* Add contributor (#1243) ([`18f7306`](https://github.com/embeddings-benchmark/mteb/commit/18f730696451a5aaa026494cecf288fd5cde9fd0))

* Update of my affiliation (#1242)

Update points.md ([`7469afa`](https://github.com/embeddings-benchmark/mteb/commit/7469afabbbc3b40ca85949472267ecf2baa09612))

* Added author-information ([`c02c8e5`](https://github.com/embeddings-benchmark/mteb/commit/c02c8e5bbe575306a0c5f6b881a9958cfad2e84e))

* Update points table ([`eece6ec`](https://github.com/embeddings-benchmark/mteb/commit/eece6ecdb3248b1fb5a044d33c904f3d48cd6eab))

* Update points table ([`dddf5c2`](https://github.com/embeddings-benchmark/mteb/commit/dddf5c249bd102cd22f46965e38c1ebe0896a33d))

## v1.14.21 (2024-09-20)

### Documentation

* docs: clarify adding a model (#1222) ([`25b7a2f`](https://github.com/embeddings-benchmark/mteb/commit/25b7a2fd1c6c1c24a48bf3c2c4d8c00dfa2820b9))

### Fix

* fix: Add RepLLaMA style models (#1223)

* init commit

* working and reproducing

* lint

* update hashes

* warning

* add pyproject ([`bedcfb3`](https://github.com/embeddings-benchmark/mteb/commit/bedcfb3e3991c0573aebb05add24c4f627e14f92))

### Unknown

* Update points table ([`694e563`](https://github.com/embeddings-benchmark/mteb/commit/694e5639c0622af3bf90de5855c1af1ab01d86df))

* Update points table ([`4de39ee`](https://github.com/embeddings-benchmark/mteb/commit/4de39ee917565c8b5da0a101c4769e5b025745e2))

* Update points table ([`b66aaeb`](https://github.com/embeddings-benchmark/mteb/commit/b66aaeb0919707530a41ad983c61413bd6933a53))

## v1.14.20 (2024-09-17)

### Fix

* fix: Allow benchmark to specify eval_splits (#1217)

* fix: Allow benchmark to specify eval_splits

This PR allow for benchmarks to specify specific eval. splits. This allow us to fully specify a benchmark within the benchmark object.

To do this it add the following:
- added eval_splits to the Abstask object, which default to metadata.eval_splits
- use the task.eval_splits unless overwritten in mteb.MTEB.run
- added eval_splits arg to mteb.get_tasks, which filter the tasks based on splits
- updated documentation
  - renamed the &#34;Advanced Usage&#34; to &#34;Usage Documentation&#34; to make it more accicible
- added tests where relevant

* Added correction based on feedback ([`00260b5`](https://github.com/embeddings-benchmark/mteb/commit/00260b5497b4c82583be6383d8b22a3fceb64b54))

## v1.14.19 (2024-09-14)

### Documentation

* docs: Fix broken links in docs (#1212)

* Added fixes for broken links in adding_a_dataset and adding_a_model docs.

* Updated link name ([`b1bd941`](https://github.com/embeddings-benchmark/mteb/commit/b1bd9410715aeadf26af34d6845ddd0a7ee3ade8))

### Fix

* fix: Ensure that results are returned even when hitting cache (#1215)

Fixes #1122 ([`64e01ae`](https://github.com/embeddings-benchmark/mteb/commit/64e01ae9d6fcf125a4ea6516263fa062b2aafeef))

### Unknown

* Update tasks table ([`88b4f6e`](https://github.com/embeddings-benchmark/mteb/commit/88b4f6eda695201ee297cf0e6483344cba9a5985))

* Mismatch of the category of AmazonPolarityClassification (#1220)

Fixes #1219 ([`4595b19`](https://github.com/embeddings-benchmark/mteb/commit/4595b198a7aa2f297999e32d25cb116d12ad1e7d))

## v1.14.18 (2024-09-10)

### Fix

* fix: Normalize benchmarks no only include task objects and added getter for benchmarks (#1208)

* Normalize benchmarks to only include tasks

- Force benchmarks to only include tasks. This fixes a few bugs where benchmarks can reference a task which is not implemented
- implements `mteb.get_benchmark`, which makes it easier to fetch benchmarks
- Added tests + updated docs

A few outstanding issues:

I would like `mteb.MTEB(benchmark)` to always reproduce the benchmark. Currently this is not possible as MTEB(eng) required the split to be specified. A solution it to allow &#34;eval_splits) to be specified when initializing a task and then pass it on to the `load_data()`. This way we can write the following:

`mteb.get_tasks(tasks=[...], eval_splits=[&#34;test&#34;], ...)`

I would also love the aggregation to be a part of the benchmark (such that it is clear how it should be aggregated). This is especially relevant for MTEB(eng) as it average the CQAD datasets before creating the global average. This way we can also create a result object for the benchmark itself. A complimenting solution for this is to allow nested benchmarks.

* fix error in tests

* format

* Added corrections based on review

* added example and formatted ([`f93154f`](https://github.com/embeddings-benchmark/mteb/commit/f93154f465b99bd9737b2ecfd54b3beb491a996d))

## v1.14.17 (2024-09-09)

### Fix

* fix: Normalize licenses including casing, uses of &#34;-&#34; etc. (#1210)

* fix: Normalize licenses including casing, uses of &#34;-&#34; etc.

* fix tests ([`768c031`](https://github.com/embeddings-benchmark/mteb/commit/768c031d3e1e29e39edcf20dd4f9f1ea6092db50))

* fix: Normalize licenses including casing, uses of &#34;-&#34; etc. ([`a8f7d80`](https://github.com/embeddings-benchmark/mteb/commit/a8f7d80e20efd97b0c00ef2c028eba830ce1d308))

## v1.14.16 (2024-09-09)

### Ci

* ci: remove positional argument (#1191)

remove positional argument ([`b75cd29`](https://github.com/embeddings-benchmark/mteb/commit/b75cd299f724ef78a2b5951f140b509169f1c784))

### Documentation

* docs: Add @xhluca to contributor list (#1196)

Add Xing Han Lu to contributor list

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`660bd1c`](https://github.com/embeddings-benchmark/mteb/commit/660bd1cc858707cbb037d801c1c64729c7d17474))

* docs: Add affiliation of @mrshu (#1199)

* Add affiliation details of @mrshu to `docs/mteb/points.md`

Signed-off-by: mr.Shu &lt;mr@shu.io&gt; ([`75cabc9`](https://github.com/embeddings-benchmark/mteb/commit/75cabc9344c63ccf674689db7970bff17634e3d2))

* docs: Adding contributor details (#1195)

Adding contributor details

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`acd631a`](https://github.com/embeddings-benchmark/mteb/commit/acd631a972495fe0b410644fdac1d3eb84ccdb31))

* docs: Added points for ideation and coordination (#1194)

* fix: Added points for ideation and coordination

We have added 50 points for primary coordinators, 20 points for secondary coordinators and 20 points for ideation.

I additionally checked for users which have more than 10 point, but where we do not have their author information.

Will just ping you guys here to ensure that you get a chance to add the authorship information (@akshita-sukhlecha, @loicmagne, @mrshu, @crystina-z, @thakur-nandan, @xhluca)

If anyone notice any other authors which haven&#39;t yet been credited please let me know!

* added secondary contributor ([`8b0834d`](https://github.com/embeddings-benchmark/mteb/commit/8b0834dc1c2480052faec786c9bcd3067e0e2e0a))

* docs: authorship-info for crystina-z (#1198) ([`08c1efe`](https://github.com/embeddings-benchmark/mteb/commit/08c1efe57387c429ddbec3d36bfa717f99879b8b))

* docs: Adding contributor details (#1184)

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`0fc93dc`](https://github.com/embeddings-benchmark/mteb/commit/0fc93dca1170866d2236bfee664b82e05f230b2d))

* docs: add reranker / cross encoder to README advanced usage (#1186)

* add reranker / cross encoder to README advanced usage

* use preferred way for task selection

* make script runnable ([`aa5479d`](https://github.com/embeddings-benchmark/mteb/commit/aa5479da71a40b545dd339d345101d3a02e688c3))

* docs: Update contributors table (#1189)

Add conributor information ([`929733b`](https://github.com/embeddings-benchmark/mteb/commit/929733b4ea172a5d9deeb85ef59af71e5492b863))

### Fix

* fix: Ensure STS pearson and spearman does not use the p-value only the correlation (#1207)

Fixes #1206 ([`5aa401d`](https://github.com/embeddings-benchmark/mteb/commit/5aa401dcc7ec5bdf6ccbc9cfe1207267a08c4523))

* fix: OpenAI BadRequestError by limiting input dimensions to 2048 elemâ€¦ (#1203)

* fix: OpenAI BadRequestError by limiting input dimensions to 2048 elements (#1201)

Fix OpenAI BadRequestError by limiting input dimensions to 2048 elements

- Ensure the &#39;sentences&#39; list passed to OpenAI API does not exceed 2048 elements
- Reference: OpenAI&#39;s Embedding API documentation on input limits

Co-authored-by: Ali Shiraee &lt;ShiraeA@basfad.basf.net&gt;

* fix ruff formatting

* Added minor test fixes to ensure reproducility across systems

* Ensure that tmp.json is not created within repo when running tests

* format

* fixes path issues

* Rerun CI

---------

Co-authored-by: HSILA &lt;a.shiraee@gmail.com&gt;
Co-authored-by: Ali Shiraee &lt;ShiraeA@basfad.basf.net&gt; ([`ba562ce`](https://github.com/embeddings-benchmark/mteb/commit/ba562cef8a123f1b760d70b66ad6e1d959c7c3bc))

### Unknown

* Update points table ([`16b2220`](https://github.com/embeddings-benchmark/mteb/commit/16b222019c595aea7cdbbb04b506736851c6316b))

* Update points table ([`9733d06`](https://github.com/embeddings-benchmark/mteb/commit/9733d06764f71cddf3755993b49f6f1006609903))

* Update points table ([`a574c76`](https://github.com/embeddings-benchmark/mteb/commit/a574c76c53abebc65a1e3148afdd83ff6cd95d8b))

* Update points table ([`6b50759`](https://github.com/embeddings-benchmark/mteb/commit/6b50759ae6cb45e4b8a622ef386fbece91698e24))

* Update points table ([`b8fb4d3`](https://github.com/embeddings-benchmark/mteb/commit/b8fb4d31fc9b504bbb8cc489fabcaaddc4558f22))

* Update points table ([`1024b24`](https://github.com/embeddings-benchmark/mteb/commit/1024b24cffb46f1a0d98061aa6899a6cb285018f))

* Update points table ([`4c1b6b5`](https://github.com/embeddings-benchmark/mteb/commit/4c1b6b5ffb5ba149e668e2172df2d55b8355966c))

## v1.14.15 (2024-09-01)

### Fix

* fix: Add save prediction cli (#1187)

* add save predictions cli option

* add how to save retrieval task predictions to README

* simplify example script

* add cli test

* Update README.md

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`826cdf5`](https://github.com/embeddings-benchmark/mteb/commit/826cdf513d233d8a71019bf75fef7f3f76991b5e))

## v1.14.14 (2024-09-01)

### Fix

* fix: Remove test set form eval sets as test labels are unknown (#1190) ([`d375ff7`](https://github.com/embeddings-benchmark/mteb/commit/d375ff7b252309492c7f30f0706f4a4d9388d95c))

## v1.14.13 (2024-09-01)

### Documentation

* docs: Add missing Author (#1188)

add missing author ([`24eb38e`](https://github.com/embeddings-benchmark/mteb/commit/24eb38ee25192c5f1800c6d4f07cf6c45717a63b))

* docs: Adding collaborators user details (#1182)

add user details

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`d1e6e5f`](https://github.com/embeddings-benchmark/mteb/commit/d1e6e5f1f487c0562f768f8427ffdfac8a217eef))

### Fix

* fix: create_meta (#1179)

* refactor: create_meta

* add points

* fix windows ([`a43d1ff`](https://github.com/embeddings-benchmark/mteb/commit/a43d1ff6abf15c6c1dc389e85531af760d654e00))

* fix: Added multilingual and indic benchmark (#1174)

* revert pyproject.toml

* format

* format

* added benchmark result tables

* format

* fix: Unsure that tests work with the new update

* Added results fetching to readme

* minor fixes

* Added points for running models
propably a gross misestimation

* Added script for creating contributions and author list (#1178)

* Added points for running models
propably a gross misestimation

* docs: Added notebook for creating authorlist, point table and affil table

* format

* Remove aff. upon request from contributor

* format ([`74ec7d2`](https://github.com/embeddings-benchmark/mteb/commit/74ec7d2dfb53b1b77746351d153205fb9bbd9383))

### Unknown

* Update tasks table ([`6d6db67`](https://github.com/embeddings-benchmark/mteb/commit/6d6db676a976fb8a434dfbf37d1d2add9fc58f41))

* Update tasks table ([`9ca4ab4`](https://github.com/embeddings-benchmark/mteb/commit/9ca4ab421007efe1fe8b5d363525800680818fdf))

* Update citation ([`d9bc4a1`](https://github.com/embeddings-benchmark/mteb/commit/d9bc4a1e9a68e30fffc38feab06ac281a9fb780f))

## v1.14.12 (2024-08-25)

### Fix

* fix: add points (#1180)

* add points

* add #1159

* add openreview

* fix points ([`86fc8a9`](https://github.com/embeddings-benchmark/mteb/commit/86fc8a96ae39f70aeb0d2b3a43062d4112d3a2b8))

### Unknown

* Update points table ([`702b31b`](https://github.com/embeddings-benchmark/mteb/commit/702b31b4d1ef523bf5bf509cb514e0faf42d69bf))

## v1.14.11 (2024-08-25)

### Fix

* fix: add citation rumteb (#1181) ([`605587a`](https://github.com/embeddings-benchmark/mteb/commit/605587a5e9f7aac42885de1975fa5d40e13c4f52))

### Unknown

* format main (#1177)

format ([`877db0f`](https://github.com/embeddings-benchmark/mteb/commit/877db0f798cb85abf600a1e30b83d32ad6ebd279))

## v1.14.10 (2024-08-22)

### Fix

* fix: add multilingual mocks and test descriptive_stats (#1173)

* add multilingual mocks and test descriptive_stats

* fix task

* lint

* remove comment ([`f941aa0`](https://github.com/embeddings-benchmark/mteb/commit/f941aa0c6b405e4b377c74487271fb927bd4a05b))

* fix: Remove unavailable test split from OCNLI  (#1175)

fix ocnli ([`b21223a`](https://github.com/embeddings-benchmark/mteb/commit/b21223a39baa1d403fe6f6ebe1ef2fef9e15882f))

### Unknown

* Update tasks table ([`5ddff62`](https://github.com/embeddings-benchmark/mteb/commit/5ddff6230d58f92d9a1cb2db7bea16d2236b8476))

## v1.14.9 (2024-08-21)

### Fix

* fix: Added multilingual and indic benchmark

This adds outlines for the multilingual and indic benchmarks as well as a few adjustments to existing benchmarks due to a few discovered bugs in the previous implementation.

It also add utilites for easily creating a table from a list of tasks:

```
tasks = mteb.get_tasks(tasks=[...])
tasks.to_latex()
tasks.to_dataframe()
``` ([`8c9dada`](https://github.com/embeddings-benchmark/mteb/commit/8c9dadac6b23dc5f05656cc3284109f7d79e03b7))

### Unknown

* Update tasks table ([`4699b43`](https://github.com/embeddings-benchmark/mteb/commit/4699b43a232fcdea096be08c899ce7f6479f4914))

## v1.14.8 (2024-08-21)

### Fix

* fix: Added contruction of MTEB(eng, v2) and its lite version (#1168)

* Added metadata

* Added EU benchmark given current tasks

* Updated task selection and benchmark

* Added csv

* Added benchmark scores

* Added evaluation time

* format

* fixed baed on corrections

* fix: Added construction of MTEB(eng, v2) and MTEB(eng, v2 lite)

* Added v2 lite comparison with v1

* format

* format

* reformulate to not introduce mtebv2 ([`e861ef2`](https://github.com/embeddings-benchmark/mteb/commit/e861ef24524858800f96012edc887fbd4e67750a))

## v1.14.7 (2024-08-21)

### Fix

* fix: Added task selection for the EU benchmark (#1166)

* Added metadata

* Added EU benchmark given current tasks

* Updated task selection and benchmark

* Added csv

* Added benchmark scores

* Added evaluation time

* format

* fixed baed on corrections

* Added romani

* format ([`0f4f2df`](https://github.com/embeddings-benchmark/mteb/commit/0f4f2dff35381632097ded347ffe5b4b8a767b76))

### Unknown

* Update tasks table ([`c220741`](https://github.com/embeddings-benchmark/mteb/commit/c2207410c3e6dd5a161d89808404b1a50a6d1d9b))

## v1.14.6 (2024-08-21)

### Fix

* fix: Add function for metadata create (#1167)

* init calculate metadata

* add bitextmetadata

* add classification

* add calculate metrics

* add docs

* fix speed

* fix dummy task

* add typed dict

* update stats

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/abstasks/AbsTaskClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* fix docstrings

* add overall

* update stats

* fix retrieval dict

* change to typeddict

* rename lang to hf_subset

* update task table

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`56382b5`](https://github.com/embeddings-benchmark/mteb/commit/56382b53ef33cd747b3fc65aa0d517480c52ef17))

## v1.14.5 (2024-08-19)

### Fix

* fix: Merge pr 1128 (#1169)

* Create arctic_models.py

* Update run_mteb_english_cluster.py

* updates

---------

Co-authored-by: Daniel Campos &lt;daniel.campos@snowflake.com&gt; ([`04dbcbb`](https://github.com/embeddings-benchmark/mteb/commit/04dbcbb8535cb81bde1d86ec0e05c0fa865a38d5))

* fix: Update COIR datasets  (#1159)

* integrate mteb

* fix bug

* update monolingual tasks for coir

* fix bugs

* update

* update

* fix

* remove title

* rm dates

* fix typo

* fix formatting

* edit metadata

* fix

* update new paths

* update revision

* fix

* update

* fix revision

* fix metadata

* add coir codesearchnet

* fix metclass error

* fix metaclass error

* fix hf commit

---------

Co-authored-by: l00856372 &lt;lee.yi.quan@huawei.com&gt; ([`c5bd338`](https://github.com/embeddings-benchmark/mteb/commit/c5bd3381f2efdc985d1538038c50300d733d1923))

### Unknown

* Update tasks table ([`ecdc240`](https://github.com/embeddings-benchmark/mteb/commit/ecdc240d7542d18229e05d3e1f60d31a812a0494))

* Format recent additions to the codebase ([`bd2db98`](https://github.com/embeddings-benchmark/mteb/commit/bd2db98cbacc65b2a97a8cf56ab977d19666be44))

## v1.14.4 (2024-08-19)

### Fix

* fix: Ensure that summarization only calculates the metric across the statistic. (#1157)

* fix: Ensure that summarization only calculates the metric across the statistic.

Fixes #1156

* Added versioning to datasets ([`e57efad`](https://github.com/embeddings-benchmark/mteb/commit/e57efad4655460506111cecbfba9144d813424d4))

### Unknown

* Update tasks table ([`b47a81e`](https://github.com/embeddings-benchmark/mteb/commit/b47a81ed6c4b330988854ca63d68783f282acbb1))

## v1.14.3 (2024-08-19)

### Documentation

* docs: format notebooks and upgrade ruff (#1164) ([`4e98381`](https://github.com/embeddings-benchmark/mteb/commit/4e98381993fa1c1e55ceeb4e1ba6f5d99d4f0192))

### Fix

* fix: load_data in MintakaRetrieval (#1155)

fix: add trust remote code ([`1a1ea2e`](https://github.com/embeddings-benchmark/mteb/commit/1a1ea2eaf9eded2435a613ac12203bbb288d4838))

### Unknown

* Fix: test wrappers and export all tasks results in tests (#1116)

* test wrappers and export all tasks results

* lint

* change to monkeypatch

* lint

* add Mxbai

* Update tests/test_benchmark/mock_models.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* remove create meta test

* remove gritlm models

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`7f3ad0e`](https://github.com/embeddings-benchmark/mteb/commit/7f3ad0e8c4929a518f0815d51193ea7f7b1acb4a))

* Update ruMTEB tasks list (#1163)

* update Russian benchmark

* add detailed instructions

* add language filter

* fix lint ([`f619201`](https://github.com/embeddings-benchmark/mteb/commit/f619201a9ab91d453d7f500a0db6f8f3789a5840))

## v1.14.2 (2024-08-15)

### Documentation

* docs: Updating the contributor information (#1161)

Update points.md

Hey, this just adds some &#34;contributor information&#34; about my coworker and myself ([`1325a6a`](https://github.com/embeddings-benchmark/mteb/commit/1325a6a922bc474d2e19b9c307fe30e7bd2a2579))

### Fix

* fix: Added Task selection and aggregation (#1140)

* task metric selection initial commit (#891)

Co-authored-by: vaibhavad &lt;vaibhavadlakha95@gmail.com&gt;

* Add changes to PR

* save

* save

* Added significant rank

* clean up

* save attemtps

* add scores plot

* update scores plot

* latent models

* Added utility function for downloading models results

* Added result tables

* Added bench construction

* format

* Added correction citations

* format

* sav

* sav

* sav

* added task selection for EU languages

* remove token

* clean up branch

* clean up branch

* merge

* minor

* minor

* fix metadata

* fix: Move benchmarks from script to benchmarks.py

- A few of the benchmarks weren&#39;t implemented in the benchmark list. The best choice seem to move them benchmarks and remove the script (there were already a few issues). To ensure that they are maintained with the rest.
- Removed trivial (e.g. running one task) or outdated examples. Removing them ensure that we have less to maintain.
- moved mteb specific script into a mteb-folder.

* format

* fix: Convert arbitrary imports to absolute imports.

This avoids loading in classes as modules (see PR ...)

* Added example

* Final correction to notebook

* format

* reorder scripts

* remove additional files

* remove plots

* fixed loading

* Added corrections

---------

Co-authored-by: vaibhavad &lt;vaibhavadlakha95@gmail.com&gt; ([`57f4fb2`](https://github.com/embeddings-benchmark/mteb/commit/57f4fb254391285cb93a82228abf61baafc2b9ba))

### Unknown

* Update tasks table ([`b879133`](https://github.com/embeddings-benchmark/mteb/commit/b87913368736854fd43a47a3b34b44cf3be7218e))

* Update tasks table ([`1e5cdaf`](https://github.com/embeddings-benchmark/mteb/commit/1e5cdafc3cd625d50aa5008a0a1b00110cbff3d1))

* Update points table ([`35a17c5`](https://github.com/embeddings-benchmark/mteb/commit/35a17c551f1098ff0df35896e0de28f2ac598b76))

* LitSearchRetrieval added (#1150)

* LitSearchRetrieval added

* points added

* fixed descriptive_stats in LitSearchRetrieval

* fix lint

* metadata fixed for LitSearchRetrieval

* metadata fixed for LitSearchRetrieval again

* metadata fixed for LitSearchRetrieval again

* points 1150 updated

* metadata fixed for LitSearchRetrieval again

* lint fix ([`a6458aa`](https://github.com/embeddings-benchmark/mteb/commit/a6458aa283c7253a6347f78d3043b30fecc3e2e8))

## v1.14.1 (2024-08-13)

### Fix

* fix: removed test set for AFQMC with no gold labels (#1153)

The test set of AFQMC is hidden so has removed it from the default suite. This influences the C-MTEB. Who is the best person to contact for this? (@Muennighoff) ([`14cff3e`](https://github.com/embeddings-benchmark/mteb/commit/14cff3e7830150e28b45098a008048189c7d1e1e))

### Unknown

* Fix: llm2vec for retrieval (#1152)

* fix: remove  kwargs LLM2Vec doesn&#39;t have

* fix: linter error

* fix: an item automatically added by linter ([`d1794cd`](https://github.com/embeddings-benchmark/mteb/commit/d1794cd2edaf9236699d6d1ccba4cbc15b5f8708))

## v1.14.0 (2024-08-12)

### Feature

* feat: Cleaned up scripts folder  (#1144)

* fix: Move benchmarks from script to benchmarks.py

- A few of the benchmarks weren&#39;t implemented in the benchmark list. The best choice seem to move them benchmarks and remove the script (there were already a few issues). To ensure that they are maintained with the rest.
- Removed trivial (e.g. running one task) or outdated examples. Removing them ensure that we have less to maintain.
- moved mteb specific script into a mteb-folder.

* format

* fix: Convert arbitrary imports to absolute imports. (#1145)

This avoids loading in classes as modules (see PR ...)

* restructe scripts folder ([`ebe6def`](https://github.com/embeddings-benchmark/mteb/commit/ebe6defb6942e7e98edcece6eb8be9820ce7899a))

## v1.13.2 (2024-08-11)

### Fix

* fix: Remove unused tests (#1148)

These tests are no longer used since results moved to the results repo. ([`28f592f`](https://github.com/embeddings-benchmark/mteb/commit/28f592f2289b31d8de5e49b76a49e19f94810ebc))

### Unknown

* Update tasks table ([`8560d9f`](https://github.com/embeddings-benchmark/mteb/commit/8560d9fb4bec43e584540b0d1642b02cfd449c44))

* Missing import for SadeemQuestionRetrieval (#1146)

Fixes #1143 ([`3b6e27d`](https://github.com/embeddings-benchmark/mteb/commit/3b6e27d6c0c58c2624c2f3cb40e30f8f20fea39d))

* Simplify models (#1118)

* Merge

* Adapt

* Simplify

* Check for rev again

* Rmv cmmnt

* Simplify

* simplify

* Rmv comment

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Use logging; change try except; add info

* Lint

* Rmv results

* Update rev

* Simplify models; Allow instructions

* Jobs

* Fix merge

* Format

* Adapt models

* Fix task types

* Update

* Fix syntax

* Simplify

* Add comparison

* Format

* Fix double comment

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Move example

* Format

* Rmv outdated instructions

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`79c1a42`](https://github.com/embeddings-benchmark/mteb/commit/79c1a420f62716c2dfd1284185d5f35c630e0f47))

## v1.13.1 (2024-08-10)

### Fix

* fix: add CoIR as Benchmark (#1142)

* add CoIR as Benchmark

* lint ([`1b80fce`](https://github.com/embeddings-benchmark/mteb/commit/1b80fcebd3a8f1f4b4347895cc8c84b181f1c31c))

## v1.13.0 (2024-08-09)

### Feature

* feat: Added in functionality to allow loading outdated results (#1141) ([`d76e686`](https://github.com/embeddings-benchmark/mteb/commit/d76e6868e5cdf04ed790f9fd04d046e15f798fcc))

## v1.12.94 (2024-08-08)

### Fix

* fix: add CoIR tasks (#1130)

* add CoIR tasks

* change to mteb datasets ([`aa97e39`](https://github.com/embeddings-benchmark/mteb/commit/aa97e3931494e9c68aab47345003b47e1933ad3b))

### Unknown

* Update tasks table ([`e9a3ce8`](https://github.com/embeddings-benchmark/mteb/commit/e9a3ce8c84dc63152dbd8051e2d8e6dc753c3a2f))

* Update points table ([`76e2bff`](https://github.com/embeddings-benchmark/mteb/commit/76e2bffa77e85205cd0cac6fc4fde9218bec73ae))

* Added pyupgrade (using ruff) to lint CI (#1137)

* Added pyupgrade (using ruff) to lint CI
* Added FA ruleset
* Added C4 ruleset for simplifying comprehensions
* Added a few exceptions for points
Co-authored-by: bryant1410 &lt;name@example.com&gt;
* Added required import
* Add co-author
Co-authored-by: bryant1410 &lt;bryant1410@gmail.com&gt;
* format
---------
Co-authored-by: bryant1410 &lt;name@example.com&gt;
Co-authored-by: bryant1410 &lt;bryant1410@gmail.com&gt; ([`e4afd0e`](https://github.com/embeddings-benchmark/mteb/commit/e4afd0ee871cb641ac67661c08c831b4f8f0bca0))

## v1.12.93 (2024-08-04)

### Fix

* fix: Allow more linient TaskMetadata (#1131)

* fix: Allow more linient TaskMetadata

This fix allows for more lenient TaskMetadata when using the package, but maintain the validation for the package within the tests.

This is intended to ensure flexibility and ease of use, while maintaining high-quality doucementation of tasks

* Added fixes based on corrections ([`8b36887`](https://github.com/embeddings-benchmark/mteb/commit/8b368879bfb7b4d198121ebce3c343f6ba1dea37))

### Unknown

* Update points table ([`8b060b9`](https://github.com/embeddings-benchmark/mteb/commit/8b060b9384d086642014f9e894dfb2e294442c98))

## v1.12.92 (2024-08-02)

### Fix

* fix: IWSLT2017BitextMining loading dataset. (#1132)

fix: the way of loading and transform dataset and typo of filename on IWSLT2017BitextMining ([`d264046`](https://github.com/embeddings-benchmark/mteb/commit/d264046ec76abe8a4e6496ad47dcd83934fdabc3))

## v1.12.91 (2024-08-01)

### Fix

* fix: when create meta merge results with existing README.md (#1117)

* init version

* merge scores

* add test without frontmatter

* lint ([`61a4c31`](https://github.com/embeddings-benchmark/mteb/commit/61a4c31dc9feed661eeadf018749214ffb32972e))

## v1.12.90 (2024-07-30)

### Fix

* fix: nomic models using prefix correctly (#1125)

* fix: nomic models using prefix correctly

* chore: remove comment

* fix: handling in case not torch tensor

* Fix typo

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`9cd2199`](https://github.com/embeddings-benchmark/mteb/commit/9cd2199a16776fc14ef2dd7c8e87b1f4eaebfc35))

### Unknown

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`a1dc3ac`](https://github.com/embeddings-benchmark/mteb/commit/a1dc3ace5c2519dbb3e95401219aa2a518fe2bc8))

## v1.12.89 (2024-07-25)

### Fix

* fix: Simplify models implementations (#1085)

* Merge

* Adapt

* Simplify

* Check for rev again

* Rmv cmmnt

* Simplify

* simplify

* Rmv comment

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Use logging; change try except; add info

* Lint

* Rmv results

* Update rev

* format

* Simplify models; Allow instructions

* Jobs

* Fix merge

* Format

* Adapt models

* fix: ensure that e5 ignores the NQ

* format

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`30e0617`](https://github.com/embeddings-benchmark/mteb/commit/30e061705e7e3015c108516457e95d24cce4c02a))

### Unknown

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`5b9dfca`](https://github.com/embeddings-benchmark/mteb/commit/5b9dfca154b5f345669ed9c0eb1064b7f562be0b))

## v1.12.88 (2024-07-25)

### Documentation

* docs: improve searchability in the advanced usage documentation (#1113)

* docs: improve searchability in the advanced usage documentation

* docs: update based on corrections ([`7492e04`](https://github.com/embeddings-benchmark/mteb/commit/7492e0481ab42d923b83abc979c558502e65eeb2))

### Fix

* fix: export type for `mteb create_meta` (#1114)

* fix export type

* fix dataset version too ([`475967e`](https://github.com/embeddings-benchmark/mteb/commit/475967e396fa9644367df9c95e64a9db5fe48917))

## v1.12.87 (2024-07-25)

### Documentation

* docs: improve searchability in the advanced usage documentation ([`7e036de`](https://github.com/embeddings-benchmark/mteb/commit/7e036de02e1b04aab33b3c6363654a9a92fc0e37))

### Fix

* fix: Ensure that MLSUMClusteringP2P.v2 use the fast implementation as was intended (#1112)

* fix: Ensure that MLSUMClusteringP2P.v2 use the fast implementation as was intended

* fix: fixed formatting for cli ([`47df0f3`](https://github.com/embeddings-benchmark/mteb/commit/47df0f389d9467b43084f05fb5ee8e4016e03cff))

## v1.12.86 (2024-07-25)

### Fix

* fix: MultilingualSentimentClassification (#1109) ([`46e2634`](https://github.com/embeddings-benchmark/mteb/commit/46e2634dc51784498a7158b63cad3b288e029d45))

* fix: Avoid spaces in dataset name for CQADupstack and ignore speed tasks ([`553620c`](https://github.com/embeddings-benchmark/mteb/commit/553620c28971028aa4b7f8e514fc464d8e3148ea))

### Unknown

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`8e34c25`](https://github.com/embeddings-benchmark/mteb/commit/8e34c251bfdd550e5a8f22c8a8c19ceb39c96724))

* Update points table ([`57e885f`](https://github.com/embeddings-benchmark/mteb/commit/57e885f16a59e44809743c227e459a97c845f75e))

## v1.12.85 (2024-07-22)

### Fix

* fix: fix bug-causing spelling error in function name of e5-mistral-instruct (#1106)

found bug ([`2759cc1`](https://github.com/embeddings-benchmark/mteb/commit/2759cc1d3110fde44345d975a857851bb2b6acb0))

### Unknown

* Update points table ([`aa32a26`](https://github.com/embeddings-benchmark/mteb/commit/aa32a26604dda19ef39b4b0491f064d790cba735))

* fix instruction retrival (#1072)

* fix instruction retrival

* fix test

* add points

* make nested results

* add test

* skip instruction test

* fix instruction passes

* fix unions

* move do_length_ablation

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`a7a5e28`](https://github.com/embeddings-benchmark/mteb/commit/a7a5e28d119d3f1bd21a7b06cfdec0de06488e85))

## v1.12.84 (2024-07-18)

### Ci

* ci: Splitting doc CI in two to ensure that it runs on PRs AND on main (#1096)

* ci: Splitting doc CI in two to ensure that it runs on PRs AND on main

* minor fixes to clarify intent ([`304bac0`](https://github.com/embeddings-benchmark/mteb/commit/304bac040ce7133a049a14b71ec587375e7c003c))

### Fix

* fix: Added fix for voyage models to handle too large batches (#1098)

Additonally also added voyage multilingual. ([`2f25626`](https://github.com/embeddings-benchmark/mteb/commit/2f25626f2c66c17477b40c81de95dc43a6cfd885))

* fix: Added misisng license (#1097) ([`81f0e22`](https://github.com/embeddings-benchmark/mteb/commit/81f0e223d24c121203af27164e89fa37cb6f66b5))

### Unknown

* Update tasks table ([`b55eed5`](https://github.com/embeddings-benchmark/mteb/commit/b55eed545a93d22cc7a7307d19b10e5fbfa312fa))

## v1.12.83 (2024-07-18)

### Fix

* fix: update lang codes for language classification (#1094)

Add language classification ([`930e23c`](https://github.com/embeddings-benchmark/mteb/commit/930e23c583b6a614d4f70542ddecbf5f73cebde5))

## v1.12.82 (2024-07-18)

### Fix

* fix: Add google API models (#1087)

* Add google API models

* fix based on revisions ([`11443dc`](https://github.com/embeddings-benchmark/mteb/commit/11443dc9c0a9f4c5fbf686dffbf0b9a6f63493fe))

## v1.12.81 (2024-07-16)

### Fix

* fix: Add bm25s as a model for retrieval (#1082)

* add bm25s as a model
* getting bm25s working
* add nf corpus results
* add as optional dependecies
* add bm25 to make install-for-tests
* move results to results repo
* add run script
* make test passing
* make lint
* types

Co-authored by: @malteos &lt;github@i.mieo.de&gt; ([`5269f2c`](https://github.com/embeddings-benchmark/mteb/commit/5269f2c4538cc3b0e691de235d1cd2011e1bab5a))

## v1.12.80 (2024-07-15)

### Ci

* ci: fix ci docs to work on prs and in main (#1084)

* ci: allow docs ci to be run by contributors on PRs

* ci: Add missing &#34;fi&#34; at the end ([`c977d35`](https://github.com/embeddings-benchmark/mteb/commit/c977d35996c12ee94546470bb7875d68bb304084))

* ci: allow docs ci to be run by contributors on PRs (#1081) ([`db45092`](https://github.com/embeddings-benchmark/mteb/commit/db45092f31a1be05f264a0752fa68964a35b5927))

* ci: run docs ci on PRs (#1078) ([`bf02080`](https://github.com/embeddings-benchmark/mteb/commit/bf02080f6062bc28bff597663ed1759a63233535))

### Fix

* fix: ensure that CQADupstackRetrieval is included in results if possible (#1079)

* move mmteb script into correct folder

* remove unec file

* add results to gitignore

* fix: ensure that CQADupstackRetrieval is included in results if possible

* remvoe cqadupstack script

* Added fixes based on corrections ([`3109b4d`](https://github.com/embeddings-benchmark/mteb/commit/3109b4deaf2ca080036240d4f734b304da7fc23a))

### Unknown

* Add support for the Bright benchmark  (#971)

* Bright

* Update mteb/tasks/Retrieval/eng/BrightRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/abstasks/TaskMetadata.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Retrieval/eng/BrightRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Retrieval/eng/BrightRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Retrieval/eng/BrightRetrieval.py

Co-authored-by: xiamengzhou &lt;296337231@qq.com&gt;

* Create run_mteb_bright.py

* Fix format

* Fix splits

* Update metadata

* Rmv newline

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: xiamengzhou &lt;296337231@qq.com&gt;
Co-authored-by: hongjin-su &lt;114016954+hongjin-su@users.noreply.github.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`e05c53c`](https://github.com/embeddings-benchmark/mteb/commit/e05c53cbc7a5be62090de156a033689f16cab040))

## v1.12.79 (2024-07-12)

### Fix

* fix: Added models x tasks which haven&#39;t yet been run (#1038)

* Added models x tasks which haven&#39;t yet been run

* removed duplicate citations

* adapt to new results repo structure

* Rename PawsX to PawsSXPairClassification

* rename PawsX class

* updated missing tasks

* Updated missing tasks

* tmp

* format ([`ae2e2b7`](https://github.com/embeddings-benchmark/mteb/commit/ae2e2b7c8140176f0aa4f3d7d90856f5acbbabb6))

## v1.12.78 (2024-07-12)

### Fix

* fix: Multi-gpu/simpler models; Add gte (#1059)

* Merge

* Adapt

* Simplify

* Check for rev again

* Rmv cmmnt

* Simplify

* simplify

* Rmv comment

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Use logging; change try except; add info

* Lint

* Rmv results

* Update rev

* format

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`66ae979`](https://github.com/embeddings-benchmark/mteb/commit/66ae979f29eef1d66cb98870e19773ca76d30819))

## v1.12.77 (2024-07-12)

### Fix

* fix: Added benchmark construction (#1003)

* Added utility function for downloading models results

* Added bench construction

* format

* Added correction citations

* format ([`dd76c67`](https://github.com/embeddings-benchmark/mteb/commit/dd76c674b86c7370de73a3d4d49f9e161f77ea96))

## v1.12.76 (2024-07-12)

### Documentation

* docs: Update contributor table (#1071)

update contributor table ([`778d7a3`](https://github.com/embeddings-benchmark/mteb/commit/778d7a3bf85b2023cc8ba9b2c35a810dcfa5e924))

### Fix

* fix: restructure test suite to avoid to many external dependencies (#1070)

* fix: restructure test suite to avoid to many external dependencies

The intention behind this is to make tests faster and more robust. Especially to avoid false positives where the test works, but fails due to interaction with HF, the OS (CLI commands).

- Restructure test suite to make it easier to find specific tests and add tests in the future. e.g. added all evaluators test to a folder
- splits test_mteb into multiple segments, one for testing SentenceTransformers, one for testing evaluation workflow, one for testing integration with datasets
- avoid using encoders when testing evaluation workflow (one extra interaction with hf which can fail and it is slow)
- Added MockEncoders for testing torch, numpy and torch bf16 return types (see FP16 embeddings fail with BitextMining #1064)
- Added MockTask for all task types to avoid downloading too many datasets and to allow for more diverse without making the test suite too slow

The slowest test are now the mteb_rerank tests along with the integration tests. @orionw was hoping we might be able to to replace the dataset with a dummy dataset. However the slowest atm. is 20s

This PR also added a few minor fixes (surprisingly few actually) for handling torch bf16 which was not handled and a minor fix to AbstaskClusteringFast (@isaac-chung)

* fix: Remove precision for more readable scores and lower memory footprint (#1075)

* fix: reduce precision of results for readability

* Added example cases

* Removed &#34;dev&#34; as a default split from flores

* remove flores results

* fixes errors due to merge ([`636018b`](https://github.com/embeddings-benchmark/mteb/commit/636018be6ec04a2051881abd0068ce018e485be5))

### Refactor

* refactor: update TaskMetadata (#1076)

* update TaskMetadata.py

* update _add_stats.grit

* update _add_stats.grit

* update 415 files

* update _add_stats.grit and TaskMetadata.py

* update _add_stats.grit

* update 86 files

* update 6 files update 341 files

* delete 1 file and update 416 files

* misc. ([`57c1c12`](https://github.com/embeddings-benchmark/mteb/commit/57c1c12727b6300465cb647f2e55c9af0049d759))

### Unknown

* Update points table ([`cff1ae6`](https://github.com/embeddings-benchmark/mteb/commit/cff1ae6c2515b8aa97b15da7d72c47b824c7d94f))

* Update points table ([`86eb18c`](https://github.com/embeddings-benchmark/mteb/commit/86eb18c1c8a2d2c04c0a2752fd9302726119100f))

* Change refresh description (#1074)

Update adding_a_model.md ([`d98dcd8`](https://github.com/embeddings-benchmark/mteb/commit/d98dcd8958ecaeda9b7f97f340412be42f6f9efb))

## v1.12.75 (2024-07-09)

### Fix

* fix: standardize PairClassification results (#1063)

* make pairclassification as one dict

* lint

* add max

* return precision, recall

---------

Co-authored-by: Roman Solomatin &lt;36135455+Samoed@users.noreply.github.com&gt; ([`e244777`](https://github.com/embeddings-benchmark/mteb/commit/e2447774c07381b09553f44844e8d89307929157))

### Unknown

* Update points table ([`4e29dce`](https://github.com/embeddings-benchmark/mteb/commit/4e29dce0fc59ff1cda9d9e20c7efe4acc3617ecc))

* Update points table ([`4a5c0f4`](https://github.com/embeddings-benchmark/mteb/commit/4a5c0f49e5508b5d63b85b25a015135b9449d0ef))

## v1.12.74 (2024-07-09)

### Fix

* fix: Fix Jina model loading (#1062)

match ST model card load script ([`4ce6989`](https://github.com/embeddings-benchmark/mteb/commit/4ce6989572454df8cfac43493a3b910383320079))

## v1.12.73 (2024-07-09)

### Fix

* fix: Simplify (#1017)

* Simplify

* Fix ([`a28c722`](https://github.com/embeddings-benchmark/mteb/commit/a28c722d002c6c607175d3c84760cd32dc3849a4))

## v1.12.72 (2024-07-09)

### Fix

* fix: Fixes for encode_conversation and better default for CLI device (#1048)

* fix: ensure that argument are passed correctly for fatihdial

* fix: reformat encode_corpus to always check for encode_conversation functionality. Additionally remove encode_corpus from DresModel

* Added better default for device in CLI ([`2f1dc38`](https://github.com/embeddings-benchmark/mteb/commit/2f1dc38f39b57b0e6f78eb5bf36f5d8a48458b2f))

## v1.12.71 (2024-07-08)

### Fix

* fix: reuse corpus utils for LLM2Vec (#1040)

* reuse function by modifying little

* make lint

---------

Co-authored-by: ryan.agile &lt;ryan.agile@kakaobrain.com&gt; ([`0cb5807`](https://github.com/embeddings-benchmark/mteb/commit/0cb5807385c248d0b356cf19c5deb1e0cbba9976))

## v1.12.70 (2024-07-08)

### Fix

* fix: Add STS22.v2 and LivedoorNewsClustering.v2 (#1055)

* Added STS22.v2

* Added LivedoorNewsClustering.v2

* Updated description of v2

* Update mteb/tasks/Clustering/jpn/LivedoorNewsClustering.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`01c551a`](https://github.com/embeddings-benchmark/mteb/commit/01c551ad2c8648b6345a44205b50bc551084c5e6))

* fix: ensure reranking kwargs are properly passed (#1058) ([`9f922ae`](https://github.com/embeddings-benchmark/mteb/commit/9f922ae4c740ef11d02e1531ec9000bd9cd3db8e))

### Unknown

* Update tasks table ([`f41a963`](https://github.com/embeddings-benchmark/mteb/commit/f41a9633ee25ce29f19360eb76929b47099c62d9))

## v1.12.69 (2024-07-08)

### Documentation

* docs: points (#1057)

* points

* Update 980.jsonl ([`30f12ca`](https://github.com/embeddings-benchmark/mteb/commit/30f12caaef466447aab547f17ad9de57ece44875))

### Fix

* fix: Update salesforce_models (#1053)

Update salesforce_models.py ([`061c3e3`](https://github.com/embeddings-benchmark/mteb/commit/061c3e3e02e2769430678580bb72765b84670807))

### Unknown

* Update points table ([`38552d5`](https://github.com/embeddings-benchmark/mteb/commit/38552d577db99501e5a7e89c584d6431e7df8755))

* Fix query format (#1042)

* Fix query format

* format ([`8adcaa0`](https://github.com/embeddings-benchmark/mteb/commit/8adcaa01d6021d54817ca5343cb69c9b77accdc9))

## v1.12.68 (2024-07-05)

### Fix

* fix: update __init__ in the classfication task for the swalihiNewsClassfication model to be seen (#1044)

* swahili_news_classfication

* update_two

* Update Swahili addin source and refeence

* Update SwahiliNewsClassification.py

* Update SwahiliNewsClassification.py

* addition info about group

* remove unnecessary line

* Create __init__.py

* update __init__.py

This update __init__ in the classification tasks is to enable it to be seen by the tasks calling.

from .swa.SwahiliNewsClassification import *

* Upate with new test and lint ([`0822cd6`](https://github.com/embeddings-benchmark/mteb/commit/0822cd676a6f4f8f6e40a8cee6f9bcba10410afa))

### Unknown

* Update tasks table ([`265e861`](https://github.com/embeddings-benchmark/mteb/commit/265e86185899aeeee087615b1a30c6a9d1cc2893))

## v1.12.67 (2024-07-04)

### Fix

* fix: Added Missing Models (#1014)

* Added utility function for downloading models results

* Added result tables

* Added missing models

* fix: Fixed subset warning for later versions of polars

* Update scripts/mmteb/running_model/check_results.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* removed used code segment

* format

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`602f4c0`](https://github.com/embeddings-benchmark/mteb/commit/602f4c0c6c39dde976604d057844d5e1d2e3c5bb))

## v1.12.66 (2024-07-03)

### Fix

* fix: Added encode_kwargs as the input for encode arguments and added batch_size to CLI (#1030)

* ci: fix outdated CI for pandas

* fix: Added encode_kwargs as the input for encode arguments and added batch_size to CLI

This PR adds encode_kwargs as an argument to MTEB.run(..., encode_kwargs) which allows passing in arguments to model.encode calls. This has the benefit of removing/distinguishing between multiple model arguments present in the code.

Where default were already in place I have replaced kept them, future PRs might standardize or remove these.

I also add a test to ensure that the encode_kwargs in all cases are passed to the model.encode.

I additionally also add the batch_size argument to the CLI.

* add batch size in for backward compat.

* fixed misspecified defaults

* format

* Added in example of encode_kwargs

* Update mteb/abstasks/AbsTask.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Update README.md

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`9032f02`](https://github.com/embeddings-benchmark/mteb/commit/9032f02b56fb0ee6aa43f2cfbfa3a2125ac13c2b))

## v1.12.65 (2024-07-03)

### Fix

* fix: change e5 default to use cuda if available (#1033) ([`91400d3`](https://github.com/embeddings-benchmark/mteb/commit/91400d36a794facc1c8ed703617d2b3ea034a40b))

## v1.12.64 (2024-07-03)

### Ci

* ci: fix docs ci again (#1031) ([`2daeeb9`](https://github.com/embeddings-benchmark/mteb/commit/2daeeb977ba5262d273f1b43caee97bae940215c))

### Fix

* fix: minor update __init__ was not included make the repo not being able to be called as the module (#1032)

* swahili_news_classfication

* update_two

* Update Swahili addin source and refeence

* Update SwahiliNewsClassification.py

* Update SwahiliNewsClassification.py

* addition info about group

* remove unnecessary line

* Create __init__.py ([`593d349`](https://github.com/embeddings-benchmark/mteb/commit/593d349b05030458983cf18ed87a9564f7b20f47))

### Unknown

* Update tasks table ([`403dcdb`](https://github.com/embeddings-benchmark/mteb/commit/403dcdbbbb50ad67aadd3c0cff2d20cb4c957860))

## v1.12.63 (2024-07-02)

### Ci

* ci: fix outdated CI for pandas (#1029) ([`039c976`](https://github.com/embeddings-benchmark/mteb/commit/039c9765d6918ce375fea7aaa5e393ade12dac9d))

### Fix

* fix: parallel bitext tasks scores (#1028)

* fix: Added imenes fix

* fix: found and fixes two other mistakes for MLSUMClustering (one caused by python 3.8 and the other in the downsampling function)

* fix: parallel bitext tasks scores

Due to the implementation of parallel bitext tasks it computes all combinations even though only some are specified by eval_langs. This leads to a minor computational overhead when evaluating and most notably an error when constructing MTEBResults.

This fix does the following:
- it ensures that only desired language pairs are being evaluated
- it simplified bitext evaluation (there is no longer two cases)
- it additionally only encodes the sentence pairs required for the specific selected pairs (make it faster when we only want to consider a subset of languages)

I tested it using:
- A monolingual bitext task
- A multilingual parallel bitext task
- A multilingal non-parallel bitext task

All pass and reproduce the same results (cheers!)

* Update mteb/abstasks/AbsTaskBitextMining.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`3e5ba61`](https://github.com/embeddings-benchmark/mteb/commit/3e5ba61de0d8b3081f394f1c618937769417d0b8))

## v1.12.62 (2024-07-02)

### Unknown

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`e02fe6e`](https://github.com/embeddings-benchmark/mteb/commit/e02fe6e105391d57863b8cf4f3feba006b7213a4))

## v1.12.61 (2024-07-02)

### Fix

* fix: The Swahili Classification Task (#998)

* swahili_news_classfication

* update_two

* Update Swahili addin source and refeence

* Update SwahiliNewsClassification.py

* Update SwahiliNewsClassification.py

* addition info about group

* remove unnecessary line ([`7e4ba06`](https://github.com/embeddings-benchmark/mteb/commit/7e4ba0634feb41b27c9e17b3adbe0e1df914af4b))

## v1.12.60 (2024-07-02)

### Documentation

* docs: Update figure (#1027)

* Updated figure colors

* Updated figure with current numbers

* Added reasoning as retrieval to figure ([`0acf259`](https://github.com/embeddings-benchmark/mteb/commit/0acf2590b9b6059fc5dbe66c31b1fc5f313efdd6))

* docs: Added result tables (#996)

* Added utility function for downloading models results

* Added result tables ([`f809cad`](https://github.com/embeddings-benchmark/mteb/commit/f809cadcbaa259f8bbfc5d3fe98de217023883f1))

* docs: Add Mariya&#39;s points (#1016)

* Create 1004.jsonl (#1011)

add points for working on introduction

* Create 784.jsonl (#1012)

add points for working on Appendix B

* rename files

* fix: Fixed subset warning for later versions of polars

---------

Co-authored-by: Mariya Hendriksen &lt;35101262+mariyahendriksen@users.noreply.github.com&gt; ([`4e1f43b`](https://github.com/embeddings-benchmark/mteb/commit/4e1f43b1d56843fe36637068d64e5a09e63964fd))

* docs: Update points.md (#1010)

Added an author, fixed alignment issues and some typos
Co-authored-by: dokato &lt;raymon92@gmail.com&gt; ([`1d1f7aa`](https://github.com/embeddings-benchmark/mteb/commit/1d1f7aadc71b89444837ea59bd142107789f648a))

### Fix

* fix: Fix broken clustering tasks (#1026)

* fix: Added imenes fix

* fix: found and fixes two other mistakes for MLSUMClustering (one caused by python 3.8 and the other in the downsampling function) ([`ca9e81d`](https://github.com/embeddings-benchmark/mteb/commit/ca9e81de8e950eef823e31e6799fe9e3fa5767dd))

* fix: Added imenes fix ([`11d5570`](https://github.com/embeddings-benchmark/mteb/commit/11d557045c97f211bb1887d56e09477939b9a8f6))

### Unknown

* LLM2Vec multi-gpu bug fix (#1020)

* map device to device_map

* lint ([`3a64ed9`](https://github.com/embeddings-benchmark/mteb/commit/3a64ed9ffe87a8673b6c5ebe05bb0c095a2d1698))

* Update points table ([`b3a58d2`](https://github.com/embeddings-benchmark/mteb/commit/b3a58d2ab40cfee130aba2784ba9a067a929ad4f))

* add SFR embed model (#1002)

* add sfr model
* add instruction to encode ([`1e25fe0`](https://github.com/embeddings-benchmark/mteb/commit/1e25fe04cd024b3032c80c1479f07f661a788d3f))

## v1.12.59 (2024-06-30)

### Fix

* fix: Add more russian models (#1000)

* add models meta

* add models

* fix models versions

* fix models versions

* add models

* add points

* lint

* add to points table ([`d97310d`](https://github.com/embeddings-benchmark/mteb/commit/d97310d6bc090d4e7bb0fde93e52b9241044bc7e))

### Unknown

* Update points table ([`17262fe`](https://github.com/embeddings-benchmark/mteb/commit/17262fe895c3f1cc3b6119c42754294d2a3a1851))

## v1.12.58 (2024-06-28)

### Fix

* fix: Added utility function for downloading and loading models results (#995)

Added utility function for downloading models results ([`abef8dc`](https://github.com/embeddings-benchmark/mteb/commit/abef8dc2366d56c790a99ed205b97fc81d0894c2))

### Unknown

* Update points table ([`17308b3`](https://github.com/embeddings-benchmark/mteb/commit/17308b3d0634a2baae373586f30f34f83bbee7ec))

* [WIP] RAR-b second PR &amp; task instruction for IR tasks in general (#972)

* Reval with instruction ARC-C test

* fix formatting issue

* add default instructions to lookup

* add points for both PRs

* add points for both PRs &amp; info ([`4500e0d`](https://github.com/embeddings-benchmark/mteb/commit/4500e0d1157f1bc291dade1f558480fe620c5b9c))

* Update tasks table ([`be5bf69`](https://github.com/embeddings-benchmark/mteb/commit/be5bf694479ed26d30ba554363c80ad4033fb84c))

## v1.12.57 (2024-06-27)

### Fix

* fix: Update DanFever to use avoid using overwrite=True and ignore identical ids (#994)

* fix: Updated DanFever to use avoid using overwrite=True and ignore identical ids

* fix: Updated logging, adding utility helper when specifying the wrong task and added --overwrite flag to CLI

* fix: revert changes to danFEVER

* fixed spelling of superseeded_by &gt; superseded_by ([`56ba2d7`](https://github.com/embeddings-benchmark/mteb/commit/56ba2d7657976180ef95d83eec9743de851c5542))

### Unknown

* Update points table ([`976d921`](https://github.com/embeddings-benchmark/mteb/commit/976d921a0600cbe4ef42ba357ca4f3d39e491221))

* Fix identical query-corpus ids in retrieval tasks (#918)

* Fix bug: identical query-corpus ids

* Add results

* Make device argument optional in Encoder

* add points ([`7c50e59`](https://github.com/embeddings-benchmark/mteb/commit/7c50e59caf055bcd3cb064ddd9476a10fd2c3b08))

## v1.12.56 (2024-06-27)

### Fix

* fix: convert scores in meta to be in 0-100 instead of 0-1 (#993)

fix: convert scores in meta to be expressed in 0-100 instead of 0-1 ([`870a2d9`](https://github.com/embeddings-benchmark/mteb/commit/870a2d9417127dfacc18f42943af46a97c2b90e0))

### Unknown

* Update tasks table ([`694bbd9`](https://github.com/embeddings-benchmark/mteb/commit/694bbd9b3f2191c8e97d7ae66031808f180dd507))

* Update numbers in retrieval statistics (#988)

* example

* fix validation error

* add retrieval task info

* lint

* remove task_name key

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`10c3fbf`](https://github.com/embeddings-benchmark/mteb/commit/10c3fbf25590e97f0c26f6068d261a222d59ad33))

## v1.12.55 (2024-06-26)

### Fix

* fix: Add Nomic and Multilingual Cohere (#987)

* Add nomic and cohere models

* format

* Ensure that models run on a sample task and reproduce results on SEB

* Added normalization to encode

* fix naming variable

* Update mteb/evaluation/evaluators/model_encode.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`e398f20`](https://github.com/embeddings-benchmark/mteb/commit/e398f2012c189da1a88d18e9b9bc0e87882c675d))

### Unknown

* Add BGE large en v1.5 (#986)

* add models
* make lint
* correct naming
* does not need as Jina works out of the box with ST
* pop prompt_name
* add normalize_embeddings=True
* make lint ([`d5e8bd1`](https://github.com/embeddings-benchmark/mteb/commit/d5e8bd114f8e76da6cd0eefa8ec43ee1b0218978))

## v1.12.54 (2024-06-25)

### Fix

* fix: Update Retrieval Statistics Checker (#985)

* changes to retrieval stats

* lint

* Update mteb/abstasks/AbsTaskRetrieval.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* make print functions nicer

* add print and tqdm

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`230c311`](https://github.com/embeddings-benchmark/mteb/commit/230c3110f5dbee38ebd45425973cb262defac3fc))

## v1.12.53 (2024-06-25)

### Fix

* fix: Add MIRACL retrieval (#833)

* Adding MIRACL Retrieval (#642)

* added initial MIRACL Retrieval for yoruba

* updated langs to take self.langs

* make lint

* update points

* change the explicit always remove doc_id == query_id, harms performance on miracl and other datasets

* added the nDCG@10 self metric

* set ignore_identical_ids argument

* remove KoMiracl and fix langs

* add linter

* fix tests

* set back default ignore_identical_ids to True

* update retrieval test and set identical_ids to False

* Fix tests for ignore_identical_ids=True

* Update retrieval evaluator and tests

* Keep one set of metrics according to flag ignore_identical_ids

* format

* updated expected values for abstention test

* set ignore_identical_ids to true for required tasks

* Add linting

* add points

* update points

---------

Co-authored-by: Nandan Thakur &lt;nandant@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`306e480`](https://github.com/embeddings-benchmark/mteb/commit/306e4807c50e49536e0ec34d052e49bab998c0b2))

### Unknown

* Update tasks table ([`1a62a0b`](https://github.com/embeddings-benchmark/mteb/commit/1a62a0bccc7b055dc6cc4bd6a630793e383419cd))

* Update points table ([`6b68735`](https://github.com/embeddings-benchmark/mteb/commit/6b6873587bb56bc5783571ef29ee05762a45a142))

## v1.12.52 (2024-06-25)

### Fix

* fix: Voyage bclavie/mmarco-japanese-hard-negatives (#980)

* no message

* no message

* no message

* update metadata

* change metadata

* add results

* update metadata

* update metadata

* update metadata

* update n_samples and remove line ([`06e0a8b`](https://github.com/embeddings-benchmark/mteb/commit/06e0a8b54885f8886a6ffb57af2f17ed5c1743a7))

### Unknown

* Update tasks table ([`4bef147`](https://github.com/embeddings-benchmark/mteb/commit/4bef147c5d9e702414881129476b7fa2e0c68a2c))

## v1.12.51 (2024-06-25)

### Fix

* fix: ensure that results from parallel datasets are formatted correctly (#974)

* fix: ensure that results from parallel datasets are formatted corrected.
Additionally updated a few results.
* add pytest coverage
* remove unfinished results file
* Add test for multilingual subset loader
* removed upper bound on numpy
* sped up tests
* add trust remote code for new datasets
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`6004ec7`](https://github.com/embeddings-benchmark/mteb/commit/6004ec7b6e99afb2d31a41784ac0b3d4a6ded935))

### Unknown

* Update points table ([`ae27b5c`](https://github.com/embeddings-benchmark/mteb/commit/ae27b5c16bd2655663be28f86657569e049d7ea4))

* LLM2Vec models (#926)

* adding llm2vec model loader

* fix merge

* update import error

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* llm2vec use instructions

* prompt_name separate out of kwargs

* format

* scores

* use flash attention if available

* fixed bug for retieval

* user can provide instructions for LLM2Vec

* fix type error

* making code py 3.8 and 3.9 compatible

* proper storing results

* type combination compliant with py 3.8, 3.9

* add points

* add semicolon

* updated scores

* format

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`a6c784c`](https://github.com/embeddings-benchmark/mteb/commit/a6c784c1835ce11a9b1a974f8a6d43439d165805))

## v1.12.50 (2024-06-25)

### Fix

* fix: GritLM Retrieval instructions (#981)

* Fix GritLM instructions

* Simplify

* Simplify

* Simplify

* Format

* Added e5 conditional encode for corpus/query

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`f1c9fc7`](https://github.com/embeddings-benchmark/mteb/commit/f1c9fc775ef0edfa83e6d32e365d1e12663273b8))

### Unknown

* Update tasks table ([`b9f9ea7`](https://github.com/embeddings-benchmark/mteb/commit/b9f9ea77e3080e061e9da9f08d264d952f8511f6))

* Update points table ([`4f5542a`](https://github.com/embeddings-benchmark/mteb/commit/4f5542af892de26a55c3912c971853e7c80d489c))

* Move speedtask imports (#982)

* move speedtask import
* move speedtask import
* add points file
* Update docs/mmteb/points/982.jsonl
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`58c7866`](https://github.com/embeddings-benchmark/mteb/commit/58c78667e4ec4e1d6add18ca2fd57fb01534a5e2))

## v1.12.49 (2024-06-24)

### Fix

* fix: add max_fraction_of_documents_to_embed to clustering datasets with `max_document_to_embed` (#977)

* add max_fraction_of_documents_to_embed
* add points file
* add tests for clusteringfast
* review points
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`5367193`](https://github.com/embeddings-benchmark/mteb/commit/536719374e0e179fb1354f02e0a511d7ceefaa70))

### Unknown

* Update points table ([`44af47a`](https://github.com/embeddings-benchmark/mteb/commit/44af47a04c953c4c1cdb627be4ed29609bce1f73))

* Update points table ([`e169fb3`](https://github.com/embeddings-benchmark/mteb/commit/e169fb30e4f2cb01cdd1fa0667a325a6a73b5c01))

* add points (#979)

* add points for previous PRs.
* Update docs/mmteb/points/906.jsonl
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update docs/mmteb/points/873.jsonl
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`1c8447d`](https://github.com/embeddings-benchmark/mteb/commit/1c8447dd1e9ad41748ed7bdaacf36cafa6a1754d))

* Fix GritLM instructions (#976)

* Fix GritLM instructions

* make lint

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`a3410e9`](https://github.com/embeddings-benchmark/mteb/commit/a3410e919c1987521f5eb4a54ed7464fd44875e6))

* Update points table ([`8b6b08e`](https://github.com/embeddings-benchmark/mteb/commit/8b6b08e699fe74b0de535f847d87a3a733f977b5))

* Improve belebele retrieval task (#894)

* Multilingual/BelebeleRetrieval: Fix self.langs to self.hf_subsets
* Multilingual/BelebeleRetrieval: Use lang+script code
* Multilingual/BelebeleRetrieval: Use 7 more scripts
* Multilingual/BelebeleRetrieval: convert to cross lingual task
* Multilingual/BelebeleRetrieval: add sample results
* Multilingual/BelebeleRetrieval: update historic results language codes
* Multilingual/BelebeleRetrieval: code formattin
* Multilingual/BelebeleRetrieval: update results
* Multilingual/BelebeleCrossRetrieval: Creating new version of Belebele task
* Multilingual/BelebeleCrossRetrieval: Restricting langauge pairs
* Multilingual/BelebeleCrossRetrieval: Formatting changes
* Multilingual/BelebeleRetrieval: Replace old task
* Multilingual/BelebeleRetrieval: Use underscore between language-script in language pair
* Add points
* points
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`3137f96`](https://github.com/embeddings-benchmark/mteb/commit/3137f96008acd07e1db438ce750b2cead45579cd))

## v1.12.48 (2024-06-21)

### Documentation

* docs: fix cli commands (#966) ([`d403580`](https://github.com/embeddings-benchmark/mteb/commit/d40358089c959f812d150e40f9338f2d784bd73c))

### Fix

* fix: Add Speed tasks for CPU and GPU &amp; system info (#967)

* move add_main_score to AbsTask
* add speed tasks
* add results
* Revert &#34;move add_main_score to AbsTask&#34;
This reverts commit 77cbb569b1e5f7d748b05e22d4b5a544ca064f86.
* fix tests
* add to requirements
* add psutil
* move to optional
* add comment on virtual_memory() returning Bytes
* add optional installs when testing
* make lint
* address review comments
* we still do points right? ([`d51fa81`](https://github.com/embeddings-benchmark/mteb/commit/d51fa818ad93588049b8e44b9845c044cb0eb93d))

* fix: bug in calculate_metadata_metrics for some retrieval datasets (#965)

fix calculate_metadata_metrics ([`f3b5b1c`](https://github.com/embeddings-benchmark/mteb/commit/f3b5b1c77febd326615d645afb13635088c53474))

### Unknown

* Update points table ([`88ee978`](https://github.com/embeddings-benchmark/mteb/commit/88ee978f1b900c4e1a39c1073ec4b178762e856b))

* Fix GritLM kwarg (#970)

* Fix kwarg

* Default to None

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Format

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`5706956`](https://github.com/embeddings-benchmark/mteb/commit/5706956650a05af8aa33ab4e7db981321bab3f42))

* Rmv dup ([`81882aa`](https://github.com/embeddings-benchmark/mteb/commit/81882aa6bab85dbf12420cb196cb5bfa13deb550))

## v1.12.47 (2024-06-20)

### Fix

* fix: Add E5 model test case in test CLI (#958)

* add multilingual e5 small in test case
* switch order of kwargs
* make lint
* default to None
* add prompts to class
* correct path with model names
* add points
* no need to comment
* remove __init__ method ([`6c0f597`](https://github.com/embeddings-benchmark/mteb/commit/6c0f597e62e165f6ecef3116c0002093fbdd610c))

### Unknown

* Update points table ([`a14a03b`](https://github.com/embeddings-benchmark/mteb/commit/a14a03b1b2fba51f0ffdf84c6b0f89bc78ce1f18))

## v1.12.46 (2024-06-20)

### Fix

* fix: added models to run along with minor fixes (#953)

* added models to run

* fix: ensure prompt name is passed correctly in cases of encode_corpus and encode_queries

* allow kwargs to be passed to e5 models

* added scripts for running models

* format

* fix: Allow for arbitrary None as a model revision

* added test case

* fix: loader naming

* Added create_slurm_jobs.py

* Added missing load functions ([`9b5891d`](https://github.com/embeddings-benchmark/mteb/commit/9b5891d426eb2bc282265c620c47b35b2ea903d3))

## v1.12.45 (2024-06-20)

### Documentation

* docs: add missing points (#959)

* add missing points

* one review; ([`3ebd148`](https://github.com/embeddings-benchmark/mteb/commit/3ebd148ad1956615a43c77e5a1b4c3ea8bcbe59b))

### Fix

* fix: Update annotations for PawsX, Opusparcus and SummEval (#963)

* Update PawsX.py

* Update OpusparcusPC.py

* Update SummEvalFrSummarization.py

* Update SummEvalSummarization.py

* Add files via upload

---------

Co-authored-by: Tikhonova Maria &lt;m_tikhonova94@mail.ru&gt; ([`211d5ae`](https://github.com/embeddings-benchmark/mteb/commit/211d5ae402a7b3a9c86d62db0c4892106e03ad8e))

* fix: Add baseline models for Russian (#962)

* add sbert/rubert models with results

* move models to a separate file

* update models meta

* add points ([`664f6da`](https://github.com/embeddings-benchmark/mteb/commit/664f6da9c14940eeddf1c9e794bcdb69563c5d5e))

### Unknown

* Update tasks table ([`666fafe`](https://github.com/embeddings-benchmark/mteb/commit/666fafecb4ba6c1e1c8061fc8868a48596285b84))

* Update points table ([`f52d12b`](https://github.com/embeddings-benchmark/mteb/commit/f52d12b1cdbaecc1296bb21baed9c8d122df4c3a))

* Update points.md (#961) ([`b467004`](https://github.com/embeddings-benchmark/mteb/commit/b46700463ae82df7f577e17971f05872a25336c0))

* Update points table ([`b134527`](https://github.com/embeddings-benchmark/mteb/commit/b13452723029e9c1235f7e3ce7f8a9728d1ab2a5))

## v1.12.44 (2024-06-19)

### Fix

* fix: Add test case for results folder structure (#956)

* add test case for results folder structure

* rerun results

* add points ([`b0f597c`](https://github.com/embeddings-benchmark/mteb/commit/b0f597c19643feee029573a1b46bd34c84161e1d))

### Unknown

* Update points table ([`a8a47a0`](https://github.com/embeddings-benchmark/mteb/commit/a8a47a05fc18a9906033873445e5310790225c6a))

* Fix spacing ([`279c5e4`](https://github.com/embeddings-benchmark/mteb/commit/279c5e43daf8dbded23ec9b446670f59231338ea))

## v1.12.43 (2024-06-18)

### Fix

* fix: Merge CrosslingualTask into MultilingualTask (#952)

* merge cross lingual task into multilingual task

* Apply suggestions from code review

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`07f80c4`](https://github.com/embeddings-benchmark/mteb/commit/07f80c479a7223b188341e3be6ac5e0424f297b7))

## v1.12.42 (2024-06-18)

### Fix

* fix: Backward compatibility fixes for clustering (#954)

* Added max_document_to_embed to all existing clustering tasks

* format ([`623d833`](https://github.com/embeddings-benchmark/mteb/commit/623d83300157921fe71bc78aa6700c85a5f45486))

## v1.12.41 (2024-06-18)

### Fix

* fix: Add MINERS Bitext retrieval benchmark (#951)

* add new task
* add miners bitext mining benchmark
* Update TaskMetadata.py
* Add NollySenti
* rename metadata
* Update mteb/benchmarks.py
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update benchmarks.py
* Update benchmarks.py
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`f95b9e0`](https://github.com/embeddings-benchmark/mteb/commit/f95b9e0e17ec36272e249fbb754b7f7020727303))

### Unknown

* Update points table ([`efbce71`](https://github.com/embeddings-benchmark/mteb/commit/efbce71e314fb5d97c4d08f7b546b16c7c9a2790))

* Update points table ([`5f39d55`](https://github.com/embeddings-benchmark/mteb/commit/5f39d55c1b7d92428c39e089e7f081049a1c08b5))

## v1.12.40 (2024-06-18)

### Documentation

* docs: Add point for PR 948 (#950)

* add point

* add point ([`34286f2`](https://github.com/embeddings-benchmark/mteb/commit/34286f2a36d8bf11c0bab1160d38c5cae3b95461))

### Fix

* fix: Compare Cluster and ClusterFast scores and speedup (#892)

* first go at getting spearman corr for e5-base
* add back large
* small and large results
* v3 means downsampling by stratified subsampling + bootstrap to k=max_documents_per_cluster
* v3-1 means swapping values of max_documents_per_cluster and max_documents_to_embed
* v3-2 means increasing max_documents_per_cluster to 65536
* task-wise comparison
* use recommended syntax
* add back no-op changes
* add back no-op changes
* option c is now v2; remove all v3 variants; add back level 0 in results; add test significance&#39;
* paraphrase-multilingual-MiniLM-L12-v2 results
* lint script
* cluster without fast should not have levels
* spearman on significant rank
* add more small model results
* 2x max_documents_to_embed to 4096
* max_documents_to_embed=8192
* t
* Added plots
* format
* use 32k samples for bigger cluster datasets
* use 4% n_samples and update task metadata
* make lint
* tests passing
* make lint
* add paraphrase-multilingual-mpnet-base-v2 and e5-large-v2 results
* add e5_eng_base_v2,labse,mxbai_embed_large_v1,bge_base_en_v1.5
* move plot scripts to mmteb srcipts repo
* replace use_dataset_as_is wtih max_document_to_embed and add description in docstrings
* lint
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`2bb7623`](https://github.com/embeddings-benchmark/mteb/commit/2bb76239368c497efb92d5ae09a914eedd44a66d))

### Unknown

* Update tasks table ([`54c5745`](https://github.com/embeddings-benchmark/mteb/commit/54c5745c3b2eb285a4cd1a10e06a516040eec6f1))

* Update points table ([`6aeaff4`](https://github.com/embeddings-benchmark/mteb/commit/6aeaff45a0d657f708677752cae0b96f0fb875a6))

## v1.12.39 (2024-06-18)

### Documentation

* docs: Added a script to extract the bibtex citations and generate the consolidated bib file (#904)

* Added IndicNLP News Classificaiton

* Added IndicNLP News Classificaiton

* Added results

* Updated dataset version

* Small fixes

* Small fix

* Small fix

* Updated results

* Fix linting issues

* Added points

* Resolve conflict

* Update 610.jsonl

* Backfilled missing bibtex citations.

* Backfilled missing bibtex citations.

* Remove non-present files

* Wrote a script to scrape through the bibtex citations and create the corresponding bib file

* Added missed dependency

* Added functionality to create latex table

* Fixed linting issue

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`ab23552`](https://github.com/embeddings-benchmark/mteb/commit/ab235525d39402d9e1460eb7662d96928e055927))

### Fix

* fix: Add LinceMT Bitext Mining (MINERS) (#948)

* add new task

* add metadata

* update init

* Add results

* Update TaskMetadata.py ([`6bd165e`](https://github.com/embeddings-benchmark/mteb/commit/6bd165e95d1fe2cc623ffa7faa79aae8201d5dc8))

* fix: Add Phinc Bitext Mining (MINERS) (#947)

* add phinc

* update metadata

* add files

* add points ([`0e71110`](https://github.com/embeddings-benchmark/mteb/commit/0e711102dbe2bdef4063099ba83af99fef16839c))

* fix: pair classification inconsistency (#945)

* first go at fixing PairClassification

* added transformation for consistency

* added IndicXnliPairClassification

* added IndicXnliPairClassification 2

* lint fixes

* points added ([`6660f43`](https://github.com/embeddings-benchmark/mteb/commit/6660f432bd501eb2bbdd131fe61d697ef547e755))

### Unknown

* Update tasks table ([`3ca687f`](https://github.com/embeddings-benchmark/mteb/commit/3ca687ffe7be3ae08970f163174e3053379f72d2))

* Update tasks table ([`4e3d868`](https://github.com/embeddings-benchmark/mteb/commit/4e3d868e501c5ed2e95e8f9dbd5331c1389f07e4))

* Update points table ([`cbe8458`](https://github.com/embeddings-benchmark/mteb/commit/cbe8458e8b3328c4e83b2e517404fab625f34824))

* Update points table ([`bc9c094`](https://github.com/embeddings-benchmark/mteb/commit/bc9c094dc445120eb0686e4f4f50e47054cc55d7))

## v1.12.38 (2024-06-17)

### Fix

* fix: Merge miracl evaluator (#906)

* start merge

* removing redundancy

* removing MIRACLevaluator

* add linting

* clean up method names

* correct arg bug.

* remove type annotation

* combine unique texts

* improve readability

* merge main

* add back main changes

* adjust for task_name changes

* add back

* lint

---------

Co-authored-by: Jordan Example &lt;jordan.clive19@gmail.com&gt; ([`8ab4c14`](https://github.com/embeddings-benchmark/mteb/commit/8ab4c141313d65a6f9e265a156894889e3d32565))

### Unknown

* Added overview figure in SVG and PNG (#939)

* Added overview figure in SVG and PNG

* Added wide version

* Added centered overview and fixed svg files

* Made orange color darker on figures ([`e53821e`](https://github.com/embeddings-benchmark/mteb/commit/e53821e598790a90a55088a8b743641497dd303b))

## v1.12.37 (2024-06-17)

### Fix

* fix: Add jmteb (#938)

* fix: correct label for sib200

* fix: Add JaGovFaqs and NLPJournal datasets (#808)

* Add JaGovFaqs dataset

* Add NLPJournal datasets

* Add JAQKET dataset

* Add points

* Fix metadata

* Remove title from corpus for JAQKET dataset

* Update JAQKET scores (without title)

* Exclude JAQKET dataset

* Add points for review

---------

Co-authored-by: Ashwin Mathur &lt;97467100+awinml@users.noreply.github.com&gt; ([`f38c79b`](https://github.com/embeddings-benchmark/mteb/commit/f38c79b33eb3d306a557c56234b43601a4307ffc))

### Unknown

* Update tasks table ([`980dfa8`](https://github.com/embeddings-benchmark/mteb/commit/980dfa874a9fcf2ee118187d48fc944a510c968a))

* Update points table ([`a104512`](https://github.com/embeddings-benchmark/mteb/commit/a10451249a2528ade57ad9610e08051be97957cc))

## v1.12.36 (2024-06-17)

### Fix

* fix: temporarily limit numpy version due to bug in datasets (#940)

see https://github.com/huggingface/datasets/pull/6976 ([`0b0705e`](https://github.com/embeddings-benchmark/mteb/commit/0b0705e0b485d3236703b68408139ca14f286b53))

### Unknown

* Update tasks table ([`077ca56`](https://github.com/embeddings-benchmark/mteb/commit/077ca569c298b019db84331a1fd3b7a4d9ea9b79))

* Update points table ([`c666597`](https://github.com/embeddings-benchmark/mteb/commit/c666597b808197808a80ffdc5d6e6a3044f7102f))

* Fix bugs (#898)

* Remove usage of deprecated langs: self.langs to self.hf_subsets

* Correct link of WikipediaRetrievalMultilingual task

* multilingual/MLQARetrieval: deduplicate corpus

* multilingual/MLQARetrieval: de-duplicate questions

* multilingual/MLQARetrieval: Separate spaces for query-ids and context-ids

* Add points

* Update docs/mmteb/points/898.jsonl

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`4fa6e9d`](https://github.com/embeddings-benchmark/mteb/commit/4fa6e9de4a9a3313639f33b6e9556d8652fa2133))

## v1.12.35 (2024-06-17)

### Documentation

* docs: Update annotations for tasks (#936)

* annottations

* annotate

* annotate

* annotate

* annotate

* ann

* ann

* ann

* ann

* ann

* formatted

* add data

* add data

* Update docs/mmteb/points/936.jsonl

* lint

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`8823369`](https://github.com/embeddings-benchmark/mteb/commit/8823369b91c82d7641367cfb0b9cdfec075143b1))

### Fix

* fix: RAR-b initial PR (#929)

* RARb initial PR

* RAR-b initial PR

* RAR-b initial PR

* RAR-b initial PR

* fill metadata

* add metadata n samples&amp;char length

* taskdata subtask reasoning as retrieval

* fix formatting errors

* metadata description made descriptive ([`b75a9c9`](https://github.com/embeddings-benchmark/mteb/commit/b75a9c9fe6c976f12a9e6d7219901b9fedb99a69))

### Unknown

* Update tasks table ([`a098a59`](https://github.com/embeddings-benchmark/mteb/commit/a098a5917d77e6986a82a568ec0a9de881b79b3e))

* Update tasks table ([`ea62028`](https://github.com/embeddings-benchmark/mteb/commit/ea62028c6e29001a11ee776b62530c879502866f))

* Update points table ([`2529093`](https://github.com/embeddings-benchmark/mteb/commit/25290938ca7855d4a7cf40ed38ae29635509d775))

## v1.12.34 (2024-06-16)

### Unknown

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`677dc93`](https://github.com/embeddings-benchmark/mteb/commit/677dc930b250a4db4b19fce46757926b5d98d390))

## v1.12.33 (2024-06-15)

### Fix

* fix: Add NusaParagraph Emotion Classification (#928)

* add NusaTranslationEmotionClassification

* update name

* add new task

* add new task

* Update mteb/tasks/Classification/multilingual/NusaParagraphEmotionClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* add sizes

* add point

* add results

* update desc

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`5e4ad44`](https://github.com/embeddings-benchmark/mteb/commit/5e4ad442535a20719f42457ca034269df3de3646))

* fix: Add NusaParagraph Topic Classification (#927)

* add data

* update lang code

* update metadata

* update metadata

* update metadata

* update files

* Update mteb/tasks/Classification/multilingual/NusaParagraphTopicClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* update avg char

* add points

* add results and fix lint

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`e13f037`](https://github.com/embeddings-benchmark/mteb/commit/e13f0371341dd08b7868f5e049478dae891a27a5))

* fix: Add NollySenti Bitext Mining (MINERS) (#915)

* add NollySentiBitextMining

* update reference

* update avg char

* add points

* add results ([`df68f8c`](https://github.com/embeddings-benchmark/mteb/commit/df68f8c7aadbee9b09da4193b9d6badc3990a97b))

### Unknown

* Update tasks table ([`bf7fc5b`](https://github.com/embeddings-benchmark/mteb/commit/bf7fc5b72ef1d09fa5dcd5445bbc617e13e04e13))

* Update points table ([`19cc06f`](https://github.com/embeddings-benchmark/mteb/commit/19cc06ffbea0d732e936ff4431d66fd6004efbb4))

* Update tasks table ([`0f51819`](https://github.com/embeddings-benchmark/mteb/commit/0f5181945db20410e9d1f3af3be2060b411aadb4))

* Update points table ([`4a8bfd2`](https://github.com/embeddings-benchmark/mteb/commit/4a8bfd2cd9b1acc2d14bf4a45b84719d57104330))

* Update points table ([`2a31c8c`](https://github.com/embeddings-benchmark/mteb/commit/2a31c8c6f1e21fe5f91e794a313f1cd3083beff3))

* Merge branches &#39;update_mteb_meta_cli&#39; and &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`7570f9c`](https://github.com/embeddings-benchmark/mteb/commit/7570f9c5b4949ce67a7a0a4547a89844b1ed15cd))

## v1.12.32 (2024-06-15)

### Fix

* fix: Add NusaTranslation Bitext Mining (MINERS) (#914)

* add NusaTranslationBitextMining

* fix lint

* update dataset nameg

* update language code

* update avg len

* add points

* add results and fix lint ([`78f34ad`](https://github.com/embeddings-benchmark/mteb/commit/78f34ad33841ee1a15073cee8a5af1d7e881c67d))

* fix: Add NusaX Bitext Mining (MINERS) (#910)

* add init and dataset

* update metadata

* update bibtex

* update metadata

* update avg character length

* update dataset nameg

* add instruction

* revert instructions

* fix lint

* update avg char length

* add points

* update points ([`25c7606`](https://github.com/embeddings-benchmark/mteb/commit/25c76061db029f4dd65e4542a1199b2f460b34ab))

### Unknown

* Update tasks table ([`83ccaa1`](https://github.com/embeddings-benchmark/mteb/commit/83ccaa1f684f0411bdb6084da371e3838d87a389))

* Update points table ([`12d5272`](https://github.com/embeddings-benchmark/mteb/commit/12d5272c39e9ed2434af9fb46494ff6cb1c63b9e))

* Update tasks table ([`a21310a`](https://github.com/embeddings-benchmark/mteb/commit/a21310addacd1ef2c1088087a4e1696bc13b7a3b))

* Update points table ([`a26bb6a`](https://github.com/embeddings-benchmark/mteb/commit/a26bb6a6ed4b843b080ad62e890a86120ead1df1))

## v1.12.31 (2024-06-15)

### Documentation

* docs: added documentation for wiki clustering (#934)

docs: added documentatio for wiki clustering ([`8e39cfb`](https://github.com/embeddings-benchmark/mteb/commit/8e39cfb036a922d3f457eeb898b9d0e3857a9d21))

### Fix

* fix: Add STS dataset SemRel2024 (#917)

* Add STS dataset: SemRel2024

* Add results for STS task SemRel24

* Add points

* Update mteb/tasks/STS/multilingual/SemRel24STS.py

* Update review points

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`319ed83`](https://github.com/embeddings-benchmark/mteb/commit/319ed833ae744cfc1006060638324a7c3fe67256))

### Unknown

* Update tasks table ([`dab4aff`](https://github.com/embeddings-benchmark/mteb/commit/dab4aff2c15744635acade8c12e04660c42dd551))

* Update points table ([`8ce9771`](https://github.com/embeddings-benchmark/mteb/commit/8ce97713090ad43e0cd67a1d2574dd4931b46207))

## v1.12.30 (2024-06-15)

### Fix

* fix: Update annotations for multilingual classification tasks (#923)

* Update MTOPIntentClassification.py

* Update MTOPDomainClassification.py

* Update MassiveIntentClassification.py

* Update MassiveScenarioClassification.py

* Update MassiveScenarioClassification.py

* Update MassiveIntentClassification.py

* add points

---------

Co-authored-by: Tikhonova Maria &lt;m_tikhonova94@mail.ru&gt; ([`568651b`](https://github.com/embeddings-benchmark/mteb/commit/568651bab6dd57ae8fc2216d5e192da351f44a98))

* fix: mteb meta now includes all scores

- Also added test for retrieval tasks and STS using old results format ([`49f2c3b`](https://github.com/embeddings-benchmark/mteb/commit/49f2c3b8957c9d4c65afd377187b4a673234992c))

### Unknown

* Update tasks table ([`42d4ecd`](https://github.com/embeddings-benchmark/mteb/commit/42d4ecd63d50301ea0f094e3189457fb18cd6c39))

* Update points table ([`53fb2f8`](https://github.com/embeddings-benchmark/mteb/commit/53fb2f8ed6de90b1d2a9a2e8723771aaefcfaede))

* added hf subset to model card generation ([`f19d227`](https://github.com/embeddings-benchmark/mteb/commit/f19d2278b2cf40438ed51dda1ee6562255f677d4))

* Added hf subset score ([`b81adad`](https://github.com/embeddings-benchmark/mteb/commit/b81adad0d74db48ebe74c64bd2b44c7a25520e03))

* Added similiarity metric to pairclf and summarization evaluator ([`8c35455`](https://github.com/embeddings-benchmark/mteb/commit/8c3545530da237c9e9178dd5701e0d41b185d983))

* change to similarity_fn_name ([`6cf6c51`](https://github.com/embeddings-benchmark/mteb/commit/6cf6c51553301de65aa97dd23a53278e7282123a))

* format ([`7d13e1a`](https://github.com/embeddings-benchmark/mteb/commit/7d13e1af44f0fdc8043f8d7c00c39b6664106711))

* make sure to sort tasks ([`c42f553`](https://github.com/embeddings-benchmark/mteb/commit/c42f553362374a8f1a9eeabbd63d2099d5983403))

* tests: ignore order when comparing frontmatter ([`1fb278d`](https://github.com/embeddings-benchmark/mteb/commit/1fb278d76583f6ce2d63a0c54426c7e6cba2b52b))

* Added model-based similiarity and flattened STS results for consistency with &#34;main_score&#34; ([`b1ec767`](https://github.com/embeddings-benchmark/mteb/commit/b1ec76738acd390e6113cc38bc52078f81b4c835))

* format ([`1fac33c`](https://github.com/embeddings-benchmark/mteb/commit/1fac33c4da46d4fb99dc251c6703af6d6451637d))

* Added additional normalization for STS ([`c995c3d`](https://github.com/embeddings-benchmark/mteb/commit/c995c3d94034c802efdc4286c2f01dca1d0ca161))

## v1.12.29 (2024-06-15)

### Fix

* fix: Added the ability to make task specific instructions, tested using e5 instruct (#888)

* Added prompting along with e5 instruct

All encode calls now include a prompt_name (following the variable name in sentence transformer&#39;s encode), which provided the task name. The model can then use a custom prompt pr. task if they wish (or encode based on e.g. task type).

Additionally to test it out I have also added the two e5 instruct models.

* format

* updated based on review

* format

* Update mteb/models/instructions.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/models/__init__.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Added additional tests for instructions

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`40208cf`](https://github.com/embeddings-benchmark/mteb/commit/40208cfaf0bf588515e3a077b4d7e5fc5fa98200))

### Unknown

* Update points table ([`b97ad77`](https://github.com/embeddings-benchmark/mteb/commit/b97ad779c3eac25d9ac8098bf84300197964666f))

## v1.12.28 (2024-06-15)

### Fix

* fix: Fix create_meta function in cli.py (#912)

* Update cli.py

Fix create_meta function

* Update test files ([`af365b7`](https://github.com/embeddings-benchmark/mteb/commit/af365b795e2c54b25b0e02bbb0788ba9d3c403c7))

### Unknown

* format ([`c47d279`](https://github.com/embeddings-benchmark/mteb/commit/c47d2795b4297792aa55f059b833055a4a13106c))

* Fix GritLM Loading (#925)

* add gritlm to init file

* sort

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`55fb52e`](https://github.com/embeddings-benchmark/mteb/commit/55fb52e514109aef8a8077bf88ffd16c950eb4c2))

## v1.12.27 (2024-06-13)

### Documentation

* docs: Add points for #911 (#913)

Add poinhts ([`5deeb3c`](https://github.com/embeddings-benchmark/mteb/commit/5deeb3c6351fbedde24dc77d8981e32562d9b516))

### Fix

* fix: Update annotations for English STS tasks (#908)

* Update STS16STS.py

* Update STS15STS.py

* Update STS14STS.py

* Update STS13STS.py

* add points for 902&amp;908 prs

* Update STS16STS.py

* Update STS14STS.py

* Update STS14STS.py

* Update STS16STS.py

---------

Co-authored-by: Tikhonova Maria &lt;m_tikhonova94@mail.ru&gt; ([`f1dd8bb`](https://github.com/embeddings-benchmark/mteb/commit/f1dd8bb60fe730d34fcd7bb909834ad1d9daba80))

### Unknown

* Update tasks table ([`844e743`](https://github.com/embeddings-benchmark/mteb/commit/844e7432de16d4ffea07bd4312f18da1e7bc6fdc))

* Update points table ([`cffd94c`](https://github.com/embeddings-benchmark/mteb/commit/cffd94c1699fd9a4f954950eb7adcebee169da45))

## v1.12.26 (2024-06-13)

### Documentation

* docs: Update annotations for multilingual STS tasks (#902)

* Update STS12STS.py

* Update STSBenchmarkMultilingualSTS.py

* Update STS22CrosslingualSTS.py

* Update STS17CrosslingualSTS.py

* Update STS22CrosslingualSTS.py

* Update STSBenchmarkMultilingualSTS.py

* Update STS17CrosslingualSTS.py

* Update STS12STS.py

* Update STS17CrosslingualSTS.py

* Update STSBenchmarkMultilingualSTS.py

* Update STS22CrosslingualSTS.py

---------

Co-authored-by: Tikhonova Maria &lt;m_tikhonova94@mail.ru&gt; ([`4383fd3`](https://github.com/embeddings-benchmark/mteb/commit/4383fd3a65c16df9598581f32643408e33273cb0))

### Fix

* fix: Incorrect handling of qrel_revision fix: #909 (#911)

* fix: #909

* fix: #909

* add: points

* clean ([`63cd4b7`](https://github.com/embeddings-benchmark/mteb/commit/63cd4b7f99e9371a90e26014a328231b1f3db810))

### Unknown

* Update tasks table ([`30433a9`](https://github.com/embeddings-benchmark/mteb/commit/30433a9a7d8ef6b2b47a95cf2ff9b002088b8a03))

* Update points table ([`d771437`](https://github.com/embeddings-benchmark/mteb/commit/d77143791408269ea69fd6455f4dd5a6782d1805))

* (1) Add WebLINX Candidate Elements Reranking Task; (2) move `convert_conv_history_to_query` from `mteb.evaluation.evaluators.RetrievalEvaluator` to `mteb.evaluation.evaluators.utils` (#820)

* Initial file (WIP)

* Update dates, and indicate dotos

* Update mteb/tasks/Reranking/eng/WebLINXCandidatesReranking.py

* Move `convert_conv_history_to_query` from RetrievalEvaluator to utils

* Add WebLINXCandidatesReranking to mteb.tasks.Reranking

* Lint RetrievalEvaluator&#39;s imports

* lint mteb.evaluation.evaluator.utils

* Update dataset path, name and revision, n_samples and avg_character_lenght

* Update revision, add load_data method

* Fix typo

* Change main score to mrr, since recall@10 is not supported

* Add average results

* Add points

* Run `make lint` ([`e34ddaa`](https://github.com/embeddings-benchmark/mteb/commit/e34ddaac76777e4f3a360a30b5ee2d111c5a9f61))

* Update tasks table ([`b16d7d5`](https://github.com/embeddings-benchmark/mteb/commit/b16d7d5620b987992e16ee663e5d82ee007acd8e))

## v1.12.25 (2024-06-11)

### Documentation

* docs: Add points for paper writing (#901)

* add points for paper writing

* add PR number

* correct typo ([`fbbc44b`](https://github.com/embeddings-benchmark/mteb/commit/fbbc44b51702930d3dafbc6f7529233c5de7a138))

### Fix

* fix: Backfilled bibtex citations data (#900)

* Added IndicNLP News Classificaiton

* Added IndicNLP News Classificaiton

* Added results

* Updated dataset version

* Small fixes

* Small fix

* Small fix

* Updated results

* Fix linting issues

* Added points

* Resolve conflict

* Update 610.jsonl

* Backfilled missing bibtex citations.

* Backfilled missing bibtex citations.

* Remove non-present files

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`77d0e06`](https://github.com/embeddings-benchmark/mteb/commit/77d0e06e88e7645d14c278b25a9bbb6c97b8fed6))

### Unknown

* Update points table ([`a7ce58f`](https://github.com/embeddings-benchmark/mteb/commit/a7ce58f81728e7adaba940d30f41fe124e4ad64d))

* Update tasks table ([`97eb8b3`](https://github.com/embeddings-benchmark/mteb/commit/97eb8b342f42a372dc74449c383ecc20c3c9f7a3))

## v1.12.24 (2024-06-09)

### Fix

* fix: Add openai and voyage models (#887)

* Add openai and voyage models

* Add rate limit for voyage model

* Add rate and token limit for voyage ([`ad9b3ce`](https://github.com/embeddings-benchmark/mteb/commit/ad9b3ce2bfd4ac90dab74d397d740afbe8f142a5))

### Unknown

* Update points table ([`052c9dd`](https://github.com/embeddings-benchmark/mteb/commit/052c9dd646f6ea3d6154db516310a9f3e1c8482d))

## v1.12.23 (2024-06-08)

### Documentation

* docs: Update points.md (#890) ([`4318c82`](https://github.com/embeddings-benchmark/mteb/commit/4318c8223dcd1f82038eb63d2cbe4970af1d539b))

### Fix

* fix: abstention metric for small datasets (#893)

* fix abstention bug

* make lint ([`9d28296`](https://github.com/embeddings-benchmark/mteb/commit/9d2829671c5e2833bcc65c37f65c2ed87c3ae825))

### Unknown

* Update tasks table ([`bab7503`](https://github.com/embeddings-benchmark/mteb/commit/bab7503c20f8c46172b263cb4e5fb7d77484b5b3))

* Update points table ([`c61ab09`](https://github.com/embeddings-benchmark/mteb/commit/c61ab09aa084dc6dbf26f71027a4fac1ddce1abb))

* Added multilabel stratification to AbsTaskMultilabelClassification (#760)

merge conflicts fixed for stratification ([`d7dc9a8`](https://github.com/embeddings-benchmark/mteb/commit/d7dc9a80db287c28899d0aa481f36c9c7c9ca78a))

## v1.12.22 (2024-06-06)

### Fix

* fix: Add GritLM (#880)

* Add GritLM

* Remove unused imports

* Use embedding mode to save memory

* Format

* Format

* Add langs

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Add langs

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Change loader

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`0c99a4e`](https://github.com/embeddings-benchmark/mteb/commit/0c99a4ebcc4a6f3a47fe5e59161c832ddbea9294))

## v1.12.21 (2024-06-05)

### Documentation

* docs: Added source for CmedqaRetrieval (#886)

docs: update CmedqaRetrieval description to specify source ([`3e910ff`](https://github.com/embeddings-benchmark/mteb/commit/3e910ff76b5cc4713682d2cef2dd860e38de513a))

### Fix

* fix: Add error reporting for Retrieval (#873)

* add error reporting.
* no message
* Update mteb/abstasks/AbsTaskRetrieval.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* add kwarg args
* change to metadata.name
* fix format
* Update mteb/abstasks/AbsTaskRetrieval.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* change to explicit args
* remove cmdline changes
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`5397bd2`](https://github.com/embeddings-benchmark/mteb/commit/5397bd2153700ff026697038d6174fe67b6033d8))

## v1.12.20 (2024-06-05)

### Fix

* fix: Updated CLI for MTEB (#882)

* Updated CLI for MTEB

It now includes three main commands one for running, one for getting an overview and one for creating the metadata for hf.

I also
- added lower bound on dependencies as it caused a few issues.
- deleted some results with a model revision attached (also created a fix to make sure that doesn&#39;t happen as much going forward)
- Added a test for the cli
- Added a quite extensive docstring to the CLI
- made relevant changed to the documentation

* ensure tests pass

* minor changes to PR template

* Minor changes to PR template

* remove tmp file

* fixed failing test and updated it to avoid future false positives

* fix deprecation warning for logger.warn

* don&#39;t clear path before running tests as it disturbs other tests when run in parallel ([`c6f618b`](https://github.com/embeddings-benchmark/mteb/commit/c6f618b0ab5b265acf8ac736db1ddca8d73222c5))

## v1.12.19 (2024-06-05)

### Documentation

* docs: minor fix for point validation to avoid error when people split up points ([`7d0d631`](https://github.com/embeddings-benchmark/mteb/commit/7d0d6319f67251b65b37ec835adea605aa05c893))

### Fix

* fix: Add CEDR, SensitiveTopics for multilabel and RuBQ for reranking (#881)

* add russian reranking and multilabel tasks

* fix import order

* add results for baselines

* add points

* add points for review ([`9128df4`](https://github.com/embeddings-benchmark/mteb/commit/9128df46f4d9deb06ad1878b321942ac281cfc7d))

### Unknown

* Update tasks table ([`7d3ce53`](https://github.com/embeddings-benchmark/mteb/commit/7d3ce53d017a11b9427ed04a7af7828fee5cc7b7))

* Update points table ([`ef52f95`](https://github.com/embeddings-benchmark/mteb/commit/ef52f95e13ed00caef0b77a5c6d8e39c18293793))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`7c7ee2b`](https://github.com/embeddings-benchmark/mteb/commit/7c7ee2bd27c01930d05a63e55891882b5d70a761))

* Updated CLI for MTEB

It now includes three main commands one for running, one for getting an overview and one for creating the metadata for hf.

I also
- added lower bound on dependencies as it caused a few issues.
- deleted some results with a model revision attached (also created a fix to make sure that doesn&#39;t happen as much going forward)
- Added a test for the cli
- Added a quite extensive docstring to the CLI
- made relevant changed to the documentation ([`29b1c34`](https://github.com/embeddings-benchmark/mteb/commit/29b1c347270594d4fe4ad6b928b245a92c885077))

## v1.12.18 (2024-06-05)

### Fix

* fix: Ensure result are consistently stored in the same way (#876)

* Ensure result are consistently stored in the same way

- (due to failing test): updated missing dataset references
- (to test with more than one model) Added e5 models base and large
- updated mteb.get_model to now include metadata in the model object
- ensure that model name is always included when saving (with a default when it is not available)
- use the ModelMeta for the model_meta.json

* format

* minor test fixes

* docs: Minor updated to repro. workflow docs

* fixed failing test

* format

* Apply suggestions from code review

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* docs: update PR template

* fix: Added benchmark object (#878)

* removed duplicate task

* Added benchmark object

* removed import for duplicate task

* fix dataset references

* added seb

* Added test for running benchmarks

* changed tasks to be an iterable

* format

* Apply suggestions from code review

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`fb843d0`](https://github.com/embeddings-benchmark/mteb/commit/fb843d040e8af63b4d0c2d61b78a69ca55652bcd))

### Unknown

* Update tasks table ([`dfbdfdc`](https://github.com/embeddings-benchmark/mteb/commit/dfbdfdce8423dddb9821ffa349a7ee1df8bdb2ca))

## v1.12.17 (2024-06-04)

### Fix

* fix: Add FaithDialRetrieval dataset (#874)

* faithdial dataset

* results

* added metadata

* add points

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Add reviewer points

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* only test set

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`582381b`](https://github.com/embeddings-benchmark/mteb/commit/582381bd75ec111ba1ed8c81dc2df21336091546))

### Unknown

* Update tasks table ([`35dcec7`](https://github.com/embeddings-benchmark/mteb/commit/35dcec7358ee5038c968545976a2abee007b2713))

* Update points table ([`527c5eb`](https://github.com/embeddings-benchmark/mteb/commit/527c5eb718c7b8b5f82972a9f4eae4f32460d2ae))

## v1.12.16 (2024-06-04)

### Fix

* fix: Add feedbackQA dataset (#856)

* add feedbackQA
* Update mteb/tasks/Retrieval/eng/FeedbackQARetrieval.py
Co-authored-by: Xing Han Lu &lt;21180505+xhluca@users.noreply.github.com&gt;
* Update mteb/tasks/Retrieval/eng/FeedbackQARetrieval.py
Co-authored-by: Xing Han Lu &lt;21180505+xhluca@users.noreply.github.com&gt;
* Update mteb/tasks/Retrieval/eng/FeedbackQARetrieval.py
Co-authored-by: Xing Han Lu &lt;21180505+xhluca@users.noreply.github.com&gt;
* add feedbackQA
* add feedbackQA
* Update mteb/tasks/Retrieval/eng/FeedbackQARetrieval.py
Co-authored-by: Xing Han Lu &lt;21180505+xhluca@users.noreply.github.com&gt;
* add feedbackQA
* points
* make lint
* typo
* missing datasets
---------
Co-authored-by: Xing Han Lu &lt;21180505+xhluca@users.noreply.github.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`0796efa`](https://github.com/embeddings-benchmark/mteb/commit/0796efa4f987fa65920b3853455c1e592ca6b697))

### Unknown

* Update tasks table ([`24e3d92`](https://github.com/embeddings-benchmark/mteb/commit/24e3d92f7a16a56a24fb8efe6feadce15d319aee))

* Update points table ([`8b52f03`](https://github.com/embeddings-benchmark/mteb/commit/8b52f0342ada6a8e81f1867bf70d50f8740fde03))

## v1.12.15 (2024-06-04)

### Documentation

* docs: Affiliation modification (#871)

modified affiliation

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`6e43bbf`](https://github.com/embeddings-benchmark/mteb/commit/6e43bbf389b8c71e1d15b50054a0183789d6c580))

### Fix

* fix: Add MIRACL reranking (#830)

* fix: MIRACL reranking (#641)

* miracl reranking

* clean

* reranking eval based on pytrec

* eval miracl-reranking using pytrec

* miracl reranking

* dataset name

* compute_metrics_batched

* dataset name typo

* clean

* make lint

* points

* Update mteb/evaluation/evaluators/RerankingEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/evaluation/evaluators/RerankingEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/evaluation/evaluators/RerankingEvaluator.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Reranking/multilingual/MIRACLReranking.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* solve part of PR comments

* docstring

* n-samples and avg_char_length

* make lint

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Addressed changes from main PR

* remove unused import

* removed abstract from citation

* added *(MIRACL) to results

* fix: Miracl reranking fix (#870)

* change evaluate and evaluate_custom back to @staticmethod

* using MIRACLRerankingEvaluator rather than RerankingEvaluator; adapt to latest RetrievalEvaluator

* formatted

* fix: fixed missing references

---------

Co-authored-by: Crystina Xinyu Zhang &lt;x978zhan@uwaterloo.ca&gt;
Co-authored-by: Your Name &lt;you@example.com&gt; ([`4218675`](https://github.com/embeddings-benchmark/mteb/commit/421867588007e7664a1584e3f273d2978b3bade1))

### Unknown

* Update tasks table ([`2291242`](https://github.com/embeddings-benchmark/mteb/commit/2291242b8c3e99f84826adf43a427e9e42dd8f4e))

* Update points table ([`77badee`](https://github.com/embeddings-benchmark/mteb/commit/77badee59c439d537486317fd490ed801c441108))

## v1.12.14 (2024-06-03)

### Fix

* fix: dataset not available (#872)

fix dataset not available ([`397519b`](https://github.com/embeddings-benchmark/mteb/commit/397519b4aea562dc2912d49874ec819550f2e28f))

## v1.12.13 (2024-06-03)

### Fix

* fix: main score for longEmbed (#869)

* Fix main score

* Fix main score ([`db8bb5e`](https://github.com/embeddings-benchmark/mteb/commit/db8bb5ecaa6f5038cb090aba224461ab20015741))

## v1.12.12 (2024-06-03)

### Fix

* fix: Updated the revision of dataset (#866)

* Updated the revision of dataset

* Updated the test results ([`e48eef9`](https://github.com/embeddings-benchmark/mteb/commit/e48eef9457b246adaba5e16064c425374d78dad8))

## v1.12.11 (2024-06-02)

### Documentation

* docs: removed spacing is github user name ([`facdb76`](https://github.com/embeddings-benchmark/mteb/commit/facdb7653cd14e92dfe853da6054e8fa0f7247bb))

### Fix

* fix: Convert MLSUM to fast (#865)

* add MLSUMClusteringS2S.v2

* add e5 results

* add MLSUMClusteringS2SFast

* points

* make lint

* review ([`b70bb5a`](https://github.com/embeddings-benchmark/mteb/commit/b70bb5afd808b7a46094029ab07604a08fbd7356))

### Unknown

* Update tasks table ([`d3413b9`](https://github.com/embeddings-benchmark/mteb/commit/d3413b9d48f088132aa36d90dcb892d9db160aa0))

* Update points table ([`4ebc68a`](https://github.com/embeddings-benchmark/mteb/commit/4ebc68af640ea54ebcf55430596bbd6c4faa9582))

* Update points table ([`bad247a`](https://github.com/embeddings-benchmark/mteb/commit/bad247afaefc3ba8a6b8ab36376a24cdd36504cc))

## v1.12.10 (2024-06-02)

### Fix

* fix: add check_label_distribution for ClusteringFast (#862)

* check_label_distribution and results

* make lint

* points

* correct validation ([`6afb8a9`](https://github.com/embeddings-benchmark/mteb/commit/6afb8a9b923e59a32affd6ca3671d257387ce086))

### Unknown

* Update tasks table ([`a2ad6ef`](https://github.com/embeddings-benchmark/mteb/commit/a2ad6efb903e1611c18b54adbad4f9c8a500be2e))

* Update points table ([`52c5ba4`](https://github.com/embeddings-benchmark/mteb/commit/52c5ba442788644b51bdc2f73f24e91d460c268b))

## v1.12.9 (2024-06-02)

### Fix

* fix: Add model implementations and script for running the models (#845)

* delete existing model results

* fix: Added models implementations and script for running the models

Note there is still a few things missing due to a *very* poor internet connection

* Added loader to metadata obj

* Update revision

* Add e5 models

* Update mteb/models/e5_models.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Minor update on print

* tested that everything works

* formatted

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`b331c34`](https://github.com/embeddings-benchmark/mteb/commit/b331c340e8f48e5530c9c71003b252769a55cacb))

## v1.12.8 (2024-06-02)

### Fix

* fix: formatted ([`8d3fc1b`](https://github.com/embeddings-benchmark/mteb/commit/8d3fc1b0c6efa8e6cd31db6ab14884b080fb53ab))

### Unknown

* Add abstention metrics to retrieval and reranking tasks (#854)

* add abstention as retrieval/reranking metric

* add reviewer points

* update docstrings

* Update docs/mmteb/points/854.jsonl

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`53c477f`](https://github.com/embeddings-benchmark/mteb/commit/53c477fd0604f5afbf114a50c54bfe259a071be8))

## v1.12.7 (2024-06-02)

### Fix

* fix: Add Russian tasks (RU-MTEB) (#815)

* add ru-mteb tasks

* add results for new tasks

* downsample classifcation tasks &amp; remove validation splits

* update clustering tasks to fit size limit

* remove mmarco dataset

* minor changes

* add points

* add list of tasks to benchmarks ([`e9d61bb`](https://github.com/embeddings-benchmark/mteb/commit/e9d61bba729c0c50f4baa0aec3280ed94b116a96))

### Unknown

* Update tasks table ([`eebf973`](https://github.com/embeddings-benchmark/mteb/commit/eebf9735fd165bad71695bb354b153d0625968c7))

* Update points table ([`cebf1fc`](https://github.com/embeddings-benchmark/mteb/commit/cebf1fc12c46c8e1764eb1d1abfd84195591371c))

## v1.12.6 (2024-06-01)

### Fix

* fix: Use model revision in results folder (#842)

* use model revision in results folder
* make lint
* tests (not dataset missing ones) passing
* load specified model revision
* check for model.revision first
* use no_revision_available
* make lint
* add revisions to test dir
* points
* make lint ([`2c6065b`](https://github.com/embeddings-benchmark/mteb/commit/2c6065b28e5212deecc6af973ca97d0c56d16264))

### Unknown

* Update points table ([`c2e3d30`](https://github.com/embeddings-benchmark/mteb/commit/c2e3d30f098c729fa6ef063ca8ea83c7b8590bc4))

* update affiliation (#855) ([`5fa2aee`](https://github.com/embeddings-benchmark/mteb/commit/5fa2aee8252ff83c0404e0a05e3b150832c30a67))

* Update tasks table ([`4bded5a`](https://github.com/embeddings-benchmark/mteb/commit/4bded5a653a806d9068cfb9f246c86d75c3e4c55))

* Update points table ([`f40c8a8`](https://github.com/embeddings-benchmark/mteb/commit/f40c8a861e493578368e92b912260958d0f9f4e1))

* Add Norwegian and Swedish to WikipediaRerankingMultilingual and update points (#796)

* first proper upload of wikipedia-retrieval dataset

* update license and README of dataset

* fix test split and add WikipediaRetrievalDE task

* add WikipediaRerankingDE task

* add Bengali tasks

* multilingual reranking dataset

* add Multilingual Reranking

* add Retrieval tasks

* update metadata for Reranking task

* run make lint

* fix metadata validation errors

* delete German and Bengali Reranking tasks

* fix more task metadata, tests passing now

* add retrieval results

* WIP: reranking with multilingual dataset

* undo changes to run script

* update points and contributor info

* subcall MultilingualTask for reranking task and add reranking results

* WIP: make retrieval a multilingual dataset, too

* WIP: first run of WikipediaRetrievalMultilinugal

* add WikipediaRetrievalMultilinugal task and results

* delete language specific retrieval tasks and results

* update points and add Openreview IDs

* make lint

* remove debugging print statement

* add Norwegian and Swedish to ellamind/wikipedia-2023-11-reranking-multilingual dataset

* update reranking dataset revision and add new reranking results

* add missing multilingual-e5-small result on WikipediaRetrievalMultilingual

* update points for adding Norwegian and Swedish to WikipediaRerankingMultilingual

* make lint

* fix merge conflict in reranking results ([`06e4844`](https://github.com/embeddings-benchmark/mteb/commit/06e484441ab5f4765779862ccbdcba244569ffd2))

## v1.12.5 (2024-05-29)

### Fix

* fix: Find missing dataset revisions (#844)

fix missing dataset revisions ([`c9b4c0c`](https://github.com/embeddings-benchmark/mteb/commit/c9b4c0c425c67f6219c38761f72ab50fed356880))

## v1.12.4 (2024-05-28)

### Fix

* fix: add model meta to create reproducible workflow (#807)

* replace get_tasks as default filtering.

The intention here is to:

1) move complexity away from the MTEB object
2) ensure that the filters are applied in the same way across the benchmark (currently MTEB filters slightly differently due to not handling the new language codes)
3) deprecate filtering in MTEB going forward (only with a warning atm.)
4) doing it in a two step fashion ensure that users are able to inspect the tasks before they are run (also allow for much more custom filtering on the user end)

* add model meta to create reproducible workflow

- Add outline for model meta object
- Added a single model as a an example
- Added test for the reproducible workflow

The intention is that a reproducible workflow should then look like:

```
# assuming the same mteb and sent. trf. version

model_meta = mteb.get_model(model_name)
task = mteb.get_task(task_name)

model = model_meta.load_model() # load model either using custom loader or sentence transformer (with revision)

eval = MTEB(tasks=[task])
eval.run(model, output_folder=&#34;tests/results&#34;, overwrite_results=True)
```

For running models we can the simply have tasks like:

1) implement model
2) ensures that it runs on all tasks types

Running the models then become simple:

```
eval = MTEB(tasks=mteb.get_tasks())
for mdl_name in models:
   model_meta = mteb.get_model(mdl_name)
   mdl = model_meta.load_model()
   eval.run(mteb.get_model(mdl)
```

We can start with this already now e.g. on classification tasks.

* import ISO_LANGUAGE from languages

* fix import

* Apply suggestions from code review

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* format

* Apply suggestions from code review

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Updated based on suggestions from review

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`0319105`](https://github.com/embeddings-benchmark/mteb/commit/0319105734444de0626c068a3284832d96233dac))

* fix: Updated CLI to use new task filter (#826)

* replace get_tasks as default filtering.

The intention here is to:

1) move complexity away from the MTEB object
2) ensure that the filters are applied in the same way across the benchmark (currently MTEB filters slightly differently due to not handling the new language codes)
3) deprecate filtering in MTEB going forward (only with a warning atm.)
4) doing it in a two step fashion ensure that users are able to inspect the tasks before they are run (also allow for much more custom filtering on the user end)

* tests passing

* Added corrections from review

* Updated CLI

* docs: Added points

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`fb5fec8`](https://github.com/embeddings-benchmark/mteb/commit/fb5fec8b763c107fbcc9bdc853a64d6d8a8d0043))

### Unknown

* Update points table ([`f926216`](https://github.com/embeddings-benchmark/mteb/commit/f926216f8427ee514196d200caa089a16a22db48))

* Update tasks table ([`d560c31`](https://github.com/embeddings-benchmark/mteb/commit/d560c31d3d10d6e13cf41d4f3aabff9ef4d37cec))

* Update points table ([`84e6856`](https://github.com/embeddings-benchmark/mteb/commit/84e6856cfb9f251c102a77394fe26eaaa1c01624))

* Add MLQuestions dataset (#799)

* mlquestions load script

* more metadata

* add to init

* baseline model results

* add points

* complete metadata

* lint

* Update points and metadata

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* clarification of period in comments

* minor fix

* linting

* Fix validation error

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`3a14885`](https://github.com/embeddings-benchmark/mteb/commit/3a14885b8ea0406f9ae0edf7b550bfadb37fcb4e))

## v1.12.3 (2024-05-27)

### Fix

* fix: Convert blurbs to fast for s2s and p2p (#832)

* add BlurbsClusteringS2S.v2

* add BlurbsClusteringP2P.v

* make lint

* points

* update n_samples ([`a00fdba`](https://github.com/embeddings-benchmark/mteb/commit/a00fdba44d1fadd0be449b7f988dd08145cd5b87))

### Unknown

* Update tasks table ([`04d5494`](https://github.com/embeddings-benchmark/mteb/commit/04d549462482f96066b4a10f828094f3da076d92))

* Update points table ([`4b31692`](https://github.com/embeddings-benchmark/mteb/commit/4b316922499d927672a518f1d44dbf8196ea547e))

## v1.12.2 (2024-05-27)

### Fix

* fix: (1) Add `StatcanDialogueDatasetRetrieval` (2) Fix `DRESModel.encode_conversations` to allow list of dictionaries (#779)

* WIP

* Update metadata based on reviewer requested changes

* Finalize metadata

* add statcandialoguedatasetretrival to mteb.tasks.retrieval

* Convert query from JSON string to dictionary (parsed using `json`)

* Fix: DRESModel to allow conversations composed of list of dictionaries, alongside lists of strings (e.g. Topicoqa). Also fix batch_size parameter in encode_conversations

* Add baseline results

* Change revision to hash

* Add points

* Fix incorrect object reference ([`7943ff0`](https://github.com/embeddings-benchmark/mteb/commit/7943ff05d4ec4d4c4da81a5a6c50fd298de907dd))

### Unknown

* Update tasks table ([`04f6cdc`](https://github.com/embeddings-benchmark/mteb/commit/04f6cdc8022a1514a55ce20fb38cd11431c11842))

* Update points table ([`3a96c69`](https://github.com/embeddings-benchmark/mteb/commit/3a96c6955e29c0a7a9d7e61e25f89fdd15269d7c))

* Update points table ([`6563218`](https://github.com/embeddings-benchmark/mteb/commit/656321807a3bf132753920d6f076266925613d6f))

* Add fast clustering version to existing files (#827)

* Add fast clustering to existing file

* add points ([`a0ebf87`](https://github.com/embeddings-benchmark/mteb/commit/a0ebf87da18c6e94b27b855f136dc3a13a0d7a5d))

## v1.12.1 (2024-05-27)

### Fix

* fix: rename *fast to *v2 for clustering task (#825)

* rename *fast to *v2 for clustering task

* added correction from review ([`365c0d4`](https://github.com/embeddings-benchmark/mteb/commit/365c0d4c67162c9d3a50fcd5c38d3dae37a96eac))

### Unknown

* Update tasks table ([`e3641ea`](https://github.com/embeddings-benchmark/mteb/commit/e3641ea91c677c44851f2e7fe2680dc495fbc54f))

## v1.12.0 (2024-05-27)

### Feature

* feat: replace get_tasks as default filtering. (#806)

* replace get_tasks as default filtering.

The intention here is to:

1) move complexity away from the MTEB object
2) ensure that the filters are applied in the same way across the benchmark (currently MTEB filters slightly differently due to not handling the new language codes)
3) deprecate filtering in MTEB going forward (only with a warning atm.)
4) doing it in a two step fashion ensure that users are able to inspect the tasks before they are run (also allow for much more custom filtering on the user end)

* tests passing

* Added corrections from review

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`0ca3bc1`](https://github.com/embeddings-benchmark/mteb/commit/0ca3bc1219981af0c901b4918e78658453f3949b))

## v1.11.19 (2024-05-25)

### Fix

* fix: Convert AlloProfClustering to Fast (#822)

* Convert AlloProfClustering to Fast
* Apply suggestions from code review
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`4cae4f9`](https://github.com/embeddings-benchmark/mteb/commit/4cae4f98a759bed66d83ba54de54ac79439acfcc))

### Unknown

* Update tasks table ([`07866a5`](https://github.com/embeddings-benchmark/mteb/commit/07866a5d0eed038c12df735f97e03c68b6b38e51))

* Update points table ([`c41f0e0`](https://github.com/embeddings-benchmark/mteb/commit/c41f0e01dadcf4808748b67eb0ab228cca5f0a52))

## v1.11.18 (2024-05-25)

### Documentation

* docs: Typo in points for #716 (#821)

* Fix the typo in points as per the discussion in https://github.com/embeddings-benchmark/mteb/pull/716#issuecomment-2130437694

Signed-off-by: mr.Shu &lt;mr@shu.io&gt; ([`c0b5991`](https://github.com/embeddings-benchmark/mteb/commit/c0b5991649e64bb30e755c94f1ecb8259650d84e))

* docs: Adding contributor information (#794)

* Adding contributor information and fixing points from previous PR

* Update docs/mmteb/points/731.jsonl

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`3ba6362`](https://github.com/embeddings-benchmark/mteb/commit/3ba636209d81f1fda5cfd614e6a94ba5baf7d274))

### Fix

* fix: Convert HALClustering to Fast (#817)

* Convert HALClustering to Fast
* Add review points
* Add superseeded_by
* Rename task
* Add review points
* Apply suggestions from code review
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`c7adcd8`](https://github.com/embeddings-benchmark/mteb/commit/c7adcd8769894b63ba77fe29f6d6a289826d746c))

### Unknown

* Update tasks table ([`37c02ee`](https://github.com/embeddings-benchmark/mteb/commit/37c02ee1e7f66f6c7062837c3898907b69fc1d8f))

* Update points table ([`8033a84`](https://github.com/embeddings-benchmark/mteb/commit/8033a84bd840fa46fdb2992034e13ef7cb733545))

* Update points table ([`7e89166`](https://github.com/embeddings-benchmark/mteb/commit/7e89166284aebbb967fde6480f8ce41b19c7c32a))

## v1.11.17 (2024-05-24)

### Fix

* fix: Convert BigPatent to Fast (#813)

* Convert BigPatentClustering to fast, fill metadata

* Fix num samples ([`9b85380`](https://github.com/embeddings-benchmark/mteb/commit/9b85380beaf0395363b4c67c6b056f067da11024))

* fix: Fixes MultilabelClassification eval_split (#812)

* fixes MultilabelClassification
* added MalteseNewsClassification to test_mteb
* points added ([`9b602ad`](https://github.com/embeddings-benchmark/mteb/commit/9b602ade56d6be9018aac74a5addc8c3fd18c43a))

* fix: Convert Biorxiv and Medrxiv clustering to fast  (#788)

* Rework biorxiv and medrxiv data processing scripts
- AbsTaskClusteringFast format for biorxiv
- AbsTaskClusteringFast format for medrxiv
- deduplication
* Add AbsTaskClusteringFast versions of the Biorxiv and Medrxiv tasks
- fast bio p2p
- fast bio s2s
- fast med p2p
- fast med s2s
- linting
- fix metadata
Bio/medrxiv: add metadata to old tasks, naming scheme for fast tasks, revision hashes
* Add results for biorxiv and medrxiv tasks
rerun tasks
* Add points
update points
---------
Co-authored-by: supplyandcommand &lt;42962106+supplyandcommand@users.noreply.github.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`13147aa`](https://github.com/embeddings-benchmark/mteb/commit/13147aa1ebf196007d7a6bf6c3f3d384fa55b8a2))

### Unknown

* Update tasks table ([`8b88a25`](https://github.com/embeddings-benchmark/mteb/commit/8b88a25e33d68ca5f357c8ec405d2cfe3852e578))

* Update points table ([`de25749`](https://github.com/embeddings-benchmark/mteb/commit/de257498203a2a65eb8512053f1e969c1adf4eb8))

* Update points table ([`07dce3b`](https://github.com/embeddings-benchmark/mteb/commit/07dce3b78c7d6424961e7f92fe4b4844823e0a92))

* Update tasks table ([`d508c82`](https://github.com/embeddings-benchmark/mteb/commit/d508c82682991245d58e74c9acf00c06388727f2))

* update reranking Fr tasks (#811)

* update tasks

* fix missing import

* fix dates

* apply linter

* add call to dataset_transform

* remove stratified subsampling

* apply lint

* update results

* add multilingual-e5-small results

* update mteb version

---------

Co-authored-by: Imene Kerboua &lt;imenelydia.kr@gmail.com&gt; ([`7980167`](https://github.com/embeddings-benchmark/mteb/commit/798016747f6d5d19e65fae6a5d51b1a3ffd30fdf))

* Update tasks table ([`1e69ed2`](https://github.com/embeddings-benchmark/mteb/commit/1e69ed287422a02f8bdd8b7569babb6489b04ca0))

* Update points table ([`264a4c8`](https://github.com/embeddings-benchmark/mteb/commit/264a4c8d3754b96734f95a9e4957c1df885f1931))

* Multilabel Brazilian Toxic Tweets Classification (#773)

* BrazilianToxic Tweets multilabel classification

* minor maltese news clf fixes

* BrazilianToxicTweetsClassification improvements

* BrazilianToxicTweetsClassification cleanup

* Update mteb/tasks/MultiLabelClassification/por/BrazilianToxicTweetsClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* points added

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`5f0cd32`](https://github.com/embeddings-benchmark/mteb/commit/5f0cd32f922e092bfe5f06842b1af0bf6fbaaa1e))

## v1.11.16 (2024-05-24)

### Fix

* fix: Speed up Reranking tasks (#793)

* Speed up MindSmallReranking

* Fix typo

* Update docs/mmteb/points/792.jsonl

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Fix points files

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`9707621`](https://github.com/embeddings-benchmark/mteb/commit/970762142550d8ba4b58de506b90dc45043935ea))

### Unknown

* Update points table ([`4fd87f7`](https://github.com/embeddings-benchmark/mteb/commit/4fd87f779b8515be41a5c7ab682b56acbd658167))

## v1.11.15 (2024-05-24)

### Fix

* fix: Converted VG to  hierarchical (#694)

* Added hierarchical VG clustering tasks

* Added startified subsampling for multilabel tasks to AbsTask

* Added stratified subsampling to VG clustering

* Fixed stratified subsampling for multilabel tasks

* fix: Converted VG to AbsTaskClusteringFast

* Added results for paraphrase model

* Removed debugging print statements

* Added &#39;not specified&#39; license to VGHierarchical

* Added proper license from Norsk Aviskorpus

* Ran linting

* Replaced stratification with just regular subsampling

* fix: fixed subsampling

* Added results for VG

* Added points

* fix: Fixed JSON in 694.jsonl

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`ece878e`](https://github.com/embeddings-benchmark/mteb/commit/ece878eb274c4d72084d4488367e944c7db99fe1))

### Unknown

* Update tasks table ([`d813be0`](https://github.com/embeddings-benchmark/mteb/commit/d813be0c0a9e5bf2c60c5540ac2421005171dcf0))

* Update points table ([`418a2b1`](https://github.com/embeddings-benchmark/mteb/commit/418a2b1df1885496b2cdd4a66f037c784b9e5911))

* Update points table ([`9a9f2e6`](https://github.com/embeddings-benchmark/mteb/commit/9a9f2e6f1f173e1ca66701d6b0f7840e8c25b768))

* Fix French retieval metrics (#805)

* fix French retieval metrics

* chore: add points ([`e82ab71`](https://github.com/embeddings-benchmark/mteb/commit/e82ab710af174d4bc705f68320282fa54a3fc819))

## v1.11.14 (2024-05-24)

### Documentation

* docs: fixed points ([`774ca70`](https://github.com/embeddings-benchmark/mteb/commit/774ca70f5f51eae7b467f990bf4bc49dc771e21e))

### Fix

* fix: broken dataset references (#803)

* format

* updated datasets paths ([`9bbd2dd`](https://github.com/embeddings-benchmark/mteb/commit/9bbd2dd6779f36e2c75a5ae20af1f10ce613f934))

* fix: Added ArXiv Hierarchical clustering (S2S and P2P) (#699)

* Added ArXiv Hierarchical clustering (S2S and P2P)

* Use dummy subsampling in ArXivHierarchical

* fix: convert iterables to list

* Added results for ArXivHierarchical

* Added points ([`396eefa`](https://github.com/embeddings-benchmark/mteb/commit/396eefa32e99c4aff372543ae2aa88be32a34381))

### Unknown

* Update points table ([`266dfce`](https://github.com/embeddings-benchmark/mteb/commit/266dfce170b94d73a6e1c99c3f02c52f2d3c93cc))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`6afad5b`](https://github.com/embeddings-benchmark/mteb/commit/6afad5b24f58994a6db1d812bf9414ea5cfa9af2))

* Update tasks table ([`9b79eb2`](https://github.com/embeddings-benchmark/mteb/commit/9b79eb2d61fcf669a610527f868b1696d310be48))

## v1.11.13 (2024-05-23)

### Fix

* fix: GPT4-o generated queries for 14 languages (#718)

* first proper upload of wikipedia-retrieval dataset

* update license and README of dataset

* fix test split and add WikipediaRetrievalDE task

* add WikipediaRerankingDE task

* add Bengali tasks

* multilingual reranking dataset

* add Multilingual Reranking

* add Retrieval tasks

* update metadata for Reranking task

* run make lint

* fix metadata validation errors

* delete German and Bengali Reranking tasks

* fix more task metadata, tests passing now

* add retrieval results

* WIP: reranking with multilingual dataset

* undo changes to run script

* update points and contributor info

* subcall MultilingualTask for reranking task and add reranking results

* WIP: make retrieval a multilingual dataset, too

* WIP: first run of WikipediaRetrievalMultilinugal

* add WikipediaRetrievalMultilinugal task and results

* delete language specific retrieval tasks and results

* update points and add Openreview IDs

* make lint

* remove debugging print statement ([`411e232`](https://github.com/embeddings-benchmark/mteb/commit/411e232e3f696d0c3cb2921cb3e51b53d52d331c))

* fix: add Xstance and ensure valid dataset paths (#795)

* fix: Added new dataset XStance pair classification (#737)

* Added xstance dataset

* Adding points, fixed hard-coded data loading

* fix: ensure dataset paths a valid

---------

Co-authored-by: malteos &lt;git@i.mieo.de&gt; ([`47eb54c`](https://github.com/embeddings-benchmark/mteb/commit/47eb54c205cea7b7fe059769347a8d8126ac32e3))

### Unknown

* Update tasks table ([`2b105d7`](https://github.com/embeddings-benchmark/mteb/commit/2b105d7afd7efee3ff31abc8665c108a9d722ead))

## v1.11.12 (2024-05-22)

### Fix

* fix: update CO2 tracker attribute (#791)

* fix: update CO2 tracker attribute

* chore: add points ([`bef9508`](https://github.com/embeddings-benchmark/mteb/commit/bef9508d60cb23d955b113413b167e5db9ee8e4b))

### Unknown

* Update points table ([`c39cf08`](https://github.com/embeddings-benchmark/mteb/commit/c39cf08acf6adb73b86e2c6fff2026f47cd2b8b5))

## v1.11.11 (2024-05-22)

### Fix

* fix: Convert Polish cluster to fast (#787)

* add EightTagsClusteringFast and results
* add points and lint
* add PlscClusteringFast for S2S and P2P and results
* make lint
* validate points
* add task subtype
* points ([`a1fa96e`](https://github.com/embeddings-benchmark/mteb/commit/a1fa96eff6fe7a15c26f0db9876b1d2277d68138))

### Unknown

* Update tasks table ([`4cf6d25`](https://github.com/embeddings-benchmark/mteb/commit/4cf6d25e7b5d9293c8d4d472d2514233d7f01f69))

* Update points table ([`352179c`](https://github.com/embeddings-benchmark/mteb/commit/352179c187173d13ba3956f004d754e7ed529a30))

## v1.11.10 (2024-05-22)

### Fix

* fix: select language in multilingual tasks (#789)

* fix: select language in multilingual tasks
* add points ([`15ef9af`](https://github.com/embeddings-benchmark/mteb/commit/15ef9afb0c48edbda74baedf36c09d84a50de12f))

### Unknown

* Update points table ([`966460e`](https://github.com/embeddings-benchmark/mteb/commit/966460ed089d15f776a5b5670239e990f2ea524a))

## v1.11.9 (2024-05-22)

### Fix

* fix: Remove duplicate subset of flores clustering (#785)

* remove duplicate subset of flores clustering

* points ([`d5977b8`](https://github.com/embeddings-benchmark/mteb/commit/d5977b89b62ba118db20dff8b83a9f54d8961ebf))

### Unknown

* Update tasks table ([`d04230e`](https://github.com/embeddings-benchmark/mteb/commit/d04230e45d7c95daa917908923d6e48e3323f7d1))

* Update points table ([`ae8b7ce`](https://github.com/embeddings-benchmark/mteb/commit/ae8b7ceb9bc80a63a407491fcf4347a404ae7a4f))

## v1.11.8 (2024-05-22)

### Fix

* fix: Added metadata to a bunch of datasets (#781)

* Added metadata to a bunch of datasets
* points
* snuck in a fix
* review points
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`f38bdac`](https://github.com/embeddings-benchmark/mteb/commit/f38bdac87c8ad000fb567b1e913766e6087e1573))

### Unknown

* Update tasks table ([`47ab4cd`](https://github.com/embeddings-benchmark/mteb/commit/47ab4cd0adc92e6d5e67c4107cb7e185d01e0798))

* Update points table ([`dad7307`](https://github.com/embeddings-benchmark/mteb/commit/dad73075df5c0484a460074125848bb0f57cb010))

## v1.11.7 (2024-05-22)

### Documentation

* docs: remove duplicate info (#780)

docs: remove duplicate name

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt; ([`706b602`](https://github.com/embeddings-benchmark/mteb/commit/706b602c16fd7ccaea8a601c68d50b1351322b8a))

### Fix

* fix: restructure folders (#777)

* fix: restructering retrieval tasks

* removed CSLD

* fix: restructure folders

Moved the following:
Abstasks/MTEBResults -&gt; MTEBResults
Abstasks/languages -&gt; languages (and related files)
Abstasks/LangMapping -&gt; Evaluation/LangMapping (only used here)

* format

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`ac95521`](https://github.com/embeddings-benchmark/mteb/commit/ac955216b9bf61ab2d1e0ee6560923586ad84ea7))

## v1.11.6 (2024-05-21)

### Documentation

* docs: add missing points (#778)

add missing points ([`24a9d45`](https://github.com/embeddings-benchmark/mteb/commit/24a9d45a1eafad2a6fec2a73a1f7a8d03c14fb61))

### Fix

* fix: Metadata for Polish STS (#758)

* The Polish STS had missing metadata. This commit should fix the
  situation.

Signed-off-by: mr.Shu &lt;mr@shu.io&gt; ([`e16807e`](https://github.com/embeddings-benchmark/mteb/commit/e16807e43382feb1bc5248bbbbdf9833cb7b035a))

### Unknown

* Update tasks table ([`156ceaf`](https://github.com/embeddings-benchmark/mteb/commit/156ceaf4065cfef547e3d4d73dd28c325723eff5))

* Update points table ([`95bf14c`](https://github.com/embeddings-benchmark/mteb/commit/95bf14c119deabd090f427b5cf7ce4cd2935a119))

* Update tasks table ([`17c265c`](https://github.com/embeddings-benchmark/mteb/commit/17c265c93c3980438c0a9171948691524aa17798))

* Update points table ([`9933b17`](https://github.com/embeddings-benchmark/mteb/commit/9933b177f9de645d887f980601084102c8f735f5))

* Extending XPQA to add cross lingual evaluation (#730)

* Extending XPQA to add cross lingual evaluation
* Adding points ([`e545c7a`](https://github.com/embeddings-benchmark/mteb/commit/e545c7a00020d6e507d873166bddae8690c7ecc7))

* Update points table ([`a697c99`](https://github.com/embeddings-benchmark/mteb/commit/a697c994fe321ea62d879b316fa42a42dc188b82))

## v1.11.5 (2024-05-21)

### Fix

* fix: Added new dataset: TenKGnadClassification (#735) ([`7fdae83`](https://github.com/embeddings-benchmark/mteb/commit/7fdae839018d29023f510e6e723689b39bdb6fe8))

* fix: Convert TwentyNewsgroups to ClusteringFast (#772)

* add TwentyNewsgroupsClusteringFast
* make lint and typos
* fix bug for monolingual cluster fast
* add run results
* add points
* call add main score within _evaluate_subset
* test passing
* points for review ([`74cead0`](https://github.com/embeddings-benchmark/mteb/commit/74cead062ab552ed89194933ae46304b1161c6c7))

* fix: Add turkic datasets (#588)

* add MIRACLFrReranking dataset

* remove old fr file

* add turkic data

* add turkic data

* fix bibtext error

* add missing results

---------

Co-authored-by: Shreeya Dhakal &lt;shreeyadhakal@Shreeyas-Mac-mini.local&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`cdc41a6`](https://github.com/embeddings-benchmark/mteb/commit/cdc41a6a0d9764cd9512b4d7590500683eacc661))

* fix: Added Indic NLP News Classification tasks (#610)

* Added IndicNLP News Classificaiton

* Added IndicNLP News Classificaiton

* Added results

* Updated dataset version

* Small fixes

* Small fix

* Small fix

* Updated results

* Fix linting issues

* Added points

* Resolve conflict

* Update 610.jsonl

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`1a08f76`](https://github.com/embeddings-benchmark/mteb/commit/1a08f760e754c661996d6030fa0d757944ae0c3e))

* fix: add AfriSenti dataset (#512)

* add AfriSenti dataset

* update metadata and add results

* fix formatting issues

* add avg_character_length

* fix format issue

* add MIRACLFrReranking dataset

* remove old fr file

* add scores

* remove import to old fr files

* Update scores

---------

Co-authored-by: Shreeya Dhakal &lt;shreeyadhakal@Shreeyas-Mac-mini.local&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`e59e7cc`](https://github.com/embeddings-benchmark/mteb/commit/e59e7cc2fbec7f6345d2fa816c8ce1a9f5afd5d4))

### Unknown

* Update tasks table ([`ffcb319`](https://github.com/embeddings-benchmark/mteb/commit/ffcb31948df4e8f0a74732e95d9dade022ac9ba4))

* Update points table ([`8061f0c`](https://github.com/embeddings-benchmark/mteb/commit/8061f0c5fa72aca6ed22e11eabc743c3586db57d))

* Update points table ([`7af857f`](https://github.com/embeddings-benchmark/mteb/commit/7af857f0b06aa08fae66425d2571176babc58c71))

*  fix: Add LegalBench datasets - 12 (#665)

* Add LegalBench datasets

* Add points

* Remove files added in #680 ([`088589f`](https://github.com/embeddings-benchmark/mteb/commit/088589f0dd5d35deb97c94645e48cd62581c55c9))

*  fix: Add LegalBench datasets - 11  (#661)

* Add LegalBench datasets

* Add points

* Remove files added in #680

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`c3acf03`](https://github.com/embeddings-benchmark/mteb/commit/c3acf039b3d3c373c694c844699bee9e4b658d11))

* Update tasks table ([`d7d677c`](https://github.com/embeddings-benchmark/mteb/commit/d7d677c91bced2784e1f2bb3a87f67efb85c16e9))

* Update points table ([`3e3f0b0`](https://github.com/embeddings-benchmark/mteb/commit/3e3f0b02473faa1d958c58c4cf4eaef09834ad62))

## v1.11.4 (2024-05-21)

### Fix

* fix: Added option to load historic result files (#770)

* feat: standardized results output

* minor fixes

* fix: Added option to load historic result files

* formatted and removed additional historic test cases

* fixed referene

* Added points for PR

* minor corrections

* made true the default ([`f6d8d65`](https://github.com/embeddings-benchmark/mteb/commit/f6d8d65f090ccdb35816b07b91d83e62637c1419))

### Unknown

* Update tasks table ([`655fad0`](https://github.com/embeddings-benchmark/mteb/commit/655fad02ab6d6dee8e4b455077f34e908d8a33f4))

* Update points table ([`6c44257`](https://github.com/embeddings-benchmark/mteb/commit/6c44257366a2094beeec3e7d0bf1a0df045bea09))

## v1.11.3 (2024-05-21)

### Fix

* fix: restructering retrieval tasks (#776)

* fix: restructering retrieval tasks

* removed CSLD ([`4b71792`](https://github.com/embeddings-benchmark/mteb/commit/4b71792c80914e5dd7e92fb1ef0e629c4baf996c))

## v1.11.2 (2024-05-21)

### Fix

* fix: Remove v_measures from metadata (#775)

Update mteb_meta.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`56a5e10`](https://github.com/embeddings-benchmark/mteb/commit/56a5e10db4dc16e943a26da0de464986ecad77a9))

## v1.11.1 (2024-05-21)

### Fix

* fix: Convert StackExchangeClustering to fast (#740)

* add MIRACLFrReranking dataset
* remove old fr file
* merge upstream
* Update StackExchangeClustering to Fast
* run lint
* add results
* add old task and superseed attr
* add old task and superseed attr
* added task metadata
* add scores
---------
Co-authored-by: Shreeya Dhakal &lt;shreeyadhakal@Shreeyas-Mac-mini.local&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`7c23ac9`](https://github.com/embeddings-benchmark/mteb/commit/7c23ac936be36ca09e07e8156cbb9a0bbcf9f2de))

### Unknown

* Update tasks table ([`aeda96b`](https://github.com/embeddings-benchmark/mteb/commit/aeda96b872621a629ee76c37200c3fc9de10eab6))

* Update points table ([`5f93cc6`](https://github.com/embeddings-benchmark/mteb/commit/5f93cc679e4fd2e30215a2e58a77c3bba5dfbd94))

* Update tasks table ([`44a031c`](https://github.com/embeddings-benchmark/mteb/commit/44a031c1c12c9ed744e80f96daa8315df3263081))

* Update points table ([`411a0a9`](https://github.com/embeddings-benchmark/mteb/commit/411a0a98e1172fee37d4fbacc7afa89651b6bde5))

* Conversation Retrieval Task and TopiOCQA dataset (#714)

* conv retrieval evaluation

* add encode_conversations to DenseRetrievalExactSearch

* remove duplication of default logic of conv -&gt; query

* fix: queries has been converted from dict to list by this

* make it cross encoder compatible

* topiocqa dataset

* dont need a separate function

* metadata, full corpus

* more metadata

* baseline results

* add points

* update points ([`140de21`](https://github.com/embeddings-benchmark/mteb/commit/140de2139880e508e1697d782bbbb4a101e18c1f))

## v1.11.0 (2024-05-20)

### Feature

* feat: Standardized results output (#759)

* feat: standardized results output

* minor fixes ([`1029a27`](https://github.com/embeddings-benchmark/mteb/commit/1029a271418e54cd48231cd77aaad90908da2b11))

## v1.10.18 (2024-05-20)

### Fix

* fix: Add JMTEB Clustering datasets (#768)

* Add JMTEB Clustering datasets
* Add points
* Add points for review ([`970b03c`](https://github.com/embeddings-benchmark/mteb/commit/970b03ca7fd1898b4a5e47fea775fa72b6f0f668))

### Unknown

* Update tasks table ([`4124a5b`](https://github.com/embeddings-benchmark/mteb/commit/4124a5b09bfe41180598709dfba5bd1831994d0f))

* Update points table ([`ee6ba43`](https://github.com/embeddings-benchmark/mteb/commit/ee6ba43c6dc0bf6bba33cbbc6a90b23eda491894))

* Update tasks table ([`6befb3b`](https://github.com/embeddings-benchmark/mteb/commit/6befb3be0ddfb0ba184eb186f011fb2d556ad36d))

## v1.10.17 (2024-05-20)

### Fix

* fix: Add JSICK dataset (#769)

* Add JSICK dataset
* Add points
* Add points for review
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`755fe35`](https://github.com/embeddings-benchmark/mteb/commit/755fe35c3a145049b38e3ee145dcc6964786e164))

### Unknown

* Update points table ([`47f7736`](https://github.com/embeddings-benchmark/mteb/commit/47f7736758caaeaf595270fda0e7592b621a6fa2))

## v1.10.16 (2024-05-20)

### Fix

* fix: Convert SIB200Class to SIB200Cluster (#767)

* missing change from pr$757
* SIB200ClusteringFast task working
* add e5 small results
* add results
* add points
* review points ([`211f339`](https://github.com/embeddings-benchmark/mteb/commit/211f33985dae80f6102b830fad8cd2655e94cb76))

### Unknown

* Update tasks table ([`1a39d2d`](https://github.com/embeddings-benchmark/mteb/commit/1a39d2d839549d707a3b68d0bb26652b2a3d1af5))

* Update points table ([`4e1cbda`](https://github.com/embeddings-benchmark/mteb/commit/4e1cbda69c3c7918df24ce4d00ff25a654709520))

## v1.10.15 (2024-05-19)

### Fix

* fix: Add `bibtex_citation` in CMTEBClustering (#765)

* Ensure the entries in CMTEBClustering have an appropriate `bibtex_citation`.

Signed-off-by: mr.Shu &lt;mr@shu.io&gt; ([`bf6e2a0`](https://github.com/embeddings-benchmark/mteb/commit/bf6e2a0aee2d87f2e91cd5b7b6ec1d447c02cff2))

## v1.10.14 (2024-05-19)

### Fix

* fix: Convert CLSClustering and ThuNews to fast (#757)

* convert CLSClustering to fast
* convert thunews to fast
* make lint
* points
* results for CLSClusteringP2P and CLSClusteringS2S for comparison
* review points
* rename to v2
* forgot some files ([`43e0246`](https://github.com/embeddings-benchmark/mteb/commit/43e0246aa3a2b6417876c934912f71ae71eeb74f))

### Unknown

* Update tasks table ([`b02c107`](https://github.com/embeddings-benchmark/mteb/commit/b02c107f267e80c9fad48325c10945e335214e36))

* Update points table ([`0e92f96`](https://github.com/embeddings-benchmark/mteb/commit/0e92f960e7b519e1ea0817a11d4d708abf68c79b))

## v1.10.13 (2024-05-18)

### Ci

* ci: fix slovaksum dir (#764) ([`1c14edb`](https://github.com/embeddings-benchmark/mteb/commit/1c14edb9b0fabc5bd0f3ab12b027151e2cc864e4))

### Fix

* fix: Add MalteseNewsClassification (#546)

* MalteseNewsClassification added

* lint fixes

* MalteseNewsClassification as multilabel + WIP stratification added

* results for multilabel classfication updated

* Maltese MultiLabelClassification added

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`5314bf5`](https://github.com/embeddings-benchmark/mteb/commit/5314bf5729409e78653021f8cbf04df78068903c))

### Unknown

* Update points table ([`4b89a1a`](https://github.com/embeddings-benchmark/mteb/commit/4b89a1a204184304aa081585f793bda62596d429))

* Update tasks table ([`76758f8`](https://github.com/embeddings-benchmark/mteb/commit/76758f833b3c9ce0fd03c3348f0b44168316325d))

## v1.10.12 (2024-05-18)

### Fix

* fix: Add PublicHealthQA (#750)

* Create new PublicHealthQA class and add to `mteb/tasks/Retrieval/__init__.py`

* Add retriever results

* Update metadata

* Update mteb/tasks/Retrieval/multilingual/PublicHealthQARetrieval.py

Co-authored-by: Wissam Siblini &lt;36303760+wissam-sib@users.noreply.github.com&gt;

* Update mteb/tasks/Retrieval/multilingual/PublicHealthQARetrieval.py

Co-authored-by: Wissam Siblini &lt;36303760+wissam-sib@users.noreply.github.com&gt;

* Update mteb/tasks/Retrieval/multilingual/PublicHealthQARetrieval.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Add contribution points

---------

Co-authored-by: Wissam Siblini &lt;36303760+wissam-sib@users.noreply.github.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`ca7266e`](https://github.com/embeddings-benchmark/mteb/commit/ca7266e6c81d8155a42d3532b725126c9c896a94))

### Unknown

* Update tasks table ([`06862df`](https://github.com/embeddings-benchmark/mteb/commit/06862df1f452278d163a12595e893e93c38b5aba))

* Update points table ([`cb7a077`](https://github.com/embeddings-benchmark/mteb/commit/cb7a0776d486b812f17d5c9ffc83e7c4180f9061))

## v1.10.11 (2024-05-18)

### Fix

* fix: Quick fix CI/CD issue due to dataset redirect (#761) ([`495d6f6`](https://github.com/embeddings-benchmark/mteb/commit/495d6f68efd4a4da7adb5dc8b4f5de6557c0c7e3))

### Unknown

* Update tasks table ([`68f9cbc`](https://github.com/embeddings-benchmark/mteb/commit/68f9cbcf34f2c3b99cd3f83249439b9c7afefc74))

* Update points table ([`bf16840`](https://github.com/embeddings-benchmark/mteb/commit/bf16840f28f863c2cdb625ebed663a4dbe6aeba6))

* Adding FarsTail (Persian) for Pair Classification (#736)

* Adding FarsTail (Persian) for Pair Classification
* change for entailment label
* adding points ([`c19db06`](https://github.com/embeddings-benchmark/mteb/commit/c19db06961f566e1946a3de2097890a0a686d209))

* Update points table ([`ff9c000`](https://github.com/embeddings-benchmark/mteb/commit/ff9c000e4e509543bca307934f2dccbba35a4c2d))

* add: Points for #697 (#754)

* A follow up on https://github.com/embeddings-benchmark/mteb/pull/697

Signed-off-by: mr.Shu &lt;mr@shu.io&gt; ([`7b20638`](https://github.com/embeddings-benchmark/mteb/commit/7b20638d29e039d97efe40c4820e4195d05487e1))

## v1.10.10 (2024-05-17)

### Fix

* fix: Convert Multilingual/Crosslingual to fast-loading format (#635)

* STS

* DatasetDict for better compatibility

* IndicCrosslingualSTS

* MultiHateClassification

* subsetloader fix

* MultilingualSentimentClassification

* lint

* TweetSentimentClassification

* IndicSentimentClassification

* STSBenchmarkMultilingualSTS

* xnli

* fix readmes

* tests

* MasakhaNEWSClassification

* SIB200Classification

* MassiveIntentClassification

* MassiveScenarioClassification

* points

* support for parallel subsets

* missing subsets parameters

* bucc

* fixes

* Flores, IN22Conv, IN22Gen, NTREX

* lin

* BUCC and BUCC.v2

* lint

* tests

* points

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`aa82ada`](https://github.com/embeddings-benchmark/mteb/commit/aa82ada7b29826df0104193ddcc98cf7bb76c884))

### Unknown

* Update tasks table ([`3b54004`](https://github.com/embeddings-benchmark/mteb/commit/3b540045c4548fadd78a1302f4c2fbc3581910a7))

* Update points table ([`3c7f7f4`](https://github.com/embeddings-benchmark/mteb/commit/3c7f7f451848c5dfca9036b50b5edf6dbd520a2f))

## v1.10.9 (2024-05-17)

### Fix

* fix: Convert WikiClustering to fast (#745)

* add WikiClusteringFastP2P
* get task to work and run results
* add poionts
* bibtex
* points
* fix AbsTaskClusteringFast early return and rerun results
* points for bug fix
* refactor to be faster
---------
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt; ([`153827b`](https://github.com/embeddings-benchmark/mteb/commit/153827b022980ce9f454d1ef622f78e5856b0a77))

### Unknown

* Update tasks table ([`393f001`](https://github.com/embeddings-benchmark/mteb/commit/393f001d24c662c056fa6ebd461a25d5f074a68b))

* Update points table ([`2a6e837`](https://github.com/embeddings-benchmark/mteb/commit/2a6e837660dc86b918ded0ef3e3cfd2060d2364b))

* Update tasks table ([`e2babab`](https://github.com/embeddings-benchmark/mteb/commit/e2bababd3038171d0a42a610a680360b03f83a23))

* add: SICK-BR (#697)

* Add the Portugese version of the SICK dataset as an STS task.

* Add the Portugese version of the SICK dataset as a PairClassification task.

Signed-off-by: mr.Shu &lt;mr@shu.io&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`804b120`](https://github.com/embeddings-benchmark/mteb/commit/804b1200660eaf7674f8390590f11f65058192bb))

## v1.10.8 (2024-05-17)

### Fix

* fix: Add new dataset: GermanGovServiceRetrieval (#731)

* Add new dataset: GermanGovServiceRetrieval

* points for GermanGovServiceRetrieval; changed main metric

* Update docs/mmteb/points/731.jsonl

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`66792ef`](https://github.com/embeddings-benchmark/mteb/commit/66792efbfc12cc43df87ab17684f5202775ff253))

### Unknown

* Update tasks table ([`e8dd8af`](https://github.com/embeddings-benchmark/mteb/commit/e8dd8aff8a227f9f042dda4319e607f48bf5d70c))

* Update points table ([`904c039`](https://github.com/embeddings-benchmark/mteb/commit/904c039433e30f5a7b333737d8c492f16f754c27))

## v1.10.7 (2024-05-17)

### Fix

* fix: Convert Reddit cluster s2s and p2p to fast (#729)

* reddit cluster s2s to fast
* got task running and add results
* rerun with 16k samples
* full reddit cluster s2s
* filter out labels and result runs
* points
* make lint
* validation ([`b02f252`](https://github.com/embeddings-benchmark/mteb/commit/b02f252c707bce6de61af56ca3b5d7e921f6ef09))

### Unknown

* Update tasks table ([`6745475`](https://github.com/embeddings-benchmark/mteb/commit/67454756dc0d872f9b829f61c04bbf866f66ee19))

* Update points table ([`a416bd1`](https://github.com/embeddings-benchmark/mteb/commit/a416bd1e22b0dba5757b44035da1a6b813b4a116))

## v1.10.6 (2024-05-17)

### Fix

* fix: RomanianReviewsSentiment moved to new repo (#751)

hot fit ([`b636c23`](https://github.com/embeddings-benchmark/mteb/commit/b636c23f4a32d4c7929eeccda5e4afc8454062ca))

## v1.10.5 (2024-05-16)

### Fix

* fix: MindSmallReranking not loading (#748)

.gz -&gt; .zip ([`a5c4f5b`](https://github.com/embeddings-benchmark/mteb/commit/a5c4f5bc03e38c416fc4b6ed4317058bfa73ffd2))

## v1.10.4 (2024-05-16)

### Fix

* fix: Add RUParaPhraserSTS (#716)

* Add the Russian ParaPhraser STS dataset as an STS task.

Signed-off-by: mr.Shu &lt;mr@shu.io&gt; ([`5b13b5c`](https://github.com/embeddings-benchmark/mteb/commit/5b13b5c36022e28d6b6e0ce8e7dc21ce61fb67d8))

### Unknown

* Update tasks table ([`744c94d`](https://github.com/embeddings-benchmark/mteb/commit/744c94d95eda6298bc6511dcb7fa725b0299cb1f))

* Update points table ([`52ba68a`](https://github.com/embeddings-benchmark/mteb/commit/52ba68aa3d6385ae5c8ac7ad35dea8703574d59b))

* Update tasks table ([`871750b`](https://github.com/embeddings-benchmark/mteb/commit/871750b0232888378d1d89f6b1229014f9513260))

* Update points table ([`2b57fb9`](https://github.com/embeddings-benchmark/mteb/commit/2b57fb9467fcab8efb238f6b9c8acf1bfaa4455d))

* Addition of : Thai, Romanian, Hebrew, Korean, Burmese, Nigerian (Multilingual) Datasets (#724)

* Added a new dataset for the Burmese Language and ran the required tests

* Moved from classifications to clustering

* Adding a Hebrew Classification Dataset

* Added a financial sentiment analysis dataset in Korean

* Added a Korean Sentiment Analysis Dataset

* Added a Burmese News Classification Dataset

* Added a Hebrew Sentiment Analysis Dataset

* Added a Thai dataset on restaurant reviews

* Made changes to the thai dataset and hebrew dataset

* Made changes to all 4 datasets

* Made changes and added a new dataset

* Add files via upload

* Added a multilingual dataset on sentiment analysis in different Nigerian Languages

* Made changes to the thai and romanian datasets

* Making changes and adding the new dataset through a new PR

* Added the dialect codes for Moldavian

* added points

* Update mteb/tasks/Classification/multilingual/IndicSentimentClassification.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* Update mteb/tasks/Classification/multilingual/IndicSentimentClassification.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* Added to Contributor Information

* Added to Contributor Information after making lint

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`8f7817f`](https://github.com/embeddings-benchmark/mteb/commit/8f7817f52cf18678886ffafa7b99d92e533c4837))

## v1.10.3 (2024-05-16)

### Fix

* fix: Add IndicGenBenchFlores Dataset (#733)

* Add IndicGenBench Flores Dataset

* Add contributor info and points ([`84dcd3c`](https://github.com/embeddings-benchmark/mteb/commit/84dcd3c0fc77875e6caed755a3bccbc0ddce8b20))

### Unknown

* Update tasks table ([`081b177`](https://github.com/embeddings-benchmark/mteb/commit/081b17795ff1f611fc2cacbd26344f66b4d2d8ff))

* Update points table ([`fdef62b`](https://github.com/embeddings-benchmark/mteb/commit/fdef62b24b8dbff934e547e1d5ef75cc3597f12d))

* Update tasks table ([`325fb14`](https://github.com/embeddings-benchmark/mteb/commit/325fb14e9582435e1769f2d51d540e1f55badaa8))

* Update points table ([`a3b95ae`](https://github.com/embeddings-benchmark/mteb/commit/a3b95ae9fccb3087e7033af7550646b0be830213))

* Adding a new Dataset: Arabic Reviews of SHEIN (#710)

* Dataset: Arabic_Reviews_of_SHEIN

* Dataset: Arabic_Reviews_of_SHEIN

* Dataset: Arabic_Reviews_of_SHEIN

* Dataset: Arabic_Reviews_of_SHEIN

* Dataset: Arabic_Reviews_of_SHEIN

* Dataset: Arabic_Reviews_of_SHEIN

* Dataset: Arabic_Reviews_of_SHEIN

* Dataset: Arabic_Reviews_of_SHEIN

* Dataset: Arabic_Reviews_of_SHEIN

* Resolve the comments at the review

* Update the Citation

* Remove a file and resolve some review comments

* iso codes and Citation

* adding all reviewers

* adding the reviewer

* adding all reviewers

* run make pr

* Fix make pr erorrs

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`ba79fc8`](https://github.com/embeddings-benchmark/mteb/commit/ba79fc8f21f7f67b12d9ad63fe48bdfe7dc66f7a))

## v1.10.2 (2024-05-16)

### Chore

* chore: Fix command in PR template (#700)

* The new version of `mteb` doesn&#39;t expect the `run` parameter, yielding
  a command that causes an erorr. This commit fixes that issue.

Signed-off-by: mr.Shu &lt;mr@shu.io&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`6dc9730`](https://github.com/embeddings-benchmark/mteb/commit/6dc973093589433f96d981bdca72374a4a92d163))

### Documentation

* docs: Add Task Count table per language (#701)

* add task count per lang table
* make lint
* address PR comments
* use polars and get total at the end
* add points
* merge conflict
* change keys
* lowercase ([`d9deea0`](https://github.com/embeddings-benchmark/mteb/commit/d9deea0b8de5b16890fbbd5602479593862fec9a))

### Fix

* fix: IWSLT2017 (#727)

add: IWSLT2017
* Add the IWSLT2017 BitextMining dataset
Signed-off-by: mr.Shu &lt;mr@shu.io&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`5c9468c`](https://github.com/embeddings-benchmark/mteb/commit/5c9468c01168fc0c6ac6898fc11ff718ddc94830))

### Unknown

* Update tasks table ([`96ff3d9`](https://github.com/embeddings-benchmark/mteb/commit/96ff3d9e9cd2c112430446cf33abfec3d69ccc62))

* Update points table ([`dcef3b2`](https://github.com/embeddings-benchmark/mteb/commit/dcef3b2356e0ec5b0353e20386c0a8fa7dd57cdd))

* Update points table ([`f05c50f`](https://github.com/embeddings-benchmark/mteb/commit/f05c50f911b2725514d7248bf928db2cd7b0159c))

* Update points table ([`06a222b`](https://github.com/embeddings-benchmark/mteb/commit/06a222b4aebbf43512658df4bcdd74d92a04a9fb))

* Update points table ([`4b4574f`](https://github.com/embeddings-benchmark/mteb/commit/4b4574f52e90c27c3af3f92c5c08bc19481fa090))

* Update points table ([`1172202`](https://github.com/embeddings-benchmark/mteb/commit/1172202404b0e70ecb2c6ff9f4bea72ec08ae50f))

* Update points table ([`2fb0862`](https://github.com/embeddings-benchmark/mteb/commit/2fb086296e8b0e87c7d92cbdb08273d87fcd0ed7))

* Update points table ([`e93832b`](https://github.com/embeddings-benchmark/mteb/commit/e93832b7ea4bcc8372b06c690a352e99f01aed48))

*  fix: Add LegalBench datasets - 13 (#678)

* Add LegalBench datasets

* Add points

* Remove files added in #680

* Add points for review ([`5032bf8`](https://github.com/embeddings-benchmark/mteb/commit/5032bf8a27553e1bc703ba9b9458fe809c970a86))

* Update tasks table ([`a8704f6`](https://github.com/embeddings-benchmark/mteb/commit/a8704f610a5b8d19f99782e8f20a7db65d96e6c4))

* Update points table ([`b7a3607`](https://github.com/embeddings-benchmark/mteb/commit/b7a3607bae73f3bd28a61fb4ae0db6daf852a1ec))

* Update points table ([`ef7875a`](https://github.com/embeddings-benchmark/mteb/commit/ef7875a113fc7e3d8f02f14a64137a2d83ad0d59))

* add: Czech/Slovak Classification Datasets (#695)

* Add a Czech and a Slovak classification dataset based on CSFD.

Signed-off-by: mr.Shu &lt;mr@shu.io&gt;
Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt; ([`003e323`](https://github.com/embeddings-benchmark/mteb/commit/003e323bd3f11966d889d377bf18630105c0675f))

* Update tasks table ([`2bc404e`](https://github.com/embeddings-benchmark/mteb/commit/2bc404e3dddd8d2553a7ee4eaf832a1de833cf14))

* Update points table ([`6f3430d`](https://github.com/embeddings-benchmark/mteb/commit/6f3430df67ca1c4a889dc201762d9c5181e4dff5))

* Czech and Slovak classification tasks (#650)

* Add CzechProductReviewSentimentClassification

fix: proper task_subtype, take the string label

add results for CzechProductReviewSentimentClassification

fix: annotations

update: increased the number of samples for czech prod review

* Added CzechSoMeSentimentClassification

update: increased number of samples

* Added SlovakMovieReviewSentimentClassification

* add points for #650

* add contributor

* fix: n_samples for ces and svk classification

---------

Co-authored-by: supplyandcommand &lt;42962106+supplyandcommand@users.noreply.github.com&gt; ([`40e4ccf`](https://github.com/embeddings-benchmark/mteb/commit/40e4ccf905ffac9a89021eaf2bfa5fcbb299c91e))

* Update tasks table ([`8f48a5e`](https://github.com/embeddings-benchmark/mteb/commit/8f48a5e85cf4e83f8a20b601c2f33d0668936179))

* Update points table ([`180c235`](https://github.com/embeddings-benchmark/mteb/commit/180c2353267eae03fda7d564e622743915030cbc))

*  fix: Add LegalBench datasets - 14 (#680)

* Add LegalBench datasets

* Add points

* Update docs/mmteb/points/680.jsonl

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Add results using e5-base

* Fix points

* Combine all MAUD datasets

* Update LegalBenchClassification.py

* Fix typo

* Fix tests

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`59d89e0`](https://github.com/embeddings-benchmark/mteb/commit/59d89e000c87a8dcde4a4fd6c946e0a75dd75474))

* Update tasks table ([`917bb23`](https://github.com/embeddings-benchmark/mteb/commit/917bb2329f137a39221d80a6a904d7ce68bfda8c))

* Update points table ([`201bd2f`](https://github.com/embeddings-benchmark/mteb/commit/201bd2f6e462f53e48343a245b8bf65970b66155))

* Adding CTKFactsNLI (Czech) (#725)

* Adding CTKFactsNLI (Czech)

* adding validation set, and adding points ([`99e45f0`](https://github.com/embeddings-benchmark/mteb/commit/99e45f027af9a7329bd1b96703fb2b424355e771))

* Update tasks table ([`9f4440f`](https://github.com/embeddings-benchmark/mteb/commit/9f4440f217afbc491c9a68dc24e77ae844b33ef8))

* Update points table ([`b3e2f86`](https://github.com/embeddings-benchmark/mteb/commit/b3e2f867d547d926f151d48969a47f1db35bd10a))

* Adding ASSIN2 (portuguese) - STS and PC tasks (#721)

* Adding ASSIN2 (portuguese) - STS and PC tasks

* Update mteb/tasks/PairClassification/por/Assin2RTE.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* Update mteb/tasks/STS/por/Assin2STS.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* reruning evals after fixes

* adding points

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`4d5e925`](https://github.com/embeddings-benchmark/mteb/commit/4d5e925d7d81fbc0f61a7e176b1b8fab38d69c3f))

* Update points table ([`06874c3`](https://github.com/embeddings-benchmark/mteb/commit/06874c3d9d7802c2bde626749862ed0f03e33d30))

* Update tasks table ([`2fcb428`](https://github.com/embeddings-benchmark/mteb/commit/2fcb4288eea9073bb236d00f3100f5413833428a))

* Update points table ([`f7c4747`](https://github.com/embeddings-benchmark/mteb/commit/f7c474783c1e428e27f161e80a35983b746a87d6))

* Adding IndoNLI dataset (#723)

* Adding IndoNLI dataset

* change annotations_creators to expert-annotated

* adding points ([`2fabf5f`](https://github.com/embeddings-benchmark/mteb/commit/2fabf5f8a9cbf1a77e51c0084db2be4e06b67ee8))

## v1.10.1 (2024-05-15)

### Fix

* fix: Adding ArEntail dataset (#676)

* Adding ArEntail dataset

* adding points

* updating points and data

* fixing lint

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`06347a6`](https://github.com/embeddings-benchmark/mteb/commit/06347a6c4c815ef47e9575c8f46518d5a7f2c892))

### Unknown

* Update tasks table ([`ca614e5`](https://github.com/embeddings-benchmark/mteb/commit/ca614e52ca90daf0f88f0858cc4588642990d948))

* Update points table ([`1b9d6be`](https://github.com/embeddings-benchmark/mteb/commit/1b9d6be1348afac706fe00585c691efbb4094edc))

## v1.10.0 (2024-05-14)

### Feature

* feat: Add carbon emissions estimation (#712)

* feat: add carbon emissions estimation

* fix: make tracker optional

* fix: making package import optional

* chore: adding points

* chore: fix package install ([`2123473`](https://github.com/embeddings-benchmark/mteb/commit/2123473c3ab1565825ffaa3f652b6c9002233161))

### Unknown

* Update points table ([`e9384be`](https://github.com/embeddings-benchmark/mteb/commit/e9384be839ebe86d9c469fb940b39dd4b3b029ae))

* Update tasks table ([`4ab4f2d`](https://github.com/embeddings-benchmark/mteb/commit/4ab4f2dc87b487de295957b10ca80ec235d70d5f))

* Update points table ([`047b52a`](https://github.com/embeddings-benchmark/mteb/commit/047b52a57bab8a12804c6c93a3cadf653b24a3f8))

*  fix: Add LegalBench datasets - 17 (#693)

* Add LegalBench datasets

* Add points

* Add points for review

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`83ed1ee`](https://github.com/embeddings-benchmark/mteb/commit/83ed1ee810c23e32ee607a845878495dfe601ba1))

* Add FollowIR (#715) ([`67037d8`](https://github.com/embeddings-benchmark/mteb/commit/67037d818803b01105899aeab6bf3805bee236ae))

## v1.9.3 (2024-05-14)

### Fix

* fix: Add LegalBench datasets - 15 (#682)

* Add LegalBench datasets

* Add points

* Combine all Pair Classification datasets

* Add points for review

* Update docs/mmteb/points/682.jsonl

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`6fbe071`](https://github.com/embeddings-benchmark/mteb/commit/6fbe071fec806866857ef5ee898941d6f4749726))

### Unknown

* Update tasks table ([`91ccbc8`](https://github.com/embeddings-benchmark/mteb/commit/91ccbc82aa8bfce6a112f5b3dce9a14d6cf7f55a))

* Update points table ([`b773d4c`](https://github.com/embeddings-benchmark/mteb/commit/b773d4c0dd4ba269ae5704dafa81c6a5e310ffc5))

* Update points table ([`31fc7a3`](https://github.com/embeddings-benchmark/mteb/commit/31fc7a3bdaa0ed37ba43d46216c90c174de91897))

* Reallocate CMTEB credits (#711)

* Reallocate CMTEB credits

* Add contributor

* Rmv trailing line

* Rmv trailing line

* Rmv trailing line ([`8cff07b`](https://github.com/embeddings-benchmark/mteb/commit/8cff07b225a5605e303ae73b86a414244a9056e2))

* Delete outdated script (#707) ([`abddef7`](https://github.com/embeddings-benchmark/mteb/commit/abddef75a0fe31882816be37fb687243f831d573))

## v1.9.2 (2024-05-14)

### Fix

* fix: Add supply chain tasks of LegalBench (#690)

* Add SCDBPAccountability

* Add SCDBPAudits

* Add supply chain cert

* Add supply chain training

* Add supply chain verification

* Licensing fix + dis acc

* Add supply chain audits task

* Finish adding legal bench supply chain tasks

* Linting

* Add results + points

* Update docs/mmteb/points/690.jsonl

Co-authored-by: Ashwin Mathur &lt;97467100+awinml@users.noreply.github.com&gt;

* Update mteb/tasks/Classification/eng/LegalBenchClassification.py

Co-authored-by: Ashwin Mathur &lt;97467100+awinml@users.noreply.github.com&gt;

* Update mteb/tasks/Classification/eng/LegalBenchClassification.py

Co-authored-by: Ashwin Mathur &lt;97467100+awinml@users.noreply.github.com&gt;

* Update docs/mmteb/points/690.jsonl

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Ashwin Mathur &lt;97467100+awinml@users.noreply.github.com&gt; ([`d9f1a55`](https://github.com/embeddings-benchmark/mteb/commit/d9f1a5501b333251d28bebcc2fcfafd686ba8457))

### Unknown

* Update tasks table ([`d0fa462`](https://github.com/embeddings-benchmark/mteb/commit/d0fa46254f066deb831a59c362d1e493fb200432))

* Update points table ([`1b4c2b0`](https://github.com/embeddings-benchmark/mteb/commit/1b4c2b0ce0bdeb99a9b7763105619864abe8b068))

## v1.9.1 (2024-05-14)

### Documentation

* docs: Add contribution (#688)

* add MIRACLFrReranking dataset

* remove old fr file

* add contribution

* fix missing french data

* update to individual contributor

---------

Co-authored-by: Shreeya Dhakal &lt;shreeyadhakal@Shreeyas-Mac-mini.local&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`e3d230a`](https://github.com/embeddings-benchmark/mteb/commit/e3d230a5a4da54d85314d40c0643ffe0c0ac02de))

* docs: Update points.md (#687) ([`85c7858`](https://github.com/embeddings-benchmark/mteb/commit/85c7858ceb47acbf943bb8b96a6c845fb0affe7b))

* docs: Adding contributor information (#683)

* chore: adding myself as a contributor

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* chore: add openreview username

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

---------

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt; ([`93a1248`](https://github.com/embeddings-benchmark/mteb/commit/93a1248559d23efb49d572d28ae92a91a81511ae))

* docs: Update points system  (#666)

* Update readme.md

* Update docs/mmteb/readme.md

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* Added upper bound on points along with validator

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`d731c98`](https://github.com/embeddings-benchmark/mteb/commit/d731c98ed38ae1299acd27495adfade37c068dd3))

### Fix

* fix: Double assignemnt in RomanianReviewsSentiment (#692)

* Fix a double assignment in the RomanianReviewsSentiment class.

Signed-off-by: mr.Shu &lt;mr@shu.io&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`b4155b5`](https://github.com/embeddings-benchmark/mteb/commit/b4155b555ddf4f77ecab45775f6b3c0289bd4bb9))

### Unknown

* Update tasks table ([`05f94b1`](https://github.com/embeddings-benchmark/mteb/commit/05f94b127fbabb138523f593ed52df231de19ff8))

* Update points table ([`34d666d`](https://github.com/embeddings-benchmark/mteb/commit/34d666db71720c29e4610e65f53e01d9ea635071))

* Adding Klue-NLI dataset (#675)

* Adding Klue-NLI dataset
* adding points ([`57c3579`](https://github.com/embeddings-benchmark/mteb/commit/57c35792d83f398ac4f2ac712ce996b82ac0b89f))

* Update tasks table ([`c63d408`](https://github.com/embeddings-benchmark/mteb/commit/c63d408037c82b4f9c994e758ea037b14ef3a7be))

* Update points table ([`f01ad7d`](https://github.com/embeddings-benchmark/mteb/commit/f01ad7d88e616a53f3c9be686c60d3da29f4eef0))

* Add classification datasets (eng, ron, swe) (#673)

* add swedish reviews

* add poem sentiment

* add romanian reviews

* updates

* add points

* update date

* update date

* update points

---------

Co-authored-by: MÃ¡rton Kardos &lt;power.up1163@gmail.com&gt; ([`01caff0`](https://github.com/embeddings-benchmark/mteb/commit/01caff0edd67b269fdff36f095d09456b33025b5))

* Update points table ([`681b530`](https://github.com/embeddings-benchmark/mteb/commit/681b53019b473704e41dfa1e9875f8ee7929efc2))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`779c5bc`](https://github.com/embeddings-benchmark/mteb/commit/779c5bcd6a02f688404260337c1088a095e37d56))

* Update tasks table ([`8e7173e`](https://github.com/embeddings-benchmark/mteb/commit/8e7173e44e2bbf3e674d6f0b462825271afc3245))

* Update points table ([`7090005`](https://github.com/embeddings-benchmark/mteb/commit/709000511a5b9c3a26af171da3f95cf5eb291767))

* Hierarchical clustering (#624)

* Added Hierarchical clustering abstask (naive implementation)

* Added SNL as a hierarchical clustering task

* Added Hierarchical clustering as valid task type

* Added results on SNL hierarchical

* fix: Ran linting and fixed metadata

* Turned fast clustering to hierarchical

* Merged hierarchical clustering into fast clustering

* fix: Fixed indentation in clustering fast

* SNLHierarchicalCLustering now superseeds SNL

* fix: Clustering model is now initiated at each level

* Added results for hierarchical clustering with bootstrapping

* Ran linting

* Removed HierarchicalClustering from task types

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* SNL task type is not Clustering

* Updated docstring for fast clustering

* Ran linting

* Made max_depth None by default

* Set max depth to 5 on SNL clustering

* Ran linting

* Fix: clustering now wraps labels that are not hierarchical in lists

* Reran SwednClustering

* Reran linting

* Added points

* fix: Corrected number of samples and mean length in SNLHierarchicalClustering

* Split SNL clustering to S2S and P2P tasks

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`74a19a7`](https://github.com/embeddings-benchmark/mteb/commit/74a19a7a534865d89bc830afccc616f376327d29))

* Update tasks table ([`2e2979e`](https://github.com/embeddings-benchmark/mteb/commit/2e2979ee357267fec110cbf0d53f3a7d2577c444))

* Update points table ([`7ff5b0d`](https://github.com/embeddings-benchmark/mteb/commit/7ff5b0d224f92103cadb836ab877d03ab4e1c43c))

* Add Belebele Retrieval (#636)

* feat: belebele retrieval

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* feat: support langs

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* docs: adjust description

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* chore: results

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* refactor: change num_samples and remove answers

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* chore: update results

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* refactor: update avg length

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* chore: points

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* refactor: apply suggestions

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* fix: jsonl

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* style: linting

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* chore: points

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

---------

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`4a2b9db`](https://github.com/embeddings-benchmark/mteb/commit/4a2b9db43987f26df77c940f25e980bf459144c4))

## v1.9.0 (2024-05-13)

### Documentation

* docs: remove prompt kwargs for example (#681) ([`df490cf`](https://github.com/embeddings-benchmark/mteb/commit/df490cfc16164c2b63e46c8cfe25b01a84e1153d))

* docs: remove prompt kwargs for example ([`43f7157`](https://github.com/embeddings-benchmark/mteb/commit/43f7157235023e46fa36060c73c64ceee49c8d36))

### Feature

* feat: Standardize MTEB results (#658)

* remove misplaced file

* Added MTEBResults and langscript filter

* Ensure standard format for classification

* format

* fixed failing tests and added central task registry

* Added changes from review

* fix: reformatted according to wishes in PR

* fix: Refactored out get_main_score

* Added points

* format ([`7166c31`](https://github.com/embeddings-benchmark/mteb/commit/7166c317c1748b4b11772fe59b8410d5f53aa0f0))

### Fix

* fix: Two Korean classification datasets added (#670)

* two korean classification datasets added

* kor init points added

* Update docs/mmteb/points/670.jsonl

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Kor datasets use self.stratified_subsampling

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`7c2299c`](https://github.com/embeddings-benchmark/mteb/commit/7c2299c9d0b41fb00978b97807bcbb4d946ef105))

### Unknown

* Update points table ([`bc7ed5e`](https://github.com/embeddings-benchmark/mteb/commit/bc7ed5e32e51614f7b6184e889075e154a4aae5c))

* Update points table ([`fd241ba`](https://github.com/embeddings-benchmark/mteb/commit/fd241baa360259c21a9e184649b6e5a03803159e))

* Update tasks table ([`30c94a7`](https://github.com/embeddings-benchmark/mteb/commit/30c94a7c80273d2f8d5297efd0ab82383f8d405d))

* Update points table ([`c9ea24b`](https://github.com/embeddings-benchmark/mteb/commit/c9ea24b03cb2086a47ecebb992de922b683187fc))

* Adding the RTE3 dataset (#672)

* Adding the RTE3 dataset

* fixing metadata

* adding points ([`eea0537`](https://github.com/embeddings-benchmark/mteb/commit/eea0537a50de7fcba504dd1772e28f6ca354b8f9))

## v1.8.11 (2024-05-12)

### Fix

* fix: Add cyrillic turkic lang classification (#659)

* add MIRACLFrReranking dataset

* remove old fr file

* Add Cyrillic Turkic Lang Classification

* update metadata and add scores

* Update mteb/tasks/Classification/multilingual/CyrillicTurkicLangClassification.py

---------

Co-authored-by: Shreeya Dhakal &lt;shreeyadhakal@Shreeyas-Mac-mini.local&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`11b4888`](https://github.com/embeddings-benchmark/mteb/commit/11b4888aba0709b071512a5a042ad1d1043c06d1))

### Unknown

* Update tasks table ([`8132af9`](https://github.com/embeddings-benchmark/mteb/commit/8132af985ac4c2b1cd9cd879e5d33b9ef331f0d4))

* Update points table ([`6402ceb`](https://github.com/embeddings-benchmark/mteb/commit/6402ceb7f82753597285be88f3e65e4bbc815c00))

## v1.8.10 (2024-05-12)

### Fix

* fix: ensure that task.languages return a list of languages (#671)

* fix: ensure that task.languages return a list of languages

* docs: added points

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`2a8f8f5`](https://github.com/embeddings-benchmark/mteb/commit/2a8f8f58b14f071df9c05fe6b861d76e86e899c5))

### Unknown

* Update points table ([`4dd940f`](https://github.com/embeddings-benchmark/mteb/commit/4dd940f295a4999b285113ff027ba3d353e1fc05))

* Update tasks table ([`071ea70`](https://github.com/embeddings-benchmark/mteb/commit/071ea70b548c7fdced60c50463c2a115d8b62ce7))

* Update points table ([`78299fb`](https://github.com/embeddings-benchmark/mteb/commit/78299fb8cc28e5a762c59fd72928d351e9c7e2bf))

* added nusax-senti dataset (#662)

* added nusax-senti dataset

* evaluated NusaX-Senti

* added points

* made changes in NusaX-senti based on comments

* linted correctly

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`59092c3`](https://github.com/embeddings-benchmark/mteb/commit/59092c33e46f884acd0feee781a096020ead23e1))

## v1.8.9 (2024-05-11)

### Fix

* fix: Add Marathi news classification (#504)

* first commit for Telugu News Classification

* revert to original main

* add first push

* add dataset

* add results and points

* complete adding points ([`d93488a`](https://github.com/embeddings-benchmark/mteb/commit/d93488a6fe461eb00e3deb47397908af9a467805))

### Unknown

* Update tasks table ([`600dbd0`](https://github.com/embeddings-benchmark/mteb/commit/600dbd0026172eb6bccbb5210baf16953b753f5c))

* Update points table ([`73422b7`](https://github.com/embeddings-benchmark/mteb/commit/73422b7118bb2de4e2011eb364ac7b9064bab25b))

* Update tasks table ([`dc73123`](https://github.com/embeddings-benchmark/mteb/commit/dc731232a876a4588072b92cf1160266937281ce))

* Update points table ([`54192c7`](https://github.com/embeddings-benchmark/mteb/commit/54192c7299ff33193eb5a608d1aeef878ae00f7a))

* Multilabel classification (#440)

* Added Multilabel kNN classification evaluator

* Added Multilabel classification AbsTask

* Added MultiLabelClassification Task type to TaskMetadata

* bugfix

* Removed all references to metadata_dict from Multilabel classification

* Added Eurlex (wip)

* Made MultiLabelClassification more efficient by moving the embedding step outside the evaluator and encoding every possible training sentence before running the evaluation.

* fix: changed itertools.chain to itertools.chain.from_iter

* fix: Fixed validation and import on MultiEURLEX

* Removed MultioutputClassifier, because kNN can already do that

* fix: multilabels are not turned into an array

* Ran linting

* Added points for PR (2+23*4 for eurlex, 10 for new task type)

* fix: Fixed undersampling for training set in Multitask classification

* fix: sped up sampling by using select() instead of indexing

* fix: removed duplicate code for selecting train sentences

* Added n_samples and avg_length to MultiEURLEX

* Added MultiEURLEX results for paraphrase-multilingual-MiniLM-L12

* Added EURLEX results for multilingual-e5-small

* Changed evaluation in multilabel classification to use MLPClassifier

* Limited evaluation to test split in EURLEX

* multilabel classification now subsamples test set, and the neural network is smaller.

* Multilabel classification now allows tasks to define the samples per label for training

* Removed unused code

* Moved subsampling to before encoding

* Made subsampling error tolerant

* Made sure all labels are represented in the training set

* Revert &#34;Made sure all labels are represented in the training set&#34;

This reverts commit 96312c7ca55b2870995c9b69ab4b88eeaf92fe79.

* Reran EURLEX

* EURLEX only evaluates on test set, not validation set

* Made KNeighbours the default classifier in MultiLabelClassification, made switching out classifiers more flexible

* Added results for EURLEX ([`2aa0c67`](https://github.com/embeddings-benchmark/mteb/commit/2aa0c67b05acd9dadb9b1731f8a8bb28de58702f))

## v1.8.8 (2024-05-11)

### Fix

* fix: mmteb | Arabic Retrieval Task | SadeemQuestionRetrieval (#643)

* create a new directory for Arabic Retrieval tasks

* Push SadeemQuestionRetrieval dataset

* Push SadeemQuestionRetrieval baseline results

* remove invalid comments

* update SadeemQuestionRetrieval metadata

* update SadeemQuestionRetrieval metadata

* add points to the PR

* update points

* apply lint ([`f2d6c1a`](https://github.com/embeddings-benchmark/mteb/commit/f2d6c1a6cb6cb13edffad6a7735148da806e972d))

### Unknown

* Update points table ([`1198ba1`](https://github.com/embeddings-benchmark/mteb/commit/1198ba1963709e1763d1cdd5db58f5c5689ca089))

* Update points table ([`a3082f4`](https://github.com/embeddings-benchmark/mteb/commit/a3082f4ea519c954d824e82de2a7aa04e6dc1dba))

* Small typo fix from #649 (#668)

Fixed naming 649.json to 649.jsonl ([`f58b7f5`](https://github.com/embeddings-benchmark/mteb/commit/f58b7f5614980b6822ac39de19337562d14ae722))

* Update tasks table ([`3765683`](https://github.com/embeddings-benchmark/mteb/commit/376568330d79367f1330c3faf7ba3f6533cbd41f))

* Added XNLI V2.0 Greek, Turkish, Russian support (#649)

* Added xnli_greek

* Added also XNLI Turkish and XNLI Russian whilst at it

* Added description and fixed text creation method of previous commit

* updated descriptions

* Switched to the multilingual setup, removed previous independent files. as requested

* changed to abstart task, MTEB dataset

* Added points

* small fix

* fixed points

* Apply suggestions from code review

used original xnli2.0-multi-pair

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: Orion Weller &lt;31665361+orionw@users.noreply.github.com&gt; ([`22eae1b`](https://github.com/embeddings-benchmark/mteb/commit/22eae1bb756cdbd1ec17b01ad59629829c5d36b1))

* Delete mteb/results directory (#664) ([`8296c17`](https://github.com/embeddings-benchmark/mteb/commit/8296c17071c82f7f9713ad61ddacd9bfdd27faf3))

* Update tasks table ([`0cf33d7`](https://github.com/embeddings-benchmark/mteb/commit/0cf33d73b1f3ff5be1d3689f2aa8abbbe4454c99))

* Update points table ([`5a8a78d`](https://github.com/embeddings-benchmark/mteb/commit/5a8a78d56871d9aa6ddfaf168bd2fcae65580829))

*  fix: Add LegalBench datasets - 8 (#648)

* Add LegalBench datasets

* Add points

* Update docs/mmteb/points/648.jsonl

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Reformulate Diversity datasets; Update description for Function of Decision Section dataset

* Fix linting

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`10a0354`](https://github.com/embeddings-benchmark/mteb/commit/10a03544b9cd7b6839bc3c725dcddea27f2cdccf))

## v1.8.7 (2024-05-09)

### Fix

* fix: Added Tswana News Classification dataset and eval results (#653)

* Added Tswana News Classification dataset and eval results

* add best guess date and points

* fix typo

* Apply suggestions from code review

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`89f671f`](https://github.com/embeddings-benchmark/mteb/commit/89f671f43c6cc0f5963f15f0b52ec75b66ee545f))

### Unknown

* Update tasks table ([`0724329`](https://github.com/embeddings-benchmark/mteb/commit/07243294586cbd97806897b02b58bb28ffc28450))

* Update points table ([`e387daf`](https://github.com/embeddings-benchmark/mteb/commit/e387daf40adfb3334c3885d0297a5ad60d1ae151))

* Update tasks table ([`549c93c`](https://github.com/embeddings-benchmark/mteb/commit/549c93c2fca95d8fedefadd579cc6e71868b24c0))

* Update points table ([`a05ac9e`](https://github.com/embeddings-benchmark/mteb/commit/a05ac9e25335a38bf4bebf56bf8f513ba49c7892))

* Add LegalBench datasets - 10 (#657)

* Add LegalBench datasets

* Add points

* Add points for review ([`2a349d9`](https://github.com/embeddings-benchmark/mteb/commit/2a349d9176c3bff33b273207872d085b6b3b1503))

* Update tasks table ([`99e1f24`](https://github.com/embeddings-benchmark/mteb/commit/99e1f24a2d163a787da1429e37342425ec7e0a5f))

* Update points table ([`a50dce6`](https://github.com/embeddings-benchmark/mteb/commit/a50dce66979dd031f10e46cebdc1a8dacec7f0bb))

*  Add LegalBench datasets - 9 (#655)

* Add LegalBench datasets

* Add points

* Add points for review ([`3737810`](https://github.com/embeddings-benchmark/mteb/commit/3737810c2e495d28b2af21207872307b2b2c1f51))

* Added names and affiliation to table (#654) - Auto-merged ([`3c7728d`](https://github.com/embeddings-benchmark/mteb/commit/3c7728dfa5446d5d0f491133a80e4e90dcad534e))

## v1.8.6 (2024-05-08)

### Fix

* fix: swiss judgement classification dataset (#569)

* swiss judgement classification dataset

* linted properly

* resolved comments

* added points

* resolved merge conflicts

* fixed inconsistent spacing and added name and info in contributor details

* implemented downsampling to run models

* fixed typo in points

* inconsistency in points table fixed

* check linting

* made changes based on review comments

* Update mteb/tasks/Classification/multilingual/SwissJudgementClassification.py

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`2d69957`](https://github.com/embeddings-benchmark/mteb/commit/2d69957b0f4a72ed60f755d73c429aa622c513e6))

### Unknown

* Update tasks table ([`60b4065`](https://github.com/embeddings-benchmark/mteb/commit/60b40656d67844517ee360ec1b9575b69c7458aa))

* Update points table ([`5b9c41b`](https://github.com/embeddings-benchmark/mteb/commit/5b9c41b0c9e78419d56446bb6a98c90b890a0731))

## v1.8.5 (2024-05-08)

### Fix

* fix: Added Crosslingual Semantic Discrimination Task with Four Evaluation Pairs (#645)

* added Crosslingual Semantic Discrimination Task

* linting updates

* fix

* fixed failing tests

* Added more details

* updated to rely on AbsTaskRetrieval instead, rerun everything (identical results)

* Added points

* Added points (fixed)

* fix pointchecks ([`542ee28`](https://github.com/embeddings-benchmark/mteb/commit/542ee28fdc9b8e9ef8819eb17282c46d76368659))

### Unknown

* Update tasks table ([`64977e2`](https://github.com/embeddings-benchmark/mteb/commit/64977e2d02125df30dabfb1ec26735b1debc40c4))

* Update points table ([`c05ee9e`](https://github.com/embeddings-benchmark/mteb/commit/c05ee9e7373a823f5cfd83ff4ea21bfbe27be903))

## v1.8.4 (2024-05-08)

### Ci

* ci: Added repeat to windows test to hopefully alleviate the ci issues (#646) ([`d6ef5b6`](https://github.com/embeddings-benchmark/mteb/commit/d6ef5b63ebfb4bd8c8478385d3dc842373d67375))

### Fix

* fix: Making ScalaClassification multilingual  (#606)

* ScalaClassification changed to multilang dataset

* removed abs from citation : scala

* Update mteb/tasks/Classification/multilingual/ScalaClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Classification/multilingual/ScalaClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Classification/multilingual/ScalaClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Classification/multilingual/ScalaClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Classification/multilingual/ScalaClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* fix lint scala

* scala: fixed metadata

* scala: fixed metadata

* scala: lint fix

* scala: metadata fix

* scala fixed domains

* fixed scala metadata

* Scala updates

* Scala updates

* Scala: points

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`0be4b1f`](https://github.com/embeddings-benchmark/mteb/commit/0be4b1f54b6200625e9721366bd89e8873864294))

### Unknown

* Update tasks table ([`01adcbf`](https://github.com/embeddings-benchmark/mteb/commit/01adcbf4e7a88b0091848bc345907335b9ba84e8))

* Update points table ([`5683a28`](https://github.com/embeddings-benchmark/mteb/commit/5683a28650fb5d803149aed57c93d2680cfd883c))

* Update contributor list (#640)

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`70f17b7`](https://github.com/embeddings-benchmark/mteb/commit/70f17b7ab5cf9006e7abf98430a6148bc49c32be))

* Update tasks table ([`3df1f19`](https://github.com/embeddings-benchmark/mteb/commit/3df1f1967ef7c4d86ba20c4fef93920ea1133e23))

* Update points table ([`195a069`](https://github.com/embeddings-benchmark/mteb/commit/195a0690abae841a385196705440204240eb1b1f))

* Add 5 new datasets for poor covered languages. (#626)

* Add 5 new datasets for languages with poor support

* Make test, make lint, add points

* Added points for PR review

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`b2094f7`](https://github.com/embeddings-benchmark/mteb/commit/b2094f7dc4ffb82c7636ec638311fcfd62fd47a8))

## v1.8.3 (2024-05-07)

### Fix

* fix: Add LegalBench datasets - 7 (#644)

* Add LegalBench datasets

* Add points

* Update docs/mmteb/points/644.jsonl

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`dcb4c4c`](https://github.com/embeddings-benchmark/mteb/commit/dcb4c4cb6b2080f3ec388deb610266d4a152f343))

### Unknown

* Update tasks table ([`6258078`](https://github.com/embeddings-benchmark/mteb/commit/6258078c4596178bd4f52e93440aa331a957e124))

* Update points table ([`44fa404`](https://github.com/embeddings-benchmark/mteb/commit/44fa4043edaf79e6de94664beac83902042998d6))

## v1.8.2 (2024-05-06)

### Fix

* fix: Add IndonesianMongabay classification dataset (#634)

* Add IndonesianMongabay classification dataset

* Add points for dataset

* Update license

* Address reviewer comments

* Add estimate based on whitepaper

https://assets-global.website-files.com/623952e7f678f73f3096fd25/655c6ef18e93de9b458078e3_Mongabay-First%20Indonesian%20Weak%20Supervised%20Dataset%20-%20Curated%20by%20Data%20Programming%20(3).pdf

* Rerun make lint

* Add average character length

* Update points

* Update mteb/tasks/Classification/ind/IndonesianMongabayConservationClassification.py

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`f20831f`](https://github.com/embeddings-benchmark/mteb/commit/f20831f17b1a0909919c4fd07dc1c84902b51f23))

### Unknown

* Update tasks table ([`83f3536`](https://github.com/embeddings-benchmark/mteb/commit/83f35369b900a6e88faba424a44471a715245f89))

* Update points table ([`0e9957f`](https://github.com/embeddings-benchmark/mteb/commit/0e9957f9eadf873b901484218174f6483c152532))

## v1.8.1 (2024-05-06)

### Fix

* fix: XNLI 2.0 subset added  (#623)

* XNLI 2.0 subset added

* added results to xnli2.0

* clean up scraping script xnli2

* XNLI2: lint + points added

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`f62b830`](https://github.com/embeddings-benchmark/mteb/commit/f62b83047651d94fd0bb1187e40141bfc65741b8))

### Unknown

* Update points table ([`dcaa571`](https://github.com/embeddings-benchmark/mteb/commit/dcaa5715028700c7a452ff9ad045d825347834ba))

* Update tasks table ([`379badb`](https://github.com/embeddings-benchmark/mteb/commit/379badb33425538abf19e861e64588235c344be7))

* Update points table ([`69678a5`](https://github.com/embeddings-benchmark/mteb/commit/69678a5743cc6468117130457da97c8767323219))

* Adding FaroeseSTS dataset (#637)

* add FaroeseSTS dataset

* add FaroeseSTS dataset

* Update 637.jsonl ([`4d9cd29`](https://github.com/embeddings-benchmark/mteb/commit/4d9cd29b45747e5483fa05c79df5802229f6c7b6))

## v1.8.0 (2024-05-05)

### Feature

* feat: Add MLQA dataset for CrossLingual Retrieval (#560)

* feat: add MLQA dataset

* add arabic to german results

* add metadata

* update pair languages mapping

* fix typo

* add paraphrase multilingual-minilm-v6 results

* chore: add comments for corpus and query lang

* rename function

* update language pair format

* add points and update results

* fix: update typing

* fix: update typing ([`7f48327`](https://github.com/embeddings-benchmark/mteb/commit/7f4832772fa693368b07d4c3d19a672ab7a83bad))

### Unknown

* Update tasks table ([`31cdc3c`](https://github.com/embeddings-benchmark/mteb/commit/31cdc3ca35c63b80cde4db42f9b13ed599330556))

* Update points table ([`24145f1`](https://github.com/embeddings-benchmark/mteb/commit/24145f120a1ed0573a18dd4362673ca890f459aa))

## v1.7.64 (2024-05-05)

### Fix

* fix: Add JavaneseIMDBClassification (#632)

* Add JavaneseIMDBClassification

* Add results for JavaneseIMDBClassification

* Add points for new language-task combination

* Add MIT license

* Add average character length

* Add best estimate of dataset date

I based it on the commit history from the original page:
https://github.com/w11wo/nlp-datasets/commit/886db531be0caa2b5e280fc74a7e01c1f425044b

* Add bibtex citation

* Update points table

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`73aa304`](https://github.com/embeddings-benchmark/mteb/commit/73aa304b6d33eb6788fcf15e2138cdd995ac851c))

### Unknown

* Update tasks table ([`1c9fc3d`](https://github.com/embeddings-benchmark/mteb/commit/1c9fc3d55e162fb1899cfc013631bbd17eb1ce30))

* Update points table ([`95c58e8`](https://github.com/embeddings-benchmark/mteb/commit/95c58e887a9c8211e2ba2a0a8af4699b1a78fea5))

## v1.7.63 (2024-05-05)

### Fix

* fix: Add FilipinoShopeeReviewsClassification (#630)

* Add FilipinoShopeeReviewsClassification dataset

* Include run results

* Update points directory

* Update license

* Update points

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`cc7582f`](https://github.com/embeddings-benchmark/mteb/commit/cc7582fcf17144b15ae23a3def702d54788cf13a))

### Unknown

* Update tasks table ([`386169d`](https://github.com/embeddings-benchmark/mteb/commit/386169d3c323d0defe5678ce40447e8e33a396f8))

* Update points table ([`e7731cf`](https://github.com/embeddings-benchmark/mteb/commit/e7731cf3a486e948eb3e699996a773841855a975))

## v1.7.62 (2024-05-05)

### Fix

* fix: CataloniaTweetClassification dataset added (#629)

* CataloniaTweetClassification dataset added

* Cata tweet lint fixes

* points to 629

* CataloniaTweetClassification changed eval splits to classification ([`fe48afe`](https://github.com/embeddings-benchmark/mteb/commit/fe48afe166da101d73ce5224e9cbd1cfe253cd45))

### Unknown

* Update points table ([`170ac1a`](https://github.com/embeddings-benchmark/mteb/commit/170ac1af7b4dd4aecf7cec2355449987d4affcdc))

## v1.7.61 (2024-05-05)

### Fix

* fix: 2 datasets for Georgian language (#633)

* feat: georgian faq dataset

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* fix: language code

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* feat: tbilisi city hall dataset

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* fix: inherit crosslinguality

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* style: make lint

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* chore: results

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* chore: add some metadata

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* refactor: fill metadata

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* fix: add avg length and license

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* fix: license

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* chore: flaky ci?

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* chore: add points

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

---------

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt; ([`1dfae84`](https://github.com/embeddings-benchmark/mteb/commit/1dfae840c8876fe7eb6be204dfa09bf15e00098b))

### Unknown

* Update tasks table ([`9b49f1f`](https://github.com/embeddings-benchmark/mteb/commit/9b49f1f6a766597376b35031150df44dddd3f9c0))

* Update points table ([`a512677`](https://github.com/embeddings-benchmark/mteb/commit/a512677453fc4f6a85806bc3a30afdc0ba7c158f))

## v1.7.60 (2024-05-04)

### Fix

* fix: add Frenk hr dataset (#628)

* add frenk hr dataset

* add points ([`0957eb4`](https://github.com/embeddings-benchmark/mteb/commit/0957eb461801c709c59acabdae22bd9cf3ec91dc))

### Unknown

* Update tasks table ([`104fc8d`](https://github.com/embeddings-benchmark/mteb/commit/104fc8d0a5134fe5bdf77c3c82e3c7e8708274d4))

* Update points table ([`bff248c`](https://github.com/embeddings-benchmark/mteb/commit/bff248c35cf0b7c541b949d158254bf0d28ce537))

## v1.7.59 (2024-05-04)

### Documentation

* docs: add info for LongEmbed (#625)

* add info for LongEmbed
* Update docs/mmteb/points/393.jsonl
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`531cbe0`](https://github.com/embeddings-benchmark/mteb/commit/531cbe030a09208b336bebba3e4b3df78c03ec8d))

### Fix

* fix: Add Frenk en dataset (#627)

* add frenk en dataset

* add points ([`7dd0f16`](https://github.com/embeddings-benchmark/mteb/commit/7dd0f165279c0b52149d7377f7a9a5e863e89dbe))

### Unknown

* Update tasks table ([`0a687ef`](https://github.com/embeddings-benchmark/mteb/commit/0a687ef206a5041368f7e3ddb484dc35cfd2bc81))

* Update points table ([`6f3a55d`](https://github.com/embeddings-benchmark/mteb/commit/6f3a55d68f151e09044dc0608f24103ccbe6826c))

* Update tasks table ([`9762e35`](https://github.com/embeddings-benchmark/mteb/commit/9762e359d7a23090351b579f441fda5ee60b8152))

* Update points table ([`56adb99`](https://github.com/embeddings-benchmark/mteb/commit/56adb99131b9160f867b55ff171b27950b7c17a9))

* Add afri senti lang classification (#564)

* add MIRACLFrReranking dataset

* Add Afri LID dataset

* Add Afri LID dataset

* remove old fr files

* added scores

---------

Co-authored-by: Shreeya Dhakal &lt;shreeyadhakal@Shreeyas-Mac-mini.local&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`07f00a3`](https://github.com/embeddings-benchmark/mteb/commit/07f00a3eac6703a7d2e015b3c5955a8cd82a5b84))

* Update tasks table ([`a662776`](https://github.com/embeddings-benchmark/mteb/commit/a662776ce0b4b433a18569d6a3b17f4af4b4290d))

* Update points table ([`e72612a`](https://github.com/embeddings-benchmark/mteb/commit/e72612a351c10b9d7940db0bda7b911c5ef4ad19))

## v1.7.58 (2024-05-02)

### Ci

* ci: Only attempt push when on main branch ([`c64c189`](https://github.com/embeddings-benchmark/mteb/commit/c64c1898213c615aa309b307aed21fb6ec22c000))

### Fix

* fix: Add new Polish clustering tasks (PL-MTEB) (#607)

* Update contributor information

* Add new Polish clustering tasks based on PLSC - Polish Library of Science Corpus

* Points

* Lint format

* Lint check

* PLSC clustering tasks refactoring

---------

Co-authored-by: rposwiata &lt;rposwiata@opi.org.pl&gt; ([`25087de`](https://github.com/embeddings-benchmark/mteb/commit/25087de051933acc23a6c9fba0612d79f38484a4))

### Unknown

* Update tasks table ([`214be0d`](https://github.com/embeddings-benchmark/mteb/commit/214be0de886033ca996171bc5d2daa47f36d6b97))

* Update points table ([`4b7f9c1`](https://github.com/embeddings-benchmark/mteb/commit/4b7f9c156b0b92e3dd7c3cdae246a222f47f10c0))

* Update tasks table ([`3c17632`](https://github.com/embeddings-benchmark/mteb/commit/3c176323fe4e27fdcd676b2ecbe6b8337ce964b6))

* Update points table ([`24d6227`](https://github.com/embeddings-benchmark/mteb/commit/24d62271e968792c35cf2527541bb394999cb5ba))

*  fix: Add LegalBench datasets - 6 (#622)

* Add LegalBench datasets

* Add points

* Add points for review

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`51adc5f`](https://github.com/embeddings-benchmark/mteb/commit/51adc5f5caf0fe83a8b024257f36a7507580d760))

## v1.7.57 (2024-05-02)

### Fix

* fix: Add LegalBench datasets - 5 (#613)

* Add LegalBench datasets; update n_samples and avg_char_length for CUAD datasets

* Update date for CUAD and ContractNLI datasets

* Add points

* Update date for CUAD and ContractNLI datasets ([`87568f6`](https://github.com/embeddings-benchmark/mteb/commit/87568f695fd408d76efa91b6dc8492e70fa2cde3))

### Unknown

* Update tasks table ([`658a56a`](https://github.com/embeddings-benchmark/mteb/commit/658a56a45c93edf4fa6b3dd086c8d2da2cbacbda))

* Update points table ([`6240d7e`](https://github.com/embeddings-benchmark/mteb/commit/6240d7e78cb2edc31e49f5764dd65d09068d381d))

* Update tasks table ([`775c73c`](https://github.com/embeddings-benchmark/mteb/commit/775c73ce388dca6a47952d92c04965d8de9e2be7))

* Update points table ([`e647f6c`](https://github.com/embeddings-benchmark/mteb/commit/e647f6c7a65ab8c9862f7b880cf976703971512f))

* Add KLUE-TC (Korean Language Understing Evaluation - Topic Classification) dataset (#619)

* add: KLUE-TC (Topic Classification)

* lint

* add socioeconomic_status

* fix: gather label_feature

* add points

* add points

* add : stratified subsampling

* fix for validate_points.py

* Update mteb/tasks/Classification/kor/KlueTC.py

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`ff6f08d`](https://github.com/embeddings-benchmark/mteb/commit/ff6f08dfe67b643e251db5bf10b8437be54a521f))

## v1.7.56 (2024-05-02)

### Fix

* fix: Fix Docs CI Workflow (#621)

* add back end of table
* points
* Update docs/mmteb/points/621.jsonl ([`778355d`](https://github.com/embeddings-benchmark/mteb/commit/778355db702d1759bcb8ed67f78035908e3534db))

### Unknown

* Update points table ([`9425bc8`](https://github.com/embeddings-benchmark/mteb/commit/9425bc8d5d031eb3bce5d3d038593a81a4feacc8))

## v1.7.55 (2024-05-02)

### Fix

* fix: BSARDRetrieval dataset (#615)

* Removing extra join in query preparation

* changing main score to recall at 100

* add extra space

* updating results

* Adding points

---------

Co-authored-by: Wissam Siblini &lt;wissam.siblini@komodohealth.com&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`3c32c40`](https://github.com/embeddings-benchmark/mteb/commit/3c32c40c6231adddb072649f04dd88b747e31bbd))

### Unknown

* Update points table ([`a45187d`](https://github.com/embeddings-benchmark/mteb/commit/a45187df712e3819af7920c233a64c32379f5f79))

## v1.7.54 (2024-05-02)

### Fix

* fix: Add Hindi dialect classification (#616)

* first commit for Telugu News Classification

* revert to original main

* complete langauges part

* add results

* fix import

* ruffen the code

* change acc-&gt;f1

* add points

* fix licence

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`9939715`](https://github.com/embeddings-benchmark/mteb/commit/9939715c0ca2ea7621d05b2d04a485839582f3a4))

### Unknown

* Update points table ([`6611ab7`](https://github.com/embeddings-benchmark/mteb/commit/6611ab74f8e142dcdd1922ff4143d87dd9ead1fc))

## v1.7.53 (2024-05-02)

### Documentation

* docs: Add points for LegalBench datasets - 4 (#611) (#612)

Add points for #611

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`fbce958`](https://github.com/embeddings-benchmark/mteb/commit/fbce958171edc12f6b27a9401f2dd4454754d054))

### Fix

* fix: CodeEditSearch: Instruction -&gt; Diff retrieval (#594)

* new task

* edits

* added langs

* fix

* dates

* points

* citation

* review pr points

* remove

* fix split size

* fix lint

* results

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`a9aa486`](https://github.com/embeddings-benchmark/mteb/commit/a9aa486e09cb8c1db38510e6d432fa4901c5f11a))

### Unknown

* Update points table ([`59dd397`](https://github.com/embeddings-benchmark/mteb/commit/59dd397f0c78cadd6b0a4ee375eb8f1fa14a8e56))

* Update points table ([`4dc41f1`](https://github.com/embeddings-benchmark/mteb/commit/4dc41f19447d5dd76fc9ea72c55259ed9055258c))

* Update tasks table ([`3740795`](https://github.com/embeddings-benchmark/mteb/commit/37407956817c24e1e798e68281b3acf4b1f98fda))

* Update points table ([`e747af6`](https://github.com/embeddings-benchmark/mteb/commit/e747af6c1e220b76478031a54709656e261bb3a2))

* Add Yahoo answers dataset (#509)

* add yahoo dataset

* PR comments

* final updates

* fill all metadta

* fix test

* make bibtex_citation empty str

* commit suggestion

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* fix linting

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`a0a88ef`](https://github.com/embeddings-benchmark/mteb/commit/a0a88efabdf58585e9a2aa8ce1eca16a198da1f7))

## v1.7.52 (2024-05-01)

### Fix

* fix: Add LegalBench datasets - 4 (#611)

* Reorganize datasets for better readability; add additional citations

* Update descriptions for all tasks

* Add LegalBench datasets ([`ad314cf`](https://github.com/embeddings-benchmark/mteb/commit/ad314cf9c717ac490efdee4a73322de26da01c03))

### Unknown

* Update tasks table ([`b8864f2`](https://github.com/embeddings-benchmark/mteb/commit/b8864f2cadd81d828b4897e9a0520a8891f02380))

## v1.7.51 (2024-05-01)

### Fix

* fix: Add new languages to NTREX (#543)

* Add 21 additional (new)  languages to NTREX

* Improved subsampling of language pairs

* add results

* added points: 21 new languages to NTREX -&gt; 84 points

* fixed review suggestions

* add results for all-MiniLM-L6

* lint fix

* add results for 1997

* lint fix

* update points

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`809e1ee`](https://github.com/embeddings-benchmark/mteb/commit/809e1ee0a4ba016c6ae35c925f55aa737a9224a8))

### Unknown

* Update tasks table ([`9e091cf`](https://github.com/embeddings-benchmark/mteb/commit/9e091cf3f554d636a979f7c2b55f0323c87733e6))

* Update points table ([`210efe3`](https://github.com/embeddings-benchmark/mteb/commit/210efe3171bcc6f0a985a5c012bba08ae29b5ce0))

## v1.7.50 (2024-04-30)

### Fix

* fix: Fast loading for cross lingual tasks (#572)

* fast loading for bitext mining

* lint

* consistency

* bump datasets version

* add polars dependency

* loader mixin

* documentation for fast loading

* detail

* fix tests

* tatoeba dataset in mteb org

* added points

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`aa2ffe8`](https://github.com/embeddings-benchmark/mteb/commit/aa2ffe8dad092bb333260148652cfad67cf757c7))

### Unknown

* Update points table ([`b011ae3`](https://github.com/embeddings-benchmark/mteb/commit/b011ae3aa857503543c8a4c7b7f2efa49f7c0172))

* Update points table ([`08800ad`](https://github.com/embeddings-benchmark/mteb/commit/08800adb975cd3d800132559a94117e844f3f2c6))

* get_task now filters languages in multilingual tasks (#604)

* bugfix language in bibleNLP

* Added deep language filtering

* added points

* removed extra lines from jsonl file

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`8f69a34`](https://github.com/embeddings-benchmark/mteb/commit/8f69a34449428f24872f2717703dab7cf7b7071a))

## v1.7.49 (2024-04-30)

### Fix

* fix: Add sentiment classification datasets as one multilingual task (#575)

* fix: add multlingual sentiment classification

* fix: remove old tasks and fix typo

* chore: add nb  samples

* chore:update comment

* chore: remove useless import

* add Welsh train split

* fix: add linting

* chore: add points and remove old eval files ([`ef53f68`](https://github.com/embeddings-benchmark/mteb/commit/ef53f6898d4c184771d2f4f2b56e21361ffaa2de))

### Unknown

* Update tasks table ([`39f90eb`](https://github.com/embeddings-benchmark/mteb/commit/39f90eb97281e2f9c49037b83907322e16107fd4))

* Update points table ([`46f1701`](https://github.com/embeddings-benchmark/mteb/commit/46f1701b0ff581f8a3460dca1018021396febd9d))

## v1.7.48 (2024-04-30)

### Fix

* fix: Add LegalBench datasets - 3 (#579)

* Add datasets

* Move LegalBench datasets to single file

* Add points

* Combine PC datasets

* Remove redundant PC results

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`07b04e6`](https://github.com/embeddings-benchmark/mteb/commit/07b04e683bdb836948a973c2e106b993d7e38dc7))

### Unknown

* Update tasks table ([`b519042`](https://github.com/embeddings-benchmark/mteb/commit/b519042a28c5e4e875c66000036dc19b9408fa6c))

* Update points table ([`0a373b0`](https://github.com/embeddings-benchmark/mteb/commit/0a373b0e9736555a2c2ba2f2f301ab6123127b7d))

## v1.7.47 (2024-04-30)

### Documentation

* docs: fixed error in points ([`6385153`](https://github.com/embeddings-benchmark/mteb/commit/638515361ca37e2b6c684abf72c9d359cf2f2ffe))

### Fix

* fix: TweetTopicSingleClassification added (#603)

* TweetTopicSingleClassification added
* Update mteb/tasks/Classification/eng/TweetTopicSingleClassification.py
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Update mteb/tasks/Classification/eng/TweetTopicSingleClassification.py
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* TweetTopicSingleClassification points added
---------
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`ec2579e`](https://github.com/embeddings-benchmark/mteb/commit/ec2579e0c0be10ecc4561d99ebc0372eb02cce9c))

### Unknown

* Update points table ([`8e19d10`](https://github.com/embeddings-benchmark/mteb/commit/8e19d10786f7b6eed7d7d430a12a3d7c0123f3fd))

* Update points table ([`99d17f0`](https://github.com/embeddings-benchmark/mteb/commit/99d17f0427edd3240da2832c1a8dbf5d3c01b66d))

* Update tasks table ([`8aa4de2`](https://github.com/embeddings-benchmark/mteb/commit/8aa4de20f3b6e3f70afabb32b6a5ea7042419aee))

* Add Spanish Sentiment dataset (#539)

* add spanish sentiment dataset

* PR comments

* add points

* PR comments

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`cac06fa`](https://github.com/embeddings-benchmark/mteb/commit/cac06fa7bdec20224f909208dcaa66a9ae0a8b83))

## v1.7.46 (2024-04-29)

### Fix

* fix: Add Multiple Sentiment/Hate Speech Classification Datasets (#598)

* new dataset GermanPoliticiansTwitterSentiment

* add HateSpeechPortugueseClassification dataset (new language)

* Added multilingual tweet sentiment classification dataset (8 languages, 1 new)

* update points

* Rename 595.jsonl to 598.jsonl

* update files

* update files

* make lint

* update scores

* Update mteb/tasks/Classification/multilingual/TweetSentimentClassification.py

* Update mteb/tasks/Classification/por/HateSpeechPortugueseClassification.py

* update scores

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`9db1dde`](https://github.com/embeddings-benchmark/mteb/commit/9db1dde9dfd2c099a252c1fd199afd73996f8b45))

### Unknown

* Update tasks table ([`0a28e82`](https://github.com/embeddings-benchmark/mteb/commit/0a28e82eacf3de42bda071db0cf7990be4f33b11))

## v1.7.45 (2024-04-29)

### Fix

* fix: count_languages func added (#589)

* count_languages func added

* mteb/get_tasks.py lint fix

* fix improts in get_tasks

* fixed exclude_superseeded

* introduced MTEBTasks collection

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`f740929`](https://github.com/embeddings-benchmark/mteb/commit/f740929329f05d2fc4893237a3d1cfe4f1e151a5))

## v1.7.44 (2024-04-29)

### Fix

* fix: Add XNLI as multilingual pair classification (#600)

* add XNLI
* make lint
* add run results
* fill in meta
* stratify sampling
* add points
* make ilnt ([`7f8f14d`](https://github.com/embeddings-benchmark/mteb/commit/7f8f14d446861f700a674b7f60cb99aa050c6e78))

### Unknown

* Update tasks table ([`ba3793a`](https://github.com/embeddings-benchmark/mteb/commit/ba3793af8799718780c27897495eeb74aecbcf96))

* Update points table ([`e2b56e7`](https://github.com/embeddings-benchmark/mteb/commit/e2b56e7fa7233e3a40847c66b3877b2508f0424c))

## v1.7.43 (2024-04-29)

### Fix

* fix: Fix instructions in DRESModel (#580)

* fix

* fix ([`a3e8b91`](https://github.com/embeddings-benchmark/mteb/commit/a3e8b91625d2bff021333158c50b13b074d014b3))

## v1.7.42 (2024-04-29)

### Fix

* fix: SIB200Classification dataset added (#545)

* SIB200Classification dataset added

* amendments to SIB200Classification

* tran, val added to SIB200Classification

* points added ([`1846e73`](https://github.com/embeddings-benchmark/mteb/commit/1846e732bd802fffeafabd473e3e7354736c9af1))

### Unknown

* Update tasks table ([`3f6929e`](https://github.com/embeddings-benchmark/mteb/commit/3f6929ec0751e186b1f478e33b506441892a588e))

* Update points table ([`08857cc`](https://github.com/embeddings-benchmark/mteb/commit/08857cc0e9e04d5cb366be9a19d652cdefa9b4bb))

## v1.7.41 (2024-04-28)

### Fix

* fix: add Arabic Jordanian General Tweets (AJGT) corpus (#592)

* added AJGT corpus

* made changes based on comments and added points ([`41b51a9`](https://github.com/embeddings-benchmark/mteb/commit/41b51a9f66b5c03e12881bbd38d7817a413ec700))

### Unknown

* Update tasks table ([`34f3956`](https://github.com/embeddings-benchmark/mteb/commit/34f39569d021d1d21b286d7c9e4c7e9371f125fd))

* Update points table ([`7362745`](https://github.com/embeddings-benchmark/mteb/commit/73627459b0ed22b426595a82345d5ea330bf016c))

## v1.7.40 (2024-04-28)

### Fix

* fix: Add BibleNLP dataset (#583)

* Add BibleNLP multilingual corpus
* added results
* addressed review comments
* calculated points
* fix style typo
* fix style typo ([`593fc8f`](https://github.com/embeddings-benchmark/mteb/commit/593fc8fcdfc6e0c2a38c559748c332451559b3ee))

### Unknown

* Update tasks table ([`c2f7614`](https://github.com/embeddings-benchmark/mteb/commit/c2f76141577d5c14aa837d4da5faa563498f1468))

* Update points table ([`6eea696`](https://github.com/embeddings-benchmark/mteb/commit/6eea6960713fd0032786c7319f8e868154df15d5))

## v1.7.39 (2024-04-28)

### Fix

* fix: Add South African Language Identification (#590)

* first commit for Telugu News Classification
* revert to original main
* complete preliminary version
* add results
* add points
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`d5a9a7e`](https://github.com/embeddings-benchmark/mteb/commit/d5a9a7e3571eaf6cd53063ad0ae913532ca9ce0b))

### Unknown

* Update tasks table ([`9bce0c1`](https://github.com/embeddings-benchmark/mteb/commit/9bce0c180668e616a911d71272248f15cfa343fe))

* Update points table ([`70f278f`](https://github.com/embeddings-benchmark/mteb/commit/70f278f78f18794b2456c21705a51f4e731e1f01))

* Update tasks table ([`a7cbda8`](https://github.com/embeddings-benchmark/mteb/commit/a7cbda899f3278534a4952c0162919fd189ce219))

* Update points table ([`ee98eff`](https://github.com/embeddings-benchmark/mteb/commit/ee98eff406e294c8f565df68422fbc4435eb3e17))

* SlovakSumRetrieval added (#561)

* SlovakSumRetrieval added

* added more details to SlovakSumRetrieval

* added more details to SlovakSumRetrieval 2

* SlovakSumRetrieval: confirmed and updated dates

* typo fix

* fixed metadata in SlovakSumRetrieval.py

* points added 561

* SlovakSumRetrieval main score changed to ndcg_at_10

* fixed typo in JaQuADRetrieval

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`18ed280`](https://github.com/embeddings-benchmark/mteb/commit/18ed280ec01f9ebf484f46b34e6f3b2cca0f85f5))

## v1.7.38 (2024-04-27)

### Fix

* fix: Add Odia news classification (#503)

* first commit for Telugu News Classification

* revert to original main

* add preliminary

* stash

* add results

* fix linting

* add points

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`9dd4cd9`](https://github.com/embeddings-benchmark/mteb/commit/9dd4cd97654a10804f5b479e394e6f0fc43c32cb))

### Unknown

* Update tasks table ([`267e0ac`](https://github.com/embeddings-benchmark/mteb/commit/267e0ac14faa2a547ff08082b636d3ca8e71b1fa))

* Update points table ([`f75d471`](https://github.com/embeddings-benchmark/mteb/commit/f75d47121a22ba923792fbb428b6bb66f844f08a))

* Update tasks table ([`689d5b3`](https://github.com/embeddings-benchmark/mteb/commit/689d5b3c76fe666b173f43d5ce77fc01b3c49263))

## v1.7.37 (2024-04-27)

### Fix

* fix: Add LegalBench datasets - 2 (#571)

* Add datasets

* Add points

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`202e0ed`](https://github.com/embeddings-benchmark/mteb/commit/202e0edd67813f076cf601b48f6294419eaa7aea))

### Unknown

* Update points table ([`faa389d`](https://github.com/embeddings-benchmark/mteb/commit/faa389d46a65a7920e45c36d825d7f8cda4b4823))

* Update tasks table ([`e1798b4`](https://github.com/embeddings-benchmark/mteb/commit/e1798b44fbd100e6d52af273839a0eeb3219079e))

* Update points table ([`13ab2ea`](https://github.com/embeddings-benchmark/mteb/commit/13ab2ea56e5028c3979b3187c7ffd256da7eec76))

* Add two sinhala classification datasets (#563)

* add MIRACLFrReranking dataset

* add sinhala classification dataset

* remove old fr files

* remove old fr files

* change dataset version

* updated code and re-ran classification tasks

* add scores

---------

Co-authored-by: Shreeya Dhakal &lt;shreeyadhakal@Shreeyas-Mac-mini.local&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`1d53f58`](https://github.com/embeddings-benchmark/mteb/commit/1d53f58eec750173eaf1d10a24919ebc47ffc819))

* Update tasks table ([`0dc5ed7`](https://github.com/embeddings-benchmark/mteb/commit/0dc5ed793158c872e1962fa8f0b5f45cd28b76c3))

* Update points table ([`0be28a8`](https://github.com/embeddings-benchmark/mteb/commit/0be28a823bdeb527ccd1cd79539599d52fceb3d9))

* FinToxicityClassification added (#585)

* FinToxicityClassification added

* FinToxicityClassification lint fix

* FinToxicityClassification removed stratified subs

* FinToxicityClassification topic changed

* points added to docs/mmteb/points/585.jsonl

* Update 585.jsonl ([`4189cb7`](https://github.com/embeddings-benchmark/mteb/commit/4189cb75540d36c80c18d7af190dc87137ba634c))

* Update points table ([`a9ff392`](https://github.com/embeddings-benchmark/mteb/commit/a9ff392720fa43335010569693429ee381c937e7))

* Update tasks table ([`25e6eac`](https://github.com/embeddings-benchmark/mteb/commit/25e6eac0352d6bf685e0e265f1f52dd66bbd4d95))

* UkrFormalityClassification added (#574)

* UkrFormalityClassification added

* cleanup UkrFormalityClassification

* points added

* Update 574.jsonl

* UkrFormalityClassification transform fix

* Update 574.jsonl ([`bc833f5`](https://github.com/embeddings-benchmark/mteb/commit/bc833f5d53bd74d3dcfffbcab5f8977da773865b))

* Update points table ([`ca2f340`](https://github.com/embeddings-benchmark/mteb/commit/ca2f34057442a973d1a5109a751b7da23aabcb0a))

* Update tasks table ([`af70797`](https://github.com/embeddings-benchmark/mteb/commit/af70797fa666b9261c3a969d97b41143c84e7bc3))

* Add slv dataset (#576)

* add MIRACLFrReranking dataset

* remove old fr file

* add svl data and results

* change formatting

* add points

---------

Co-authored-by: Shreeya Dhakal &lt;shreeyadhakal@Shreeyas-Mac-mini.local&gt; ([`53ed6b1`](https://github.com/embeddings-benchmark/mteb/commit/53ed6b15af4dab2fcbd867524054210d07dedd08))

## v1.7.36 (2024-04-26)

### Fix

* fix: languages is a sorted-list now (#578)

* refactor: languages is a sorted-list now

* refactor: fix linting

* remove newline

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`adcc8c6`](https://github.com/embeddings-benchmark/mteb/commit/adcc8c6101a9ccdc8e678cbd591d2153d1d56f44))

### Unknown

* Update points table ([`f62fd99`](https://github.com/embeddings-benchmark/mteb/commit/f62fd99579251e6b0016118f3d6d9e01d21c6f82))

## v1.7.35 (2024-04-26)

### Fix

* fix: Add GreekCivicsQA and results (#570)

* add GreekCivicsQA and results
* remove title
* points
* use sha256 yields the same results
* make lint ([`94c3b9a`](https://github.com/embeddings-benchmark/mteb/commit/94c3b9a29618d9c1cf059ae72f2e9119ea0e0273))

### Unknown

* Update tasks table ([`2452aee`](https://github.com/embeddings-benchmark/mteb/commit/2452aeee3e7a7c8c878202255f8ee7b9ea3024ba))

* Update points table ([`3964256`](https://github.com/embeddings-benchmark/mteb/commit/39642568ae122ae0fd49f4281a18f39115adcbf5))

## v1.7.34 (2024-04-26)

### Fix

* fix: Add DBpedia dataset (#501)

* add dbpedia dataset

* add points

* PR comments

* calc results again

* fill all metadata

* fix test

* Update docs/mmteb/points/501.jsonl

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`c49de83`](https://github.com/embeddings-benchmark/mteb/commit/c49de833fc11544e3623267e87df7c50ed7104cf))

### Unknown

* Update tasks table ([`b93e595`](https://github.com/embeddings-benchmark/mteb/commit/b93e59551e32d559bf208df7bc55d872e33ff6a7))

* Update points table ([`a5b75e0`](https://github.com/embeddings-benchmark/mteb/commit/a5b75e025271a3f6375b4f0024dc094280769d90))

## v1.7.33 (2024-04-26)

### Fix

* fix: Add Big Patent Classification dataset (#497)

* add MIRACLFrReranking dataset

* remove old fr file

* re-add patent data

* fix for mat issue

* add dataset and result files

* add bibtex

* add scores

---------

Co-authored-by: Shreeya Dhakal &lt;shreeyadhakal@Shreeyas-Mac-mini.local&gt; ([`5baeb90`](https://github.com/embeddings-benchmark/mteb/commit/5baeb9009e26159e6951003e2799a69146031565))

### Unknown

* Update tasks table ([`06d9794`](https://github.com/embeddings-benchmark/mteb/commit/06d9794263ff5b22118ce736d2dbcab0041dfe95))

* Update points table ([`29f4fb1`](https://github.com/embeddings-benchmark/mteb/commit/29f4fb1610405da65f79a0149df0b9bad9b14e9c))

* Update tasks table ([`7102977`](https://github.com/embeddings-benchmark/mteb/commit/7102977eeb8fb2c8540256ab5669c3f144390a21))

* Update points table ([`9fb3e37`](https://github.com/embeddings-benchmark/mteb/commit/9fb3e37a1e381c134a097ef0878a890cb9cde44e))

* Add XQuAD dataset in Retrieval task (#565)

* add XQuAD dataset in Retrieval task

* update metadata and make data loading efficient

* add points for contribution

* add contributor information to README

* update points ([`c7a7b36`](https://github.com/embeddings-benchmark/mteb/commit/c7a7b36eff8d4fb42e26fe10fd4ef3933022a78c))

* Update points table ([`28e5522`](https://github.com/embeddings-benchmark/mteb/commit/28e55225dd2fd4d68f6598fae5f3be43cac7e30b))

* Check that metadata is filled (#550)

* fix: don&#39;t change bibtex citation to &#34;&#34; for historic datasets

* specify empty values for dialect and bibtex

* chore: move historic datasets to test file

* fix: update taskmetadata in adding a dataset example

* chore: update datasets without filled metadata

* chore: lint

* 1.7.31

Automatically generated by python-semantic-release

* chore: add new datasets without filled metadata to whitelist

* chore: delete unused file

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: github-actions &lt;github-actions@github.com&gt; ([`49353d6`](https://github.com/embeddings-benchmark/mteb/commit/49353d6e8c809c75de353d74a69c116551299aa7))

* Update tasks table ([`8088e65`](https://github.com/embeddings-benchmark/mteb/commit/8088e65b9cf6cac6bdf0ccd081f3226fdd71df37))

## v1.7.32 (2024-04-25)

### Fix

* fix: Add LegalBench datasets (#515)

* Add LegalBench: Canada Tax Court Outcomes dataset

* Apply suggestions from code review

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Make changes based on review; Add information to points table

* Add additional datasets

* Add points

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`53429e1`](https://github.com/embeddings-benchmark/mteb/commit/53429e1d50327a553b1030fdfa8a889b1723dd49))

### Unknown

* Update points table ([`d634c13`](https://github.com/embeddings-benchmark/mteb/commit/d634c1329cf1b648846ad466533269a7b2c4ed00))

## v1.7.31 (2024-04-25)

### Fix

* fix: Converted german clustering task to fast (#528)

* Added get tasks getter

* Updated german clusterings tasks

* Added meta

* docs: Added points ([`1e44b98`](https://github.com/embeddings-benchmark/mteb/commit/1e44b98535eb612551a5d8f68378b45e3a51670c))

* fix: Make MLSUM a multilingual task (#556)

* fix: make MLSUM multilingual

* chore: add result

* fix: update languages

* chore: add linting

* fix: add bibtext citation

* Update mteb/tasks/Clustering/multilingual/MLSUMClusteringP2P.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* chore: add minilm results and comment

* chore: add more results

* chore: update metadata

* Update mteb/tasks/Clustering/multilingual/MLSUMClusteringP2P.py

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;

* chore: add points

* chore: fix metadata

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`b02f481`](https://github.com/embeddings-benchmark/mteb/commit/b02f48146be608c558e1a742dd54196bc0031fc3))

### Unknown

* Update tasks table ([`f52fe21`](https://github.com/embeddings-benchmark/mteb/commit/f52fe2100067e7851c3720f392e8284a4a90f90e))

* Update points table ([`ce56c1c`](https://github.com/embeddings-benchmark/mteb/commit/ce56c1c733244e8021143981815c1f7ebd370f0e))

* Update points table ([`ad6f3d8`](https://github.com/embeddings-benchmark/mteb/commit/ad6f3d871b55110a91be4a1d812fc89a84a4d4c0))

* Update tasks table ([`fbc1b59`](https://github.com/embeddings-benchmark/mteb/commit/fbc1b59dc453337d17485def7af4e46ab16788e7))

* Update points table ([`1f4b14e`](https://github.com/embeddings-benchmark/mteb/commit/1f4b14ef18452ce94b87ae38e624220c0df8fd14))

* Add Sanskrit Shlokas Dataset (#506)

* Add Sanskrit Shlokas Dataset

* Add model results and review changes

* Add model results and review changes

* Add points ([`0486777`](https://github.com/embeddings-benchmark/mteb/commit/048677712943cc27158e2d7745882781c26bc2c8))

## v1.7.30 (2024-04-25)

### Fix

* fix: Change MultiHateClassification to use dataset_transform (#558)

* change MultiHateClassification to use dataset_transform istead of overloading load_dataset

* added points

* Update docs/mmteb/points/558.jsonl

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`2a3cd79`](https://github.com/embeddings-benchmark/mteb/commit/2a3cd79352860669623f096aa0125738f40c6a65))

### Unknown

* Update points table ([`f79217a`](https://github.com/embeddings-benchmark/mteb/commit/f79217abb1ce6c6e88b3ecee5069e578ee66db01))

## v1.7.29 (2024-04-25)

### Fix

* fix: Add Tamil news classification (#484)

* first commit for Telugu News Classification
* revert to original main
* add first commit for integrating tamil news classification
* run models and add rsults
* add stratifstratified_subsampling
* add results after stratified
* add f1 as main score
* correct points
* correc dialect ([`5a8ca99`](https://github.com/embeddings-benchmark/mteb/commit/5a8ca99a70670208fe75db335d0c8285bb2357cc))

* fix: Add Malayalam news classification (#485)

* first commit for Telugu News Classification
* revert to original main
* add first commit for integrating malayalam news classification
* minor typo fixes
* add points
* fix ruff errors
* change dataset_transform
* add results ([`aea61f5`](https://github.com/embeddings-benchmark/mteb/commit/aea61f5cbed5e77ef81775f036f7d542671b8be1))

### Unknown

* Update tasks table ([`01f96e2`](https://github.com/embeddings-benchmark/mteb/commit/01f96e2ec074eb594f5d95f9805ec341ed75ca8f))

* Update points table ([`7837b9f`](https://github.com/embeddings-benchmark/mteb/commit/7837b9f5cce07cca611dbf9f8edd7774526d5a98))

## v1.7.28 (2024-04-25)

### Fix

* fix: Telugu news classification (#557)

* first commit
* complete generating results
* do linting
* add points
* fix description
* correct dialect setting
* Update docs/mmteb/points/557.jsonl
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
* Apply suggestions from code review
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`e3b1ba7`](https://github.com/embeddings-benchmark/mteb/commit/e3b1ba722dadf4c51f405e3cd2271ae35e7601cb))

### Unknown

* Update tasks table ([`bae3b6a`](https://github.com/embeddings-benchmark/mteb/commit/bae3b6a83a7b0657543167bf06f4563119f7053d))

* Update points table ([`279e1f1`](https://github.com/embeddings-benchmark/mteb/commit/279e1f12472cff03709f179894f9e8d14a188aaa))

## v1.7.27 (2024-04-24)

### Fix

* fix: Fix minor bugs in FollowIR implementation; bump datasets revision id to the fixed version (#555)

* add web downloading for prediction files, update followir hf links

* fix ablation

* update the un-patched version

* undo merge conflict error

* update sizes

* cleanup

* add lint ([`7b6d2ec`](https://github.com/embeddings-benchmark/mteb/commit/7b6d2ecc72c5af19d5fdcee71a0f166043bbb7a0))

* fix: Add IndicQA dataset in Retrieval task (#547)

* add Indic clustering dataset

* update module import statement

* add points for the contribution

* add IndicQA dataset in Retrieval task

* add points for the dataset contribution

* update metadata and points

* update number of samples in metadata ([`6eeb596`](https://github.com/embeddings-benchmark/mteb/commit/6eeb596a4e19459386aed62bca96e48e68fcaab0))

### Unknown

* Update tasks table ([`ab29165`](https://github.com/embeddings-benchmark/mteb/commit/ab29165df35c5d5c98a384199a4503a9b56977df))

* Update points table ([`3b98f48`](https://github.com/embeddings-benchmark/mteb/commit/3b98f483963eedf6eade795d525628e72e646e59))

* Update tasks table ([`4fec8d5`](https://github.com/embeddings-benchmark/mteb/commit/4fec8d5ffbcf7c0ae040dc3fa638eaa592638223))

* Update points table ([`94db149`](https://github.com/embeddings-benchmark/mteb/commit/94db1490e2e38b246217ae7036bcfc4df52d5b81))

* Add SRNCorpus (#551)

* Add SRNCorpus

* Add SRNCorpus

* add points: 2 for new dataset, 4 for new language -&gt; 6 points

* Update mteb/tasks/BitextMining/srn/SRNCorpusBitextMining.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* lint change

* add points for reviewing

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`e947a56`](https://github.com/embeddings-benchmark/mteb/commit/e947a56c94f2e08bb36faf856fdc2fd2073a1df9))

## v1.7.26 (2024-04-24)

### Fix

* fix: Fill metadata for Danish datasets (#549)

* chore: fill metadata for BornholmBitextMining

* chore: add bibtex

* fill metadata for angrytweets

* fill metadata for DKHateClassification

* fix: move dalaj to swedish and fill metadata

* add metadata for LCC

* style: lint

* add points

* add information for publication ([`be8eced`](https://github.com/embeddings-benchmark/mteb/commit/be8eced8cf327c60c2d815a7793386e0dbb4183b))

### Unknown

* Update tasks table ([`1bea436`](https://github.com/embeddings-benchmark/mteb/commit/1bea43631576a7ff9b59a4d61e117928bdf2649b))

* Update points table ([`f0b34e8`](https://github.com/embeddings-benchmark/mteb/commit/f0b34e8f2a0493cfc55804a0683ba73463cbe302))

## v1.7.25 (2024-04-24)

### Fix

* fix: Add Urdu Latin Sentiment Classification Dataset (#535)

* Add Urdu Roman Sentiment Classification Dataset

* Add review changes

* Add points ([`aed0c75`](https://github.com/embeddings-benchmark/mteb/commit/aed0c758408d8f4f638b0848aac4ebea988b20be))

### Unknown

* Update tasks table ([`7dca0f7`](https://github.com/embeddings-benchmark/mteb/commit/7dca0f7df362d220b4ae82a87cf49a8166cff0d6))

* Update points table ([`742013e`](https://github.com/embeddings-benchmark/mteb/commit/742013e93b590af34ff464e580aaedbad6f73f68))

## v1.7.24 (2024-04-24)

### Fix

* fix: added the first thai classification dataset (#538)

* added thai sentiment dataset

* all changes based on comments made. models rerun and points added

* Update mteb/tasks/Classification/tha/wisesight_sentiment_classification.py

* Update docs/mmteb/points/538.jsonl

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`5f5935c`](https://github.com/embeddings-benchmark/mteb/commit/5f5935c93baaff217684da160a010b2205e7a075))

### Unknown

* Update tasks table ([`e988b7b`](https://github.com/embeddings-benchmark/mteb/commit/e988b7bd827fdf4b2eebb7656dfe1944e3cc44b0))

* Update points table ([`c7c7758`](https://github.com/embeddings-benchmark/mteb/commit/c7c775847145353a55425995fbccc3ec9160138b))

## v1.7.23 (2024-04-24)

### Fix

* fix: Add Financial Phrasebank dataset (#499)

* add dataset
* add points
* PR comments
* add rough dates based on paper
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`c79a509`](https://github.com/embeddings-benchmark/mteb/commit/c79a509b0f17bdd4e402126109cb8280fd5fdac5))

### Unknown

* Update tasks table ([`b2dc594`](https://github.com/embeddings-benchmark/mteb/commit/b2dc5943781ca99cb1d38e81f59a7873d1d188f2))

* Update points table ([`4e398be`](https://github.com/embeddings-benchmark/mteb/commit/4e398bee8a8462d526221dfcb51c48a9e6b20135))

## v1.7.22 (2024-04-24)

### Documentation

* docs: Updated ordering of languages ([`6faae86`](https://github.com/embeddings-benchmark/mteb/commit/6faae8658f47d5bebc79a665529740b472519856))

### Fix

* fix: AddingGeorgian Sentiment Classification (#534)

* Adding First Georgian Dataset
* Points
* Update __init__.py
* Update __init__.py ([`31d3b57`](https://github.com/embeddings-benchmark/mteb/commit/31d3b5794a92430b6f2049e3c224cf89a3ba24a6))

* fix: Update previous tasks and scores using new subsampling function (#527)

* update sampling on old tasks

* update paraphrase minilm v12 results

* chore: add linting

* fix: update missing results

* fix: update ToxicChatClassification languages

* chore: add linting

* chore: add points ([`7b595d7`](https://github.com/embeddings-benchmark/mteb/commit/7b595d7ba1d60423a882af328725ad641008db2e))

### Unknown

* Update tasks table ([`d4ba114`](https://github.com/embeddings-benchmark/mteb/commit/d4ba1148341b41acfda60ad0cdc015684803bf81))

* Update points table ([`d08dc76`](https://github.com/embeddings-benchmark/mteb/commit/d08dc76abb41c42ac26ecca4fb7dba7c70e93081))

* Update points table ([`768b7a2`](https://github.com/embeddings-benchmark/mteb/commit/768b7a241ae62bf97521fd3671741c961ec84fec))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`f3044b1`](https://github.com/embeddings-benchmark/mteb/commit/f3044b1119bc06a0ee6becb983612d9470233051))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`10f3d4b`](https://github.com/embeddings-benchmark/mteb/commit/10f3d4b369e3e94bb82b3f0dc9d7436b74e9791a))

## v1.7.21 (2024-04-24)

### Ci

* ci: Fix create tasks table loop by sorting languages (#541)

sort languages ([`ed16cbf`](https://github.com/embeddings-benchmark/mteb/commit/ed16cbffd78886b9accb26feebd50105a3c933c7))

### Fix

* fix: First Turkish Retrieval dataset (#533)

* First Turkish Retrieval dataset
* linted
* linted again
* Update mteb/tasks/Retrieval/tur/TurHistQuad.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Only consider eval_splits and points
* Update docs/mmteb/points/533.jsonl
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`6607f2f`](https://github.com/embeddings-benchmark/mteb/commit/6607f2fc80620c0e6e841e5fb7d3007b68116f04))

* fix: Added Sentiment Analysis Bengali Dataset (#536)

* Added Hindi sentiment analysis dataset
* Made changes based on comments and added points on points table
* linted correctly
* bengali sentiment analysis dataset
* Added Sentiment Analysis Bengali Dataset
* deleted old hindi sentiment files
* removed hindi points
* updated all references, rerun tests, and added points ([`ba9bcaa`](https://github.com/embeddings-benchmark/mteb/commit/ba9bcaa2dc976de407b05da86176d8929ee5e96e))

* fix: Add Armenian Paraphrase Dataset (#537)

* First Armenian Dataset
* added points ([`37bf08e`](https://github.com/embeddings-benchmark/mteb/commit/37bf08ebd59fedeead29ced1293095a25564447e))

* fix: Added encoder interfaces (#469)

* docs: Added script for creating point

* ci: enable linting on all PRs

* ci: Added missing dependency

* docs: Added points

* fix: Added encoder interfaces

* Update mteb/encoder_interface.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`7625b1d`](https://github.com/embeddings-benchmark/mteb/commit/7625b1d15cdc55248ecc2cc9873732c4dd3f9cc0))

* fix: add Multilingual Hate Speech detection task (#439)

* resolve conflicts

* remove legacy results

* remove legacy itahate results

* load from new mteb-hosted dataset and align metadata

* add results

* complete rebase

* create points file

* remove old ita hatespeech results

* restore correct init file for classification tasks

* rerun with all languages

* add points ([`eee7175`](https://github.com/embeddings-benchmark/mteb/commit/eee71755a403143f21c2fd09518742c689a36681))

### Unknown

* Update tasks table ([`2b4bfbd`](https://github.com/embeddings-benchmark/mteb/commit/2b4bfbdf7e9e7077d54bccec8c52a34d592f84e6))

* Update tasks table ([`4fc2461`](https://github.com/embeddings-benchmark/mteb/commit/4fc2461c212b9e1b2b182b33bcbedbe7253734df))

* Update points table ([`3895d96`](https://github.com/embeddings-benchmark/mteb/commit/3895d962a2b11b8d0b4ab61652888929bdbf35ad))

* Update tasks table ([`38bbc87`](https://github.com/embeddings-benchmark/mteb/commit/38bbc8756dbfd0d5dfdbc70d6373f784ef30c8f4))

* Update tasks table ([`2337201`](https://github.com/embeddings-benchmark/mteb/commit/233720150875807217b555fd4281641026f22221))

* Update tasks table ([`ee96dc8`](https://github.com/embeddings-benchmark/mteb/commit/ee96dc87f0bfd1383eef3253fe95d8f0db1887d1))

* Update tasks table ([`39740e0`](https://github.com/embeddings-benchmark/mteb/commit/39740e02eb3cbd6a643f606dc8f80b45df93963a))

* Update tasks table ([`69f5b0a`](https://github.com/embeddings-benchmark/mteb/commit/69f5b0a8f9f048eb699b53cc91bb9ec84436578e))

* Update tasks table ([`4e3c3ec`](https://github.com/embeddings-benchmark/mteb/commit/4e3c3ec6da15ffbb9d3e3ba766301e49b425a015))

* Update tasks table ([`f741ff1`](https://github.com/embeddings-benchmark/mteb/commit/f741ff122d031954955de72f407116f1566c24f6))

* Update tasks table ([`5ea9a78`](https://github.com/embeddings-benchmark/mteb/commit/5ea9a78ecc2cf4d185cbd2e35e8f7781d5762048))

* Update tasks table ([`947779e`](https://github.com/embeddings-benchmark/mteb/commit/947779e15b247940f1c34df02016cdeb4c490226))

* Update tasks table ([`a0611ef`](https://github.com/embeddings-benchmark/mteb/commit/a0611ef15a41755d2e324cd63399e2b3574e0420))

* Update tasks table ([`5e6d503`](https://github.com/embeddings-benchmark/mteb/commit/5e6d50362b83b504da9edca2f57e60984368291d))

* Update points table ([`2d3a46f`](https://github.com/embeddings-benchmark/mteb/commit/2d3a46f8d0c6b85e0d9218735240709e0d906da0))

* Update tasks table ([`98aa8ec`](https://github.com/embeddings-benchmark/mteb/commit/98aa8ec89e2f91e797fe6585fd327317748fd36c))

* Update tasks table ([`9bbc86e`](https://github.com/embeddings-benchmark/mteb/commit/9bbc86e0b5b42cf5623d946ba2bc795459ded869))

* Update tasks table ([`39394ea`](https://github.com/embeddings-benchmark/mteb/commit/39394ea58a68edf887ce895f4be0c175d3545331))

* Update points table ([`6a44ef5`](https://github.com/embeddings-benchmark/mteb/commit/6a44ef55c3ede09dda569d5834ece7c0f3dc668e))

* Update points table ([`f14548b`](https://github.com/embeddings-benchmark/mteb/commit/f14548bb096388525ab561bc7836e63d5f26f1b3))

* Update tasks table ([`542ce19`](https://github.com/embeddings-benchmark/mteb/commit/542ce19aeb26b6ab551b39199d0482b849d3cf64))

## v1.7.20 (2024-04-24)

### Documentation

* docs: LB tab instructions (#531)

* LB tab instructions

* Add LB Tab instructions ([`e4e627d`](https://github.com/embeddings-benchmark/mteb/commit/e4e627deef6099d61d062a4297562bc4e7904ef9))

### Fix

* fix: add Clustering dataset for Indic languages (#532)

* add Indic clustering dataset

* update module import statement

* add points for the contribution ([`dc9ba24`](https://github.com/embeddings-benchmark/mteb/commit/dc9ba24bfa48774e488df671bc2fb6df0080c2b3))

### Unknown

* Update tasks table ([`76771c0`](https://github.com/embeddings-benchmark/mteb/commit/76771c0a9e4faff39abc540d1f5dda1e016f2b01))

* Update points table ([`e029d73`](https://github.com/embeddings-benchmark/mteb/commit/e029d736f9ac2159134c6bc84cd090f332e35a05))

* Update tasks table ([`a61de4c`](https://github.com/embeddings-benchmark/mteb/commit/a61de4c011db0f6df2c96311cb535ec05e3b4f00))

* Update tasks table ([`398748f`](https://github.com/embeddings-benchmark/mteb/commit/398748f038d275ed03d29d0453289a4710b2cc07))

* Update tasks table ([`09dd021`](https://github.com/embeddings-benchmark/mteb/commit/09dd021527a1ba0a34f46f7f138faa94b8325939))

* Update tasks table ([`f4606dd`](https://github.com/embeddings-benchmark/mteb/commit/f4606dda9ff79b20e4388b1ffb1eae900384b07d))

* Update tasks table ([`2d5b194`](https://github.com/embeddings-benchmark/mteb/commit/2d5b1945933d93c26ba94a36c2339e61a869474a))

## v1.7.19 (2024-04-24)

### Fix

* fix: Added Kannada News Classification Dataset (#492)

* Added Kannada News Classification Dataset
* made changes according to comments and added points
* Update mteb/tasks/Classification/kan/Kannada_News_Classification.py
* rename and use stratified_subsampling
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`e1b6c1c`](https://github.com/embeddings-benchmark/mteb/commit/e1b6c1c366add45edfea6e4de3aafcee44212d4b))

* fix: Added Hindi sentiment analysis dataset (#491)

* Added Hindi sentiment analysis dataset
* Made changes based on comments and added points on points table
* linted correctly
* use stratified_subsampling
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`4ed19ce`](https://github.com/embeddings-benchmark/mteb/commit/4ed19ce4e48d01ef3f8b4d27f20c8b8a6fed45d9))

* fix: Add yelp review dataset (#478)

* add yelp review dataset
* add results
* PR comments and update results
* add points
* use stratified_subsampling
* rerun with stratified
* fill in metadata from dataset/paper
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`5458f2b`](https://github.com/embeddings-benchmark/mteb/commit/5458f2b81d5e0e15de32eaa9003ae07024339f33))

### Unknown

* Update tasks table ([`95ab467`](https://github.com/embeddings-benchmark/mteb/commit/95ab467ed02263792dc98b68729243c53a1666e1))

* Update points table ([`dccd93d`](https://github.com/embeddings-benchmark/mteb/commit/dccd93d9d248bac312d5b1761bc58b01dfe4a482))

* Update tasks table ([`fdedf69`](https://github.com/embeddings-benchmark/mteb/commit/fdedf6970dc671c86210b1968a91f61c7bbb95a9))

* Update tasks table ([`7a8b323`](https://github.com/embeddings-benchmark/mteb/commit/7a8b3239c380faf566d290dda46191731d4520eb))

* Update tasks table ([`51bd5de`](https://github.com/embeddings-benchmark/mteb/commit/51bd5ded51d23b0faaab39e5902c3bf872dfc5b0))

* Update tasks table ([`0e3a7e2`](https://github.com/embeddings-benchmark/mteb/commit/0e3a7e2271354119739f17da0ebe723770162727))

* Update points table ([`691c448`](https://github.com/embeddings-benchmark/mteb/commit/691c44836822c48b815805f736449bd302502bec))

* Update tasks table ([`230844b`](https://github.com/embeddings-benchmark/mteb/commit/230844bce1eb926fa1be83bb972b9a6678678189))

* Update tasks table ([`d8b3931`](https://github.com/embeddings-benchmark/mteb/commit/d8b39313e2be866e93645ed2e8e8ae4b8be4480f))

* Update tasks table ([`f2393d4`](https://github.com/embeddings-benchmark/mteb/commit/f2393d4a7fd620170e60072f0295e657a8ca05a9))

* Update tasks table ([`f755386`](https://github.com/embeddings-benchmark/mteb/commit/f7553860667db26c749dc285deac19a581cc130f))

* Update tasks table ([`5080c48`](https://github.com/embeddings-benchmark/mteb/commit/5080c4818500d4c2eaa8273a82ee8bc401b6f6f6))

## v1.7.18 (2024-04-24)

### Documentation

* docs: Added create task table (#525)

* Added get tasks getter
* docs: added points
* added create task table
* docs: added points
* Update .github/workflows/docs.yml
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update docs/create_tasks_table.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`5974e05`](https://github.com/embeddings-benchmark/mteb/commit/5974e058abaf0a6d7ccfbd246d535530e974a700))

### Fix

* fix: Add Nepali news classification dataset (#502)

* Add nepali news classification dataset
* Add model results and run tests
* Add review changes and points
* Add review changes and points ([`dd3f0a5`](https://github.com/embeddings-benchmark/mteb/commit/dd3f0a502f1980f969e959cedc2d201560891186))

### Unknown

* Update tasks table ([`6e5735f`](https://github.com/embeddings-benchmark/mteb/commit/6e5735f30f50b3888ff2e2cf825989afd2f5bb53))

* Update tasks table ([`8ce9c0b`](https://github.com/embeddings-benchmark/mteb/commit/8ce9c0ba5a7043216dba1d67e1f4836827b0aed7))

* Update tasks table ([`20210f7`](https://github.com/embeddings-benchmark/mteb/commit/20210f77dbe3cce052c3a420bde32229796f6ee7))

* Update tasks table ([`d29ae53`](https://github.com/embeddings-benchmark/mteb/commit/d29ae53e5ebf65c0c2f4b933938bc87e57d0955c))

* Update tasks table ([`d0caa69`](https://github.com/embeddings-benchmark/mteb/commit/d0caa6966deea036dfdad8697bca1dcbb419ed11))

* Update tasks table ([`519ceb3`](https://github.com/embeddings-benchmark/mteb/commit/519ceb345221f904e7e79567dafcb0b1ac0d8011))

* Update points table ([`5f158d9`](https://github.com/embeddings-benchmark/mteb/commit/5f158d9a8749d8ca4ad17e4bd9659ee3b1aecde9))

## v1.7.17 (2024-04-23)

### Chore

* chore: Move files to correct folder (#526)

move files to correct folder

Co-authored-by: Imene Kerboua &lt;imene.kerboua@esker.com&gt; ([`5370b44`](https://github.com/embeddings-benchmark/mteb/commit/5370b44435e63a9c00e76db51d01812824b559d0))

### Fix

* fix: Add Indic STS benchmark dataset (#524)

* add Indic STS benchmark dataset

* update metadata for Indic STS benchmark

* add points for the contribution

* update reviewer name in points

* downsample the test set size

* Update mteb/tasks/STS/multilingual/IndicCrosslingualSTS.py

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`1f26615`](https://github.com/embeddings-benchmark/mteb/commit/1f2661513c697246ffc816d5f0dcf40a02c1db8e))

### Unknown

* Update points table ([`c3d8602`](https://github.com/embeddings-benchmark/mteb/commit/c3d8602617530b68fcb4c367d78c4abb893b19ae))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`36312ac`](https://github.com/embeddings-benchmark/mteb/commit/36312acd48e7986e7784e7bf30c67da99399e39b))

## v1.7.16 (2024-04-23)

### Fix

* fix: Add get_tasks (#522)

* Added get tasks getter

* docs: added points ([`ede97a1`](https://github.com/embeddings-benchmark/mteb/commit/ede97a15fc6c6dd74ccef4407daa57b5d3088915))

### Unknown

* Update points table ([`b93777a`](https://github.com/embeddings-benchmark/mteb/commit/b93777a47d9902b2b91c22dfa1bdd218a4c58801))

* Update points table ([`252cbc6`](https://github.com/embeddings-benchmark/mteb/commit/252cbc681afaea3ec5760570ce125ad7d7332728))

* Update points for PR 521 (#523)

* Update points for PR 520

* Rename 520.jsonl to 521.jsonl ([`3800141`](https://github.com/embeddings-benchmark/mteb/commit/38001411586283a9f720dfa954c5c24d91fed11f))

## v1.7.15 (2024-04-23)

### Fix

* fix: update current dict and do not remove other splits (#521)

Co-authored-by: Imene Kerboua &lt;imene.kerboua@esker.com&gt; ([`26e7cbd`](https://github.com/embeddings-benchmark/mteb/commit/26e7cbdd2c97e43ebcac7f8eb3a2779fd302c59f))

### Unknown

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`a9108bc`](https://github.com/embeddings-benchmark/mteb/commit/a9108bc999044d50cc2b0a71ce66358bed06906b))

## v1.7.14 (2024-04-23)

### Fix

* fix: Add Indic language identification dataset in Classification category (#514)

* add IndicSentimentClassification dataset for Indic languages
* fix linting
* fix typo in rename columns
* add results for all languages
* add points for the dataset contribution
* add Indic Language Identification dataset
* add points for the dataset addition and PR review
* fix linting issues ([`e1833d5`](https://github.com/embeddings-benchmark/mteb/commit/e1833d545824cc27be45d93a5906682df794ad57))

### Unknown

* Update points table ([`1251e87`](https://github.com/embeddings-benchmark/mteb/commit/1251e87e2af0d3515b6b0b627fd9e347170bee91))

* Added get tasks getter ([`cf31ffa`](https://github.com/embeddings-benchmark/mteb/commit/cf31ffad12040a2abc48e6e88a2b813b471f1181))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`af6691f`](https://github.com/embeddings-benchmark/mteb/commit/af6691f103207c4d681b090133e8d12c3225d9ba))

## v1.7.13 (2024-04-23)

### Fix

* fix: Fast Clustering (#481)

* added outline for fast clustering

* added examples of clustering transformations

* docs: added points

* added superseeded by logic

* format

* Added fast clustering task

* Added results for new datasets

* Typo

* added results

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`8d454bd`](https://github.com/embeddings-benchmark/mteb/commit/8d454bdbcf44ecc89de859bd67903e53052659e2))

### Unknown

* Update points table ([`319aa89`](https://github.com/embeddings-benchmark/mteb/commit/319aa8961f448b6a2d0d31cdd33e42c76e57225d))

* added_outline_for_table ([`8140f5f`](https://github.com/embeddings-benchmark/mteb/commit/8140f5fbfbd5817ff147250bad6a9ed7cdcaaded))

## v1.7.12 (2024-04-23)

### Chore

* chore: Unify subsampling with stratify (#513)

* add stratified_subsampling to`AbsTask`
* dupe key
* try on HotelReviewSentimentClassification
* specify split
* add run results
* hint on PR checklist
* lint and wording
* points ([`10922bb`](https://github.com/embeddings-benchmark/mteb/commit/10922bbb61ddeff810508489ed5ca04c1e8263ae))

### Fix

* fix: Stratify subsample fixes (#518)

* address comments on AbsTask

* check that it runs and produces the same result

* make lint

* updates with seed

* points ([`439ba93`](https://github.com/embeddings-benchmark/mteb/commit/439ba935bbb1017334b0bcc8e765df1f54933182))

### Unknown

* Update points table ([`1bff92a`](https://github.com/embeddings-benchmark/mteb/commit/1bff92a5503822607ad87c778ae59f135168d17c))

* Update points table ([`b33e765`](https://github.com/embeddings-benchmark/mteb/commit/b33e765c594eb13cdc19374d032c75fee6b3703d))

* Update points table ([`6180bd0`](https://github.com/embeddings-benchmark/mteb/commit/6180bd054cba52dfa1a19bc142770143f9028b0e))

* Add NTREX dataset (#409)

* Added TedTalks BitextMining task

* Added NTREX task.

* Update mteb/tasks/BitextMining/multilingual/NTREXBitextMining.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* remove changes unrelated to this PR (#386 got entangled by accident)

* Update mteb/tasks/BitextMining/multilingual/NTREXBitextMining.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update points.md

added points for reviewing

* add points

* small fixes

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`1ebbcd7`](https://github.com/embeddings-benchmark/mteb/commit/1ebbcd7f16f690e7d883dd5e6c1c8eaceae6c654))

## v1.7.11 (2024-04-23)

### Fix

* fix: Add Arxiv classification dataset (#479)

* add dataset
* add results
* run formatter
* update metadata
* add scores
* update metadata based on the comments
* fix date issue
* revert name
* change date type
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`bb56724`](https://github.com/embeddings-benchmark/mteb/commit/bb567240d6363cfa77bd5c318703e9b022e54593))

* fix: Add rerankers to mteb, following `CrossEncoder` (#457)

* init commit

* minor cleanup

* lint

* remove testing file

* change API

* minor cleanup

* update test

* update linter; re-run lint

* updated test

* fix test style

* rename save_qrels

* docs: added points for pr

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`23fe8bd`](https://github.com/embeddings-benchmark/mteb/commit/23fe8bdc99c326a766c811adb27bac828e8bcbc0))

### Unknown

* Update points table ([`723aa6d`](https://github.com/embeddings-benchmark/mteb/commit/723aa6db0f241933111d581b943e11a6dccb69cb))

* Update points table ([`a2924a0`](https://github.com/embeddings-benchmark/mteb/commit/a2924a0d455025e2dc21ecbcfcffffe958372e8a))

## v1.7.10 (2024-04-23)

### Ci

* ci: hotfix for points (#510) ([`032ca25`](https://github.com/embeddings-benchmark/mteb/commit/032ca25d88f246ad12811583384b56261cf6ecb9))

### Fix

* fix: Punjabi news classification (#500)

* first commit for Telugu News Classification
* revert to original main
* add dataset and test it
* add points table
* Apply suggestions from code review
* make lint
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`eda2020`](https://github.com/embeddings-benchmark/mteb/commit/eda2020f59f96ae7b3e18f6a06c789aad71062c0))

### Unknown

* Update points table ([`3cd2da0`](https://github.com/embeddings-benchmark/mteb/commit/3cd2da0eb2822e5cb82591baabb2738cd8a5bb0f))

* Update points table ([`005f50c`](https://github.com/embeddings-benchmark/mteb/commit/005f50c5057f9f1d294530bfe0e00a6c056a68d5))

## v1.7.9 (2024-04-23)

### Fix

* fix: add IndicSentimentClassification dataset for Indic languages (#489)

* add IndicSentimentClassification dataset for Indic languages
* fix linting
* fix typo in rename columns
* add results for all languages
* add points for the dataset contribution ([`61ffadf`](https://github.com/embeddings-benchmark/mteb/commit/61ffadf8ed19737de175a1a082ee9f9a7452fa0f))

### Unknown

* add finnish paraphrase-based STS dataset (#487)

* add finnish paraphrase-based STS dataset

* use seed

* add new eval and points

* pass n_samples as variable

* recompute avg length ([`a6f8d14`](https://github.com/embeddings-benchmark/mteb/commit/a6f8d14e3ec3d7f3f74728172c836802f13f34cd))

## v1.7.8 (2024-04-23)

### Fix

* fix: add french squad (#460)

* add french squad

* add french squad

* update splits and metadata

* lint space

* add points for mmteb and fix comments and bibtex ([`0e24482`](https://github.com/embeddings-benchmark/mteb/commit/0e24482292757da1ebd82ea1135ef46c3e2583bf))

## v1.7.7 (2024-04-23)

### Fix

* fix: Add Gujarati news classification (#493)

* first commit for Telugu News Classification

* revert to original main

* add major update

* fix ruff errors

* add points ([`3a59a4d`](https://github.com/embeddings-benchmark/mteb/commit/3a59a4dbdb4a4b4d20bddb64670cf209135116a6))

### Unknown

* Update points table ([`64fa2ce`](https://github.com/embeddings-benchmark/mteb/commit/64fa2ce4f4f1df97dc0359d34bd8a49d0e4a5fa0))

## v1.7.6 (2024-04-22)

### Fix

* fix: Update WikiClusteringP2P with 10 new languages (#486)

* update with new languages
* add new scores with new languages
* Add points (if Kenneth Reviews)
* reviewer
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`100e160`](https://github.com/embeddings-benchmark/mteb/commit/100e160337321814187ad4abc5018c0adf54782c))

### Unknown

* Update points table ([`2ce1b6a`](https://github.com/embeddings-benchmark/mteb/commit/2ce1b6ac3ca3815bf46b3408bf9bb7db98b21cc0))

## v1.7.5 (2024-04-22)

### Ci

* ci: Use if-else instead for points table creation (#477)

* use git diff-index instead

* using if-else worked on my fork ([`317ee44`](https://github.com/embeddings-benchmark/mteb/commit/317ee44073c93946ba693e35114a8b62f3dcee4d))

* ci: Only create table in ci when pushing to main (#473)

* only run mmteb ci when pushing to main

* points for now

* git diff will be empty after git add

* add back pr and split jobs

* points

* move release token and checkout

* install deps

* move if stmt higher to save time ([`738076d`](https://github.com/embeddings-benchmark/mteb/commit/738076de0c5115331eb908dc61386b7681e915e9))

### Fix

* fix: ToxicChatClassification task added to multilingual (#480)

* ToxicChatClassification task added to multilingual
* ToxicChatClassification lint fixes
* ToxicChatClassification: added bibtex and points
* Update 480.jsonl
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`eb1959d`](https://github.com/embeddings-benchmark/mteb/commit/eb1959da84762ccd465e5a4d6352cb926391af61))

### Unknown

* Update points table ([`a166b40`](https://github.com/embeddings-benchmark/mteb/commit/a166b40b5a89435e96a475298eaa09e821d73784))

* Update points table ([`e59f061`](https://github.com/embeddings-benchmark/mteb/commit/e59f061af93774aecf6e3806459610e0590d8a65))

* Add IN22-Conv dataset in BitextMining task category (#476)

* contribute IN22-Conv dataset for BitextMining task category

* remove for loops and use map/filter for data preprocessing

* add results for few language pairs

* add points ([`a08baac`](https://github.com/embeddings-benchmark/mteb/commit/a08baacaa4f7963cbb92b88daa3ad0aad39e4b81))

* Update points table ([`1c56d45`](https://github.com/embeddings-benchmark/mteb/commit/1c56d45b98a1ab6d0e463d600ec4be5cdaaf922d))

## v1.7.4 (2024-04-21)

### Fix

* fix: Add Siswati News Classification (#474)

* add SiswatiNewsClassification
* add run results
* points
* correct lang code
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
* review points
---------
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`9201dff`](https://github.com/embeddings-benchmark/mteb/commit/9201dffc46b32a5dc70437c9aff175041c7f7cf8))

## v1.7.3 (2024-04-21)

### Fix

* fix: add IN22-Gen dataset under BitextMining task (#451)

* add IN22-Gen dataset under BitextMining task

* add missing details as per reviewer suggestion

* add domain metadata for dataset

* update dataset description

* add points to the md

* Update docs/mmteb/points/451.jsonl

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`d8ab2e7`](https://github.com/embeddings-benchmark/mteb/commit/d8ab2e718418fc7c375abcdd63996120f882ae0a))

## v1.7.2 (2024-04-21)

### Fix

* fix: Add GreekLegalCodeClassification dataset (#456)

* Add GreekLegalCodeClassification dataset
* Add points
* Address review comments
* Fix lint ([`0c53579`](https://github.com/embeddings-benchmark/mteb/commit/0c53579db92318c115fc79c34f08864c3657ef30))

## v1.7.1 (2024-04-21)

### Ci

* ci: fixes issue when there is no point updates ([`22ca0e4`](https://github.com/embeddings-benchmark/mteb/commit/22ca0e4e941b14d62d543d866fb4daecacdd2805))

### Fix

* fix: Add Filipino Classification Dataset (#472)

* Add Filipino Classification Dataset
* Add points
* Update docs/mmteb/points/472.jsonl
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`611f56a`](https://github.com/embeddings-benchmark/mteb/commit/611f56a26ade11186ec4d58d13a00c6cd3c3eede))

### Unknown

* Action: Update points table ([`13ed323`](https://github.com/embeddings-benchmark/mteb/commit/13ed323a2a883280c8667e523d096ca5ef7a1049))

## v1.7.0 (2024-04-20)

### Documentation

* docs: Add points table 2 (#471)

* actually write to file
* remove print
* bold and wording
* points ([`fde4876`](https://github.com/embeddings-benchmark/mteb/commit/fde4876a2f0298fb5e5baefdf77e269103af2534))

* docs: Add points table (#468)

* docs: Added script for creating point
* ci: enable linting on all PRs
* ci: Added missing dependency
* docs: Added points
* file name match PR
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`e22c0c8`](https://github.com/embeddings-benchmark/mteb/commit/e22c0c8153c921940a3588548247e6a3b1742a0d))

### Feature

* feat: Add Greek sentiment classification (#470)

* feat: add GreekSentimentClassifciation task

* feat: add metadata

* add metadata

* chore: update license

* chore: add points ([`153bbb7`](https://github.com/embeddings-benchmark/mteb/commit/153bbb73965020edd70843ab043ebef319a099b2))

### Unknown

* Update points table ([`1c17394`](https://github.com/embeddings-benchmark/mteb/commit/1c17394f6147acee175cdbb4dfaeb9a49ac96200))

* Update points table ([`7e1e88c`](https://github.com/embeddings-benchmark/mteb/commit/7e1e88c31988d72f54dfb21e1959e03ea77ef37b))

## v1.6.38 (2024-04-20)

### Ci

* ci: Added doc linting rules to ensure google style docstrings. (#461)

* Added doc linting rules to ensure google style docstrings.

* docs: added points

* remove tmp/results folder

* review points

---------

Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`a8c0703`](https://github.com/embeddings-benchmark/mteb/commit/a8c07032fbfecd3730c7a6b1f90391bebcf22ecd))

### Fix

* fix: Add Zulu/Isizulu News Classification (#466)

* add isiZuluNewsClassification
* capitalization
* capitalize
* add dataset transform
* add run results
* make lint
* points, anticipating Kenneth ... :thinking: ([`d9383b7`](https://github.com/embeddings-benchmark/mteb/commit/d9383b7a289f228889e1d225580b132374e76754))

## v1.6.37 (2024-04-20)

### Documentation

* docs: coordination contributions for mmteb by auto validating points (#462)

* coordination contributions for mmteb by auto validating points
* 1!=2 ([`6121822`](https://github.com/embeddings-benchmark/mteb/commit/6121822c2f588d3995af41479b5172c07be06680))

* docs: Fix broken link in README (#458)

fix broken link ([`57eb5c3`](https://github.com/embeddings-benchmark/mteb/commit/57eb5c37f9510ac9e06c9cbcfcacd4da7cb2241d))

### Fix

* fix: Add Bambara Sentiment Classification (#463)

* add Bambara sentiment classification

* add run results

* 2+4 for dataset

* Update docs/mmteb/points/463.jsonl

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`f128a37`](https://github.com/embeddings-benchmark/mteb/commit/f128a3721de23eccb5ece7d87096d88c2a3a4fe0))

## v1.6.36 (2024-04-19)

### Fix

* fix: Set the min Pydantic version to 2 (#453)

Set the min pydantic version to 2 ([`92e089e`](https://github.com/embeddings-benchmark/mteb/commit/92e089eaca953067eb52fea95ac2370edea5f83a))

## v1.6.35 (2024-04-19)

### Ci

* ci: Correct jsonl validation (#448)

* actually validate this time

* test CI

* make lint

* validation should fail

* raise error instead of printing

* make lint

* revert ci fail

* fix key ([`22ef608`](https://github.com/embeddings-benchmark/mteb/commit/22ef608a2537e35fafc752fa53df4ef40876c344))

### Fix

* fix: Fix split name of AlloprofRetrieval and SyntecRetrieval (#449)

* fix: update revision for  alloprof retrieval

* fix: update SyntecRetrieval metadata and loading fn

* fix: update eval split key

* chore: add results of run_mteb_french script

* chore: add linting

---------

Co-authored-by: Imene Kerboua &lt;imene.kerboua@esker.com&gt; ([`734e946`](https://github.com/embeddings-benchmark/mteb/commit/734e946fcfb0a58354b8fb1410950ac77c8bded6))

## v1.6.34 (2024-04-19)

### Fix

* fix: Add AbsTaskInstructionRetrieval from the FollowIR paper (#408)

* init commit w comments from other PR

* simplify the evaluator

* verified results match paper

* remove extra kwargs from DRESModel

* undo

* add lint

* add tests

* lint

* fix test

* lint

* fix bug in indentation

* add back in old comment for parity

* Update RetrievalEvaluator.py

add comment back in

* add e5-small results

* add metadata

* add points ([`b700f94`](https://github.com/embeddings-benchmark/mteb/commit/b700f946a15871d93b6ad31dfefc4ba8c862e52c))

## v1.6.33 (2024-04-19)

### Chore

* chore: Validate jsonl points files (#441)

* Validate jsonl points files

* make lint

* remove print stmts

* remove upper limit ([`8dccdc0`](https://github.com/embeddings-benchmark/mteb/commit/8dccdc07e2bf4093be5792d8ebcb549d61670c38))

### Fix

* fix: Add Persian Food Sentiment Classification (#447)

* Adding Persian Food Sentiment Dataset (#432)
* downsample
* rerun results
* points
* make lint
---------
Co-authored-by: Ã–mer Veysel Ã‡aÄŸatan &lt;72755761+asparius@users.noreply.github.com&gt; ([`5aac728`](https://github.com/embeddings-benchmark/mteb/commit/5aac7289c0d5f78f6dcc5f5f0fdfd4565f81058e))

## v1.6.32 (2024-04-19)

### Fix

* fix: Add Bulgarian Online Store Review Dataset (#445)

* Add Bulgarian Online Store Review Dataset (#436)
* Add Bulgarian store review dataset
* Address review comments and rerun
* Simplify code
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* add points
---------
Co-authored-by: guangyusong &lt;15316444+guangyusong@users.noreply.github.com&gt; ([`8109e2d`](https://github.com/embeddings-benchmark/mteb/commit/8109e2dcaa97cd42821c0e871d19c507027f7c4c))

* fix: Add Kurdish sentiment (#446)

* Adding Kurdish Sentiment dataset (#431)
* add points
---------
Co-authored-by: Ã–mer Veysel Ã‡aÄŸatan &lt;72755761+asparius@users.noreply.github.com&gt; ([`61dee74`](https://github.com/embeddings-benchmark/mteb/commit/61dee74f531a9bd5f10531fea1ba61c70bc7b9a9))

## v1.6.31 (2024-04-19)

### Fix

* fix: Merge Italian cola (#348) (#444)

* docs: Added points

* Add Wikiclustering benchmark for multiple languages:)) (#376)

* add tasks and leaderboard update

* change names to the right ones:))

* update points and start migrating to multilingual format

* add metadata and working revision

* bump revision to newest version of data

* Update mteb/tasks/Clustering/multilingual/WikiClusteringP2P.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Clustering/multilingual/WikiClusteringP2P.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Clustering/multilingual/WikiClusteringP2P.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Clustering/multilingual/WikiClusteringP2P.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Clustering/multilingual/WikiClusteringP2P.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* update to match main

* add date and fix literal

* add result for MiniLM-L12-v2

* add scores for intfloat model

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* format

* added points

* fix: Italian cola (#348)

* WIP adding italian acceptability classification dataset

* bump itacola dataset

* linting

* added task description

* WIP updating itacola task metadeta and results

* added n_samples and avg character lenght to metadata

* update metadata

* updating date and socioeconomic status metadata

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* style: formatted

---------

Co-authored-by: Jonathan HR &lt;39084161+Rysias@users.noreply.github.com&gt;
Co-authored-by: marcobellagente93 &lt;marco.bellagente@gmail.com&gt; ([`16438ce`](https://github.com/embeddings-benchmark/mteb/commit/16438ceccfdfe5a50e64d5df32d599e8301efeb1))

## v1.6.30 (2024-04-19)

### Chore

* chore: remove useless sub directory (#442)

Co-authored-by: Imene Kerboua &lt;imene.kerboua@esker.com&gt; ([`ce10347`](https://github.com/embeddings-benchmark/mteb/commit/ce103474350cb41388746c4db10fd60f81e1a32f))

### Fix

* fix: Add Wikiclustering benchmark for multiple languages:)) (#376) (#443)

Add Wikiclustering benchmark for multiple languages:)) (#376)

* add tasks and leaderboard update

* change names to the right ones:))

* update points and start migrating to multilingual format

* add metadata and working revision

* bump revision to newest version of data

* Update mteb/tasks/Clustering/multilingual/WikiClusteringP2P.py



* Update mteb/tasks/Clustering/multilingual/WikiClusteringP2P.py



* Update mteb/tasks/Clustering/multilingual/WikiClusteringP2P.py



* Update mteb/tasks/Clustering/multilingual/WikiClusteringP2P.py



* Update mteb/tasks/Clustering/multilingual/WikiClusteringP2P.py



* update to match main

* add date and fix literal

* add result for MiniLM-L12-v2

* add scores for intfloat model

---------

Co-authored-by: Jonathan HR &lt;39084161+Rysias@users.noreply.github.com&gt; ([`c2c6d52`](https://github.com/embeddings-benchmark/mteb/commit/c2c6d527d0787a8b052eaf5aca9f32ea1128af11))

## v1.6.29 (2024-04-19)

### Fix

* fix: Add Uyghur Sentiment Classification (#430)

* UyghurSentimentClassification
* add run results
* points but there will be conflicts
* use new points structure
* review points ([`ac4315b`](https://github.com/embeddings-benchmark/mteb/commit/ac4315b8ccd5daf7d72a8ad4e13f15bfc221d1b8))

## v1.6.28 (2024-04-19)

### Documentation

* docs: Added new scoring system (#438) ([`0bb2d7a`](https://github.com/embeddings-benchmark/mteb/commit/0bb2d7ac3a502c48b9e64d0ae907ae99efa6a6d2))

* docs: Correct review points (#437)

* docs: Updated review points

* fix missing and double duplicate points ([`f3abf71`](https://github.com/embeddings-benchmark/mteb/commit/f3abf717031d7b65eea2ef67519eb398ffe0a713))

### Fix

* fix: Add Bulgarian Sentiment Classification Dataset (#429)

* add BulgarianSentimentClassification
* add run results
* points
* correct points
* use updated points structure ([`ea9c386`](https://github.com/embeddings-benchmark/mteb/commit/ea9c3869b1e52b8efedc93975cd6cb52e5ffe7f8))

## v1.6.27 (2024-04-19)

### Documentation

* docs: Updated review points (#435) ([`160a607`](https://github.com/embeddings-benchmark/mteb/commit/160a60796a038ac7b7792afdbd82bccbf7c7e7f7))

### Fix

* fix: add SlovakSentimentClassification dataset (#433)

* add SlovakSentimentClassification dataset
* Update points.md
* Update mteb/tasks/Classification/slk/SlovakSentimentClassification.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update SlovakSentimentClassification.py
* Update points.md
* Update SlovakSentimentClassification.py
---------
Co-authored-by: Manan Dey &lt;159106637+manandey-sfdx@users.noreply.github.com&gt;
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`4988867`](https://github.com/embeddings-benchmark/mteb/commit/4988867f5f579c278354cedd373c46782b56376a))

## v1.6.26 (2024-04-19)

### Fix

* fix: add Romanian STS dataset (#427)

* import new task
* add new task
* add bibtex_citation
* add results
* linting
* add points
* add date estimate and add review points
* linting
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`0678036`](https://github.com/embeddings-benchmark/mteb/commit/0678036c2b3cd949c383269f3a56d2062dfb6c60))

## v1.6.25 (2024-04-18)

### Documentation

* docs: Add missing points from PR reviews (#425)

add missing points - see PR description ([`d3c16ed`](https://github.com/embeddings-benchmark/mteb/commit/d3c16edc6e0b53cee0588d2921fb632660a3a793))

### Fix

* fix: update dataset source name for GermanDPR (#428)

* fix: update dataset source name for GermanDPR

* docs: add point for bug fix

---------

Co-authored-by: Imene Kerboua &lt;imene.kerboua@esker.com&gt; ([`9ee6bbe`](https://github.com/embeddings-benchmark/mteb/commit/9ee6bbefdd835f6dd4c09be659675353f4301df5))

### Unknown

* Add French classification dataset (#422)

* add allocine dataset

* add citation and points

* Update docs/mmteb/points.md

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`3bf6e62`](https://github.com/embeddings-benchmark/mteb/commit/3bf6e6267257eccabaa916e820ef6e429c3d23cb))

## v1.6.24 (2024-04-18)

### Fix

* fix: Add Maltese Sentiment Classification Dataset (#423)

* add MalteseSentimentClassification
* add run results
* make lint
* pointsssss ([`8276549`](https://github.com/embeddings-benchmark/mteb/commit/82765497fc90ff31e7e4b8ccc6485287f659b74b))

## v1.6.23 (2024-04-18)

### Fix

* fix: Add KorSTS and KLUE-STS datasets (#414)

* add KorSTS and KLUE-STS tasks

* refactor: ruff linting

* modify points.md

* add run results

* modify points.md

* add metadata of KLUE-STS

* add metadata of KorSTS

* add descriptions and avg_character_lengths

* Update KorSTS.py

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`4135e9b`](https://github.com/embeddings-benchmark/mteb/commit/4135e9bc0ffe42777f559fbc7226d4bdfaf1fbed))

## v1.6.22 (2024-04-18)

### Fix

* fix: Add support for the LongEmbed benchmark (#393) (#421)

* add the longembed benchmark

* add longembed bench &amp; make lint

* add meta data and model scores

* add all metadata and passkey&amp;needle scores

* remove prints

* replace context length with test_256, test_512, ...

Co-authored-by: Dawei Zhu &lt;52273452+dwzhu-pku@users.noreply.github.com&gt; ([`d21f25e`](https://github.com/embeddings-benchmark/mteb/commit/d21f25e0096264b68a4b3f7a72a0a158cb3c1fd5))

## v1.6.21 (2024-04-18)

### Fix

* fix: Add Croatian Sentiment Classification (#416)

* add CroatianSentimentClassification
* fix citation
* actually fix citation
* add results
* add e5-base results
* points!
---------
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`e7c0362`](https://github.com/embeddings-benchmark/mteb/commit/e7c0362cd70edcb4fa99f332fdb9baf2ca50ffe6))

### Unknown

* Fix: EstQA is now properly formulated as a retrieval task (#418)

* fix: EstQA is now properly formulated

* Ran linting ([`ae0da50`](https://github.com/embeddings-benchmark/mteb/commit/ae0da506b5a3e20024f5ae853fd06d234c7815f3))

## v1.6.20 (2024-04-18)

### Documentation

* docs: Update contributor information (#417)

Co-authored-by: rposwiata &lt;rposwiata@opi.org.pl&gt; ([`36de85e`](https://github.com/embeddings-benchmark/mteb/commit/36de85eb17976d595f3e9430f8cdc5bfc5dfa146))

### Fix

* fix: add italian HateSpeech dataset (#385) (#420)

* fix: add italian HateSpeech dataset (#385)

* add italian HateSpeech dataset

* add points

* update dialect, socioeconomic status, domains and points

* add PR review points

* add task_domain for constructed data + rerun models

* update points

* minor fix

* merge points from main

* add review points to main

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* run linting

---------

Co-authored-by: Roberta Rocca &lt;32483140+rbroc@users.noreply.github.com&gt; ([`4ce7f35`](https://github.com/embeddings-benchmark/mteb/commit/4ce7f35ce2e43eb5659e67abb32379cb99d4641f))

## v1.6.19 (2024-04-18)

### Fix

* fix: add custom load dataset function for MLSUM tasks (#405)

* fix: add custom load dataset function

* fix: fix linter

* docs: added points

---------

Co-authored-by: Imene Kerboua &lt;imene.kerboua@esker.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`c549af2`](https://github.com/embeddings-benchmark/mteb/commit/c549af2cc076f6b6474c36013adca485eedaa841))

## v1.6.18 (2024-04-18)

### Fix

* fix: Added Hungarian Roma Tales bitext task and Romani Bible clustering task (#396)

* Added Romani-Hungarian bitext task

* Added results for Roma Tales

* Added Romani Bible clustering task with results

* Changed task subtype from None to [] in Roma Tales

* Added points for Marton for datasets and Kenneth for review

* Made Roma Tales a CrosslingualTask and readded results

* style: Use rename_columns instead of rename_column

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* Ran linting

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`6f9d19f`](https://github.com/embeddings-benchmark/mteb/commit/6f9d19f607c19b492cc5236855a80f68650910cc))

## v1.6.17 (2024-04-18)

### Fix

* fix: Id clickbait (#411)

* add indonesian clickbait

* Update points.md

* update

---------

Co-authored-by: Manan Dey &lt;159106637+manandey-sfdx@users.noreply.github.com&gt; ([`a0fa60b`](https://github.com/embeddings-benchmark/mteb/commit/a0fa60b32335e31c0aa6dbb2861d14c3c3ce06e8))

### Unknown

* Add Czech Subjectivity Classification Dataset (#413)

* CzechSubjectivityClassification
* add results
* review comments
* points
* update results
---------
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`deebcb0`](https://github.com/embeddings-benchmark/mteb/commit/deebcb0d158a26bbfc5dd3ba9c9a9760f9afa052))

* Add 3 Arabic classification datasets (#410)

* add ara-sarcasm dataset

* add tweet emotion dataset

* add hard dataset

* fix formatting

* Update mteb/tasks/Classification/ara/HotelReviewSentimentClassification.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* Update mteb/tasks/Classification/ara/HotelReviewSentimentClassification.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* Update mteb/tasks/Classification/ara/HotelReviewSentimentClassification.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* Update mteb/tasks/Classification/ara/TweetSarcasmClassification.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* add points and suggestions

* Update points.md

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`c874110`](https://github.com/embeddings-benchmark/mteb/commit/c8741101b868bcda2f0705d30aa284c885afb4e4))

* Turkish multidomain product review data (#406)

* Tur multidomain product review data

* Update mteb/tasks/Classification/tur/TurkishProductSentimentClassification.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* point update

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`86db1b8`](https://github.com/embeddings-benchmark/mteb/commit/86db1b8c32632fd084b2304c581b49efdd6317a1))

* Add Romanian Sentiment Classification Task (#404)

* add RomanianSentimentClassification
* add run results
* e5-base results
* add points
* only sample test set
* thanks Imene! ([`268324b`](https://github.com/embeddings-benchmark/mteb/commit/268324b1867acb132aabda8921729322cf44bcf1))

* Add points missing from PR#389 (#403)

add points missing from PR 389 ([`628beb4`](https://github.com/embeddings-benchmark/mteb/commit/628beb4368ce52176f4690930b171e55e0547eb5))

* Adding Turkish Movie Sentiment Dataset (#389)

* Adding Turkish Movie Sentiment Dataset
* Update mteb/tasks/Classification/tur/TurkishMovieSentimentClassification.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update mteb/tasks/Classification/tur/TurkishMovieSentimentClassification.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update mteb/tasks/Classification/tur/TurkishMovieSentimentClassification.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update mteb/tasks/Classification/tur/TurkishMovieSentimentClassification.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update mteb/tasks/Classification/tur/TurkishMovieSentimentClassification.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update avg_character length and socioecon status
* Updating licence
* Update TurkishMovieSentimentClassification.py
* Update mteb/tasks/Classification/tur/TurkishMovieSentimentClassification.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update mteb/tasks/Classification/tur/TurkishMovieSentimentClassification.py
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt;
* Update TurkishMovieSentimentClassification.py
* Update TurkishMovieSentimentClassification.py
* Create __init__.py
* Update points.md
* Update TurkishMovieSentimentClassification.py
* Update points.md
* Update TurkishMovieSentimentClassification.py
* formatting
* Update points.md
* Update points.md
* Update points.md
---------
Co-authored-by: Isaac Chung &lt;chungisaac1217@gmail.com&gt; ([`b01382b`](https://github.com/embeddings-benchmark/mteb/commit/b01382ba6b864889e76dfbf4e2e0bf4595cb0a60))

## v1.6.16 (2024-04-17)

### Documentation

* docs: Added missing point for pr ([`32d8979`](https://github.com/embeddings-benchmark/mteb/commit/32d89793825417ac7fb94fd7f8f3fac1d60b6b29))

* docs: Added missing point for pr (#394) ([`a2d4705`](https://github.com/embeddings-benchmark/mteb/commit/a2d470572219aa5afab32c4f276db01db7d921d5))

### Fix

* fix: Add BengaliHateSpeechClassification (#398)

* Add BengaliHateSpeechClassification

* Update mteb/tasks/Classification/ben/BengaliHateSpeechClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* update scores

* make lint

* add points

* Update points.md

---------

Co-authored-by: Manan Dey &lt;159106637+manandey-sfdx@users.noreply.github.com&gt;
Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`2772ec8`](https://github.com/embeddings-benchmark/mteb/commit/2772ec8ef3051778c39c29fada964f4f95898c3e))

### Unknown

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`ad8cda3`](https://github.com/embeddings-benchmark/mteb/commit/ad8cda375236d3247d7bff10ecc1e3560629f99a))

## v1.6.15 (2024-04-17)

### Fix

* fix: Add Macedonian Tweet Sentiment Classification Task (#392)

* add MacedonianTweetSentimentClassification

* add results from runs

* edits from review

* add points ([`206f2c9`](https://github.com/embeddings-benchmark/mteb/commit/206f2c9e82417da69c6d20688bd7eabc6cff9403))

## v1.6.14 (2024-04-17)

### Ci

* ci: Ensure that linting fails when files are not linted (#394)

* style: This should fail linting

* ci: update linting to check if project is linted

* style: running linting

This should pass tests

* Add comment to ci rule to ensure that it isn&#39;t removed in the future ([`ff3cbfc`](https://github.com/embeddings-benchmark/mteb/commit/ff3cbfc29e89c8cd1c4f3bddbadf0a222be0d75a))

### Fix

* fix: Add Dutch Book Review Sentiment Classification Task (#388)

* add DutchBookReviewSentimentClassification and run models

* add points

* add name

* minor edits from review

* add multilingual-e5-base results

* add pointer for reviewers ([`10d50b6`](https://github.com/embeddings-benchmark/mteb/commit/10d50b6908c304e1a293888b51bdcc62f90142ea))

## v1.6.13 (2024-04-17)

### Fix

* fix: Added HunSum2 dataset with results (#384)

* Added HunSum2 dataset with results

* Minor fixes to HunSum2

* Updated points for Kenneth and Marton

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`c65e1d7`](https://github.com/embeddings-benchmark/mteb/commit/c65e1d70a8379056b40db31b3cbe59a699e811ba))

## v1.6.12 (2024-04-17)

### Fix

* fix: Added EstQA and Eesti Valentsikorpus datasets (#382)

* Added EstQA dataset with results.

* Added new points and e-mail address to x-tabdeveloping

* Added Estonian Valence task + results

* Added new points for Estonian Valence task

* Addressed issues highlighted by Kenneth

* Reran EstQA ([`282d421`](https://github.com/embeddings-benchmark/mteb/commit/282d4219e15f271e87785c30f84d42675a4e5a05))

## v1.6.11 (2024-04-16)

### Fix

* fix: Add neuclir (#350)

* init commit

* add revision and results

* multilingual version

* run lint

* metadata

* add new results, update metaedata

* add lint

* fix bug; add points

* update citation

* fix: Moved metadata calcuation to abstask and added minor updates to metadata

* tests: Added test for metadata calculation

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`e773f64`](https://github.com/embeddings-benchmark/mteb/commit/e773f641cc9291945137a397c0928665a37a550f))

### Unknown

* fix Added Arabic reviews (#380) (original PR #369)

* fix: Add Arabic Restaurant Reviews  (#369)

* add arabic res reviews dataset

* update changes

* update metadata

* add multilingual-e5-base results

* Update mteb/tasks/Classification/ara/RestaurantReviewSentimentClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* docs: Added points

Added 6 poins for first ara clf task (2+4) and a review points for kenneth and imene

Additionally also ran the formatter

* docs: formatted points tables

---------

Co-authored-by: Mohammed Hamdy &lt;62081584+mmhamdy@users.noreply.github.com&gt; ([`dc82dc5`](https://github.com/embeddings-benchmark/mteb/commit/dc82dc53d33528445543b86eab1267e3cda05b8f))

## v1.6.10 (2024-04-15)

### Fix

* fix: ADD JSTS Dataset for STS TASK (#359)

* add JaQuAD dataset

* fix

* add dataset stats

* add Japanese social network posts sentiment classification dataset

* add stats

* add JSTS dataset for STS tasks

* adjust points

* Update mteb/tasks/STS/jpn/JSTS.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/STS/jpn/JSTS.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`7ce0601`](https://github.com/embeddings-benchmark/mteb/commit/7ce060123da6ebb844f4ef7cb3e6226669252e3b))

## v1.6.9 (2024-04-15)

### Documentation

* docs: update mmteb points for slvnwhrl (#373)

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`b03573b`](https://github.com/embeddings-benchmark/mteb/commit/b03573b20ba615b0b74408c5a49610aab5b3b56e))

### Fix

* fix: Add Cantonese Openrice Classification task (#370)

* add openrice

* add results

* fix n_samples and lint

* rename to `YueOpenriceReviewClassification`

* move to zho and fix revision

* add points

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`91cf99e`](https://github.com/embeddings-benchmark/mteb/commit/91cf99eb471e472dceea2b57b65bad48d45fb3bb))

## v1.6.8 (2024-04-15)

### Chore

* chore: move and update contributing.md (#372)

chore: delete contributing.md ([`bc6a1e3`](https://github.com/embeddings-benchmark/mteb/commit/bc6a1e3f1dea2c7a95d8cdd9ff297687cc37a0aa))

### Documentation

* docs: updated link in readme ([`4cfd94b`](https://github.com/embeddings-benchmark/mteb/commit/4cfd94bbcda17be0f3769d539e582fec5f67f6c1))

### Fix

* fix: Add German False friend dataset (#374)

* fix: added false friends en de dataset to pair classification (#349)

* added false friends en de dataset to pair classification

* Update __init__.py to also have deu

* Rename FalseFriendsDeEnPC to FalseFriendsDeEnPC.py

* Update run_mteb_german.py

* Update points.md

* Update FalseFriendsDeEnPC.py

to the latest revision

* Create __init__.py

* Update mteb/tasks/PairClassification/deu/FalseFriendsDeEnPC.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/PairClassification/deu/FalseFriendsDeEnPC.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/PairClassification/deu/FalseFriendsDeEnPC.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update points.md

* Update FalseFriendsDeEnPC.py

* Update FalseFriendsDeEnPC.py

* Update FalseFriendsDeEnPC.py

add bibtex

* Update mteb/tasks/PairClassification/deu/FalseFriendsDeEnPC.py

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* fix: Updated to task metadata of false friend

* fix: ran linting

---------

Co-authored-by: achibb &lt;42097962+achibb@users.noreply.github.com&gt; ([`9ef2246`](https://github.com/embeddings-benchmark/mteb/commit/9ef22460196cdc38cdaa1f77bb6b53a759d9c7ec))

## v1.6.7 (2024-04-15)

### Fix

* fix: Add Japanese Social Network Posts Sentiment Classification Dataset (#358)

* add JaQuAD dataset

* fix

* add dataset stats

* add Japanese social network posts sentiment classification dataset

* add stats

* fix dataset stats

* minor fix

* fix merging

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`6433c87`](https://github.com/embeddings-benchmark/mteb/commit/6433c8750c677fdac2be16d9917b4fd28a17cc8f))

## v1.6.6 (2024-04-15)

### Fix

* fix: Add code search (edit of #345) (#371)

* fix: Adding CodeSearchNet (#345)

* add basic retrieval task

* remove test code

* fix metadata

* avoid leaking labels

* subset

* fmt

* points

* attempt 1 at splitting by lang

* add import in init

* fix

* this?

* override for &#34;Code&#34;

* inherit multiling

* enable streaming

* fmt

* fix docs

* Update mteb/tasks/Retrieval/code/CodeSearchNetRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Retrieval/code/CodeSearchNetRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Retrieval/code/CodeSearchNetRetrieval.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/abstasks/TaskMetadata.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* populate

* taxonomy

* results

* fmt

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* fix: Minor fixes to codesearch metadata

---------

Co-authored-by: Federico Cassano &lt;federico.cassano@federico.codes&gt; ([`d1152e8`](https://github.com/embeddings-benchmark/mteb/commit/d1152e8fdac87d96b676702d0088804cc389925c))

## v1.6.5 (2024-04-15)

### Fix

* fix: Add 3 tasks for Vietnamese (#364)

* add Retrieval and Classification datasets for Vietnamese

* remove avg length print

* add VieMedEV

* update meta and points

* fix typo

* fix merge

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`d054221`](https://github.com/embeddings-benchmark/mteb/commit/d054221087a88c8ebeca3503b337bc0bdecb5a37))

## v1.6.4 (2024-04-15)

### Fix

* fix: Remove Mr. TyDi Datasets (#363)

* remove tydi

* add points and remove from korean benchmark ([`b015148`](https://github.com/embeddings-benchmark/mteb/commit/b01514892248b68ce7a92ee0e1727c24fe016398))

## v1.6.3 (2024-04-14)

### Documentation

* docs: Updated examples in docs (adding a dataset) (#353)

* docs: Updated examples in documentation

* docs: Updated taskmetadata to better describe edge cases ([`9b63f50`](https://github.com/embeddings-benchmark/mteb/commit/9b63f50694196666b75c5ccc0bd9ce8dc3206fa7))

* docs: Updated examples in documentation (#351) ([`6832cf0`](https://github.com/embeddings-benchmark/mteb/commit/6832cf02b34d7959986dd36d18bf496a5b699f74))

### Fix

* fix: add Japanese Question Answering Dataset (JaQuAD) dataset (#352)

* add JaQuAD dataset

* fix

* add dataset stats

* fix dataset stats ([`ae6adf4`](https://github.com/embeddings-benchmark/mteb/commit/ae6adf447d50953f8f2c99e06781e75b3a06514e))

## v1.6.2 (2024-04-12)

### Documentation

* docs: Added points for previous submissions (#344)

* docs: Added missing points for #214

Added 6x2 points for guenthermi for datasets and 1 point to Â Muennighoff for review

I have not accounted for bonus points as I am not sure was what available at the time.

* docs: added point for #197

Added 2 points for rasdani and 2 bonus points for the first german retrieval (I believe). Added one point for each of the reviewers

* docs: added points for #116

This includes 6 points for 3 datasets to slvnwhrl +2 for first german clustering task also added points for reviews

* Added points for #134 cmteb

This includes 29 datasets (38 points) and 6x2 bonus points (12 points) for the 6 taskXlanguage which was not previously included.

All the points are attributed to @staoxiao, though we can split them if needed.

We also added points for review.

* docs: Added points for #137 polish

This includes points for 12 datasets (24) across 4 tasks (8). These points are given to rafalposwiata and then one point for review

* docs: Added points for #27 (spanish)

These include 9 datasets (18 points) across 4 news tasks (8) for spanish.

Points are given to violenil as the contributor, and one points for reviewers. Points can be split up if needed.

* docs: Added points for #224

Added points 2 points for the dataset. I could imagine that I might have missed some bonus points as well. Also added one point for review.

* docs: Added points for #210 (korean)

This include 3 datasets (6 points) across 1 new task (+2 bonus) for korean. Also added 1 points for reviewers.

* Add contributor

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`9dbf500`](https://github.com/embeddings-benchmark/mteb/commit/9dbf500c7bb3d427345549f7698e15482cf024c7))

### Fix

* fix: Added Hindi discourse dataset (#346)

* Added news classification dataset.

* Fixes on suggestions

* Added new medical qa dataset

* Update model run files and model path

* Added points for dataset.

* Fixes

* Added hindi discourse dataset

* Added points

* Added avg char length

* Fixes

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`a55ae5f`](https://github.com/embeddings-benchmark/mteb/commit/a55ae5f5b9c722d861faf5ff8c33c5dd4cb4f598))

### Unknown

* Update readme.md ([`2dec4e9`](https://github.com/embeddings-benchmark/mteb/commit/2dec4e9da4e1cc63554d12de19a41e3bbea6a496))

* Removing bitext mining tasks from fr evaluation script (#341)

fix: removing bitextmining tasks from fr script ([`86ad02d`](https://github.com/embeddings-benchmark/mteb/commit/86ad02d2d991b5786c9cad7922713f2e36c4831d))

## v1.6.1 (2024-04-11)

### Documentation

* docs: Update mmteb (#338)

docs: update mmteb ([`bee4244`](https://github.com/embeddings-benchmark/mteb/commit/bee424410a62b4602db70062a869302ae6faf068))

### Fix

* fix: missing json and updated tests to not run in editable mode (#340)

* fix: Added json files to pyproject.toml

* ci: avoid using -e when installing for tests ([`17c809d`](https://github.com/embeddings-benchmark/mteb/commit/17c809d219f95b8570ab044a60b7c56d0ac5b92c))

## v1.6.0 (2024-04-10)

### Documentation

* docs: Update points.md (#337) ([`2a3f9e6`](https://github.com/embeddings-benchmark/mteb/commit/2a3f9e6b5db55b7708d2441c78c2dcd47b3ef154))

### Feature

* feat: Added new language code standard (#326)

* fix: Added initial language code suggestion

* docs: updated task metadata description

* fix: changed folder structure to iso 639-3 codes

* fix: Updated all language tags

* clean: removed accidental results commit

* fix: Add trusting of remote code to remove warning

* fix: Added formatting

* fix: trust remote code the flores dataset

* docs: Added point for language rewrite

* fix: reran linter after merge

* fix: Added corrections from review

* fix: Updated languages for newly added datasets

* docs: added points for new annotations ([`f0daece`](https://github.com/embeddings-benchmark/mteb/commit/f0daece8d8c6491a9d06153763f0d76c2773e251))

## v1.5.6 (2024-04-10)

### Documentation

* docs: add points and affiliation for MartinBernstorff (#335)

docs: update points.md ([`2903cb4`](https://github.com/embeddings-benchmark/mteb/commit/2903cb4a738bdae0a5863059c85de97a17c95074))

### Fix

* fix: Added medical qa dataset (#333)

* Added news classification dataset.

* Fixes on suggestions

* Added new medical qa dataset

* Update model run files and model path

* Added points for dataset.

* Fixes

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`80acc3e`](https://github.com/embeddings-benchmark/mteb/commit/80acc3e39ee6fc27458275b3c2a25e0e13550c44))

### Unknown

* Update pull_request_template.md ([`84cffa2`](https://github.com/embeddings-benchmark/mteb/commit/84cffa270923dca711a57b68a739d055efd049a2))

## v1.5.5 (2024-04-09)

### Fix

* fix: Improve logging when the revision is None (#329) ([`404587b`](https://github.com/embeddings-benchmark/mteb/commit/404587b81d63d666cb121d0273ce0be1d0e70526))

## v1.5.4 (2024-04-08)

### Fix

* fix: Multiple dataset fixes (#328)

* fix: remove time of run (as it does not relate to the model itself). Time of run should be on the dataset results

* fix: fixes the PawsX datasets

* docs: Updated points

* fix: flores clustering

* fix: mulitple dataset fixes

* docs: updated points

* fix: added missing dataset_transform to multitask task

* syle: ran formatter

* fix: correctly fix pawsX ([`84408f7`](https://github.com/embeddings-benchmark/mteb/commit/84408f7bcd422fc59febe19818877299168b08b8))

## v1.5.3 (2024-04-08)

### Documentation

* docs: Added point for SEB (#318)

* docs: added points for seb

* docs: added points for seb ([`ca64fc7`](https://github.com/embeddings-benchmark/mteb/commit/ca64fc71ffd1eeecba97bc9a346f28748df5fca7))

* docs: Small fixes in readme.md (#317)

Fix typos in readme.md ([`ede12c8`](https://github.com/embeddings-benchmark/mteb/commit/ede12c8705ca42b38ed2dc167acaa4250b816a34))

### Fix

* fix: Added English news classification dataset (#323)

* Fix typos in readme.md

* Added news classification dataset.

* Added news classification dataset.

* Fixes on suggestions

* Update docs/mmteb/points.md

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`4d21807`](https://github.com/embeddings-benchmark/mteb/commit/4d21807a161aab452ede725144ce4f4c802a8da9))

### Unknown

* Fix name ([`d69bf94`](https://github.com/embeddings-benchmark/mteb/commit/d69bf94a20fc584ffe48aafaefaa944df802d497))

* Add law datasets (#311)

* add command

* add datasets

* reformat dataset

* Rephrase description

* Update mteb/tasks/Retrieval/law/GerDaLIRRetrieval.py

* Update mteb/tasks/Retrieval/law/GerDaLIRRetrieval.py

* Update mteb/__init__.py

* Update scripts/run_mteb_law.py

* Update scripts/run_mteb_law.py

* Update mteb/__init__.py

* Update mteb/tasks/Retrieval/__init__.py

* Update mteb/tasks/Retrieval/law/GerDaLIRRetrieval.py

* Update mteb/tasks/Retrieval/law/GerDaLIRRetrieval.py

* Update mteb/tasks/Retrieval/law/LegalQuADRetrieval.py

* Update mteb/tasks/Retrieval/law/LegalQuADRetrieval.py

* Update scripts/run_mteb_law.py

* Update mteb/tasks/Retrieval/law/LegalSummarizationRetrieval.py

* Update mteb/tasks/Retrieval/law/LegalSummarizationRetrieval.py

* Update mteb/tasks/Retrieval/law/LeCaRDv2Retrieval.py

* Update mteb/tasks/Retrieval/law/LeCaRDv2Retrieval.py

* Rename GerDaLIRRetrieval.py to GerDaLIRSmallRetrieval.py

* Update mteb/tasks/Retrieval/__init__.py

* Update GerDaLIRSmallRetrieval.py

Add metadata

* Update GerDaLIRSmallRetrieval.py

Update metadata

* Update AILACasedocsRetrieval.py

Update AILACasedocsRetrieval metadata

* Update AILAStatutesRetrieval.py

Update AILAStatutesRetrieval metadata

* Update LeCaRDv2Retrieval.py

Update LeCaRDv2Retrieval metadata

* Update LegalBenchConsumerContractsQARetrieval.py

Update LegalBenchConsumerContractsQARetrieval metadata

* Update LegalBenchCorporateLobbyingRetrieval.py

Update LegalBenchCorporateLobbyingRetrieval metadata

* Update LegalQuADRetrieval.py

Update LegalQuADRetrieval metadata

* Update LegalSummarizationRetrieval.py

Update LegalSummarizationRetrieval metadata

* Update AILACasedocsRetrieval.py

Update AILACasedocsRetrieval

* Update AILACasedocsRetrieval.py

Update AILACasedocsRetrieval metadata

* Update AILAStatutesRetrieval.py

Update AILAStatutesRetrieval metadata

* Update GerDaLIRSmallRetrieval.py

Update GerDaLIRSmallRetrieval metadata

* Update LeCaRDv2Retrieval.py

Update LeCaRDv2Retrieval metadata

* Update LegalBenchConsumerContractsQARetrieval.py

* Update LegalBenchCorporateLobbyingRetrieval.py

* Update LegalQuADRetrieval.py

* Update LegalSummarizationRetrieval.py

* Update AILACasedocsRetrieval.py

* Update AILAStatutesRetrieval.py

* Update GerDaLIRSmallRetrieval.py

* Update LeCaRDv2Retrieval.py

* move dataset language folder

* update order

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`6e3f419`](https://github.com/embeddings-benchmark/mteb/commit/6e3f41937cf209307aa440560f9eda115b128528))

* Fix PawsX eval splits (#316) ([`15285d4`](https://github.com/embeddings-benchmark/mteb/commit/15285d4f4f52737eaad3d105f052eab81da6c603))

## v1.5.2 (2024-04-04)

### Fix

* fix: Minor fixes to metadata (#315)

* Update MindSmallReranking.py

* fix: Updated wrong metadata ([`e0eddf9`](https://github.com/embeddings-benchmark/mteb/commit/e0eddf9f0436bda44ffa71134e651d3c70829dc0))

### Unknown

* Adding French team contribution points (#302)

* Update points.md

* Update docs/mmteb/points.md

* Update points.md

* Update points.md ([`23c9fdd`](https://github.com/embeddings-benchmark/mteb/commit/23c9fdde846aaa297bdc248a79f4e4492082f776))

## v1.5.1 (2024-04-03)

### Fix

* fix: Added tests for checking datasets (#307)

* fix: Fixed hf_hub_name for WikiCitiesClustering

* Added points for this PR and a 3 other minor dataset fixes

* feat: Added tests which validated that datasets are available

* fix: Updated hf references and revisions to multiple datasets

* Added points for submission

* fix: Added suggestions from the review

* Apply suggestions from code review

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* fix: sped up async test for whether datasets exist

* fix: Updated revisions

* fix: reuploaded scandeval datasets

* fix: Applied formatter

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`8d804f4`](https://github.com/embeddings-benchmark/mteb/commit/8d804f4956ea66b68b25c14ab05bc5ad2e102ff7))

## v1.5.0 (2024-04-02)

### Feature

* feat: Allow extending the load_dataset parameters in custom tasks inheriting AbsTask (#299)

* Allow extending the load_dataset parameters

* format

* Fix test

* remove duplicated logic from AbsTask, now handled in the metadata

* add tests

* remove comments, moved to PR

* format

* extend metadata dict from super class

* Remove additional load_data

* test: adding very high level test

* Remove hf_hub_name and add test

* Fix revision in output file

---------

Co-authored-by: gbmarc1 &lt;marcantoine.belanger@shopify.com&gt; ([`953780d`](https://github.com/embeddings-benchmark/mteb/commit/953780dd680309cbae78f6543c005965ad9caf01))

## v1.4.1 (2024-04-01)

### Fix

* fix: hf_hub_name for WikiCitiesClustering (#305)

* fix: Fixed hf_hub_name for WikiCitiesClustering

* Added points for this PR and a 3 other minor dataset fixes ([`b447235`](https://github.com/embeddings-benchmark/mteb/commit/b447235a18d2fb7261c6cb6cbb214e0bbd15452c))

## v1.4.0 (2024-04-01)

### Feature

* feat: Added windows support by replacing pytrec-eval with pytrec-eval-terrier  (#292)

* ci: Added windows to test suite

* feat: Changed to pytrec-eval-terrier to add support for windows installs ([`fc0e105`](https://github.com/embeddings-benchmark/mteb/commit/fc0e105e737352e0afd3a144717e7129654f8c90))

## v1.3.4 (2024-04-01)

### Fix

* fix: Update MindSmallReranking.py to have the correct hf reference (#303) ([`102e24e`](https://github.com/embeddings-benchmark/mteb/commit/102e24e093c4414e3ecef49cb9d0ba94995f2eb3))

## v1.3.3 (2024-03-31)

### Documentation

* docs: Added information related to the automatic release (#290)

* docs: added information related to the automatic release

* docs: removed test-parallel from docs

* docs: minor additions to contributing guidelines

* ci: removed changelog

As it already present in the git releases

* Apply suggestions from code review

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`6821d23`](https://github.com/embeddings-benchmark/mteb/commit/6821d2324f41fed2bb686eedf074e4dc6803ece6))

### Fix

* fix: fixed bug introduced in TatoebaBitextMining causing it to use a different dataset (#297) ([`d0549a3`](https://github.com/embeddings-benchmark/mteb/commit/d0549a35f9697663a3e4bc6bdbe5990977d5c2e2))

* fix: Fixed mispecified rev. id for datasets (#298)

* fix: fixed wrong rev. id for ToxicConversationsClassification

* fix: fixed wrong rev. id with RedditClusteringP2P ([`e1ae0d3`](https://github.com/embeddings-benchmark/mteb/commit/e1ae0d367eda70e6be31f0a43e20aed7cf75fedd))

## v1.3.2 (2024-03-29)

### Documentation

* docs: Update links in README.md (#296) ([`76056b5`](https://github.com/embeddings-benchmark/mteb/commit/76056b5ba92dcbfe32d629897ab6d5db3a0861c4))

### Fix

* fix: Added tasks from SEB (#287)

* Added tasks from SEB

* docs: fix link

* fix: ran linting

* fix typing for 3.8

* fixed annotation for v3.8 ([`39cff49`](https://github.com/embeddings-benchmark/mteb/commit/39cff490157ae87d1cf62c77022f325be729bf04))

## v1.3.1 (2024-03-26)

### Fix

* fix: updated version in transition to semantic release ci ([`238ab82`](https://github.com/embeddings-benchmark/mteb/commit/238ab825e9b221c363589eed89273481e058c50f))

## v1.3.0 (2024-03-26)

### Breaking

* feat: Updating version

BREAKING CHANGE: Bump version ([`caee2e9`](https://github.com/embeddings-benchmark/mteb/commit/caee2e9451999633476fb3305fb3fdc928ec9f0b))

### Ci

* ci: disable changelog ([`b7d3cde`](https://github.com/embeddings-benchmark/mteb/commit/b7d3cde561200264d74e592a678f0dea2eb68129))

* ci: moved release to the correct folder ([`b4fa85a`](https://github.com/embeddings-benchmark/mteb/commit/b4fa85a51374b78b47789557c5467700b859eba5))

* ci: renamed test job and workflow (#282)

ci: Added tests ([`6675bb8`](https://github.com/embeddings-benchmark/mteb/commit/6675bb8668ff17ca8cf3cce2703f3ebf17795bfc))

### Documentation

* docs: typos in readme (#268) ([`aa9234c`](https://github.com/embeddings-benchmark/mteb/commit/aa9234cc24f6dd3408961895d092ee019551fab2))

* docs: add dataset schemas (#255)

* docs: update AbsTaskClassification.py document schema for classification task

* update AbsTaskBitextMining.py

* update BornholmskBitextMining.py

* update AbsTaskClustering.py and BlurbsClusteringP2P.py

* update 8 files

* update 9 files

* update AbsTaskReranking.py

* update BlurbsClusteringP2P.py

* update CMTEBPairClassification.py

* update GerDaLIRRetrieval.py

* update 7 files

* update AbsTaskBitextMining.py

* update AbsTaskClassification.py ([`c3ce1ac`](https://github.com/embeddings-benchmark/mteb/commit/c3ce1ac8ac92baf9a7481c30d476b45e3ec36786))

* docs: Add development installation instructions (#246)

* docs: Add development installation instructions

* removed unused requirements file

I don&#39;t believe this is nec. with the setup.py specifying the same dependencies

* docs: Updated make file with new dependencies

* ci: Update ci to use make commands

This ensure that the user runs exactly what the CI expects

* ci: Avoid specifying tests folder as it causes issuew ith tests

* ci: removed unec. args for test ci

* Added dev install ([`0048878`](https://github.com/embeddings-benchmark/mteb/commit/0048878deba9f57147c3696dcb89ade098c90376))

### Feature

* feat: bump version again ([`294ab91`](https://github.com/embeddings-benchmark/mteb/commit/294ab910f6aa4099c0de8c9f91dbee38efd91aab))

* feat: bump version again ([`acf68c7`](https://github.com/embeddings-benchmark/mteb/commit/acf68c799133d390baba15cdf87f81c844c5a682))

### Fix

* fix: dead link in readme ([`ecbb776`](https://github.com/embeddings-benchmark/mteb/commit/ecbb776fba460c531f09e7b0ce986f075f2b665a))

* fix: Added sizes to the metadata (#276)

* restructing the readme

* added mmteb

* removed unec. method

* Added docstring to metadata

* Updated outdated examples

* formatting documents

* fix: Updated form to be parsed correctly

* fix: Added sizes to the metadata

this allow for automatic metadata generations

* Updated based on feedback

* Apply suggestions from code review

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* updated based on feedback

* Added suggestion from review

* added correction based on review

* reformatted empty fields to None

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`cd4a012`](https://github.com/embeddings-benchmark/mteb/commit/cd4a012271463b89db7a8ec9ca298a975805988d))

### Refactor

* refactor: add metadata basemodel (#260)

* refactor: rename description to metadata dict

* refactor: add TaskMetadata and first example

* update 9 files

* update TaskMetadata.py

* update TaskMetadata.py

* update TaskMetadata.py

* update LICENSE, TaskMetadata.py and requirements.dev.txt

* update 151 files

* update 150 files

* update 43 files and delete 1 file

* update 106 files

* update 45 files

* update 6 files

* update 14 files

* Added model results to repo and updated CLI to create consistent folder structure. (#254)

* Added model results to repo and updated CLI to create consistent folder structure.

* ci: updated ci to use make install

* Added missing pytest dependencies

* Update README.md

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Restructing the readme (#262)

* restructing the readme

* removed double specification of versions and moved all setup to pyproject.toml

* correctly use flat-layout for the package

* build(deps): update TaskMetadata.py and pyproject.toml

* update 221 files

* build(deps): update pyproject.toml

* build(deps): update pyproject.toml

* build(deps): update pyproject.toml

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`dd5d617`](https://github.com/embeddings-benchmark/mteb/commit/dd5d61724e71b2cdba9f9cf7e01fbed1b81cb423))

### Unknown

* overwrite version ([`bc60c9d`](https://github.com/embeddings-benchmark/mteb/commit/bc60c9dc9f9a8a10cae4794a764a01ee766b7659))

* v1.3.0 ([`50b856c`](https://github.com/embeddings-benchmark/mteb/commit/50b856cd116fbcf93b4848ab4c0e58a67d88ca4a))

* v1.3.0 ([`61c12d8`](https://github.com/embeddings-benchmark/mteb/commit/61c12d8cc7f27bea50322cf9332936fa15ccca1a))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`7b0a766`](https://github.com/embeddings-benchmark/mteb/commit/7b0a76670aa013291bbf52c98b813667d29f3ea1))

* Ci-fix (#289)

* added release pipeline

* v1.3.0

* ci: moved release to the correct folder ([`7f56c1a`](https://github.com/embeddings-benchmark/mteb/commit/7f56c1a7d2eb2fab6eb028291d85054727c650d1))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`57f500f`](https://github.com/embeddings-benchmark/mteb/commit/57f500f59dcdc27ac7edfed0475b20becc16b191))

* v1.3.0

* added release pipeline

* v1.3.0 ([`5e4d10e`](https://github.com/embeddings-benchmark/mteb/commit/5e4d10e5224d21e51d0ffcd87abee42008f2446c))

* v1.3.0 ([`cdda2f2`](https://github.com/embeddings-benchmark/mteb/commit/cdda2f2786ce582af2a75745873e207739f7f819))

* added release pipeline ([`69a440b`](https://github.com/embeddings-benchmark/mteb/commit/69a440b8a725493f63c63b06f7357648a7e9b37e))

* tests: speed up tests (#283)

update Makefile and test_all_abstasks.py ([`2155bf6`](https://github.com/embeddings-benchmark/mteb/commit/2155bf66c2ea5435744c47b03e3f14b6a5df1813))

* update TaskMetadata.py (#281) ([`acfd7d4`](https://github.com/embeddings-benchmark/mteb/commit/acfd7d420fc3aa05d624db43c5b41f85b1a93367))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`c9d1a03`](https://github.com/embeddings-benchmark/mteb/commit/c9d1a03c7d8531a0293cbd24e523e904c2be9477))

* Enable ruff ci (#279)

* restructing the readme

* added mmteb

* removed unec. method

* Added docstring to metadata

* Updated outdated examples

* formatting documents

* fix: Updated form to be parsed correctly

* fix: Added sizes to the metadata

this allow for automatic metadata generations

* Updated based on feedback

* Apply suggestions from code review

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* updated based on feedback

* Added suggestion from review

* added correction based on review

* reformatted empty fields to None

* CI: Enable linter

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`a16eb07`](https://github.com/embeddings-benchmark/mteb/commit/a16eb07da1d1a6d8380683e9fa11df3244fae87b))

* Added MMTEB (#275)

* restructing the readme

* added mmteb

* removed unec. method

* Added docstring to metadata

* Updated outdated examples

* formatting documents

* fix: Updated form to be parsed correctly

* Updated based on feedback

* Apply suggestions from code review

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* updated based on feedback

* Added suggestion from review

* added correction based on review

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`c0dc49a`](https://github.com/embeddings-benchmark/mteb/commit/c0dc49a6b99f4d8136b7ec46c49563d7e1b866db))

* dev: add ruff as suggested extension (#274) ([`b08913f`](https://github.com/embeddings-benchmark/mteb/commit/b08913f8616c580f8bbb15bfa808549e2b74912a))

* dev: add isort (#271)

* dev: add isort

* dev: add isort ([`845099d`](https://github.com/embeddings-benchmark/mteb/commit/845099d5b49b0757cc4cf23c08c6d7f65627538e))

* dev: run tests on pull request towards any branch ([`13f759a`](https://github.com/embeddings-benchmark/mteb/commit/13f759a62bff085e156e4d115f64604c2dc0f087))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb ([`b42abe4`](https://github.com/embeddings-benchmark/mteb/commit/b42abe4e37f96dd0cab898b381d644d507a228a1))

* replaced linter with ruff (#265)

* restructing the readme

* removed double specification of versions and moved all setup to pyproject.toml

* correctly use flat-layout for the package

* replaced linter with ruff

* rerun tests

* ci: Added in newer workflow

some of them are disables as they require other issues to be solved

* Update Makefile

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`023e881`](https://github.com/embeddings-benchmark/mteb/commit/023e8817f108a76718fc37f7c8937e000de56786))

* Restructing the readme (#262)

* restructing the readme

* removed double specification of versions and moved all setup to pyproject.toml

* correctly use flat-layout for the package ([`769157b`](https://github.com/embeddings-benchmark/mteb/commit/769157b1e49c97ee6ca334a299392392bc3a6523))

* restructing the readme ([`364be7f`](https://github.com/embeddings-benchmark/mteb/commit/364be7f4a26275263c9a82de594e47aaf28a1bcf))

* Added model results to repo and updated CLI to create consistent folder structure. (#254)

* Added model results to repo and updated CLI to create consistent folder structure.

* ci: updated ci to use make install

* Added missing pytest dependencies

* Update README.md

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`8a758bc`](https://github.com/embeddings-benchmark/mteb/commit/8a758bce00a6bc64dd4f0dab98f5bc3e0c683f46))

* dev: add workspace defaults in VSCode (#253)

* dev: add black as default formatter in vscode

* Update .vscode/settings.json

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt; ([`30e5b9e`](https://github.com/embeddings-benchmark/mteb/commit/30e5b9ebb288d923b3c7e8d0e55728f82a1bc5d8))

* Add Danish Discourse dataset (#247)

* misc.

* update ddisco.py

* chore: delete ddisco.py, ddisco.test.tsv and ddisco.train.tsv

* Update mteb/tasks/Classification/DdiscoCohesionClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Classification/DdiscoCohesionClassification.py

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;

* Update mteb/tasks/Classification/DdiscoCohesionClassification.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* Update mteb/tasks/Classification/DdiscoCohesionClassification.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* Update mteb/tasks/Classification/DdiscoCohesionClassification.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

---------

Co-authored-by: Kenneth Enevoldsen &lt;kennethcenevoldsen@gmail.com&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`d46d0f5`](https://github.com/embeddings-benchmark/mteb/commit/d46d0f5281d5a9036501aca437e9c76480dc8885))

* Update structure of mteb/tasks to mteb/tasks/{type}/{language}Â  (#245)

* Fix structure of mteb/tasks
Fixes #243

* fix: Added missing init files ([`b1c78c1`](https://github.com/embeddings-benchmark/mteb/commit/b1c78c1121fbd488d62d1385d6f000d3f3b46ef4))

* tests: do not run tests on collection (#249)

test: update test_all_abstasks.py ([`236614a`](https://github.com/embeddings-benchmark/mteb/commit/236614add5de4e848bc0f1db8ad997f451ae2906))

* Update README.md with correct DRESModel location ([`399edf4`](https://github.com/embeddings-benchmark/mteb/commit/399edf4331cd316b28a832fd37e187d5c5e204f1))

* Fix typo ([`9610378`](https://github.com/embeddings-benchmark/mteb/commit/96103788cd135caecdb439b5d26af38ab6cd33ef))

* Set dev version ([`716f59c`](https://github.com/embeddings-benchmark/mteb/commit/716f59cae9be31a747371497ec6792b23070270c))

## v1.2.0 (2024-03-06)

### Unknown

* Release: 1.2.0 ([`9e9dca8`](https://github.com/embeddings-benchmark/mteb/commit/9e9dca890bcced66494996863a2fb52ea4129d87))

* Rmv superfluous file ([`d772fed`](https://github.com/embeddings-benchmark/mteb/commit/d772fedb2c102112217e494987eaf2468925256e))

* Remove duplicate &amp; outdated  code ([`12bcb83`](https://github.com/embeddings-benchmark/mteb/commit/12bcb83835943011c92efaf117f16c808f3a1fe8))

* Adapt scripts ([`36b9234`](https://github.com/embeddings-benchmark/mteb/commit/36b92341e0178a7bc2276cac468f2e73b5c5880c))

* Add example ([`273ff4a`](https://github.com/embeddings-benchmark/mteb/commit/273ff4acb70b063bbcae04d5812f580e1dea4bc2))

* Simplify retrieval (#233)

* Simplify retrieval

* Simplify

* Make __call__ method

* Add splits

* Rmv outdated test

* Fix name &amp; \n

* Add qrels

* Add revisions

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* Add hf hub org

* Add test

* Add missing revision

* Rename test

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* log dres compat

---------

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt; ([`c9fccbc`](https://github.com/embeddings-benchmark/mteb/commit/c9fccbcb7f576e33b6b6f487c8f3dc5cbecc0a33))

* Fixed missing revision error on Norwegian Bitext Mining (#221)

* Removed revision specification from Norwegian Bitext Mining task

* Update to latest revision

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`b249c67`](https://github.com/embeddings-benchmark/mteb/commit/b249c6766622a6c2a2f9d9194e140eca9cbd0e3c))

* Remove HAGRID from french benchmark (#235)

* add Masakhane dataset config

* add trigram lang code for dataset who use it

* create french script eval

* fix French word

* add some documentation

* add script to process and upload alloprof on HF

* build script for HF

* adding dataset processing for mteb

* add script to process and upload alloprof on HF

* build script for HF

* adding dataset processing for mteb

* refactor few thing

* remove whitespaces

* 4 pair classification (#10)

* add Opusparcus dataset

* multilingual usage

* use eval_split of config files

* change eval_split according to data

---------

Co-authored-by: Gabriel Sequeira &lt;gsequeira@openstudio.fr&gt;

* add script to process and upload alloprof on HF

* build script for HF

* adding dataset processing for mteb

* refactor few thing

* remove whitespaces

* Clustering with HAL S2S dataset (#11)

HAL S2S dataset creation and evaluation on clustering task.

* adding BSARD dataset

* add BSARD to benchmark

* adding Hagrid dataset

* DiaBLa and Flores Bitext Mining evaluation (#12)

* Add DiaBLa dataset for bitext mining

* Add DiaBLa dataset for bitext mining

* deduplicate bitext task

* add Flores

* format files

* add flores to evaluation script

* remove prints

* add revision

---------

Co-authored-by: Gabriel Sequeira &lt;gsequeira@openstudio.fr&gt;

* add script to process and upload alloprof on HF

* build script for HF

* adding dataset processing for mteb

* refactor few thing

* remove whitespaces

* adding dataset processing for mteb

* adding BSARD dataset

* add BSARD to benchmark

* adding Hagrid dataset

* fix change on langmapping

* reset alphabetical order

* add revision handling

* Clustering: Add AlloProf dataset  (#17)

AlloProf dataset for clustering task

* handling of revision

* change split + add revision handling

* add script to process and upload alloprof on HF

* build script for HF

* adding dataset processing for mteb

* refactor few thing

* remove whitespaces

* adding dataset processing for mteb

* adding BSARD dataset

* add BSARD to benchmark

* adding Hagrid dataset

* add script to process and upload alloprof on HF

* adding dataset processing for mteb

* refactor few thing

* reset alphabetical order

* add revision handling

* handling of revision

* change split + add revision handling

* use eval variable

* alphabetic order

* Add MLSUM dataset for clustering task (#21)

* Use Masakhane dataset for clustering task (#23)

* 16 add datasets to readmemd (#18)

* run task table

* run task table

* Add MLSUM dataset for clustering task (#21)

* Use Masakhane dataset for clustering task (#23)

* run task table

* refresh readme

* refresh readme

* run task table

* refresh readme

---------

Co-authored-by: Gabriel Sequeira &lt;gsequeira@openstudio.fr&gt;
Co-authored-by: Marion Schaeffer &lt;92590517+schmarion@users.noreply.github.com&gt;

* load only test split (#25)

Co-authored-by: Gabriel Sequeira &lt;gsequeira@openstudio.fr&gt;

* Update mteb/tasks/BitextMining/DiaBLaBitextMining.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/tasks/Clustering/HALClusteringS2S.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* renaming masakhane (#28)

Co-authored-by: Gabriel Sequeira &lt;gsequeira@openstudio.fr&gt;

* Syntec dataset addition (#26)

* add scrpit to process &amp; load to HF

* add script to enable download of data from HF

* add syntec dataset files to gitignore

* add syntecretrieval

* add syntec retrival

* build dataloading script

* remove datasets

* correct typo

---------

Co-authored-by: Sequeira Gabriel &lt;gabriel.sequeira@outlook.fr&gt;

* 30 add syntec reranking (#31)

* change name to secify retrieval

* add reranking tasks

* create script to upload dataset fo reranking task

* create reranking task

* add reranking tasks

* add model name in description

* SummEval translated to french (#32)

* 7 sts (#33)

* taike into account multilingual tasks

* add stsbenchmark multilingual dataset

* add STS tasks

* taike into account multilingual tasks

* add stsbenchmark multilingual dataset

* add STS tasks

* add coma

* Adding sick fr dataset to sts tasks (#34)

* Adding sick fr dataset to sts tasks
* modifying dataset in load function to have the right column names

* Fix alloprof dataset (#36)

* change revision to use

* remove duplicate data

* change main metric because dataset is hard (#37)

* Fix alloprof dataset (#40)

* change revision to use

* remove duplicate data

* change revision

* handle queries train test split

* change dataset creation method

* change revision

* handle queries train test split

* change dataset creation method

* Fix DiaBLa by inheriting CrossLingual class (#42)

* Fix DiaBLa by inheriting CrossLingual class

* remove remaining print

* Fix DiaBLa integration

* Update mteb/tasks/BitextMining/FloresBitextMining.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update README.md

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update README.md

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/tasks/Classification/MasakhaNEWSClassification.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update README.md

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update README.md

* Update mteb/tasks/BitextMining/FloresBitextMining.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/evaluation/MTEB.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/abstasks/AbsTaskPairClassification.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* Update README.md

* Update scripts/data/syntec/create_data_reranking.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update scripts/data/alloprof/create_data_reranking.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update scripts/run_mteb_french.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update scripts/run_mteb_french.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/evaluation/MTEB.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/evaluation/MTEB.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/tasks/Retrieval/HagridRetrieval.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/tasks/Clustering/MLSUMClusteringP2P.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/tasks/Clustering/MLSUMClusteringS2S.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/tasks/Clustering/MasakhaNEWSClusteringP2P.py

* Update mteb/tasks/Clustering/MasakhaNEWSClusteringS2S.py

* Update mteb/tasks/STS/SickFrSTS.py

* Inherit OpusparcusPC init from MultilingualTask

* remove unnecessary init

* Remove train split from evaluation on MasakhaNEWSClassification (#52)

remove train split from evaluation

* put script on HF dataset repos (#56)

* put script on HF dataset repos

* remove scripts

* 49 fix dictionnary in syntecretrieval (#54)

* add trust remote code arg

* leave corpus as dict

* remove trust remote code

* add Tatoeba &amp; BUCC BitextMining tasks (#57)

add bucc and tatoeba bitextmining tasks

* 46 add other languages to masakhaneweclusterings2s and p2p (#58)

* add other language to clustering tasks

* fix main score and S2S task

* update run fr becnhmark script

* Update run_mteb_french.py

* Update AbsTaskClustering.py

* remove train and validation splits

* remove Hagrid (#60)

---------

Co-authored-by: Gabriel Sequeira &lt;gsequeira@openstudio.fr&gt;
Co-authored-by: Marion Schaeffer &lt;92590517+schmarion@users.noreply.github.com&gt;
Co-authored-by: mciancone@openstudio.fr &lt;mciancone@openstudio.fr&gt;
Co-authored-by: Sequeira Gabriel &lt;gabriel.sequeira@outlook.fr&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: wissam-sib &lt;36303760+wissam-sib@users.noreply.github.com&gt;
Co-authored-by: Wissam Siblini &lt;wissam.siblini92@gmail.com&gt; ([`d01d053`](https://github.com/embeddings-benchmark/mteb/commit/d01d053028362dc1568be6b8fcff8be915d97837))

* Restore TRECCOVID import ([`9f8e897`](https://github.com/embeddings-benchmark/mteb/commit/9f8e897b1edf80e683dcfa15931d8070d496ffd6))

* Extend MTEB with French datasets (#218)

* add Masakhane dataset config

* add trigram lang code for dataset who use it

* create french script eval

* fix French word

* add some documentation

* add script to process and upload alloprof on HF

* build script for HF

* adding dataset processing for mteb

* add script to process and upload alloprof on HF

* build script for HF

* adding dataset processing for mteb

* refactor few thing

* remove whitespaces

* 4 pair classification (#10)

* add Opusparcus dataset

* multilingual usage

* use eval_split of config files

* change eval_split according to data

---------

Co-authored-by: Gabriel Sequeira &lt;gsequeira@openstudio.fr&gt;

* add script to process and upload alloprof on HF

* build script for HF

* adding dataset processing for mteb

* refactor few thing

* remove whitespaces

* Clustering with HAL S2S dataset (#11)

HAL S2S dataset creation and evaluation on clustering task.

* adding BSARD dataset

* add BSARD to benchmark

* adding Hagrid dataset

* DiaBLa and Flores Bitext Mining evaluation (#12)

* Add DiaBLa dataset for bitext mining

* Add DiaBLa dataset for bitext mining

* deduplicate bitext task

* add Flores

* format files

* add flores to evaluation script

* remove prints

* add revision

---------

Co-authored-by: Gabriel Sequeira &lt;gsequeira@openstudio.fr&gt;

* add script to process and upload alloprof on HF

* build script for HF

* adding dataset processing for mteb

* refactor few thing

* remove whitespaces

* adding dataset processing for mteb

* adding BSARD dataset

* add BSARD to benchmark

* adding Hagrid dataset

* fix change on langmapping

* reset alphabetical order

* add revision handling

* Clustering: Add AlloProf dataset  (#17)

AlloProf dataset for clustering task

* handling of revision

* change split + add revision handling

* add script to process and upload alloprof on HF

* build script for HF

* adding dataset processing for mteb

* refactor few thing

* remove whitespaces

* adding dataset processing for mteb

* adding BSARD dataset

* add BSARD to benchmark

* adding Hagrid dataset

* add script to process and upload alloprof on HF

* adding dataset processing for mteb

* refactor few thing

* reset alphabetical order

* add revision handling

* handling of revision

* change split + add revision handling

* use eval variable

* alphabetic order

* Add MLSUM dataset for clustering task (#21)

* Use Masakhane dataset for clustering task (#23)

* 16 add datasets to readmemd (#18)

* run task table

* run task table

* Add MLSUM dataset for clustering task (#21)

* Use Masakhane dataset for clustering task (#23)

* run task table

* refresh readme

* refresh readme

* run task table

* refresh readme

---------

Co-authored-by: Gabriel Sequeira &lt;gsequeira@openstudio.fr&gt;
Co-authored-by: Marion Schaeffer &lt;92590517+schmarion@users.noreply.github.com&gt;

* load only test split (#25)

Co-authored-by: Gabriel Sequeira &lt;gsequeira@openstudio.fr&gt;

* Update mteb/tasks/BitextMining/DiaBLaBitextMining.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/tasks/Clustering/HALClusteringS2S.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* renaming masakhane (#28)

Co-authored-by: Gabriel Sequeira &lt;gsequeira@openstudio.fr&gt;

* Syntec dataset addition (#26)

* add scrpit to process &amp; load to HF

* add script to enable download of data from HF

* add syntec dataset files to gitignore

* add syntecretrieval

* add syntec retrival

* build dataloading script

* remove datasets

* correct typo

---------

Co-authored-by: Sequeira Gabriel &lt;gabriel.sequeira@outlook.fr&gt;

* 30 add syntec reranking (#31)

* change name to secify retrieval

* add reranking tasks

* create script to upload dataset fo reranking task

* create reranking task

* add reranking tasks

* add model name in description

* SummEval translated to french (#32)

* 7 sts (#33)

* taike into account multilingual tasks

* add stsbenchmark multilingual dataset

* add STS tasks

* taike into account multilingual tasks

* add stsbenchmark multilingual dataset

* add STS tasks

* add coma

* Adding sick fr dataset to sts tasks (#34)

* Adding sick fr dataset to sts tasks
* modifying dataset in load function to have the right column names

* Fix alloprof dataset (#36)

* change revision to use

* remove duplicate data

* change main metric because dataset is hard (#37)

* Fix alloprof dataset (#40)

* change revision to use

* remove duplicate data

* change revision

* handle queries train test split

* change dataset creation method

* change revision

* handle queries train test split

* change dataset creation method

* Fix DiaBLa by inheriting CrossLingual class (#42)

* Fix DiaBLa by inheriting CrossLingual class

* remove remaining print

* Fix DiaBLa integration

* Update mteb/tasks/BitextMining/FloresBitextMining.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update README.md

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update README.md

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/tasks/Classification/MasakhaNEWSClassification.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update README.md

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update README.md

* Update mteb/tasks/BitextMining/FloresBitextMining.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/evaluation/MTEB.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/abstasks/AbsTaskPairClassification.py

Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;

* Update README.md

* Update scripts/data/syntec/create_data_reranking.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update scripts/data/alloprof/create_data_reranking.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update scripts/run_mteb_french.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update scripts/run_mteb_french.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/evaluation/MTEB.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/evaluation/MTEB.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/tasks/Retrieval/HagridRetrieval.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/tasks/Clustering/MLSUMClusteringP2P.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/tasks/Clustering/MLSUMClusteringS2S.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/tasks/Clustering/MasakhaNEWSClusteringP2P.py

* Update mteb/tasks/Clustering/MasakhaNEWSClusteringS2S.py

* Update mteb/tasks/STS/SickFrSTS.py

* Inherit OpusparcusPC init from MultilingualTask

* remove unnecessary init

* Remove train split from evaluation on MasakhaNEWSClassification (#52)

remove train split from evaluation

* put script on HF dataset repos (#56)

* put script on HF dataset repos

* remove scripts

* 49 fix dictionnary in syntecretrieval (#54)

* add trust remote code arg

* leave corpus as dict

* remove trust remote code

* add Tatoeba &amp; BUCC BitextMining tasks (#57)

add bucc and tatoeba bitextmining tasks

* 46 add other languages to masakhaneweclusterings2s and p2p (#58)

* add other language to clustering tasks

* fix main score and S2S task

* update run fr becnhmark script

* Update run_mteb_french.py

* Update AbsTaskClustering.py

* remove train and validation splits

---------

Co-authored-by: Gabriel Sequeira &lt;gsequeira@openstudio.fr&gt;
Co-authored-by: Marion Schaeffer &lt;92590517+schmarion@users.noreply.github.com&gt;
Co-authored-by: mciancone@openstudio.fr &lt;mciancone@openstudio.fr&gt;
Co-authored-by: Imene Kerboua &lt;33312980+imenelydiaker@users.noreply.github.com&gt;
Co-authored-by: mciancone &lt;73994289+Sunalwing@users.noreply.github.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;
Co-authored-by: wissam-sib &lt;36303760+wissam-sib@users.noreply.github.com&gt;
Co-authored-by: Wissam Siblini &lt;wissam.siblini92@gmail.com&gt; ([`3d8b8ec`](https://github.com/embeddings-benchmark/mteb/commit/3d8b8ec563963905923fd1627093c7779d77a5cd))

* dev ([`c16eddc`](https://github.com/embeddings-benchmark/mteb/commit/c16eddcd111dd25e5a3526bcce9d7ba162a28fd5))

* Dev ([`08c7317`](https://github.com/embeddings-benchmark/mteb/commit/08c7317ba76dea38f0afb51278391e20ab2463e0))

* Add tasks for Spanish Embedding Evaluation (#227)

* feat: add xmarket es dataset

* refactor: use multilingual dataset

* fix: update revision id

* refactor: add constant for language

* feat: add two clustering datasets

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* feat: import classes

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* refactor: flores dataset

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* feat: add miracl reranking task for spanish

* feat: use hf repo with all reranking langs

* feat: update revision hash

* refactor: use description for language

* feat: add stses task

* fix: get scores from label column

* refactor: add revision to data loading

* Added spanish passage retrieval

* feat: mintaka and xpqa retrieval tasks

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* feat: import classes

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* fix: typo in data loading

* fix: id

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* refactor: try out multilingual task

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* refactor: multilingual task import

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* refactor: cmon man

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* refactor: go back to monolingual tasks

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* refactor: remove unused import

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* refactor: loading logic

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;

* feat: add miracl as retrieval task

* fix: nested corpus

* refactor: get lang from description

* Update mteb/tasks/Retrieval/MIRACLRetrieval.py

Co-authored-by: Michael GÃ¼nther &lt;michael.guenther@jina.ai&gt;

* feat: allow multlingual reranking tasks

* feat: make miraclreranking multilingual

* refactor: rename miraclretrieval

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* style: add missing eof empty line

* feat: make xmarket retrieval task multilingual

* refactor: rename xmarket

* refactor: turn spanish tasks multilingual (#11)

* refactor: make xpqa retrieval multilingual

* fix: formatting of xpqa dataset

* refactor: make mintaka into multilingual task

* refactor: make miracl retrieval multilingual

* feat: add revision ids for hf datasets

* refactor: remove patool

* Update mteb/tasks/Reranking/__init__.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update mteb/tasks/STS/__init__.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

---------

Signed-off-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;
Co-authored-by: guenthermi &lt;guenthermi50@gmail.com&gt;
Co-authored-by: jupyterjazz &lt;saba.sturua@jina.ai&gt;
Co-authored-by: Markus Krimmel &lt;markus.krimmel@jina.ai&gt;
Co-authored-by: Michael GÃ¼nther &lt;michael.guenther@jina.ai&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`52d5c9f`](https://github.com/embeddings-benchmark/mteb/commit/52d5c9f666f8b5f5e65cd9bf3f4651078ff1fced))

## v1.1.2 (2024-02-16)

### Feature

* feat: update revision id of wikicitiesclustering task ([`fb90c02`](https://github.com/embeddings-benchmark/mteb/commit/fb90c022e11834ae6605f5bbb0a79af701793a96))

### Fix

* fix: remove debugging print statement ([`d292d93`](https://github.com/embeddings-benchmark/mteb/commit/d292d937ceedb5d137537b2c25a0f135d1bb91b9))

* fix: pass parallel_retrieval kwarg to use DenseRetrievalParallelExactSearch ([`19b8f66`](https://github.com/embeddings-benchmark/mteb/commit/19b8f6619f07dfd95860f43f9376af230978f447))

### Unknown

* Release: 1.1.2 ([`def3c91`](https://github.com/embeddings-benchmark/mteb/commit/def3c9146ff437d4b9bb690dea183070ccb36a7f))

* Add task list (#228)

* Add task list

* Update mteb/__init__.py

* Update README.md ([`10bf6f8`](https://github.com/embeddings-benchmark/mteb/commit/10bf6f84840ee38ed632861cda603976f87612ec))

* Update BeIRPLTask.py (#225)

* Update BeIRPLTask.py

* Update BeIRPLTask.py ([`a8922c1`](https://github.com/embeddings-benchmark/mteb/commit/a8922c14845c2fa2a20d591f93ffa0cfb42baccc))

* Allow multiple languages ([`2cc222e`](https://github.com/embeddings-benchmark/mteb/commit/2cc222efd84c29cbb5ff04fb8e6703674d53dda9))

* Add Korean Text Search Tasks to MTEB (#210)

* add Ko-miracl, Ko-StrategyQA, Ko-mrtydi tasks

* Update mteb/abstasks/AbsTaskRetrieval.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update AbsTaskRetrieval.py

* Update mteb/abstasks/AbsTaskRetrieval.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* Update scripts/run_mteb_korean.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`dadf2da`](https://github.com/embeddings-benchmark/mteb/commit/dadf2dacc1bd12e08d7507597497d6727f4c9720))

* Add MultiLongDocRetrieval task to MTEB. (#224)

* Update AbsTaskRetrieval.py.

* Add Retrieval Task: `MultiLongDocRetrieval`

* Update AbsTaskRetrieval.py and `MLDR` task

* Update reference of MLDR ([`2f65179`](https://github.com/embeddings-benchmark/mteb/commit/2f65179e3ad31b5c46115c620815cc162b23890b))

* Fix name ([`2989f76`](https://github.com/embeddings-benchmark/mteb/commit/2989f76dfd47d719a338ea564ff1122c80b4b51f))

* only save top-k (#209)

* Update AbsTaskRetrieval.py

* Add json import; rename kwarg

* Pass OF

* Update mteb/abstasks/AbsTaskRetrieval.py

* Update AbsTaskRetrieval.py

* Update AbsTaskRetrieval.py

* Update mteb/abstasks/AbsTaskRetrieval.py

---------

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`f58888d`](https://github.com/embeddings-benchmark/mteb/commit/f58888d30439bc8e820b3f894ec12bce5393ba76))

* Add tasks for German Embedding Evaluation (#214)

* chore: solve merge conflict

* fix: gerdalir dataset

* fix: lang from en to de

* chore: solve merge conflict

* chore: add ir datasets to requirements

* refactor: limit queries to 10k

* refactor: update description of task with limit

* revert style changes

* feat: add german stsbenchmarksts task

* feat: update revision id

* refactor: update revision id after changes in scores

* add XMarket dataset

* add xmarket to init file

* feat: add revision id

* add paws x dataset

* Add ir_datasets as dependency

* add GermanDPR dataset

* fix loading

* Update mteb/tasks/Retrieval/GermanDPRRetrieval.py

Co-authored-by: Saba Sturua &lt;45267439+jupyterjazz@users.noreply.github.com&gt;

* feat: add miracl reranking task for german

* refactor: cleanup task

* prevent duplicate pos docs

* fix: use test split in MIRACL (#13)

Fixes mismatch between description and HuggingFace dataset

* refactor: remove WikiCLIR

* fix: double import; xmarket name

* add German tasks to run_mteb_german script

* fupdate revisions and style

* update MIRACL to work with latest version

* revert adding ir_datasets

* support multilingual pair classification

* remove print statement

* Apply suggestions from code review

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt;

* fix monolingual pair classification

* remove lang for monolingual tasks

---------

Co-authored-by: Isabelle Mohr &lt;isabelle.mohr@jina.ai&gt;
Co-authored-by: Markus Krimmel &lt;markus.krimmel@jina.ai&gt;
Co-authored-by: Saba Sturua &lt;45267439+jupyterjazz@users.noreply.github.com&gt;
Co-authored-by: Markus Krimmel &lt;montcyril@gmail.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`9aba9ee`](https://github.com/embeddings-benchmark/mteb/commit/9aba9ee95a49a48d23b4ff6cfb9cc84bc9dfca32))

* Simplify ([`1cd07db`](https://github.com/embeddings-benchmark/mteb/commit/1cd07db380d7ce51f19653b4f63e18585fcf6398))

* Refer to other works ([`8f28bcb`](https://github.com/embeddings-benchmark/mteb/commit/8f28bcb554d8c605aa9b2c214b3d2b53c070c066))

* Update mteb/tasks/Retrieval/GermanQuADRetrieval.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`09a9cb0`](https://github.com/embeddings-benchmark/mteb/commit/09a9cb0d589214f2d41b0755a75c2ee6609b581a))

* clean up ([`51c40fd`](https://github.com/embeddings-benchmark/mteb/commit/51c40fdd1d913479ce94a0d86b6cd949eda876ab))

* WIP: implement requested changes ([`58baad2`](https://github.com/embeddings-benchmark/mteb/commit/58baad2da110e681a78962eaf794446ad730f960))

* remove code for writing JSONL dataset ([`d23eac3`](https://github.com/embeddings-benchmark/mteb/commit/d23eac312e8e8c067c5f7fb1354829cafee0de3b))

* add docstring, remove local qrels ([`af7ee50`](https://github.com/embeddings-benchmark/mteb/commit/af7ee501008312e9c11550640fcabd529d9ad836))

* fix query id in qrel dataset, ready to merge ([`33c9dd4`](https://github.com/embeddings-benchmark/mteb/commit/33c9dd45aad83c786e7a716fd61cd46471b8140e))

* WIP: use HF dataset instead of local JSONL ([`db3fea1`](https://github.com/embeddings-benchmark/mteb/commit/db3fea1a3803da6af8df5d9f8466d83e436cee83))

* rename BeIRDETask ([`e56cf86`](https://github.com/embeddings-benchmark/mteb/commit/e56cf86c4f6b3a4ded5547d99082303a92bcbe51))

* Update scripts/run_mteb_german.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`4b18a7e`](https://github.com/embeddings-benchmark/mteb/commit/4b18a7e49b07b94f4eff215a1d0f1cc7b69302fd))

* Update mteb/tasks/Retrieval/GermanRetrieval.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`3fef61a`](https://github.com/embeddings-benchmark/mteb/commit/3fef61a3139bd05594f1c3b50fb450f8190f6e3d))

* add reference to GermanQuAD ([`ae268e0`](https://github.com/embeddings-benchmark/mteb/commit/ae268e031ac04ec715944a174de71f1b117ca44f))

* fix results folder path ([`dc7fc01`](https://github.com/embeddings-benchmark/mteb/commit/dc7fc01baabce94ce95d74d08f7782a43ac1dbaf))

* copy from local ([`9c0880d`](https://github.com/embeddings-benchmark/mteb/commit/9c0880d65402bad4862db1b7a4dd27f7379e2863))

* Update mteb/abstasks/AbsTaskRetrieval.py ([`be1fcc1`](https://github.com/embeddings-benchmark/mteb/commit/be1fcc1d47d301c1e627e587430fafd18a7dc316))

* Pass OF ([`b0e6316`](https://github.com/embeddings-benchmark/mteb/commit/b0e63164d8602bb4bb6919d4c6b457ec2726a145))

* Add json import; rename kwarg ([`d39c21c`](https://github.com/embeddings-benchmark/mteb/commit/d39c21c8cdf2b8a027ec67b0c496918835442539))

* Update AbsTaskRetrieval.py ([`4eb8e02`](https://github.com/embeddings-benchmark/mteb/commit/4eb8e02adb57c5f074d34a791703d2e996c283c8))

* Added Norwegian BokmÃ¥l-Nynorsk bitext mining task ([`c3fb742`](https://github.com/embeddings-benchmark/mteb/commit/c3fb742eca4143195c70861861288b16ac32fc9c))

* Add STS revisions ([`38277ae`](https://github.com/embeddings-benchmark/mteb/commit/38277ae6f76fe2623373a4e040cc6ddaa592dae7))

* Add RTR revisions ([`8da9487`](https://github.com/embeddings-benchmark/mteb/commit/8da9487f7cea6a3e34e575eb1479be9fe3007c3a))

* Add RRK revisions ([`2011cd8`](https://github.com/embeddings-benchmark/mteb/commit/2011cd8dc040cb38baa48307985629afd91a8b3e))

* Add PCLF revisions ([`9b6f4b9`](https://github.com/embeddings-benchmark/mteb/commit/9b6f4b9ff89103ce621b75afcfd93b49f1f0c222))

* Add CLST revisions ([`da73236`](https://github.com/embeddings-benchmark/mteb/commit/da73236d4a7c1e980895e71033194fe2435b1184))

* Add CLF revisions ([`fd91a9c`](https://github.com/embeddings-benchmark/mteb/commit/fd91a9c439b48eacd0107e62d6545f89d6608b3b))

* Update Revision ([`6b0fae5`](https://github.com/embeddings-benchmark/mteb/commit/6b0fae5799112717e45ee188a3a83b57aee48b2f))

* Fix SweFAQ linkage ([`2341c48`](https://github.com/embeddings-benchmark/mteb/commit/2341c4892a0ef7b8baf5c9aa5906303d0b7e6839))

* Fix SummEval linkage ([`7252322`](https://github.com/embeddings-benchmark/mteb/commit/7252322d0a1b6069e5cbfd827bc71093b0e4bb90))

* Fix Dalaj linkage ([`fb9ccd8`](https://github.com/embeddings-benchmark/mteb/commit/fb9ccd8dde24817455ae3465077436a13b985e7d))

* Fix medrxiv mislinkage ([`620defc`](https://github.com/embeddings-benchmark/mteb/commit/620defcc7b1048eb2cfe4041957196e22686adce))

* Fix stripping ([`02e84b2`](https://github.com/embeddings-benchmark/mteb/commit/02e84b2fa8d147a86b4896d8e57e83f36285f5c7))

* add datasets for long document evaluation

---------

Co-authored-by: Isabelle Mohr &lt;retrospect@protonmail.com&gt; ([`88beb46`](https://github.com/embeddings-benchmark/mteb/commit/88beb46d1340814875fafc27d337e0ed53125a4a))

* Do not enforce rich import ([`aa11fe7`](https://github.com/embeddings-benchmark/mteb/commit/aa11fe723e9b680f07fb01d1365d4975c5fa5803))

* fix RerankingEvaluator&#39;s compute_metrics_individual ([`fd7bfac`](https://github.com/embeddings-benchmark/mteb/commit/fd7bfac8add2a660f651fc02c9681dc4ad6e484a))

* Fix SummEval import ([`859d38e`](https://github.com/embeddings-benchmark/mteb/commit/859d38ec34b91a68f371ea81aade0f23c2d84aec))

* Increment version ([`4d75ddf`](https://github.com/embeddings-benchmark/mteb/commit/4d75ddf448c93b4b879e60e110061f7dcf76ae42))

## v1.1.1 (2023-09-20)

### Fix

* fix: msmarco-v2 uses dev.tsv, not dev1.tsv ([`6908d21`](https://github.com/embeddings-benchmark/mteb/commit/6908d21cfce644140bd70df47df0452c551ee0d0))

* fix: add missing task-langs attribute (#152) ([`bc22909`](https://github.com/embeddings-benchmark/mteb/commit/bc22909c49284efb0df1d997ac23806694424a94))

### Unknown

* Release: 1.1.1 ([`d3aaf4f`](https://github.com/embeddings-benchmark/mteb/commit/d3aaf4f1c1c503535d4d4de0a09e1ab7159dcd93))

* Merge branch &#39;main&#39; into fixconversion ([`d292258`](https://github.com/embeddings-benchmark/mteb/commit/d29225883c1e57f5dd56565080d497905ef9d92a))

* Simplify code snippets ([`d434f52`](https://github.com/embeddings-benchmark/mteb/commit/d434f5269b96d278b9b1bd286ddc70e5fb76b661))

* Simplify wording ([`3adb0b5`](https://github.com/embeddings-benchmark/mteb/commit/3adb0b542450b123c1cef22126d054e183b21b24))

* Clarify multi-gpu usage ([`5a2da23`](https://github.com/embeddings-benchmark/mteb/commit/5a2da23c801d680f4782990d3af9d48ad20030cc))

* Fix splits ([`93f6f85`](https://github.com/embeddings-benchmark/mteb/commit/93f6f8557e63dc7db0e1a41c1e6599dc4b748a93))

* Improve Cust Model explanation ([`52c1fd8`](https://github.com/embeddings-benchmark/mteb/commit/52c1fd8d1f5eb07a2d0d322a1116d7e800782d4a))

* Add bs to Clustering test ([`4df0d2e`](https://github.com/embeddings-benchmark/mteb/commit/4df0d2ed7c42b180f268555b238cecd1beffec02))

* Rely on auto-conversion to tensor in score function ([`d8512f7`](https://github.com/embeddings-benchmark/mteb/commit/d8512f7d7dd7c3e71273fa948357ab76e5613689))

* Rely on standard encode kwargs only ([`4c1660e`](https://github.com/embeddings-benchmark/mteb/commit/4c1660e99b350269a757ab9b1d5a6d380a1f6475))

* Fix eval_lang ([`7836148`](https://github.com/embeddings-benchmark/mteb/commit/7836148eeab16ad85bd1aaa1bab1d9590b831dbe))

* Improve Cust Model explanation ([`23d758f`](https://github.com/embeddings-benchmark/mteb/commit/23d758fd73ddc80a918420d11d25d7ced7a2d008))

* Add bs to Clustering test ([`6e0c0d2`](https://github.com/embeddings-benchmark/mteb/commit/6e0c0d2e53556e4a3c0c345233a20ef11a661972))

* Rely on auto-conversion to tensor in score function ([`7ec4c57`](https://github.com/embeddings-benchmark/mteb/commit/7ec4c57687b95ecfc7e84f062e750239b400e5a0))

* Rely on standard encode kwargs only ([`2fad0f9`](https://github.com/embeddings-benchmark/mteb/commit/2fad0f950acb36a38c4595fa5f9421cc6080c8bc))

* Update README.md ([`d9aa70f`](https://github.com/embeddings-benchmark/mteb/commit/d9aa70ffaad035d86815e8cf57ca3c6877b2f471))

* Update README.md ([`2211f83`](https://github.com/embeddings-benchmark/mteb/commit/2211f830cbea9e13bef5220576fc061407a548d2))

* Simplify assertion ([`f7fcbc1`](https://github.com/embeddings-benchmark/mteb/commit/f7fcbc18e99eb9f827490a6e87a76a4fd8913de7))

* Default to false ([`d64f6c7`](https://github.com/embeddings-benchmark/mteb/commit/d64f6c7be7cda5a1c34bb41012008f20fdd46ebf))

* Add multi gpu eval to readme (#140)

update readme ([`1b1c9d3`](https://github.com/embeddings-benchmark/mteb/commit/1b1c9d319f9a51ffd50c76e34c67773fc0ac75da))

* Support Multi-node Evaluation (#132)

* styling

* USE_HF_DATASETS

* Support DRPES

* we use beir.datasets.data_loader_hf in case of non dist

* distributed fixes

* update run command

* cleanup

* .

* sugg

* ruff ([`0dd82a9`](https://github.com/embeddings-benchmark/mteb/commit/0dd82a9819d32f264a24dbc057f753efbf54e9d8))

* Add Chinese tasks (C-MTEB) (#134)

* add C_MTEB

* add C_MTEB

* rename MMarcoReranking

* rename MMarcoReranking

* Update mteb/tasks/Retrieval/CMTEBRetrieval.py

* Update README.md

* Allow custom encode functions

---------

Co-authored-by: shitao &lt;stxiao@bupt.edu.cn&gt;
Co-authored-by: Nouamane Tazi &lt;nouamane98@gmail.com&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`071974a`](https://github.com/embeddings-benchmark/mteb/commit/071974a58e394332546a06a538c823440ee9ce73))

* Add Polish tasks (PL-MTEB) (#137)

* Add Polish tasks (PL-MTEB)

* Add Polish datasets to README

* Add newline

---------

Co-authored-by: rposwiata &lt;rposwiata@opi.org.pl&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`2779344`](https://github.com/embeddings-benchmark/mteb/commit/277934453a5a82c57d3b173e3c52ce0f4d0c97a5))

* Add BEIR-PL datasets to MTEB (#121)

* Add BIER-PL benchmark

* Update README with BEIR-PL datasets

* Update names

* Add tasks to init to be visible during evaluation

---------

Co-authored-by: Konrad Wojtasik &lt;konrad.wojtasik@pwr.edu.pl&gt;
Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`5972c02`](https://github.com/embeddings-benchmark/mteb/commit/5972c0238b3d119ff0fa2822a678b5d9f17f1087))

* Replaced prints with logging (#133)

* Make sure that main score is added to bitext mining tasks

* Added scandinavian languages: da, no, sv

* merge upstream main

* fix: Replaced prints with logging statements

* chore: removed accidental commits ([`d7ca378`](https://github.com/embeddings-benchmark/mteb/commit/d7ca3784451873042fb8a3fc2cdf4406f1ab465a))

* add logging ([`6412a6a`](https://github.com/embeddings-benchmark/mteb/commit/6412a6ae9839636f3dafb9f4b1a35c2f2b22c76e))

* Merge pull request #131 from embeddings-benchmark/nouamane/quick-fixes

Code cleanup ([`4fb97d0`](https://github.com/embeddings-benchmark/mteb/commit/4fb97d0497a99a97833d813701fcd38ffbd05669))

* . ([`3ebb039`](https://github.com/embeddings-benchmark/mteb/commit/3ebb0399f6ea45b040a30bed426769a03bda264d))

* add eval_splits arg ([`c407c4b`](https://github.com/embeddings-benchmark/mteb/commit/c407c4b78fa74e2d494517e9b1921334f56dc82f))

* quick fixes ([`6c5a3fa`](https://github.com/embeddings-benchmark/mteb/commit/6c5a3fafa88529b5eee016404dcdddb7d5656a37))

* clean MTEB tasks ([`b276f1d`](https://github.com/embeddings-benchmark/mteb/commit/b276f1d49fe824069368f44a0aaa44e315162e65))

* clean args ([`9365755`](https://github.com/embeddings-benchmark/mteb/commit/9365755213a6fc39153d16d8c5c45d484da6075d))

* styling ([`dd02b48`](https://github.com/embeddings-benchmark/mteb/commit/dd02b48c58b4d33bea151420a78eec863fb7bffa))

* black ([`652d07c`](https://github.com/embeddings-benchmark/mteb/commit/652d07c70a0aa7e0380d412d5f0d6d744685d445))

* ruff ([`6a58b5d`](https://github.com/embeddings-benchmark/mteb/commit/6a58b5d3b0c122d004de3f7476c1c169432208f5))

* Set dev version ([`bf98c2c`](https://github.com/embeddings-benchmark/mteb/commit/bf98c2c33021141ce237a819e41be9371479bdac))

## v1.1.0 (2023-07-31)

### Unknown

* Release: 1.1.0 ([`80d0344`](https://github.com/embeddings-benchmark/mteb/commit/80d0344dfe93b8ef4114ae8b03aeb64032263fde))

* Bump version ID and update PyPI (#128)

Bump version ID and update PyPI after adding additional tasks. ([`4a4b54b`](https://github.com/embeddings-benchmark/mteb/commit/4a4b54b3ef22a39895dbc836fb7a2edb26508a94))

* Fix typo ([`33a3140`](https://github.com/embeddings-benchmark/mteb/commit/33a3140bea6255b6b1ecbee8f816a25f3326674e))

* Sort imports ([`ab2eef8`](https://github.com/embeddings-benchmark/mteb/commit/ab2eef85ec3641987dbddeb7bdf26d3ab2335707))

* Sort imports ([`3432374`](https://github.com/embeddings-benchmark/mteb/commit/34323741f0a9696be34b5b451319ed84534e839f))

* Raise error first ([`0b1bfd2`](https://github.com/embeddings-benchmark/mteb/commit/0b1bfd250ff1ca048d2c03026fa761bcbdf036b0))

* Added support for Scandinavian Languages (#124)

* Make sure that main score is added to bitext mining tasks

* Added scandinavian languages: da, no, sv

* Updated readme with scandinavian tasks

* Changes n samples for the nordic lang CLF

* Added scandinavian models to init

* Added error logs to gitignore

* fix import error

* fix dataset columns

* rename dataset columns

* remove swefaq

* fix: Added functionality to raise error

* fix: Updated names

* fix: Removed no as a language

* Added missing data transformation

* Fix spelling error ([`acb0f59`](https://github.com/embeddings-benchmark/mteb/commit/acb0f59435ee660c266490bfa1db22bd5f19d1d5))

* Install beir ([`c50b8ab`](https://github.com/embeddings-benchmark/mteb/commit/c50b8abd995ef1d2f7180f2de6fc5d3013901165))

* Update README.md ([`29ffedf`](https://github.com/embeddings-benchmark/mteb/commit/29ffedf77fe912400ed3b3558f08820dd5857b8f))

* Update README.md ([`5825536`](https://github.com/embeddings-benchmark/mteb/commit/582553693de507f338a720a0bc572147b8c6ef33))

* fix revision hash for TenKGnadClusteringP2P dataset

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`eb622f8`](https://github.com/embeddings-benchmark/mteb/commit/eb622f88e6700a10900a9732509aefe0ae8358b0))

* change dataset order for BlurbsClustering in README

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`f6e49ba`](https://github.com/embeddings-benchmark/mteb/commit/f6e49ba09a8c7a47008fef03fe834e3fa19d03e3))

* change dataset order for TenKGnadClustering in README

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`2a2c47f`](https://github.com/embeddings-benchmark/mteb/commit/2a2c47f6bbbed94308f55cde232168b33d12a50d))

* fix descriptions for German clustering datasets ([`30a966c`](https://github.com/embeddings-benchmark/mteb/commit/30a966c0a1294bd9d0c60e76ebb60c06477d8171))

* add German clustering tasks to README ([`62457e3`](https://github.com/embeddings-benchmark/mteb/commit/62457e311856d98360291376e67121b9954caf3c))

* update reference &amp; category for TenKGnad datasets ([`2174a47`](https://github.com/embeddings-benchmark/mteb/commit/2174a47e7f3d312cadbd708dc1eb65c90f6ef6e0))

* add German clustering tasks ([`ab469be`](https://github.com/embeddings-benchmark/mteb/commit/ab469be4ba5765639c090f72e98fb17aa6d07867))

* Allow abs path ([`b56528c`](https://github.com/embeddings-benchmark/mteb/commit/b56528cea68eeac169c5921537db4310c93642aa))

* Add @property annotation to description method of AbsTask ([`98b0443`](https://github.com/embeddings-benchmark/mteb/commit/98b0443b621ec40dd74296eabe6686d363288c65))

* fix typo ([`37a986b`](https://github.com/embeddings-benchmark/mteb/commit/37a986b13939cd15c13d611560b96acd2fa9897b))

* fix extend lang pairs ([`865dffc`](https://github.com/embeddings-benchmark/mteb/commit/865dffc73739c18b5fe4e38d079570c4bc032c1d))

* Fix clustering eval, black, isort ([`bc43665`](https://github.com/embeddings-benchmark/mteb/commit/bc43665504ab4241696c9983198d1240769dd2bc))

* Add &#39;auto&#39; to sklearn clustering, add test, fix warning ([`15ce352`](https://github.com/embeddings-benchmark/mteb/commit/15ce35239d8ab35829461c953e2505a0dc0b0613))

* Update MSMARCORetrieval.py ([`d913f56`](https://github.com/embeddings-benchmark/mteb/commit/d913f5606ceb6fa883c7134e12756334aa3e39e9))

* Revert to old split ([`1f3ff6e`](https://github.com/embeddings-benchmark/mteb/commit/1f3ff6e8f693af07c0f97eef401fe83230e8e1ec))

* Add wheel instruction ([`62fad9b`](https://github.com/embeddings-benchmark/mteb/commit/62fad9b42067893a1e175b9f1690967a7832e18e))

* Dev version ([`d988e48`](https://github.com/embeddings-benchmark/mteb/commit/d988e483e2af7dd96de40fa760f3b87dfcc86929))

## v1.0.2 (2023-03-28)

### Unknown

* Release: 1.0.2 ([`e189bae`](https://github.com/embeddings-benchmark/mteb/commit/e189baeb6a1bcd49e3fc7f9ebcbf76b2d37a0096))

* Add comment

Co-authored-by: Nouamane Tazi &lt;nouamane98@gmail.com&gt; ([`3e72ee8`](https://github.com/embeddings-benchmark/mteb/commit/3e72ee8b15883d2cfda4b658f08d8be33f86fd49))

* Fix naming ([`33f2db9`](https://github.com/embeddings-benchmark/mteb/commit/33f2db97a018e3408944e0f470ac6ff686107046))

* Cleaner logging &amp; tqdm usage ([`542d871`](https://github.com/embeddings-benchmark/mteb/commit/542d871746a99a051c4235627fa2d72f975fe5a1))

* Add kwargs ([`e0b801d`](https://github.com/embeddings-benchmark/mteb/commit/e0b801d4b481c15a244ba9fa5631db591f688cd7))

* Produce embeddings in one go ([`e88bcf2`](https://github.com/embeddings-benchmark/mteb/commit/e88bcf2345c4a07bf3adc0b21012e2652a7346ec))

* Fix naming ([`6c62f18`](https://github.com/embeddings-benchmark/mteb/commit/6c62f1885357ca5b16740907bd43507814767e87))

* Make inputs always List[str] &amp; call in one ([`bdeeedf`](https://github.com/embeddings-benchmark/mteb/commit/bdeeedf8d82506fb55682ba3d6c3083e68b4cae7))

* Fix SummEval description ([`0c2b1be`](https://github.com/embeddings-benchmark/mteb/commit/0c2b1befada16c515e295c8e57ba6b8b6bf0337d))

* fix SemmEval description

Unless I&#39;m missing something, I think the SemmEval description is incorrect---the dataset consists of summaries of news articles, not biomedical abstracts. ([`1ccc068`](https://github.com/embeddings-benchmark/mteb/commit/1ccc068a956bf72ab2b24cf3c73166dc222d7937))

* Clarify script for running all of MTEB English ([`9f72434`](https://github.com/embeddings-benchmark/mteb/commit/9f72434e0519eb2c5bfdacc4ef6a8c4679694a7a))

* Update run_mteb_english.py ([`6ff57d3`](https://github.com/embeddings-benchmark/mteb/commit/6ff57d3498cdaefec7658560e210df1faad047c3))

* Update run_mteb_english.py ([`7803eea`](https://github.com/embeddings-benchmark/mteb/commit/7803eea74d4a51691e71b3a4077ef8cd8dbb4051))

* Point to English benchmarking script ([`57f3371`](https://github.com/embeddings-benchmark/mteb/commit/57f3371e1692170711f1fb49043231fdd95fbbf7))

* Eexample script for benchmarking all of MTEB English ([`77e6b22`](https://github.com/embeddings-benchmark/mteb/commit/77e6b22ab164095c7de6ebdf1303f4db40796511))

* Clarify MSMARCO split ([`bbeada8`](https://github.com/embeddings-benchmark/mteb/commit/bbeada8e6018bcef1e1f74f28f9f12420f54b7b3))

* Allow re-merging ([`b0ce501`](https://github.com/embeddings-benchmark/mteb/commit/b0ce501202749b8aa70c8ac41462dd8a260fe2b9))

* Set dataset name; Sort imports ([`2a5a661`](https://github.com/embeddings-benchmark/mteb/commit/2a5a661fad2f2dab8558216ba1f773950a25d8ea))

* Standardize CQA merging script ([`5d5a2fb`](https://github.com/embeddings-benchmark/mteb/commit/5d5a2fbfe887ed9c360b863b67e8424f15fd96ae))

* Update merge_cqadupstack.py ([`b0304c1`](https://github.com/embeddings-benchmark/mteb/commit/b0304c16feb5a327a4772d9eddb7b3b52295b77e))

* Update README.md ([`8c60c22`](https://github.com/embeddings-benchmark/mteb/commit/8c60c22473960da38b9b560e824e53efa3c28496))

* Update README.md ([`6255449`](https://github.com/embeddings-benchmark/mteb/commit/625544968a53f62fe09655ce807f6d95f8da862f))

* Remove validation split ([`875a98e`](https://github.com/embeddings-benchmark/mteb/commit/875a98e50023686b476e608c983b8b639e462603))

* Remove validation set ([`b3f9585`](https://github.com/embeddings-benchmark/mteb/commit/b3f9585acc76150a1850c815bbf52f202feeeac3))

* Update ClassificationEvaluator.py ([`93b89b6`](https://github.com/embeddings-benchmark/mteb/commit/93b89b6824e0feb53df7f67a4f16737d37807a5a))

* Set dev version ([`8a0d6b1`](https://github.com/embeddings-benchmark/mteb/commit/8a0d6b1c1764f917b09bac454a994b0d870ca2c7))

## v1.0.1 (2022-11-29)

### Unknown

* Release: 1.0.1 ([`b9f423b`](https://github.com/embeddings-benchmark/mteb/commit/b9f423b25f9d054974d3aed6253e384409e18158))

* Delete mteb_diagram.png ([`76dc363`](https://github.com/embeddings-benchmark/mteb/commit/76dc3637ed2b49d0c182e0fff762a6d5cad37105))

* Deactivate beir ([`b263157`](https://github.com/embeddings-benchmark/mteb/commit/b2631578f674d89f2e4ae0634974f28c22a13408))

* Update BeIRTask.py ([`37b7b79`](https://github.com/embeddings-benchmark/mteb/commit/37b7b7915128dbc70e87ec5914058d48be00dfbe))

* Remove validation ([`6922840`](https://github.com/embeddings-benchmark/mteb/commit/69228402cde7f755a3d764dffc51fc8cb4b364eb))

* Fix typo ([`7247233`](https://github.com/embeddings-benchmark/mteb/commit/72472339fac9235a55ae67cea2aa596a4b83bcfc))

* Add files via upload ([`9d2bb67`](https://github.com/embeddings-benchmark/mteb/commit/9d2bb67914db80c9af654ee9c3d80e996622360f))

* Increment version &amp; use abslink ([`a792a65`](https://github.com/embeddings-benchmark/mteb/commit/a792a65da5645b5666436169ee6f167ec7904355))

## v1.0.0 (2022-10-17)

### Unknown

* Release: 1.0.0 ([`9c544a4`](https://github.com/embeddings-benchmark/mteb/commit/9c544a465f05628945ab1dccc67a05c5da90f53b))

* Add paper ([`b73457a`](https://github.com/embeddings-benchmark/mteb/commit/b73457a14e682225184b95fbcd589620991b5df4))

* Fix formatting ([`c523d16`](https://github.com/embeddings-benchmark/mteb/commit/c523d1600913698f816580657e024b4d736e66a3))

* print -&gt; logging ([`4f3a559`](https://github.com/embeddings-benchmark/mteb/commit/4f3a5590d3c2ab2dd925832eaff0324850887a6c))

* Do not ignore data scripts ([`891b455`](https://github.com/embeddings-benchmark/mteb/commit/891b455f1b8401ce11563e550647f6d67a6987b1))

* Reorganize scripts ([`e157bb0`](https://github.com/embeddings-benchmark/mteb/commit/e157bb035f9591af561613a2af0b31f5db98e2cd))

* Add release instructions &amp; dev suffix to version ([`164b9ae`](https://github.com/embeddings-benchmark/mteb/commit/164b9aeb41c725dfccba7c2ed29ddba187ad8502))

## v0.9.0 (2022-10-13)

### Unknown

* Release: 0.9.1 ([`5c438cc`](https://github.com/embeddings-benchmark/mteb/commit/5c438cc3b9efb0f5fbd35516e4f41aa3bcd9b5fc))

* Merge pull request #80 from embeddings-benchmark/Muennighoff-patch-5

Update STS22CrosslingualSTS.py ([`1459309`](https://github.com/embeddings-benchmark/mteb/commit/1459309b99ea9fcccfffa762301eac4e9565f651))

* Update SummEvalSummrization.py ([`d8f232d`](https://github.com/embeddings-benchmark/mteb/commit/d8f232dd46919ba238f7d5ba4800f72a91567f22))

* Update AmazonPolarityClassification.py ([`114b0e3`](https://github.com/embeddings-benchmark/mteb/commit/114b0e30bfe5c3f8a6e06714629b917d49e5aa56))

* Update STS22CrosslingualSTS.py ([`c8df727`](https://github.com/embeddings-benchmark/mteb/commit/c8df727013009eee7227c018e8de389d174e1606))

* Update installation ([`f96ee73`](https://github.com/embeddings-benchmark/mteb/commit/f96ee732c9c8a523361469f35cab371e0a75fa5f))

* Temporarily change README installation instruction ([`e53e77c`](https://github.com/embeddings-benchmark/mteb/commit/e53e77cb1c8bed06436228c58d8b6e51439905cd))

* Fix res keyword ([`769ac67`](https://github.com/embeddings-benchmark/mteb/commit/769ac6728fb9dd98e52f393f7b1b76cc43fc8d14))

* Update example to be visible for non-registered users ([`d4f75fc`](https://github.com/embeddings-benchmark/mteb/commit/d4f75fc3687673d0cba912f72d91c47b8c6dba92))

* Merge pull request #79 from Muennighoff/feature/leaderboardexp

Add leaderboard instructions ([`4d2683a`](https://github.com/embeddings-benchmark/mteb/commit/4d2683abaccd5fc7f1a63ca223403f09bd672966))

* Move meta script ([`7a8398f`](https://github.com/embeddings-benchmark/mteb/commit/7a8398f016bb5ed1a83b15910bec597aec533222))

* dataset_version -&gt; dataset_revision &amp; logging ([`fe34f84`](https://github.com/embeddings-benchmark/mteb/commit/fe34f84756b1269664bcc3828f3e9bd8707d4acc))

* Add leaderboard instructions ([`f325aca`](https://github.com/embeddings-benchmark/mteb/commit/f325acaf7a34b29b07ecd4e176faf4752832a3b5))

* Merge pull request #78 from embeddings-benchmark/feature/add-mteb-ds-name

Add ds name to res dict ([`53b763a`](https://github.com/embeddings-benchmark/mteb/commit/53b763adc3438eddf16736e1750b76d97b3422e2))

* Update MTEB.py ([`ae86e2f`](https://github.com/embeddings-benchmark/mteb/commit/ae86e2f5b07d97d5e3bb782d343861c29c01bfcd))

* Merge pull request #73 from Muennighoff/fix/cqadupstackbeir11

Fallback to old dataloader for cqadupstack ([`7791b41`](https://github.com/embeddings-benchmark/mteb/commit/7791b41a50884150a2d3f2463422d0b5f027c445))

* Fallback to old dataloader for cqadupstack ([`262930e`](https://github.com/embeddings-benchmark/mteb/commit/262930e9069cad20c1f0c558448891cf2cf22fed))

* Merge pull request #77 from Muennighoff/fix/bcpc

Update init imports ([`865bf47`](https://github.com/embeddings-benchmark/mteb/commit/865bf473ae243082e531e785934e1170b32b3a93))

* Update init imports ([`39b7712`](https://github.com/embeddings-benchmark/mteb/commit/39b77124220acd940fd91e7878de94b9a89003d7))

* Merge pull request #76 from Muennighoff/fix/bcpc

BC -&gt; PC ([`82d3228`](https://github.com/embeddings-benchmark/mteb/commit/82d3228ac8b750558f8f9aa37d7a483fb6622acc))

* Merge branch &#39;main&#39; into fix/bcpc ([`f18c6df`](https://github.com/embeddings-benchmark/mteb/commit/f18c6dfa756cd2e9bcc2649eaccd339cf0089e13))

* Merge pull request #75 from Muennighoff/feature/leaderboard

Add LB link ([`36dbd14`](https://github.com/embeddings-benchmark/mteb/commit/36dbd144cdead594233f85777e8d14e91b6f361f))

* Add LB link ([`6aeb7ed`](https://github.com/embeddings-benchmark/mteb/commit/6aeb7ed6e334c9b6278e9d93662200e58b4ce4a4))

* Merge pull request #72 from Muennighoff/fix/revisions

Fix/revisions ([`4a8d3db`](https://github.com/embeddings-benchmark/mteb/commit/4a8d3db9c234dfc226019a01d9e07500b6977fd0))

* Add revision ([`488f1f7`](https://github.com/embeddings-benchmark/mteb/commit/488f1f7dbe8e9896fffa68d75f22497583939f98))

* Add revisions 2/2 ([`c8ba2b8`](https://github.com/embeddings-benchmark/mteb/commit/c8ba2b815b3c3e570393dc7fa7231b365726df35))

* Add revisions 1/2 ([`c75a503`](https://github.com/embeddings-benchmark/mteb/commit/c75a5033ace05eee466f5491f3404f41e4fa6517))

* Merge pull request #74 from Muennighoff/fix/mteblogo

Update logo files ([`d939de6`](https://github.com/embeddings-benchmark/mteb/commit/d939de6dec4a8819c4eb13e07f1ee745158f8f46))

* Update logo files ([`5bfb65a`](https://github.com/embeddings-benchmark/mteb/commit/5bfb65ab5553db2765b911467399c0fabd106eb1))

* BC -&gt; PC ([`7a430c2`](https://github.com/embeddings-benchmark/mteb/commit/7a430c21e20c2423f1fa38aea5330bfb1d4708d2))

* Merge pull request #69 from Muennighoff/feature/custombeirmodel

Feature/custombeirmodel ([`da9ae9a`](https://github.com/embeddings-benchmark/mteb/commit/da9ae9a3c3800ab22c59ef65afbc0e20bbcc1e9f))

* BeIRModel -&gt; DRES ([`ff554bb`](https://github.com/embeddings-benchmark/mteb/commit/ff554bbc6dcc71666446a77d67b194bea6912153))

* Do not wrap 2x ([`255c416`](https://github.com/embeddings-benchmark/mteb/commit/255c4160fd0390eb44a2def08a5b892033286653))

* Adapt naming ([`3c8f672`](https://github.com/embeddings-benchmark/mteb/commit/3c8f672b803ed97f163fbc3e188c2877ce7e4d26))

* Add explanation of BeIRModel ([`3edad09`](https://github.com/embeddings-benchmark/mteb/commit/3edad09fb839ebfe9cabb556c7a2fc423f98bfc0))

* Allow custom BeIR model ([`cd5098b`](https://github.com/embeddings-benchmark/mteb/commit/cd5098b65605f832a3f58ed34513d577731935a2))

* Merge pull request #68 from Muennighoff/feature/beirmrr

Add MRR ([`7a0993d`](https://github.com/embeddings-benchmark/mteb/commit/7a0993d9474082da56b7fc7986146cba564c832a))

* Add MRR ([`6dbb97c`](https://github.com/embeddings-benchmark/mteb/commit/6dbb97cd4140ff243d455e47963b5eac77b9ea04))

* Merge pull request #67 from Muennighoff/fix/s2p

Fix categories ([`03ed576`](https://github.com/embeddings-benchmark/mteb/commit/03ed576dd2ad2b869591951c36c057e141930a66))

* Fix categories ([`08088d7`](https://github.com/embeddings-benchmark/mteb/commit/08088d7a9432502d802a22a860ffcd2c32906d0d))

* Update RedditClusteringP2P.py ([`77a1606`](https://github.com/embeddings-benchmark/mteb/commit/77a1606868f9bcae993637e5a35314ede7ec5786))

* Merge pull request #62 from Muennighoff/feature/hublinks

Feature/hublinks ([`4f04719`](https://github.com/embeddings-benchmark/mteb/commit/4f04719099f185b34a8c1b7adc736a7d9cae970c))

* Fix hub mistakes ([`02f9e6c`](https://github.com/embeddings-benchmark/mteb/commit/02f9e6c3b56b8c37976a273b34e562ae6e514b11))

* Merge branch &#39;feature/hublinks&#39; of https://github.com/Muennighoff/mteb into feature/hublinks ([`c98b9a6`](https://github.com/embeddings-benchmark/mteb/commit/c98b9a6a729b6234ca97d3631ea2bf69adcfcd5b))

* Merge branch &#39;main&#39; into feature/hublinks ([`c3990d6`](https://github.com/embeddings-benchmark/mteb/commit/c3990d6277f91ead4954ba5f5fc15a380f6e6563))

* Add dataset stats ([`bbf2a82`](https://github.com/embeddings-benchmark/mteb/commit/bbf2a8253cf6fd01f196bc318bf36a25007e2217))

* Simplify ([`936eee2`](https://github.com/embeddings-benchmark/mteb/commit/936eee28fa453758e25666b728ff68e8c5e65fc9))

* Add Hub links &amp; descriptions ([`b8182bb`](https://github.com/embeddings-benchmark/mteb/commit/b8182bb51551a4ed29f71cac9fb8ee230dbc2473))

* Add desc ([`46078aa`](https://github.com/embeddings-benchmark/mteb/commit/46078aa614cef9ef988dfd296e7712e662a28ed0))

* Add desc ([`9ca92b0`](https://github.com/embeddings-benchmark/mteb/commit/9ca92b0243e20dce4ed579d9cdcf0af178760c75))

* Update MSMARCOv2Retrieval.py ([`f43cd1a`](https://github.com/embeddings-benchmark/mteb/commit/f43cd1adbe2df1ea6db9a0e26829d2b13a6d626c))

* Merge pull request #63 from embeddings-benchmark/Muennighoff-patch-4

Add desc ([`f93abff`](https://github.com/embeddings-benchmark/mteb/commit/f93abff68429ff04d8af8cd6eaf79429ac38ee78))

* Add desc ([`c972cc9`](https://github.com/embeddings-benchmark/mteb/commit/c972cc9781fa34d42d03f878df79cc26cbfde81e))

* Merge pull request #61 from embeddings-benchmark/fix/nolangs

Fix no langs ([`c15e1a7`](https://github.com/embeddings-benchmark/mteb/commit/c15e1a7663eb4a979e3ad07e2ef2f87286b87876))

* Update MTEB.py ([`0be4a06`](https://github.com/embeddings-benchmark/mteb/commit/0be4a0678ad8252bae9e5e948cfde3d2150b0a46))

* Merge pull request #57 from embeddings-benchmark/Muennighoff-patch-2

Update README.md ([`1ebca84`](https://github.com/embeddings-benchmark/mteb/commit/1ebca84b9b78da579a2b7305a93d86047e2dba0b))

* Update README.md ([`5b260a4`](https://github.com/embeddings-benchmark/mteb/commit/5b260a4fcf8bfb091609af00ec8ef8e60a3a6098))

* Merge pull request #59 from embeddings-benchmark/Muennighoff-patch-3

Update README.md ([`3f53c85`](https://github.com/embeddings-benchmark/mteb/commit/3f53c85fc6a2e698e273dc7242737ecf46ebd14b))

* Update README.md ([`8097f31`](https://github.com/embeddings-benchmark/mteb/commit/8097f317aa96bc9de41fcda6b4eac673491b95e2))

* Merge pull request #56 from Muennighoff/feature/readmelinks

Add README Links &amp; Images ([`f473dbd`](https://github.com/embeddings-benchmark/mteb/commit/f473dbd457229bdbdead4a4c0a3d6e47f6d63e80))

* Center title ([`1341db7`](https://github.com/embeddings-benchmark/mteb/commit/1341db76c62b653c2c7dd923d8e1e581a2470cda))

* Center title ([`8b80471`](https://github.com/embeddings-benchmark/mteb/commit/8b80471a6528fd1497891a381f2e8248ecc6d9ad))

* Beautify ([`1ab8764`](https://github.com/embeddings-benchmark/mteb/commit/1ab87643e12b14bc30047f4bf366292400c97dca))

* Merge pull request #49 from Muennighoff/fix/cqadupstack

Fix CQADupstack ([`3a4dd84`](https://github.com/embeddings-benchmark/mteb/commit/3a4dd848206731c852545971704068a32a95d999))

* Fix split ([`e3ea40b`](https://github.com/embeddings-benchmark/mteb/commit/e3ea40b7c29a69ae7665a500102b64f6ad52d77d))

* Add CQADupStack subsets ([`a32c00b`](https://github.com/embeddings-benchmark/mteb/commit/a32c00b8a71780d34b0e5708b91407e3db011f24))

* Fix CQADupstack ([`a26229f`](https://github.com/embeddings-benchmark/mteb/commit/a26229fe68b8a7294c52b974145d4a6e2f4ff1b2))

* Merge pull request #50 from Muennighoff/fix/redditp2p

New RedditP2P Script ([`7bc547e`](https://github.com/embeddings-benchmark/mteb/commit/7bc547e279a4273e8e1d814234014523ec537b50))

* New RedditP2P Script ([`f73b179`](https://github.com/embeddings-benchmark/mteb/commit/f73b179272339304ee19e5f1f24bc768644186a8))

* Merge pull request #52 from Muennighoff/fix/bucc

Default to 1-indexed gold ([`9aff7f2`](https://github.com/embeddings-benchmark/mteb/commit/9aff7f28404691939cb08cc8d2b9505091fbb468))

* Default to 1-indexed gold ([`f29e1fb`](https://github.com/embeddings-benchmark/mteb/commit/f29e1fb5877ffd05a245032291bdbd0bdaa18f41))

* Merge pull request #54 from embeddings-benchmark/Muennighoff-patch-1

Update MSMARCORetrieval.py ([`3951c41`](https://github.com/embeddings-benchmark/mteb/commit/3951c41bcff6b1258cfbb1bb145f02f90d9044a8))

* Update MSMARCORetrieval.py ([`6922be0`](https://github.com/embeddings-benchmark/mteb/commit/6922be0312533d8c1102a8c99ab4bd6a098bd4e3))

* Merge pull request #46 from Muennighoff/fix/scidocs

Fix/scidocs ([`ea10703`](https://github.com/embeddings-benchmark/mteb/commit/ea1070366ea9a56973b8cd87e4b694d9f5c4a56c))

* Update README name ([`afddfd3`](https://github.com/embeddings-benchmark/mteb/commit/afddfd38f42e3a1035586d211efb9d872ff065e7))

* Rename SciDocs ([`edc2917`](https://github.com/embeddings-benchmark/mteb/commit/edc29176fe6458e4c667fe2f0a9b43374f047f16))

* Merge pull request #45 from Muennighoff/feature/cachetestembs

Feature/cachetestembs ([`475420a`](https://github.com/embeddings-benchmark/mteb/commit/475420a9d64e1b7e85f6c4253c784b83ed60b68b))

* Return test cache in all clf evaluators ([`309a867`](https://github.com/embeddings-benchmark/mteb/commit/309a867dda40ab0139537a1ed6eb9ce672e4e88b))

* Cache test embedding / exp for all clf evals ([`7dd867f`](https://github.com/embeddings-benchmark/mteb/commit/7dd867f343e016e54970273af259ff2d2feee34d))

* Add testcache ([`08cb352`](https://github.com/embeddings-benchmark/mteb/commit/08cb352f9ee5f1ac800e9afae027654ce9406372))

* Merge pull request #44 from Muennighoff/fix/silentskip

Fix/silentskip ([`f7d6fd1`](https://github.com/embeddings-benchmark/mteb/commit/f7d6fd1ac6f17ea97efef7d760bb3334be6db7e2))

* Split into two lines ([`f756399`](https://github.com/embeddings-benchmark/mteb/commit/f756399b0c0b7865c90423e0f2f09a52eb3dbec5))

* Sort tasks ([`03658fa`](https://github.com/embeddings-benchmark/mteb/commit/03658fa5eef2b965489939f49499e4556f985b9c))

* Log known tasks ([`86f9cd6`](https://github.com/embeddings-benchmark/mteb/commit/86f9cd64655470e90885d540f6a7d0fcf11ed5b4))

* Log tasks not found ([`9ab0a7a`](https://github.com/embeddings-benchmark/mteb/commit/9ab0a7a33c69c2bbf8ee2f89b6dac3cd8b6660c7))

* Merge pull request #43 from Muennighoff/main

Add flag to overwrite results ([`ece590f`](https://github.com/embeddings-benchmark/mteb/commit/ece590feb66bc99d51407c3eebb7d7a6e4ac8693))

* Merge branch &#39;main&#39; into main ([`e986cd1`](https://github.com/embeddings-benchmark/mteb/commit/e986cd194a20c778628953d35829d2bb17e86bc2))

* Update mteb/evaluation/MTEB.py ([`23a473f`](https://github.com/embeddings-benchmark/mteb/commit/23a473f729391436af9995435731c71f1503cbfa))

* Add flag to overwrite ([`529541d`](https://github.com/embeddings-benchmark/mteb/commit/529541d19bb043f236e753a5d31705e555a06d0a))

* Merge pull request #33 from Muennighoff/fix/summeval

Fix SummEval NaN scores ([`48586e2`](https://github.com/embeddings-benchmark/mteb/commit/48586e2dfbc14aa9b4d1718e4888ea631f1ae79e))

* Update mteb/evaluation/evaluators/SummarizationEvaluator.py

Co-authored-by: Nouamane Tazi &lt;nouamane98@gmail.com&gt; ([`f667749`](https://github.com/embeddings-benchmark/mteb/commit/f66774973b614129feb446e0f0f26ee5e6a73a0d))

* Add consistent brackets ([`2cdd283`](https://github.com/embeddings-benchmark/mteb/commit/2cdd2836990ff7e2dab2f447acb9f3a9e5f8fbec))

* Remove debug leftovers ([`c674d0a`](https://github.com/embeddings-benchmark/mteb/commit/c674d0afce9b97428059cc1de9a6be8f2d6bbb96))

* Remove superfluous imports ([`68f7307`](https://github.com/embeddings-benchmark/mteb/commit/68f730773bdd2e4d12d0b8c5a410ad549e64170b))

* Skip samples with no variance ([`d39be65`](https://github.com/embeddings-benchmark/mteb/commit/d39be6541e7f95ce0f4bc729f3865493974b6c38))

* Drop nans ([`20c22a9`](https://github.com/embeddings-benchmark/mteb/commit/20c22a919ae07314e3f93f2ddd808e87b0c7dbff))

* Merge pull request #42 from Muennighoff/feature/versioning

Feature/versioning ([`1aeaede`](https://github.com/embeddings-benchmark/mteb/commit/1aeaeded0e41842643ec31e6697a37c634a94a79))

* Version mteb &amp; ds ([`78b90e9`](https://github.com/embeddings-benchmark/mteb/commit/78b90e994fddee2d4786639b6836c74cdb5dfa79))

* Formatting ([`67f6070`](https://github.com/embeddings-benchmark/mteb/commit/67f607031d12fac00dd26dc2a0a77882f62f56ee))

* Add versioning ([`fa852de`](https://github.com/embeddings-benchmark/mteb/commit/fa852de09e3546c3c231bacac147dc452a16dba2))

* Merge pull request #41 from Muennighoff/fix/sts22 ([`064e47c`](https://github.com/embeddings-benchmark/mteb/commit/064e47cedd40f3bb8c39f01b08eb55e28bcb9fd4))

* Rmv superfluous imports ([`7e8ee18`](https://github.com/embeddings-benchmark/mteb/commit/7e8ee183e0d984fc2fd34b816908b9a6634c8d23))

* Make revision optional ([`90afba5`](https://github.com/embeddings-benchmark/mteb/commit/90afba5af753d260926b48815ec3bec43766829f))

* Remove space ([`e0d22bc`](https://github.com/embeddings-benchmark/mteb/commit/e0d22bc8a6cf87049570929b76e67c9606bb54b4))

* Modify script to invert scores ([`9b9f43a`](https://github.com/embeddings-benchmark/mteb/commit/9b9f43a64154ecc5520c819da68d0efd4c2fcaed))

* Add revision to CL ([`5f68fda`](https://github.com/embeddings-benchmark/mteb/commit/5f68fda598d2ebd7093372194f2aa00426a23da8))

* Add revision kwarg ([`3448d1e`](https://github.com/embeddings-benchmark/mteb/commit/3448d1ea683527a7e2d6eb32f27068710a3cfb96))

* Merge pull request #26 from AmrMKayid/return-results ([`8f3242c`](https://github.com/embeddings-benchmark/mteb/commit/8f3242c39f469da53bc46817f06e5c91475d6f1b))

* Update docs ([`dd4a1f2`](https://github.com/embeddings-benchmark/mteb/commit/dd4a1f257d2853ec7834d8b818367b9cc984f9d5))

* Merge branch &#39;main&#39; into return-results ([`314e5d7`](https://github.com/embeddings-benchmark/mteb/commit/314e5d72ac43233f656dd21c10202cc6ffef4602))

* Update mteb/evaluation/MTEB.py

Co-authored-by: holidaydrien &lt;adrien.morisot@gmail.com&gt; ([`a4d952b`](https://github.com/embeddings-benchmark/mteb/commit/a4d952b0ede70a621ea8c1e8bf393fc2b3d91109))

* Update mteb/evaluation/MTEB.py

Co-authored-by: holidaydrien &lt;adrien.morisot@gmail.com&gt; ([`c4acb76`](https://github.com/embeddings-benchmark/mteb/commit/c4acb76fdb9d06decad58b0a6fab1f4b0b4ddd01))

* Returning Evaluation results ([`3d60490`](https://github.com/embeddings-benchmark/mteb/commit/3d60490485bbc9d9e10c9d18ce15b2bfb444ed47))

* Merge pull request #38 from Muennighoff/fix/seeds ([`720c597`](https://github.com/embeddings-benchmark/mteb/commit/720c597197470b91e9121390e1251367d69c290a))

* Seed cuda ([`d33d748`](https://github.com/embeddings-benchmark/mteb/commit/d33d748bcd86c520add9b7cdcdf32d3a14502504))

* Remove superfluous import ([`124bebe`](https://github.com/embeddings-benchmark/mteb/commit/124bebef96d8c432229f1ad00be0eebb6122c8f2))

* Remove superfluous comments ([`bf5f912`](https://github.com/embeddings-benchmark/mteb/commit/bf5f9121ca89854457edeb3ccefb0993146f2097))

* Add seed to task ([`acf8b1c`](https://github.com/embeddings-benchmark/mteb/commit/acf8b1cdd70dbaf0cbcc1d5dd230f5aca8a8c5c6))

* Add missing super calls ([`b32195e`](https://github.com/embeddings-benchmark/mteb/commit/b32195e5156a40b6cba0716158c10f5551856537))

* Set evaluation seeds ([`e69d40b`](https://github.com/embeddings-benchmark/mteb/commit/e69d40b0c683b55d517cb11ac31135c1c71c9e49))

* Set seeds ([`ef2985b`](https://github.com/embeddings-benchmark/mteb/commit/ef2985b88a9081e9bbad4500976847b05c0e3b1a))

* Merge pull request #37 from embeddings-benchmark/mindref

Fix Mind Reference ([`1834041`](https://github.com/embeddings-benchmark/mteb/commit/18340414855875013726497eacc47f28245e552f))

* Fix Mind Reference

Two other notes:
- The renaming can create confusion as there exists a test set just that I assume we don&#39;t have the labels
- MIND uses AUC &amp; MRR &amp; NDCG scores, not MAP, see https://msnews.github.io/ ([`7ce4bb1`](https://github.com/embeddings-benchmark/mteb/commit/7ce4bb16db369258e1f88e4118baf247203a8e77))

* Merge pull request #35 from embeddings-benchmark/bootstrap-logs ([`3ff35c5`](https://github.com/embeddings-benchmark/mteb/commit/3ff35c5f23f8a3db92ccad49ae6c627387f4d69c))

* Update mteb/abstasks/AbsTaskClassification.py

Co-authored-by: Niklas Muennighoff &lt;n.muennighoff@gmail.com&gt; ([`9255249`](https://github.com/embeddings-benchmark/mteb/commit/9255249d50ae8eac126bb41459e40d70769c3c5c))

* styling ([`c66610e`](https://github.com/embeddings-benchmark/mteb/commit/c66610ee085f3b71b198d8d07317abecf6e5a8f3))

* add logs for classification bootstrap experiments ([`e4000e1`](https://github.com/embeddings-benchmark/mteb/commit/e4000e12e592ce079073ab3bb359b16f4a2d1196))

* Merge pull request #36 from embeddings-benchmark/mindsmall-test ([`6fc710b`](https://github.com/embeddings-benchmark/mteb/commit/6fc710b740d219e882203144b206085526581c9b))

* rename `validation`split to `test` ([`9c4d5c6`](https://github.com/embeddings-benchmark/mteb/commit/9c4d5c634301e953c5033809d36f2eee843e6616))

* Merge pull request #32 from Muennighoff/fixsplits ([`39d0926`](https://github.com/embeddings-benchmark/mteb/commit/39d0926ee3f2f094e843eab7cd16b762244c2183))

* Fix BEIR splits ([`752d49f`](https://github.com/embeddings-benchmark/mteb/commit/752d49fdd81f967bceb78656e9d1f27ce7efd539))

* Fix splits ([`07bea18`](https://github.com/embeddings-benchmark/mteb/commit/07bea1820d1a28ca0ac677601d9e622731fc4c0a))

* Merge pull request #30 from embeddings-benchmark:selected_tasks

fix printing selected tasks for evaluation ([`f1cab40`](https://github.com/embeddings-benchmark/mteb/commit/f1cab400cb0c41a7cee83613d4e7927ac07fb71e))

* fix printing selected tasks for evaluation ([`ba0dd76`](https://github.com/embeddings-benchmark/mteb/commit/ba0dd767007cc5f4a068d479adbbf46c720b2b72))

* Merge pull request #29 from cycycc/fix-sickr-hf-hub-name ([`cb87c7a`](https://github.com/embeddings-benchmark/mteb/commit/cb87c7a388baa6461433e0dff3f47c18358b8a7d))

* fix sick-r huggingface hub name ([`2ea195a`](https://github.com/embeddings-benchmark/mteb/commit/2ea195a0fb7dd3d050f940240a8b3484c6b2cb64))

* Merge pull request #18 from Muennighoff/evalfix ([`4dabbaf`](https://github.com/embeddings-benchmark/mteb/commit/4dabbaf94863e4f78e012481899bf2f7952f263b))

* Fix task splits ([`1755356`](https://github.com/embeddings-benchmark/mteb/commit/17553566046ade6d627266f4ad1ca06e6e615dc1))

* Merge pull request #19 from Muennighoff/patch-2 ([`9e56ad3`](https://github.com/embeddings-benchmark/mteb/commit/9e56ad3d4d8089373a2c97cf85113b7c9f75f3fd))

* Update README.md ([`8b495b6`](https://github.com/embeddings-benchmark/mteb/commit/8b495b626a61564efa9ad9a3411890e1d45d35d1))

* Merge pull request #20 from Muennighoff/updatemainscores ([`a0fbd83`](https://github.com/embeddings-benchmark/mteb/commit/a0fbd835062c202e91e76d82f234a7ef947efa9c))

* Update to ndcg_at_10 ([`8d010d0`](https://github.com/embeddings-benchmark/mteb/commit/8d010d006cfe48f463618b929c2af9cf2365f92f))

* Update main scores ([`c0e773a`](https://github.com/embeddings-benchmark/mteb/commit/c0e773a3ce04558c15ac27f660f05c0620efbc75))

* Merge pull request #15 from Muennighoff/mainscorefix ([`4b5fe2b`](https://github.com/embeddings-benchmark/mteb/commit/4b5fe2b58463ff0ae22ce6ed0e7707ba2c3a5c09))

* Fix monolingual mainscore ([`61647df`](https://github.com/embeddings-benchmark/mteb/commit/61647dff0e1cd80c0e3cc5bd80ac397c48f1c89b))

* Fix main score warning multilingual ([`831a218`](https://github.com/embeddings-benchmark/mteb/commit/831a218407caee59bb83af78f8b832d8c3af830c))

* Merge pull request #14 from Muennighoff/patch-1 ([`6055ecc`](https://github.com/embeddings-benchmark/mteb/commit/6055ecc90b0b093337530cb6f957ae12fdabb546))

* Fix task language example ([`115c280`](https://github.com/embeddings-benchmark/mteb/commit/115c28081f7434c8131548c79ba7b3d2201f83fc))

* styling ([`2ff07d2`](https://github.com/embeddings-benchmark/mteb/commit/2ff07d22932e697bbc84d745c46a4a7b1c34481f))

* update example ([`b581d00`](https://github.com/embeddings-benchmark/mteb/commit/b581d00bc384f5623a970b146a9614f93115b251))

* we can now select all tasks of a specific language ([`b36e58c`](https://github.com/embeddings-benchmark/mteb/commit/b36e58ca198c7b92e508fbec516ebd12dd7980b4))

* update test ([`53d123e`](https://github.com/embeddings-benchmark/mteb/commit/53d123e12465973d2b2e9670939f9134da7ae531))

* keep only langs defined in task&#39;s description when loading ([`efa189f`](https://github.com/embeddings-benchmark/mteb/commit/efa189fc29c0f2524088ab9c140e4978c25b355f))

* better prints for multilingual and crosslingual evaluation ([`5b86950`](https://github.com/embeddings-benchmark/mteb/commit/5b869501994121bdcb978ec7503ef91dd3473480))

* styling ([`8fd8fb0`](https://github.com/embeddings-benchmark/mteb/commit/8fd8fb06847b56d4d4c1f8d8ab5e316668bb7bdb))

* move scripts to respective folders ([`028ed3e`](https://github.com/embeddings-benchmark/mteb/commit/028ed3ec673142735f666e36fe05a13f0d28258a))

* Update gitignore ([`a3cee03`](https://github.com/embeddings-benchmark/mteb/commit/a3cee0313075b85be55e79136156010bb2fc218b))

* update setup.py ([`89aaa43`](https://github.com/embeddings-benchmark/mteb/commit/89aaa43c35cb355867cffb91a18e09b1ee107fe5))

* update setup ([`2645323`](https://github.com/embeddings-benchmark/mteb/commit/26453234ccceac7258bb15ef714e78bf3f2810c9))

* update setup.cfg ([`bc5ec1d`](https://github.com/embeddings-benchmark/mteb/commit/bc5ec1dbd5a521c2e8cf8245b22e2a3dafd920c9))

* Create first pip version ([`210d012`](https://github.com/embeddings-benchmark/mteb/commit/210d012b595e0d38867b7be66ebed3e0de78cb84))

* make default evaluation for classification 10 experiments each using 8 samples per label ([`b062405`](https://github.com/embeddings-benchmark/mteb/commit/b0624055f1f923321bd2d115e93dc3d7517ff297))

* use seed from init arg ([`f58f8da`](https://github.com/embeddings-benchmark/mteb/commit/f58f8da29921d143d7ba4b945c2391e7da296b62))

* styling ([`4d1bd09`](https://github.com/embeddings-benchmark/mteb/commit/4d1bd092a955174f6cdb8b7d69ad783eaf1cab98))

* add error message when trying to load beir ([`a3d58f3`](https://github.com/embeddings-benchmark/mteb/commit/a3d58f37dac2307e3c05b71c62975ec85c64f6f3))

* add argument to specify error logs path ([`d6cef16`](https://github.com/embeddings-benchmark/mteb/commit/d6cef16190fc2fbf52ab0a8416524ec0f20a8bc4))

* make beir an optional package ([`5bcee12`](https://github.com/embeddings-benchmark/mteb/commit/5bcee120858973d5eac8736c2e489c02714c78a3))

* quick modifications ([`d774ce6`](https://github.com/embeddings-benchmark/mteb/commit/d774ce6e11819745db39a347792d8355a53eb70a))

* add example ([`21fc624`](https://github.com/embeddings-benchmark/mteb/commit/21fc6249b19105ec8daec767c49fafbefa7d1dfc))

* make beir optional dependency ([`fdd922a`](https://github.com/embeddings-benchmark/mteb/commit/fdd922a52450c56196bb67f231a28d5f2c92a44f))

* Smaller fixes in Classification task ([`c6eda26`](https://github.com/embeddings-benchmark/mteb/commit/c6eda2694204178ed3757886c5aab14bcd69a178))

* update available tasks ([`0923e50`](https://github.com/embeddings-benchmark/mteb/commit/0923e5067853c2e067cbb5ef8fe2e56e90cd2d8e))

* update available tasks ([`e192823`](https://github.com/embeddings-benchmark/mteb/commit/e192823ecb31c277a2abab49749d60d14ced2e3e))

* add evaluation time to final scores ([`9a1ca7d`](https://github.com/embeddings-benchmark/mteb/commit/9a1ca7d1af8ed1f6baa7c7ade6b384e44ea054a8))

* quick fix loading beir task ([`8e46cc8`](https://github.com/embeddings-benchmark/mteb/commit/8e46cc8be633f6f1fece72028b0e82b33fde977a))

* add available tasks ([`b7a1987`](https://github.com/embeddings-benchmark/mteb/commit/b7a1987c3636055cdc9fa2babe2131d14295f0df))

* Merge pull request #11 from embeddings-benchmark/summarization ([`bdb2691`](https://github.com/embeddings-benchmark/mteb/commit/bdb26915d476c02e7688131ca671198e15b0a53e))

* add more scores to summarization evaluator ([`12ae05f`](https://github.com/embeddings-benchmark/mteb/commit/12ae05f012ddde96fa47b8656b3bf6560bc58123))

* add SummEval task ([`3ba3e65`](https://github.com/embeddings-benchmark/mteb/commit/3ba3e65f1e51188854c92c204c01ad8025d08cf2))

* add Summarization abstract task ([`f2b0e53`](https://github.com/embeddings-benchmark/mteb/commit/f2b0e533791f1aba83284b8e2c472201a68412d1))

* add specifying language for task example ([`cdf1f18`](https://github.com/embeddings-benchmark/mteb/commit/cdf1f18224cba9bca4d239407184e8f01fa124c9))

* fix bitext mining evaluation ([`073a254`](https://github.com/embeddings-benchmark/mteb/commit/073a254c3e6ee48129686505d3cea135e7cce50d))

* update README ([`3b30e9b`](https://github.com/embeddings-benchmark/mteb/commit/3b30e9b23b0dd1136865baa41f1e4e5bcb834832))

* update README ([`529ec6b`](https://github.com/embeddings-benchmark/mteb/commit/529ec6bd27f2c64528c95ae13033ed788a75c5b7))

* add --available_tasks flag to CLI ([`de97d9a`](https://github.com/embeddings-benchmark/mteb/commit/de97d9ac3d72596476dece5507e199d122be333e))

* styling ([`324b94c`](https://github.com/embeddings-benchmark/mteb/commit/324b94c30f1c208de841b37c9a62bf261c3ba5f6))

* fix missing params eval_splits in load_data ([`ecb9d12`](https://github.com/embeddings-benchmark/mteb/commit/ecb9d12f234ccec4a4ddbfd55636ae7338590daa))

* CLI quick fixes ([`693bffa`](https://github.com/embeddings-benchmark/mteb/commit/693bffaebd485ea68b4d79eb5232fd3035d7962b))

* Merge branch &#39;main&#39; of https://github.com/embeddings-benchmark/mteb-draft into main ([`bba225d`](https://github.com/embeddings-benchmark/mteb/commit/bba225d9811aecbe4050567387ed1928b164f71a))

* styling ([`75d0449`](https://github.com/embeddings-benchmark/mteb/commit/75d0449844a06e112a38a2d51c79a55ae2ac4f46))

* quick fixes ([`2c01099`](https://github.com/embeddings-benchmark/mteb/commit/2c01099cf355e261684c34fcdd97a2bc33fb0110))

* fix eval_splits loading using beir ([`26ec6b9`](https://github.com/embeddings-benchmark/mteb/commit/26ec6b9f75f40fd7118b0e001db3c7352bec446e))

* capture errors instead of failing ([`c6aafa4`](https://github.com/embeddings-benchmark/mteb/commit/c6aafa445e978fdeb6c2d754f17e27c5c727b3b1))

* quick fixes ([`8a7e3ec`](https://github.com/embeddings-benchmark/mteb/commit/8a7e3ec49041768fdbec114f17e447450b52a247))

* update BeIRModel ([`e8b5ff9`](https://github.com/embeddings-benchmark/mteb/commit/e8b5ff952bd6315433fdea926e25768612ae5a7f))

* load data and free it after each task evaluation ([`aa467f2`](https://github.com/embeddings-benchmark/mteb/commit/aa467f2534d018a3af302c4e2159789cf524bc31))

* update reqs ([`6005c10`](https://github.com/embeddings-benchmark/mteb/commit/6005c10509097c1749a72ef44df560a8cdef2e9d))

* fixing beir imports ([`5d74d42`](https://github.com/embeddings-benchmark/mteb/commit/5d74d423df169d03f732b4368ab36b59ede51a48))

* Merge pull request #10 from embeddings-benchmark/optimisation ([`2b6caf2`](https://github.com/embeddings-benchmark/mteb/commit/2b6caf216918c0b39681b83ff5fff003a99643f3))

* add multiproc test ([`fe8b963`](https://github.com/embeddings-benchmark/mteb/commit/fe8b9633098aacb785f8e331875f5eebee3038e1))

* update BitextMining main scores ([`3b0f912`](https://github.com/embeddings-benchmark/mteb/commit/3b0f91257c9eaaf5b7e4f15e248e48c0c5192e33))

* support distributed evaluation for IR ðŸ¥³ ([`5e91971`](https://github.com/embeddings-benchmark/mteb/commit/5e91971c809fade4b9f9cdd5c4217e50cb666e14))

* remove &#34;train&#34; from eval_splits ([`6da5ed1`](https://github.com/embeddings-benchmark/mteb/commit/6da5ed1846a2a572dbf65ae617efc3301cb9370b))

* gather all nodes outputs in CPU after distributed computation ([`5eb3661`](https://github.com/embeddings-benchmark/mteb/commit/5eb366156c203780a337b24551c0ae1103d09952))

* support DRPES for Parallel IR evaluation ([`36962e9`](https://github.com/embeddings-benchmark/mteb/commit/36962e94bf6970ecf073d9fbc98539d57eb781c7))

* quick fix ([`6e0e6bd`](https://github.com/embeddings-benchmark/mteb/commit/6e0e6bd01645a20142d4a1bc464e9bd18e2d5d6e))

* set logistic regression default max_iter to 200 ([`8963b83`](https://github.com/embeddings-benchmark/mteb/commit/8963b8315fc1c3efcce3fba0e3560749fd6992f5))

* add evaluators logs ðŸ“œ ([`e9d326f`](https://github.com/embeddings-benchmark/mteb/commit/e9d326f190100f265489123f0e53d06a2c57d9b0))

* make style ([`ab8f13e`](https://github.com/embeddings-benchmark/mteb/commit/ab8f13ec5b1045acca2f369a6798f9c767cc01d0))

* add Makefile and better styling tools âœ¨ ([`156e828`](https://github.com/embeddings-benchmark/mteb/commit/156e82814ab1b8e90ae5e643fd31559fb60e8bda))

* dataloading moved from __init__ to run ([`c2b7901`](https://github.com/embeddings-benchmark/mteb/commit/c2b7901bcf632ea325124ec69519a0dbdf51d98f))

* Merge pull request #8 from embeddings-benchmark/beir-integration

Beir integration ([`f7f2426`](https://github.com/embeddings-benchmark/mteb/commit/f7f2426180727a65637ec12f1230eb3a67744627))

* Merge branch &#39;main&#39; into beir-integration ([`af12b49`](https://github.com/embeddings-benchmark/mteb/commit/af12b49e43539d4c8e475e457996206b64425ab7))

* Merge pull request #9 from embeddings-benchmark/display

Display ([`11e5758`](https://github.com/embeddings-benchmark/mteb/commit/11e5758c82339fafd8274659c878d808983bec36))

* fixes+black ([`b0527a8`](https://github.com/embeddings-benchmark/mteb/commit/b0527a81c3f088644c79b9cc5977760e32ade7e5))

* beautiful task display ([`0ff2db2`](https://github.com/embeddings-benchmark/mteb/commit/0ff2db24eb5bda300aba7d175a07397418d52ca5))

* rich library ([`27cd4cb`](https://github.com/embeddings-benchmark/mteb/commit/27cd4cb00018f78c06183aae145a61091c6ad041))

* only save if output_folder argument is specified ([`2e1eb24`](https://github.com/embeddings-benchmark/mteb/commit/2e1eb24d9b624c507e878b42a9f013a229c999fa))

* Update python-package.yml ([`6c32b6b`](https://github.com/embeddings-benchmark/mteb/commit/6c32b6bdc0bddbe9ab6e4aea2a1fa9f911840136))

* fixes ([`8902f59`](https://github.com/embeddings-benchmark/mteb/commit/8902f590476b13b85485fca4b38f235e8338d123))

* fixes ([`a394cc2`](https://github.com/embeddings-benchmark/mteb/commit/a394cc217f35962aebc425c7ed12f9ba456ca778))

* datasets ([`895c23d`](https://github.com/embeddings-benchmark/mteb/commit/895c23d66a5f6330899c8072f4e8bb44e67d52d2))

* fever ([`0724070`](https://github.com/embeddings-benchmark/mteb/commit/07240708fe30cebcf65a27b548843372a14b9a74))

* quora ([`43b93e5`](https://github.com/embeddings-benchmark/mteb/commit/43b93e5a0f2b645359b5a84858edd33da2c90abb))

* dbpedia ([`50d6700`](https://github.com/embeddings-benchmark/mteb/commit/50d67005e826c1fd29731e02f8e5dd2210d44bfb))

* climatefever ([`e506637`](https://github.com/embeddings-benchmark/mteb/commit/e5066373cbd079f8683a4500dbba0b4b26f96d2a))

* cqadupstack ([`217009f`](https://github.com/embeddings-benchmark/mteb/commit/217009faa2e12ca88c7f066101e03151b6b641f1))

* arguana ([`019b2b7`](https://github.com/embeddings-benchmark/mteb/commit/019b2b72e46e8d12c9ecd51e80ac02e289a098ae))

* beir retrieval ([`e52171b`](https://github.com/embeddings-benchmark/mteb/commit/e52171bb685debbc026a23957104c0be326ef479))

* all tests are passing now âœ… ([`6c41b75`](https://github.com/embeddings-benchmark/mteb/commit/6c41b753311d8b985605fca60937eef8ce2b046f))

* Create python-package.yml ([`3cce88f`](https://github.com/embeddings-benchmark/mteb/commit/3cce88f5e7d87ddf0164e7f5854e587b2c8b2fa8))

* Merge pull request #6 from embeddings-benchmark/testing ([`06bd1df`](https://github.com/embeddings-benchmark/mteb/commit/06bd1df888689ea6b9133ff81c9bf03ce0387452))

* Merge branch &#39;main&#39; into testing ([`5226907`](https://github.com/embeddings-benchmark/mteb/commit/522690780f249b224895810ba30f0996041fd909))

* update main scores for some tasks ([`099a32b`](https://github.com/embeddings-benchmark/mteb/commit/099a32b995e9d45ffe58554b63e4389f2522db36))

* more docs ([`8d07d59`](https://github.com/embeddings-benchmark/mteb/commit/8d07d590000c040886f792d3e959db68a844b9a0))

* normalize STS scores ([`6f98396`](https://github.com/embeddings-benchmark/mteb/commit/6f983964eb721c55cff4dc9472d92550275c7cee))

* normalize score names ([`6db134f`](https://github.com/embeddings-benchmark/mteb/commit/6db134f62820ced9b9a9d3bb04504664b695e51c))

* format @k scores ([`dcb77a0`](https://github.com/embeddings-benchmark/mteb/commit/dcb77a0f96966acb62dc7aec7617d263ddc72be0))

* rename CrossLingual to Crosslingual ([`3af3b4f`](https://github.com/embeddings-benchmark/mteb/commit/3af3b4f88f1b0c9f70d52fd80043cb2cdee8d2e5))

* remove train split from evaluation splits ([`6317bb6`](https://github.com/embeddings-benchmark/mteb/commit/6317bb64c3ae1e25dc5c9e7f23846ba6a11d9b4b))

* bug fix ([`ba8c906`](https://github.com/embeddings-benchmark/mteb/commit/ba8c9064d6b70307e2f9d33e7b82315f03bf8d08))

* calculate AP only in binary classification ([`bc293ca`](https://github.com/embeddings-benchmark/mteb/commit/bc293cad20a24e719144fc71cdd67d41b5ace052))

* add kwargs and batch_size to evaluate funcs ([`7926d3c`](https://github.com/embeddings-benchmark/mteb/commit/7926d3cfe7187742cd2ebf361dfe4ef51df56bd8))

* add limit argument to limit evaluation data ([`92e5d09`](https://github.com/embeddings-benchmark/mteb/commit/92e5d098dea013439a63c22131d36b2ee640b568))

* add test for PairClassificationEvaluator ([`ecffd35`](https://github.com/embeddings-benchmark/mteb/commit/ecffd3536c26b26819c689bd9e8b35f37c881ff7))

* use evaluators.PairClassificationEvaluator instead of sent-formers BinaryClassificationEvaluator ([`9ffdf2b`](https://github.com/embeddings-benchmark/mteb/commit/9ffdf2b0fc9e1921cfb6680cd27b0d811bfeba43))

* reformatting ([`ca25e17`](https://github.com/embeddings-benchmark/mteb/commit/ca25e17b4c8df0c6d9e56e5297f515f55ee8a2ce))

* add test for RerankingEvaluator ([`9646892`](https://github.com/embeddings-benchmark/mteb/commit/9646892bdb4cddda3448b554343b0a12ffaa3348))

* reformat RerankingEvaluator ([`3ce99cf`](https://github.com/embeddings-benchmark/mteb/commit/3ce99cfa242a78436623ceabfeb01119d03b398d))

* tests folder ([`9cd9dc2`](https://github.com/embeddings-benchmark/mteb/commit/9cd9dc2bafd3ab518af3caf85df8b8b4cccd91f4))

* add test_RetrievalEvaluator ([`5236588`](https://github.com/embeddings-benchmark/mteb/commit/52365886d4515c15f8c4bdb0e49e4d1e1888862b))

* more docs ([`06ff3d1`](https://github.com/embeddings-benchmark/mteb/commit/06ff3d10e3ead80b6162e3d25f30cb93da92925a))

* add AP score to ClassificationEvaluator ([`c950ce8`](https://github.com/embeddings-benchmark/mteb/commit/c950ce89e1d88a56c1d2d7cda6ad90e93ff344f7))

* add nDCG score to RerankingEvaluator ([`e4170c8`](https://github.com/embeddings-benchmark/mteb/commit/e4170c83246ec729d3f6be46aababbe4fbc98b51))

* Merge pull request #5 from embeddings-benchmark:update-reranking

Support multiple queries in Reranking tasks ([`cf51493`](https://github.com/embeddings-benchmark/mteb/commit/cf514935c03040edb2bda00adb786817cb413777))

* quick fix ([`0d133e1`](https://github.com/embeddings-benchmark/mteb/commit/0d133e14091d47318669965d5d94c2e0e19def08))

* use max cross similarity in case of multiple queries ([`3f80a70`](https://github.com/embeddings-benchmark/mteb/commit/3f80a703bbb198998644398a4977991d001b0b43))

* support multiple queries in Reranking tasks ([`47f871f`](https://github.com/embeddings-benchmark/mteb/commit/47f871f8a036b82491e6e4315ed4410ccf415311))

* bug fixes ([`a3dc4f6`](https://github.com/embeddings-benchmark/mteb/commit/a3dc4f6077321ec55aa3fae8a038bd86620cf288))

* rename binary classification to pair classification ([`63374fe`](https://github.com/embeddings-benchmark/mteb/commit/63374fe9456ee27d3fa24ff9a5bb6b906812cdae))

* rename available_splits to eval_splits ([`04b9f55`](https://github.com/embeddings-benchmark/mteb/commit/04b9f55ec334f100d018b3d3c279a2e1899419c4))

* rename available_langs to eval_langs ([`99ad04c`](https://github.com/embeddings-benchmark/mteb/commit/99ad04ca2aa37238c719c3f996dfbb4de18f1f91))

* minor fixes ([`c2307ef`](https://github.com/embeddings-benchmark/mteb/commit/c2307ef2201b176ac5f11f6f43dbc39e97aae225))

* Merge pull request #4 from embeddings-benchmark/packaging ([`297560d`](https://github.com/embeddings-benchmark/mteb/commit/297560d99438e2f06eac0dbcdc75d97f4a817a50))

* update README ([`db6edde`](https://github.com/embeddings-benchmark/mteb/commit/db6edde975eededec4779f6e8902315a160acb84))

* update example ([`d363a49`](https://github.com/embeddings-benchmark/mteb/commit/d363a493969da000cccfe104585fe25f44c5d63e))

* remove useless import ([`4a8966f`](https://github.com/embeddings-benchmark/mteb/commit/4a8966fbef42b9c21d4d465cd53ae95786606f8c))

* fix cmd.py arguments ([`2b17b4a`](https://github.com/embeddings-benchmark/mteb/commit/2b17b4a1552e71f298e23cbaea461ecc1efe4e17))

* add kwargs where needed ([`30f0efd`](https://github.com/embeddings-benchmark/mteb/commit/30f0efdee1ccd497a7622bd2428b7e02746e3438))

* add cli script ([`5a77900`](https://github.com/embeddings-benchmark/mteb/commit/5a77900e080a46833f0ca9792ef17d166195ce4c))

* adopt pbr packaging ([`c2fc3c1`](https://github.com/embeddings-benchmark/mteb/commit/c2fc3c1d3eccc247be7a9484ed880c9b2d43f25b))

* quick fixes ([`f5d3287`](https://github.com/embeddings-benchmark/mteb/commit/f5d32878b361dc4adeb1329e4938f7415af19533))

* quick fix bug ([`fc8ea9f`](https://github.com/embeddings-benchmark/mteb/commit/fc8ea9fa30f0cdb08e93bccc7b5e0395f278a4e7))

* report stderr in AbsTaskClassification in case of bootstrapping ([`d3723a5`](https://github.com/embeddings-benchmark/mteb/commit/d3723a591ec28f242e2ee4c74af940573e19288a))

* add STS22CrosslingualSTS ([`87f92e5`](https://github.com/embeddings-benchmark/mteb/commit/87f92e56ec947a702ebc7ad4a9d2deb191cba192))

* add MindSmallReranking ([`940642a`](https://github.com/embeddings-benchmark/mteb/commit/940642aac772ffc293ca5a340d1967e8a2314eea))

* precision recall f1 bitext evaluator ([`4f4a9e2`](https://github.com/embeddings-benchmark/mteb/commit/4f4a9e23df217675463bce42259a74a16f7cc4ea))

* korean to sts17 ([`4767300`](https://github.com/embeddings-benchmark/mteb/commit/4767300c3134176477a6089511d4a178d10f1e42))

* quick fix RetrievalEvaluator ([`afb574a`](https://github.com/embeddings-benchmark/mteb/commit/afb574a60d2fe26eb429d7f332f980583c3223bc))

* rename kNNClassification to Classification ([`44ceb4a`](https://github.com/embeddings-benchmark/mteb/commit/44ceb4a6d87919d79648357ee083c007233adf2c))

* add bootstrap parameters to AbsTaskKNNClassification ([`8ecf9d4`](https://github.com/embeddings-benchmark/mteb/commit/8ecf9d49f17dc0a3e62fc5315d381c25e73e3209))

* add EmotionClassification ([`e03db39`](https://github.com/embeddings-benchmark/mteb/commit/e03db3942f9a3043cdbc376be460a17ad7b8d96b))

* add TweetSentimentExtractionClassification ([`5c7ef5c`](https://github.com/embeddings-benchmark/mteb/commit/5c7ef5c30fb432f1ad1579deb598eada8051abbb))

* add ToxicConversationsClassification ([`94bfb4f`](https://github.com/embeddings-benchmark/mteb/commit/94bfb4f71a7913e0a15738fd0ef5037b5874f24f))

* add AmazonCounterfactualClassification ([`4052ae1`](https://github.com/embeddings-benchmark/mteb/commit/4052ae1456d01b4e23681dc1dc0dd47efcee8fa5))

* add ImdbClassification task ([`eb70842`](https://github.com/embeddings-benchmark/mteb/commit/eb70842cacb635547f24892345626347aac00e50))

* add AmazonPolarityClassification dataset ([`75684ed`](https://github.com/embeddings-benchmark/mteb/commit/75684ed8c68bebbfca49a59d943dea3c3e5c791f))

* hack fix bug loading tasks twice ([`23cc372`](https://github.com/embeddings-benchmark/mteb/commit/23cc37245149855565919e576dd9ae22a82cd385))

* add AmazonReviewsClassification ([`5f4731c`](https://github.com/embeddings-benchmark/mteb/commit/5f4731c52c80b38d47ac3a6bd3899ee8aec88b78))

* add create data script for amazon reviews multi ([`761b70e`](https://github.com/embeddings-benchmark/mteb/commit/761b70eadfbf6619986d50b5d3435b0fd6f0d97b))

* make shuffling reproducible in logReg-10-splits-5-intents ([`52e4743`](https://github.com/embeddings-benchmark/mteb/commit/52e47437886bfcd3dc71d8dfb184ca44c7764229))

* add logReg-10-splits-5-intents for kNNClassificationEvaluator ([`72c67e0`](https://github.com/embeddings-benchmark/mteb/commit/72c67e0622b8221c693ad7e001253f52bf91d13b))

* quick fix batch size ([`a88d8bf`](https://github.com/embeddings-benchmark/mteb/commit/a88d8bf3ace3feaa4133a3d5d5357d83ac2d6776))

* quick fixes ([`d4e5549`](https://github.com/embeddings-benchmark/mteb/commit/d4e55499d67a913ba13e46077790aa2f2007da70))

* add batch size to kNNClassificationEvaluator ([`c5127d8`](https://github.com/embeddings-benchmark/mteb/commit/c5127d8adaef7904c8fb8758c39ccae55aa37638))

* Merge pull request #3 from embeddings-benchmark/cross-lingual

Cross lingual ([`c844875`](https://github.com/embeddings-benchmark/mteb/commit/c8448756cd19fbd137c644e0e8bb7f74849840b1))

* black ([`a6ce618`](https://github.com/embeddings-benchmark/mteb/commit/a6ce618e73664461551508d045c1bfe823bba91c))

* bitext mining evaluator ([`db7a934`](https://github.com/embeddings-benchmark/mteb/commit/db7a934a696bfd4dd016bff853aee07d81d99bc1))

* bucc ([`96848c1`](https://github.com/embeddings-benchmark/mteb/commit/96848c182b5230657956cc6b1160f65a2cc488de))

* tatoeba ([`4783ace`](https://github.com/embeddings-benchmark/mteb/commit/4783ace1a5ab717324a861e63ba254668ef979a2))

* bitext mining ([`e0ec3a5`](https://github.com/embeddings-benchmark/mteb/commit/e0ec3a58e99dfecc8526440b37ef04bb9f86a992))

* bitext mining ([`50b2f48`](https://github.com/embeddings-benchmark/mteb/commit/50b2f48e7f511436bd32d51456b8c8388b326b88))

* crosslingual tasks ([`582aa15`](https://github.com/embeddings-benchmark/mteb/commit/582aa15413158b08bd2cdd28dfcfe5937a0f5a68))

* STS17 benchmark ([`0c38bf0`](https://github.com/embeddings-benchmark/mteb/commit/0c38bf037f6e6d5687227c35e16177903aaeab1f))

* add MTOP classification tasks ([`1ecec57`](https://github.com/embeddings-benchmark/mteb/commit/1ecec5751b34c7be01b0446a7fcf5ad5d01b7389))

* add methods ([`49afe21`](https://github.com/embeddings-benchmark/mteb/commit/49afe21a324cc995aa57e04c86df0aefdf3fb3ec))

* formatting ([`cebaf56`](https://github.com/embeddings-benchmark/mteb/commit/cebaf56c8b3a5fd67b8f7d1f4cb4d1878495cde2))

* quick fix ([`2284d17`](https://github.com/embeddings-benchmark/mteb/commit/2284d179612818472f157d7b9769f6e58a64fb94))

* Merge pull request #2 from embeddings-benchmark/knn-classification ([`6a5faec`](https://github.com/embeddings-benchmark/mteb/commit/6a5faeca9e5e2d7edaa9c2ec423a0baea406fd36))

* add MultilingualTask ([`5614a03`](https://github.com/embeddings-benchmark/mteb/commit/5614a031134068194a92f91429bcf7146eb310a2))

* fix loading for multilingual datasets ([`8658f68`](https://github.com/embeddings-benchmark/mteb/commit/8658f6833328cf13c1b88e35f79ea0ceb9398472))

* skip task if results alrdy exist ([`24f83c1`](https://github.com/embeddings-benchmark/mteb/commit/24f83c12910f414bccdd0ec6fee9cbb8ec470a31))

* add banking77 and massive scenario datasets ([`12d4d40`](https://github.com/embeddings-benchmark/mteb/commit/12d4d40deadcb4688957ba7896e78926da057b6b))

* add logRegClassificationEvaluator ([`804e3b0`](https://github.com/embeddings-benchmark/mteb/commit/804e3b0f27c3dabe152ffeacc0b74529fcf504aa))

* add kNNClassificationEvaluatorPytorch ([`31bf4d1`](https://github.com/embeddings-benchmark/mteb/commit/31bf4d1a8670a6959b78f1c94dcd85fc95ceda76))

* cosine and euclidean distances in kNNClassificationEvaluator ([`4720480`](https://github.com/embeddings-benchmark/mteb/commit/4720480b87d40c190764ebd31fab11dbd9992490))

* add requirements dev file ([`a446d3f`](https://github.com/embeddings-benchmark/mteb/commit/a446d3fb81d3e9083a0e95d12efb16360fe5e5a2))

* update results json file format to account for multi langs ([`1fe472a`](https://github.com/embeddings-benchmark/mteb/commit/1fe472a268d712d1a4aa59d393bdebfa7ae6e78f))

* load_dataset directly inside AbsTask ([`4475fee`](https://github.com/embeddings-benchmark/mteb/commit/4475fee551b9e55329c72d9447e06ea5bc03c91c))

* add default language as &#34;en&#34; for all tasks ([`faee9db`](https://github.com/embeddings-benchmark/mteb/commit/faee9db358036eda4aa6810512fb872af16e5d71))

* WIP add kNN Classification and MassiveIntentClassification task ([`885c06d`](https://github.com/embeddings-benchmark/mteb/commit/885c06d0d7d6136e8a0a1b1ddab45f0f1fb6d833))

* tasks can be provided as class now in task_list ([`3bcb767`](https://github.com/embeddings-benchmark/mteb/commit/3bcb76767a8edebe758ff0b13c79a5ee6bcb8ba7))

* add bs param in clusteringevaluator ([`b4c83e0`](https://github.com/embeddings-benchmark/mteb/commit/b4c83e085ad67c9a69d85cdb2a7f16f91073e0a7))

* quick docs fixes ([`1a48f29`](https://github.com/embeddings-benchmark/mteb/commit/1a48f29ccca9427c6d6d154133b172c3c06ad039))

* fix line length ([`faa978f`](https://github.com/embeddings-benchmark/mteb/commit/faa978f9663312d79567d9b15fe7f364b0a762df))

* linting ([`49a4138`](https://github.com/embeddings-benchmark/mteb/commit/49a4138c57d944bdb0c1b4935df008ceee74d449))

* add reqs ([`006756c`](https://github.com/embeddings-benchmark/mteb/commit/006756c94d8ed1e587d506c2be79d34df9413726))

* redditp2p + sep2p ([`2ec9c44`](https://github.com/embeddings-benchmark/mteb/commit/2ec9c4495ec1aebb5588327c44eb022c9e2dca47))

* clustering tasks ([`b8d37a0`](https://github.com/embeddings-benchmark/mteb/commit/b8d37a02c5e3f3196875187c846341259d632801))

* scripts ([`2760969`](https://github.com/embeddings-benchmark/mteb/commit/27609690b59e65eb7b988e039a53c813dbb23afd))

* first commit ([`7fbd064`](https://github.com/embeddings-benchmark/mteb/commit/7fbd064b6848e8dcdad5f4e9ac534a3f0021ff97))

* loading scripts ([`24a4310`](https://github.com/embeddings-benchmark/mteb/commit/24a4310d671f90e3adeb9e000378cb344f6d1723))

* Update README.md ([`c03618c`](https://github.com/embeddings-benchmark/mteb/commit/c03618c9baf60f74e9a022a0792d98b091550c40))

* init file ([`fd182b6`](https://github.com/embeddings-benchmark/mteb/commit/fd182b6ea5d4bb83325891c34e04d0f7bc62c673))

* Update README.md ([`97c6a99`](https://github.com/embeddings-benchmark/mteb/commit/97c6a99ae597b6b1fafbaf442f8f8327b92d608d))

* retrieval evaluator ([`39db013`](https://github.com/embeddings-benchmark/mteb/commit/39db013d20ab9b25c73e24547e22d9ae060f3a19))

* removed results folder ([`751e1fd`](https://github.com/embeddings-benchmark/mteb/commit/751e1fd2f8409fd588e003b4aea8b5ac4a1d8dac))

* reranking evaluator ([`b62a0f5`](https://github.com/embeddings-benchmark/mteb/commit/b62a0f5269f99be48cd52172cdf0fc40aa408c55))

* added custom evaluators ([`1bf7c94`](https://github.com/embeddings-benchmark/mteb/commit/1bf7c949aa7b215cdf97c85660a38838f272142d))

* STS datasets ([`9093bc1`](https://github.com/embeddings-benchmark/mteb/commit/9093bc16589c3355e3493df9f3ded040e4774da3))

* gitignore ([`8d309e4`](https://github.com/embeddings-benchmark/mteb/commit/8d309e456e2db65c7afadadbf4c6fbedb6779b59))

* added STS ([`3a2f4b9`](https://github.com/embeddings-benchmark/mteb/commit/3a2f4b92fec92c42eb6f1d7220c9f26aedc9ed3c))

* reranking ([`0cf6e1a`](https://github.com/embeddings-benchmark/mteb/commit/0cf6e1a25173074d0401fb3c8a269fb64e4be1e1))

* binary classification ([`3a15b96`](https://github.com/embeddings-benchmark/mteb/commit/3a15b96b9bf5eaefa3b8ccd6f0c2e333b94620b0))

* added verbosity level ([`1ee8f3d`](https://github.com/embeddings-benchmark/mteb/commit/1ee8f3d2d48bb2f8b980131850cd3b98e54aad98))

* added file logging ([`36f7cf3`](https://github.com/embeddings-benchmark/mteb/commit/36f7cf3d2fce8d565bf75ed76df4727f6748ede6))

* added available tasks/categories/selected list ([`5cc63a5`](https://github.com/embeddings-benchmark/mteb/commit/5cc63a5e4ee29d74ba217f48dec2c6785ca71355))

* finegrained task selection ([`7c0087b`](https://github.com/embeddings-benchmark/mteb/commit/7c0087b3561297e77d58bbd61955dfbc89c61450))

* added retrieval ([`22415e9`](https://github.com/embeddings-benchmark/mteb/commit/22415e9d12400d900337e45aefc55942ca537ae8))

* fixed seed ([`50ada77`](https://github.com/embeddings-benchmark/mteb/commit/50ada7738f0062185b289a31c765871fb2a3e2fc))

* typos ([`16dc4a9`](https://github.com/embeddings-benchmark/mteb/commit/16dc4a98c1d5a55be997ed319d9a34e272949583))

* added clustering tasks ([`1106c15`](https://github.com/embeddings-benchmark/mteb/commit/1106c1565c1d5cb7fdb439ee6ade6b70bbc6fea9))

* seeded benchmarks ([`518bc82`](https://github.com/embeddings-benchmark/mteb/commit/518bc8248381d38e7b19fbb434f86c7d417a839a))

* evaluation schema ([`bdb79d0`](https://github.com/embeddings-benchmark/mteb/commit/bdb79d0f4fd2635cc54072831a3615bc7b8eb74b))

* basic tasks schema ([`bacb9d0`](https://github.com/embeddings-benchmark/mteb/commit/bacb9d078fa7c7fa10d8b5e3fdf2a41c2beaf97e))

* proof of concept ([`6886d1b`](https://github.com/embeddings-benchmark/mteb/commit/6886d1b50f0c16ed1b86b5baec9d3853f02f9256))

* Create README.md ([`26df27b`](https://github.com/embeddings-benchmark/mteb/commit/26df27b61071ea8b6000f771c4a68412d8b2d223))

* Initial commit ([`7841bca`](https://github.com/embeddings-benchmark/mteb/commit/7841bca7daeea0473b4cfdfe37f0a290feba6b8f))
