
# STS

<!-- This document is auto-generated. Changes will be overwritten. Please change the generating script. -->

- **Number of tasks:** 43 

#### AFQMC

A Chinese dataset for textual relatedness

**Dataset:** [`C-MTEB/AFQMC`](https://huggingface.co/datasets/C-MTEB/AFQMC) • **License:** not specified • [Learn more →](https://aclanthology.org/2021.emnlp-main.357)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | cmn | not specified | not specified | not specified |



#### ATEC

A Chinese dataset for textual relatedness

**Dataset:** [`C-MTEB/ATEC`](https://huggingface.co/datasets/C-MTEB/ATEC) • **License:** not specified • [Learn more →](https://aclanthology.org/2021.emnlp-main.357)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | cmn | not specified | not specified | not specified |



#### Assin2STS

Semantic Textual Similarity part of the ASSIN 2, an evaluation shared task collocated with STIL 2019.

**Dataset:** [`nilc-nlp/assin2`](https://huggingface.co/datasets/nilc-nlp/assin2) • **License:** not specified • [Learn more →](https://link.springer.com/chapter/10.1007/978-3-030-41505-1_39)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | por | Written | human-annotated | found |



#### BIOSSES

Biomedical Semantic Similarity Estimation.

**Dataset:** [`mteb/biosses-sts`](https://huggingface.co/datasets/mteb/biosses-sts) • **License:** not specified • [Learn more →](https://tabilab.cmpe.boun.edu.tr/BIOSSES/DataSet.html)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | eng | Medical | derived | found |



#### BIOSSES-VN

A translated dataset from Biomedical Semantic Similarity Estimation.
            The process of creating the VN-MTEB (Vietnamese Massive Text Embedding Benchmark) from English samples involves a new automated system:
            - The system uses large language models (LLMs), specifically Coherence's Aya model, for translation.
            - Applies advanced embedding models to filter the translations.
            - Use LLM-as-a-judge to scoring the quality of the samples base on multiple criteria.

**Dataset:** [`GreenNode/biosses-sts-vn`](https://huggingface.co/datasets/GreenNode/biosses-sts-vn) • **License:** cc-by-sa-4.0 • [Learn more →](https://tabilab.cmpe.boun.edu.tr/BIOSSES/DataSet.html)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to category (t2c) | cosine_spearman | vie | Medical | derived | machine-translated and LM verified |



#### BQ

A Chinese dataset for textual relatedness

**Dataset:** [`C-MTEB/BQ`](https://huggingface.co/datasets/C-MTEB/BQ) • **License:** not specified • [Learn more →](https://aclanthology.org/2021.emnlp-main.357)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | cmn | not specified | not specified | not specified |



#### CDSC-R

Compositional Distributional Semantics Corpus for textual relatedness.

**Dataset:** [`PL-MTEB/cdscr-sts`](https://huggingface.co/datasets/PL-MTEB/cdscr-sts) • **License:** cc-by-nc-sa-4.0 • [Learn more →](https://aclanthology.org/P17-1073.pdf)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | pol | Web, Written | human-annotated | human-translated and localized |



#### FaroeseSTS

Semantic Text Similarity (STS) corpus for Faroese.

**Dataset:** [`vesteinn/faroese-sts`](https://huggingface.co/datasets/vesteinn/faroese-sts) • **License:** cc-by-4.0 • [Learn more →](https://aclanthology.org/2023.nodalida-1.74.pdf)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | fao | News, Web, Written | human-annotated | found |



#### Farsick

A Persian Semantic Textual Similarity And Natural Language Inference Dataset

**Dataset:** [`MCINext/farsick-sts`](https://huggingface.co/datasets/MCINext/farsick-sts) • **License:** not specified • [Learn more →](https://github.com/ZahraGhasemi-AI/FarSick)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | fas | not specified | derived | found |



#### FinParaSTS

Finnish paraphrase-based semantic similarity corpus

**Dataset:** [`TurkuNLP/turku_paraphrase_corpus`](https://huggingface.co/datasets/TurkuNLP/turku_paraphrase_corpus) • **License:** cc-by-sa-4.0 • [Learn more →](https://huggingface.co/datasets/TurkuNLP/turku_paraphrase_corpus)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | fin | News, Subtitles, Written | expert-annotated | found |



#### GermanSTSBenchmark

Semantic Textual Similarity Benchmark (STSbenchmark) dataset translated into German. Translations were originally done by T-Systems on site services GmbH.

**Dataset:** [`jinaai/german-STSbenchmark`](https://huggingface.co/datasets/jinaai/german-STSbenchmark) • **License:** cc-by-sa-3.0 • [Learn more →](https://github.com/t-systems-on-site-services-gmbh/german-STSbenchmark)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | deu | not specified | not specified | not specified |



#### IndicCrosslingualSTS

This is a Semantic Textual Similarity testset between English and 12 high-resource Indic languages.

**Dataset:** [`mteb/IndicCrosslingualSTS`](https://huggingface.co/datasets/mteb/IndicCrosslingualSTS) • **License:** cc0-1.0 • [Learn more →](https://huggingface.co/datasets/jaygala24/indic_sts)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | asm, ben, eng, guj, hin, ... (13) | Government, News, Non-fiction, Spoken, Spoken, ... (7) | expert-annotated | created |



#### JSICK

JSICK is the Japanese NLI and STS dataset by manually translating the English dataset SICK (Marelli et al., 2014) into Japanese.

**Dataset:** [`sbintuitions/JMTEB`](https://huggingface.co/datasets/sbintuitions/JMTEB) • **License:** cc-by-4.0 • [Learn more →](https://github.com/sbintuitions/JMTEB)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | jpn | Web, Written | human-annotated | found |



#### JSTS

Japanese Semantic Textual Similarity Benchmark dataset construct from YJ Image Captions Dataset (Miyazaki and Shimizu, 2016) and annotated by crowdsource annotators.

**Dataset:** [`mteb/JSTS`](https://huggingface.co/datasets/mteb/JSTS) • **License:** cc-by-sa-4.0 • [Learn more →](https://aclanthology.org/2022.lrec-1.317.pdf#page=2.00)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | jpn | Web, Written | human-annotated | found |



#### KLUE-STS

Human-annotated STS dataset of Korean reviews, news, and spoken word sets. Part of the Korean Language Understanding Evaluation (KLUE).

**Dataset:** [`klue/klue`](https://huggingface.co/datasets/klue/klue) • **License:** cc-by-sa-4.0 • [Learn more →](https://arxiv.org/abs/2105.09680)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | kor | News, Reviews, Spoken, Spoken, Written | human-annotated | found |



#### KorSTS

Benchmark dataset for STS in Korean. Created by machine translation and human post editing of the STS-B dataset.

**Dataset:** [`dkoterwa/kor-sts`](https://huggingface.co/datasets/dkoterwa/kor-sts) • **License:** cc-by-sa-4.0 • [Learn more →](https://arxiv.org/abs/2004.03289)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | kor | News, Web | not specified | machine-translated and localized |



#### LCQMC

A Chinese dataset for textual relatedness

**Dataset:** [`C-MTEB/LCQMC`](https://huggingface.co/datasets/C-MTEB/LCQMC) • **License:** not specified • [Learn more →](https://aclanthology.org/2021.emnlp-main.357)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | cmn | not specified | not specified | not specified |



#### PAWSX

A Chinese dataset for textual relatedness

**Dataset:** [`C-MTEB/PAWSX`](https://huggingface.co/datasets/C-MTEB/PAWSX) • **License:** not specified • [Learn more →](https://aclanthology.org/2021.emnlp-main.357)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | cmn | not specified | not specified | not specified |



#### QBQTC



**Dataset:** [`C-MTEB/QBQTC`](https://huggingface.co/datasets/C-MTEB/QBQTC) • **License:** not specified • [Learn more →](https://github.com/CLUEbenchmark/QBQTC/tree/main/dataset)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | cmn | not specified | not specified | not specified |



#### Query2Query

Query to Query Datasets.

**Dataset:** [`MCINext/query-to-query-sts`](https://huggingface.co/datasets/MCINext/query-to-query-sts) • **License:** not specified • [Learn more →](https://mcinext.com/)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | fas | not specified | derived | found |



#### RUParaPhraserSTS

ParaPhraser is a news headlines corpus with precise, near and non-paraphrases.

**Dataset:** [`merionum/ru_paraphraser`](https://huggingface.co/datasets/merionum/ru_paraphraser) • **License:** mit • [Learn more →](https://aclanthology.org/2020.ngt-1.6)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | rus | News, Written | human-annotated | found |



#### RonSTS

High-quality Romanian translation of STSBenchmark.

**Dataset:** [`dumitrescustefan/ro_sts`](https://huggingface.co/datasets/dumitrescustefan/ro_sts) • **License:** cc-by-4.0 • [Learn more →](https://openreview.net/forum?id=JH61CD7afTv)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | ron | News, Social, Web, Written | human-annotated | machine-translated and verified |



#### RuSTSBenchmarkSTS

Semantic Textual Similarity Benchmark (STSbenchmark) dataset translated into Russian and verified. The dataset was checked with RuCOLA model to ensure that the translation is good and filtered.

**Dataset:** [`ai-forever/ru-stsbenchmark-sts`](https://huggingface.co/datasets/ai-forever/ru-stsbenchmark-sts) • **License:** cc-by-sa-4.0 • [Learn more →](https://github.com/PhilipMay/stsb-multi-mt/)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | rus | News, Social, Web, Written | human-annotated | machine-translated and verified |



#### SICK-BR-STS

SICK-BR is a Portuguese inference corpus, human translated from SICK

**Dataset:** [`eduagarcia/sick-br`](https://huggingface.co/datasets/eduagarcia/sick-br) • **License:** not specified • [Learn more →](https://linux.ime.usp.br/~thalen/SICK_PT.pdf)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | por | Web, Written | human-annotated | human-translated and localized |



#### SICK-R

Semantic Textual Similarity SICK-R dataset

**Dataset:** [`mteb/sickr-sts`](https://huggingface.co/datasets/mteb/sickr-sts) • **License:** cc-by-nc-sa-3.0 • [Learn more →](https://aclanthology.org/L14-1314/)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | eng | Web, Written | human-annotated | not specified |



#### SICK-R-PL

Polish version of SICK dataset for textual relatedness.

**Dataset:** [`PL-MTEB/sickr-pl-sts`](https://huggingface.co/datasets/PL-MTEB/sickr-pl-sts) • **License:** cc-by-nc-sa-3.0 • [Learn more →](https://aclanthology.org/2020.lrec-1.207)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | pol | Web, Written | human-annotated | human-translated and localized |



#### SICK-R-VN

A translated dataset from Semantic Textual Similarity SICK-R dataset as described here:
            The process of creating the VN-MTEB (Vietnamese Massive Text Embedding Benchmark) from English samples involves a new automated system:
            - The system uses large language models (LLMs), specifically Coherence's Aya model, for translation.
            - Applies advanced embedding models to filter the translations.
            - Use LLM-as-a-judge to scoring the quality of the samples base on multiple criteria.

**Dataset:** [`GreenNode/sickr-sts-vn`](https://huggingface.co/datasets/GreenNode/sickr-sts-vn) • **License:** cc-by-sa-4.0 • [Learn more →](https://aclanthology.org/2020.lrec-1.207)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to category (t2c) | cosine_spearman | vie | Web, Written | derived | machine-translated and LM verified |



#### SICKFr

SICK dataset french version

**Dataset:** [`Lajavaness/SICK-fr`](https://huggingface.co/datasets/Lajavaness/SICK-fr) • **License:** not specified • [Learn more →](https://huggingface.co/datasets/Lajavaness/SICK-fr)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | fra | not specified | not specified | not specified |



#### STS12

SemEval-2012 Task 6.

**Dataset:** [`mteb/sts12-sts`](https://huggingface.co/datasets/mteb/sts12-sts) • **License:** not specified • [Learn more →](https://www.aclweb.org/anthology/S12-1051.pdf)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | eng | Encyclopaedic, News, Written | human-annotated | created |



#### STS13

SemEval STS 2013 dataset.

**Dataset:** [`mteb/sts13-sts`](https://huggingface.co/datasets/mteb/sts13-sts) • **License:** not specified • [Learn more →](https://www.aclweb.org/anthology/S13-1004/)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | eng | News, Non-fiction, Web, Written | human-annotated | created |



#### STS14

SemEval STS 2014 dataset. Currently only the English dataset

**Dataset:** [`mteb/sts14-sts`](https://huggingface.co/datasets/mteb/sts14-sts) • **License:** not specified • [Learn more →](https://www.aclweb.org/anthology/S14-1002)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | eng | Blog, Spoken, Web | derived | created |



#### STS15

SemEval STS 2015 dataset

**Dataset:** [`mteb/sts15-sts`](https://huggingface.co/datasets/mteb/sts15-sts) • **License:** not specified • [Learn more →](https://www.aclweb.org/anthology/S15-2010)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | eng | Blog, News, Spoken, Web, Written | human-annotated | created |



#### STS16

SemEval-2016 Task 4

**Dataset:** [`mteb/sts16-sts`](https://huggingface.co/datasets/mteb/sts16-sts) • **License:** not specified • [Learn more →](https://www.aclweb.org/anthology/S16-1001)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | eng | Blog, Spoken, Web | human-annotated | created |



#### STS17

Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation

**Dataset:** [`mteb/sts17-crosslingual-sts`](https://huggingface.co/datasets/mteb/sts17-crosslingual-sts) • **License:** not specified • [Learn more →](https://alt.qcri.org/semeval2017/task1/)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | ara, deu, eng, fra, ita, ... (9) | News, Web, Written | human-annotated | created |



#### STS22

SemEval 2022 Task 8: Multilingual News Article Similarity

**Dataset:** [`mteb/sts22-crosslingual-sts`](https://huggingface.co/datasets/mteb/sts22-crosslingual-sts) • **License:** not specified • [Learn more →](https://competitions.codalab.org/competitions/33835)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | ara, cmn, deu, eng, fra, ... (10) | News, Written | human-annotated | found |



#### STS22.v2

SemEval 2022 Task 8: Multilingual News Article Similarity. Version 2 filters updated on STS22 by removing pairs where one of entries contain empty sentences.

**Dataset:** [`mteb/sts22-crosslingual-sts`](https://huggingface.co/datasets/mteb/sts22-crosslingual-sts) • **License:** not specified • [Learn more →](https://competitions.codalab.org/competitions/33835)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | ara, cmn, deu, eng, fra, ... (10) | News, Written | human-annotated | found |



#### STSB

A Chinese dataset for textual relatedness

**Dataset:** [`C-MTEB/STSB`](https://huggingface.co/datasets/C-MTEB/STSB) • **License:** not specified • [Learn more →](https://aclanthology.org/2021.emnlp-main.357)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | cmn | not specified | not specified | not specified |



#### STSBenchmark

Semantic Textual Similarity Benchmark (STSbenchmark) dataset.

**Dataset:** [`mteb/stsbenchmark-sts`](https://huggingface.co/datasets/mteb/stsbenchmark-sts) • **License:** not specified • [Learn more →](https://github.com/PhilipMay/stsb-multi-mt/)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | eng | Blog, News, Written | human-annotated | machine-translated and verified |



#### STSBenchmark-VN

A translated dataset from Semantic Textual Similarity Benchmark (STSbenchmark) dataset.
            The process of creating the VN-MTEB (Vietnamese Massive Text Embedding Benchmark) from English samples involves a new automated system:
            - The system uses large language models (LLMs), specifically Coherence's Aya model, for translation.
            - Applies advanced embedding models to filter the translations.
            - Use LLM-as-a-judge to scoring the quality of the samples base on multiple criteria.

**Dataset:** [`GreenNode/stsbenchmark-sts-vn`](https://huggingface.co/datasets/GreenNode/stsbenchmark-sts-vn) • **License:** cc-by-sa-4.0 • [Learn more →](https://github.com/PhilipMay/stsb-multi-mt/)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to category (t2c) | cosine_spearman | vie | Blog, News, Written | derived | machine-translated and LM verified |



#### STSBenchmarkMultilingualSTS

Semantic Textual Similarity Benchmark (STSbenchmark) dataset, but translated using DeepL API.

**Dataset:** [`mteb/stsb_multi_mt`](https://huggingface.co/datasets/mteb/stsb_multi_mt) • **License:** not specified • [Learn more →](https://github.com/PhilipMay/stsb-multi-mt/)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | cmn, deu, eng, fra, ita, ... (10) | News, Social, Spoken, Web, Written | human-annotated | machine-translated |



#### STSES

Spanish test sets from SemEval-2014 (Agirre et al., 2014) and SemEval-2015 (Agirre et al., 2015)

**Dataset:** [`PlanTL-GOB-ES/sts-es`](https://huggingface.co/datasets/PlanTL-GOB-ES/sts-es) • **License:** cc-by-4.0 • [Learn more →](https://huggingface.co/datasets/PlanTL-GOB-ES/sts-es)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | spa | Written | not specified | not specified |



#### SemRel24STS

SemRel2024 is a collection of Semantic Textual Relatedness (STR) datasets for 14 languages, including African and Asian languages. The datasets are composed of sentence pairs, each assigned a relatedness score between 0 (completely) unrelated and 1 (maximally related) with a large range of expected relatedness values.

**Dataset:** [`SemRel/SemRel2024`](https://huggingface.co/datasets/SemRel/SemRel2024) • **License:** not specified • [Learn more →](https://huggingface.co/datasets/SemRel/SemRel2024)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | afr, amh, arb, arq, ary, ... (12) | Spoken, Written | human-annotated | created |



#### SynPerSTS

Synthetic Persian Semantic Textual Similarity Dataset

**Dataset:** [`MCINext/synthetic-persian-sts`](https://huggingface.co/datasets/MCINext/synthetic-persian-sts) • **License:** not specified • [Learn more →](https://mcinext.com/)

| Task category | Score | Languages | Domains | Annotations Creators | Sample Creation |
|-------|-------|-------|-------|-------|-------|
| text to text (t2t) | cosine_spearman | fas | Blog, News, Religious, Web | LM-generated | LM-generated and verified |
