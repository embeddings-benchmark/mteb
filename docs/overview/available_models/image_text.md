# Image-text Model

<!-- This document is auto-generated. Changes will be overwritten. Please change the generating script. -->

- **Number of models:** 46

## Instruction Model

####  [`Alibaba-NLP/gme-Qwen2-VL-2B-Instruct`](https://huggingface.co/Alibaba-NLP/gme-Qwen2-VL-2B-Instruct)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 32.8K | 1.5K | 2.2B | 8.2 GB | 2024-12-24 | cmn-Hans, eng-Latn |


####  [`Alibaba-NLP/gme-Qwen2-VL-7B-Instruct`](https://huggingface.co/Alibaba-NLP/gme-Qwen2-VL-7B-Instruct)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 32.8K | 3.6K | 8.3B | 30.9 GB | 2024-12-24 | cmn-Hans, eng-Latn |


####  [`TIGER-Lab/VLM2Vec-Full`](https://huggingface.co/TIGER-Lab/VLM2Vec-Full)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 131.1K | 3.1K | 4.2B | 7.7 GB | 2024-10-08 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @article{jiang2024vlm2vec,
      title={VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks},
      author={Jiang, Ziyan and Meng, Rui and Yang, Xinyi and Yavuz, Semih and Zhou, Yingbo and Chen, Wenhu},
      journal={arXiv preprint arXiv:2410.05160},
      year={2024}
    }
    ```
    



####  [`TIGER-Lab/VLM2Vec-LoRA`](https://huggingface.co/TIGER-Lab/VLM2Vec-LoRA)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 131.1K | 3.1K | not specified | not specified | 2024-10-08 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @article{jiang2024vlm2vec,
      title={VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks},
      author={Jiang, Ziyan and Meng, Rui and Yang, Xinyi and Yavuz, Semih and Zhou, Yingbo and Chen, Wenhu},
      journal={arXiv preprint arXiv:2410.05160},
      year={2024}
    }
    ```
    



####  [`ibm-granite/granite-vision-3.3-2b-embedding`](https://huggingface.co/ibm-granite/granite-vision-3.3-2b-embedding)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 128.0K | 128 | 3.0B | 11.1 GB | 2025-06-11 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @article{karlinsky2025granitevision,
      title={Granite Vision: a lightweight, open-source multimodal model for enterprise Intelligence},
      author={Granite Vision Team and Karlinsky, Leonid and Arbelle, Assaf and Daniels, Abraham and Nassar, Ahmed and Alfassi, Amit and Wu, Bo and Schwartz, Eli and Joshi, Dhiraj and Kondic, Jovana and Shabtay, Nimrod and Li, Pengyuan and Herzig, Roei and Abedin, Shafiq and Perek, Shaked and Harary, Sivan and Barzelay, Udi and Raz Goldfarb, Adi and Oliva, Aude and Wieles, Ben and Bhattacharjee, Bishwaranjan and Huang, Brandon and Auer, Christoph and Gutfreund, Dan and Beymer, David and Wood, David and Kuehne, Hilde and Hansen, Jacob and Shtok, Joseph and Wong, Ken and Bathen, Luis Angel and Mishra, Mayank and Lysak, Maksym and Dolfi, Michele and Yurochkin, Mikhail and Livathinos, Nikolaos and Harel, Nimrod and Azulai, Ophir and Naparstek, Oshri and de Lima, Rafael Teixeira and Panda, Rameswar and Doveh, Sivan and Gupta, Shubham and Das, Subhro and Zawad, Syed and Kim, Yusik and He, Zexue and Brooks, Alexander and Goodhart, Gabe and Govindjee, Anita and Leist, Derek and Ibrahim, Ibrahim and Soffer, Aya and Cox, David and Soule, Kate and Lastras, Luis and Desai, Nirmit and Ofek-koifman, Shila and Raghavan, Sriram and Syeda-Mahmood, Tanveer and Staar, Peter and Drory, Tal and Feris, Rogerio},
      journal={arXiv preprint arXiv:2502.09927},
      year={2025}
    }
    ```
    



####  [`intfloat/mmE5-mllama-11b-instruct`](https://huggingface.co/intfloat/mmE5-mllama-11b-instruct)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 128.0K | 4.1K | 10.6B | 19.8 GB | 2025-02-12 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    
    @article{chen2025mmE5,
      title={mmE5: Improving Multimodal Multilingual Embeddings via High-quality Synthetic Data},
      author={Chen, Haonan and Wang, Liang and Yang, Nan and Zhu, Yutao and Zhao, Ziliang and Wei, Furu and Dou, Zhicheng},
      journal={arXiv preprint arXiv:2502.08468},
      year={2025}
    }
    
    ```
    



####  [`jinaai/jina-clip-v1`](https://huggingface.co/jinaai/jina-clip-v1)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 8.2K | 768 | 223.0M | 849.0 MB | 2024-05-30 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @article{koukounas2024jinaclip,
      title={Jina CLIP: Your CLIP Model Is Also Your Text Retriever},
      author={Koukounas, Andreas and Mastrapas, Georgios and Günther, Michael and Wang, Bo and Martens, Scott and Mohr, Isabelle and Sturua, Saba and Akram, Mohammad Kalim and Martínez, Joan Fontanals and Ognawala, Saahil and Guzman, Susana and Werk, Maximilian and Wang, Nan and Xiao, Han},
      journal={arXiv preprint arXiv:2405.20204},
      year={2024}
    }
    ```
    



####  [`jinaai/jina-embeddings-v4`](https://huggingface.co/jinaai/jina-embeddings-v4)

 **License:** cc-by-nc-4.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 32.8K | 2.0K | 3.8B | 7.3 GB | 2025-06-24 | afr-Latn, amh-Latn, ara-Latn, asm-Latn, aze-Latn, ... (99) |


??? quote "Citation"

    
    ```bibtex
    @misc{günther2025jinaembeddingsv4universalembeddingsmultimodal,
          title={jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval},
          author={Michael Günther and Saba Sturua and Mohammad Kalim Akram and Isabelle Mohr and Andrei Ungureanu and Sedigheh Eslami and Scott Martens and Bo Wang and Nan Wang and Han Xiao},
          year={2025},
          eprint={2506.18902},
          archivePrefix={arXiv},
          primaryClass={cs.AI},
          url={https://arxiv.org/abs/2506.18902},
    }
    ```
    



####  [`microsoft/LLM2CLIP-Openai-B-16`](https://huggingface.co/microsoft/LLM2CLIP-Openai-B-16)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| not specified | 1.3K | 361.0M | not specified | 2024-11-07 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @misc{huang2024llm2clippowerfullanguagemodel,
      title={LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation},
      author={Weiquan Huang and Aoqi Wu and Yifan Yang and Xufang Luo and Yuqing Yang and Liang Hu and Qi Dai and Xiyang Dai and Dongdong Chen and Chong Luo and Lili Qiu},
      year={2024},
      eprint={2411.04997},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.04997}
    }
    ```
    



####  [`microsoft/LLM2CLIP-Openai-L-14-224`](https://huggingface.co/microsoft/LLM2CLIP-Openai-L-14-224)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| not specified | 1.3K | 578.0M | not specified | 2024-11-07 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @misc{huang2024llm2clippowerfullanguagemodel,
      title={LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation},
      author={Weiquan Huang and Aoqi Wu and Yifan Yang and Xufang Luo and Yuqing Yang and Liang Hu and Qi Dai and Xiyang Dai and Dongdong Chen and Chong Luo and Lili Qiu},
      year={2024},
      eprint={2411.04997},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.04997}
    }
    ```
    



####  [`microsoft/LLM2CLIP-Openai-L-14-336`](https://huggingface.co/microsoft/LLM2CLIP-Openai-L-14-336)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| not specified | 1.3K | 579.0M | not specified | 2024-11-07 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @misc{huang2024llm2clippowerfullanguagemodel,
      title={LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation},
      author={Weiquan Huang and Aoqi Wu and Yifan Yang and Xufang Luo and Yuqing Yang and Liang Hu and Qi Dai and Xiyang Dai and Dongdong Chen and Chong Luo and Lili Qiu},
      year={2024},
      eprint={2411.04997},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.04997}
    }
    ```
    



####  [`nomic-ai/colnomic-embed-multimodal-3b`](https://huggingface.co/nomic-ai/colnomic-embed-multimodal-3b)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 128.0K | 128 | 3.0B | 7.0 GB | 2025-03-31 | deu-Latn, eng-Latn, fra-Latn, ita-Latn, spa-Latn |


??? quote "Citation"

    
    ```bibtex
    
    @misc{nomicembedmultimodal2025,
      title={Nomic Embed Multimodal: Interleaved Text, Image, and Screenshots for Visual Document Retrieval},
      author={Nomic Team},
      year={2025},
      publisher={Nomic AI},
      url={https://nomic.ai/blog/posts/nomic-embed-multimodal}
    }
    ```
    



####  [`nomic-ai/colnomic-embed-multimodal-7b`](https://huggingface.co/nomic-ai/colnomic-embed-multimodal-7b)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 128.0K | 128 | 7.0B | 14.1 GB | 2025-03-31 | deu-Latn, eng-Latn, fra-Latn, ita-Latn, spa-Latn |


??? quote "Citation"

    
    ```bibtex
    
    @misc{nomicembedmultimodal2025,
      title={Nomic Embed Multimodal: Interleaved Text, Image, and Screenshots for Visual Document Retrieval},
      author={Nomic Team},
      year={2025},
      publisher={Nomic AI},
      url={https://nomic.ai/blog/posts/nomic-embed-multimodal}
    }
    ```
    



####  [`nomic-ai/nomic-embed-vision-v1.5`](https://huggingface.co/nomic-ai/nomic-embed-vision-v1.5)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 2.0K | 768 | 92.9M | 355.0 MB | 2024-06-08 | eng-Latn |


####  [`nvidia/llama-nemoretriever-colembed-1b-v1`](https://huggingface.co/nvidia/llama-nemoretriever-colembed-1b-v1)

 **License:** https://huggingface.co/nvidia/llama-nemoretriever-colembed-1b-v1/blob/main/LICENSE


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 8.2K | 2.0K | 2.4B | 9.0 GB | 2025-06-27 | eng-Latn |


####  [`nvidia/llama-nemoretriever-colembed-3b-v1`](https://huggingface.co/nvidia/llama-nemoretriever-colembed-3b-v1)

 **License:** https://huggingface.co/nvidia/llama-nemoretriever-colembed-1b-v1/blob/main/LICENSE


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 8.2K | 3.1K | 4.4B | 16.4 GB | 2025-06-27 | eng-Latn |


####  [`royokong/e5-v`](https://huggingface.co/royokong/e5-v)

 **License:** not specified


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 8.2K | 4.1K | 8.4B | 15.6 GB | 2024-07-17 | eng-Latn |


####  [`vidore/colSmol-256M`](https://huggingface.co/vidore/colSmol-256M)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 8.2K | 128 | 256.0M | 800.0 MB | 2025-01-22 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    
    @misc{faysse2024colpali,
      title={ColPali: Efficient Document Retrieval with Vision Language Models},
      author={Faysse, Manuel and Sibille, Hugues and Wu, Tony and Omrani, Bilel and Viaud, Gautier and Hudelot, C'eline and Colombo, Pierre},
      year={2024},
      eprint={2407.01449},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
    }
    ```
    



####  [`vidore/colSmol-500M`](https://huggingface.co/vidore/colSmol-500M)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 8.2K | 128 | 500.0M | 1.2 GB | 2025-01-22 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    
    @misc{faysse2024colpali,
      title={ColPali: Efficient Document Retrieval with Vision Language Models},
      author={Faysse, Manuel and Sibille, Hugues and Wu, Tony and Omrani, Bilel and Viaud, Gautier and Hudelot, C'eline and Colombo, Pierre},
      year={2024},
      eprint={2407.01449},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
    }
    ```
    



####  [`vidore/colpali-v1.1`](https://huggingface.co/vidore/colpali-v1.1)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 16.4K | 128 | 2.9B | 4.6 GB | 2024-08-21 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    
    @misc{faysse2024colpali,
      title={ColPali: Efficient Document Retrieval with Vision Language Models},
      author={Faysse, Manuel and Sibille, Hugues and Wu, Tony and Omrani, Bilel and Viaud, Gautier and Hudelot, C'eline and Colombo, Pierre},
      year={2024},
      eprint={2407.01449},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
    }
    ```
    



####  [`vidore/colpali-v1.2`](https://huggingface.co/vidore/colpali-v1.2)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 16.4K | 128 | 2.9B | 4.6 GB | 2024-08-26 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    
    @misc{faysse2024colpali,
      title={ColPali: Efficient Document Retrieval with Vision Language Models},
      author={Faysse, Manuel and Sibille, Hugues and Wu, Tony and Omrani, Bilel and Viaud, Gautier and Hudelot, C'eline and Colombo, Pierre},
      year={2024},
      eprint={2407.01449},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
    }
    ```
    



####  [`vidore/colpali-v1.3`](https://huggingface.co/vidore/colpali-v1.3)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 16.4K | 128 | 2.9B | 4.6 GB | 2024-11-01 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    
    @misc{faysse2024colpali,
      title={ColPali: Efficient Document Retrieval with Vision Language Models},
      author={Faysse, Manuel and Sibille, Hugues and Wu, Tony and Omrani, Bilel and Viaud, Gautier and Hudelot, C'eline and Colombo, Pierre},
      year={2024},
      eprint={2407.01449},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
    }
    ```
    



####  [`vidore/colqwen2-v1.0`](https://huggingface.co/vidore/colqwen2-v1.0)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 32.8K | 128 | 2.2B | 7.0 GB | 2025-11-03 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    
    @misc{faysse2024colpali,
      title={ColPali: Efficient Document Retrieval with Vision Language Models},
      author={Faysse, Manuel and Sibille, Hugues and Wu, Tony and Omrani, Bilel and Viaud, Gautier and Hudelot, C'eline and Colombo, Pierre},
      year={2024},
      eprint={2407.01449},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
    }
    ```
    



####  [`vidore/colqwen2.5-v0.2`](https://huggingface.co/vidore/colqwen2.5-v0.2)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 128.0K | 128 | 3.0B | 7.0 GB | 2025-01-31 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    
    @misc{faysse2024colpali,
      title={ColPali: Efficient Document Retrieval with Vision Language Models},
      author={Faysse, Manuel and Sibille, Hugues and Wu, Tony and Omrani, Bilel and Viaud, Gautier and Hudelot, C'eline and Colombo, Pierre},
      year={2024},
      eprint={2407.01449},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
    }
    ```

## Non-instruction Model

####  [`BAAI/bge-visualized-base`](https://huggingface.co/BAAI/bge-visualized)

 **License:** not specified


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 512.0 | 768 | 196.0M | 1.6 GB | 2024-06-06 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @article{zhou2024vista,
      title={VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval},
      author={Zhou, Junjie and Liu, Zheng and Xiao, Shitao and Zhao, Bo and Xiong, Yongping},
      journal={arXiv preprint arXiv:2406.04292},
      year={2024}
    }
    ```
    



####  [`BAAI/bge-visualized-m3`](https://huggingface.co/BAAI/bge-visualized)

 **License:** not specified


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 8.2K | 1.0K | 872.9M | 4.2 GB | 2024-06-06 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @article{zhou2024vista,
      title={VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval},
      author={Zhou, Junjie and Liu, Zheng and Xiao, Shitao and Zhao, Bo and Xiong, Yongping},
      journal={arXiv preprint arXiv:2406.04292},
      year={2024}
    }
    ```
    



####  [`Cohere/Cohere-embed-v4.0`](https://docs.cohere.com/docs/cohere-embed)

 **License:** not specified


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 128.0K | 1.5K | not specified | not specified | 2024-12-01 | afr-Latn, amh-Ethi, ara-Arab, asm-Beng, aze-Latn, ... (111) |


####  [`Cohere/Cohere-embed-v4.0 (output_dtype=binary)`](https://docs.cohere.com/docs/embeddings)

 **License:** not specified


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 128.0K | 1.5K | not specified | not specified | 2024-12-01 | afr-Latn, amh-Ethi, ara-Arab, asm-Beng, aze-Latn, ... (111) |


####  [`Cohere/Cohere-embed-v4.0 (output_dtype=int8)`](https://docs.cohere.com/docs/embeddings)

 **License:** not specified


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 128.0K | 1.5K | not specified | not specified | 2024-12-01 | afr-Latn, amh-Ethi, ara-Arab, asm-Beng, aze-Latn, ... (111) |


####  [`QuanSun/EVA02-CLIP-B-16`](https://huggingface.co/QuanSun/EVA-CLIP)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 512 | 149.0M | 568.0 MB | 2023-04-26 | eng-Latn |


####  [`QuanSun/EVA02-CLIP-L-14`](https://huggingface.co/QuanSun/EVA-CLIP)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 768 | 428.0M | 1.6 GB | 2023-04-26 | eng-Latn |


####  [`QuanSun/EVA02-CLIP-bigE-14`](https://huggingface.co/QuanSun/EVA-CLIP)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 1.0K | 4.7B | 17.5 GB | 2023-04-26 | eng-Latn |


####  [`QuanSun/EVA02-CLIP-bigE-14-plus`](https://huggingface.co/QuanSun/EVA-CLIP)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 1.0K | 5.0B | 18.6 GB | 2023-04-26 | eng-Latn |


####  [`Salesforce/blip-image-captioning-base`](https://huggingface.co/Salesforce/blip-image-captioning-base)

 **License:** bsd-3-clause


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 512.0 | 768 | 247.0M | 942.0 MB | 2023-08-01 | eng-Latn |


####  [`Salesforce/blip-image-captioning-large`](https://huggingface.co/Salesforce/blip-image-captioning-large)

 **License:** bsd-3-clause


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 512.0 | 768 | 470.0M | 1.8 GB | 2023-12-07 | eng-Latn |


####  [`Salesforce/blip-itm-base-coco`](https://huggingface.co/Salesforce/blip-itm-base-coco)

 **License:** bsd-3-clause


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 512.0 | 768 | 247.0M | 942.0 MB | 2023-08-01 | eng-Latn |


####  [`Salesforce/blip-itm-base-flickr`](https://huggingface.co/Salesforce/blip-itm-base-flickr)

 **License:** bsd-3-clause


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 512.0 | 768 | 247.0M | 942.0 MB | 2023-08-01 | eng-Latn |


####  [`Salesforce/blip-itm-large-coco`](https://huggingface.co/Salesforce/blip-itm-large-coco)

 **License:** bsd-3-clause


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 512.0 | 768 | 470.0M | 1.8 GB | 2023-08-01 | eng-Latn |


####  [`Salesforce/blip-itm-large-flickr`](https://huggingface.co/Salesforce/blip-itm-large-flickr)

 **License:** bsd-3-clause


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 512.0 | 768 | 470.0M | 1.8 GB | 2023-08-01 | eng-Latn |


####  [`Salesforce/blip-vqa-base`](https://huggingface.co/Salesforce/blip-vqa-base)

 **License:** bsd-3-clause


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 512.0 | 768 | 247.0M | 1.4 GB | 2023-12-07 | eng-Latn |


####  [`Salesforce/blip-vqa-capfilt-large`](https://huggingface.co/Salesforce/blip-vqa-capfilt-large)

 **License:** bsd-3-clause


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 512.0 | 768 | 247.0M | 942.0 MB | 2023-01-22 | eng-Latn |


####  [`Salesforce/blip2-opt-2.7b`](https://huggingface.co/Salesforce/blip2-opt-2.7b)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| not specified | 768 | 3.7B | 14.0 GB | 2024-03-22 | eng-Latn |


####  [`Salesforce/blip2-opt-6.7b-coco`](https://huggingface.co/Salesforce/blip2-opt-6.7b-coco)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| not specified | 768 | 7.8B | 28.9 GB | 2024-03-31 | eng-Latn |


####  baseline/random-cross-encoder-baseline

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| infP | 32 | 0 | 0.0 MB | not specified | not specified |


####  baseline/random-encoder-baseline

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| infP | 32 | 0 | 0.0 MB | not specified | not specified |


####  [`cohere/embed-english-v3.0`](https://huggingface.co/Cohere/Cohere-embed-english-v3.0)

 **License:** not specified


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| not specified | 1.0K | not specified | not specified | 2024-10-24 | eng-Latn |


####  [`cohere/embed-multilingual-v3.0`](https://huggingface.co/Cohere/Cohere-embed-multilingual-v3.0)

 **License:** not specified


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| not specified | 1.0K | not specified | not specified | 2024-10-24 | not specified |


####  [`google/siglip-base-patch16-224`](https://huggingface.co/google/siglip-base-patch16-224)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 64.0 | 768 | 203.0M | 775.0 MB | 2024-01-08 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @misc{zhai2023sigmoid,
          title={Sigmoid Loss for Language Image Pre-Training},
          author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},
          year={2023},
          eprint={2303.15343},
          archivePrefix={arXiv},
          primaryClass={cs.CV}
    }
    ```
    



####  [`google/siglip-base-patch16-256`](https://huggingface.co/google/siglip-base-patch16-256)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 64.0 | 768 | 203.0M | 775.0 MB | 2024-01-08 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @misc{zhai2023sigmoid,
          title={Sigmoid Loss for Language Image Pre-Training},
          author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},
          year={2023},
          eprint={2303.15343},
          archivePrefix={arXiv},
          primaryClass={cs.CV}
    }
    ```
    



####  [`google/siglip-base-patch16-256-multilingual`](https://huggingface.co/google/siglip-base-patch16-256-multilingual)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 64.0 | 768 | 371.0M | 1.4 GB | 2024-01-08 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @misc{zhai2023sigmoid,
          title={Sigmoid Loss for Language Image Pre-Training},
          author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},
          year={2023},
          eprint={2303.15343},
          archivePrefix={arXiv},
          primaryClass={cs.CV}
    }
    ```
    



####  [`google/siglip-base-patch16-384`](https://huggingface.co/google/siglip-base-patch16-384)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 64.0 | 768 | 203.0M | 776.0 MB | 2024-01-08 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @misc{zhai2023sigmoid,
          title={Sigmoid Loss for Language Image Pre-Training},
          author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},
          year={2023},
          eprint={2303.15343},
          archivePrefix={arXiv},
          primaryClass={cs.CV}
    }
    ```
    



####  [`google/siglip-base-patch16-512`](https://huggingface.co/google/siglip-base-patch16-512)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 64.0 | 768 | 204.0M | 777.0 MB | 2024-01-08 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @misc{zhai2023sigmoid,
          title={Sigmoid Loss for Language Image Pre-Training},
          author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},
          year={2023},
          eprint={2303.15343},
          archivePrefix={arXiv},
          primaryClass={cs.CV}
    }
    ```
    



####  [`google/siglip-large-patch16-256`](https://huggingface.co/google/siglip-large-patch16-256)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 64.0 | 1.0K | 652.0M | 2.4 GB | 2024-01-08 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @misc{zhai2023sigmoid,
          title={Sigmoid Loss for Language Image Pre-Training},
          author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},
          year={2023},
          eprint={2303.15343},
          archivePrefix={arXiv},
          primaryClass={cs.CV}
    }
    ```
    



####  [`google/siglip-large-patch16-384`](https://huggingface.co/google/siglip-large-patch16-384)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 64.0 | 1.0K | 652.0M | 2.4 GB | 2024-01-08 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @misc{zhai2023sigmoid,
          title={Sigmoid Loss for Language Image Pre-Training},
          author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},
          year={2023},
          eprint={2303.15343},
          archivePrefix={arXiv},
          primaryClass={cs.CV}
    }
    ```
    



####  [`google/siglip-so400m-patch14-224`](https://huggingface.co/google/siglip-so400m-patch14-224)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 16.0 | 1.2K | 877.0M | 3.3 GB | 2024-01-08 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @misc{zhai2023sigmoid,
          title={Sigmoid Loss for Language Image Pre-Training},
          author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},
          year={2023},
          eprint={2303.15343},
          archivePrefix={arXiv},
          primaryClass={cs.CV}
    }
    ```
    



####  [`google/siglip-so400m-patch14-384`](https://huggingface.co/google/siglip-so400m-patch14-384)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 64.0 | 1.2K | 878.0M | 3.3 GB | 2024-01-08 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @misc{zhai2023sigmoid,
          title={Sigmoid Loss for Language Image Pre-Training},
          author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},
          year={2023},
          eprint={2303.15343},
          archivePrefix={arXiv},
          primaryClass={cs.CV}
    }
    ```
    



####  [`google/siglip-so400m-patch16-256-i18n`](https://huggingface.co/google/siglip-so400m-patch16-256-i18n)

 **License:** apache-2.0


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 64.0 | 1.2K | 1.1B | 4.2 GB | 2024-01-08 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    @misc{zhai2023sigmoid,
          title={Sigmoid Loss for Language Image Pre-Training},
          author={Xiaohua Zhai and Basil Mustafa and Alexander Kolesnikov and Lucas Beyer},
          year={2023},
          eprint={2303.15343},
          archivePrefix={arXiv},
          primaryClass={cs.CV}
    }
    ```
    



####  [`kakaobrain/align-base`](https://huggingface.co/kakaobrain/align-base)

 **License:** not specified


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 64.0 | 768 | 176.0M | 671.0 MB | 2023-02-24 | eng-Latn |


####  [`laion/CLIP-ViT-B-16-DataComp.XL-s13B-b90K`](https://huggingface.co/laion/CLIP-ViT-B-16-DataComp.XL-s13B-b90K)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 512 | 150.0M | 572.0 MB | 2023-04-26 | eng-Latn |


####  [`laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K`](https://huggingface.co/laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 512 | 151.0M | 576.0 MB | 2023-04-26 | eng-Latn |


####  [`laion/CLIP-ViT-B-32-laion2B-s34B-b79K`](https://huggingface.co/laion/CLIP-ViT-B-32-laion2B-s34B-b79K)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 512 | 151.0M | 577.0 MB | 2022-09-15 | eng-Latn |


####  [`laion/CLIP-ViT-H-14-laion2B-s32B-b79K`](https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 1.0K | 986.0M | 3.7 GB | 2022-09-15 | eng-Latn |


####  [`laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K`](https://huggingface.co/laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 768 | 428.0M | 1.6 GB | 2023-04-26 | eng-Latn |


####  [`laion/CLIP-ViT-L-14-laion2B-s32B-b82K`](https://huggingface.co/laion/CLIP-ViT-L-14-laion2B-s32B-b82K)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 768 | 428.0M | 1.6 GB | 2022-09-15 | eng-Latn |


####  [`laion/CLIP-ViT-bigG-14-laion2B-39B-b160k`](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 1.3K | 2.5B | 9.5 GB | 2023-01-23 | eng-Latn |


####  [`laion/CLIP-ViT-g-14-laion2B-s34B-b88K`](https://huggingface.co/laion/CLIP-ViT-g-14-laion2B-s34B-b88K)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 1.0K | 1.4B | 5.1 GB | 2023-03-06 | eng-Latn |


####  [`openai/clip-vit-base-patch16`](https://huggingface.co/openai/clip-vit-base-patch16)

 **License:** not specified


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 512 | 151.0M | 576.0 MB | 2021-02-26 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    
    @article{radford2021learning,
      title={Learning Transferable Visual Models From Natural Language Supervision},
      author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
      journal={arXiv preprint arXiv:2103.00020},
      year={2021}
    }
    ```
    



####  [`openai/clip-vit-base-patch32`](https://huggingface.co/openai/clip-vit-base-patch32)

 **License:** not specified


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 512 | 151.0M | 576.0 MB | 2021-02-26 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    
    @article{radford2021learning,
      title={Learning Transferable Visual Models From Natural Language Supervision},
      author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
      journal={arXiv preprint arXiv:2103.00020},
      year={2021}
    }
    ```
    



####  [`openai/clip-vit-large-patch14`](https://huggingface.co/openai/clip-vit-large-patch14)

 **License:** not specified


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 77.0 | 768 | 428.0M | 1.6 GB | 2021-02-26 | eng-Latn |


??? quote "Citation"

    
    ```bibtex
    
    @article{radford2021learning,
      title={Learning Transferable Visual Models From Natural Language Supervision},
      author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
      journal={arXiv preprint arXiv:2103.00020},
      year={2021}
    }
    ```
    



####  [`voyageai/voyage-multimodal-3`](https://huggingface.co/voyageai/voyage-multimodal-3)

 **License:** mit


| Max Tokens | Embedding dimension | Parameters | Required Memory (Mb) | Release date | Languages |
|-------|-------|-------|-------|-------|-------|
| 32.8K | 1.0K | not specified | not specified | 2024-11-10 | not specified |