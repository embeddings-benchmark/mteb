[build-system]
requires = ["setuptools>=42", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "mteb"
version = "1.39.7"
description = "Massive Text Embedding Benchmark"
readme = "README.md"
authors = [
    { name = "MTEB Contributors", email = "niklas@huggingface.co" },
    { email = "kenneth.enevoldsen@cas.au.dk" },
    { email = "nouamane@huggingface.co" },
    { email = "info@nils-reimers.de" },
]
license = { file = "LICENSE" }
keywords = ["deep learning", "text embeddings", "benchmark"]
classifiers = [
    "Development Status :: 5 - Production/Stable",
    "Environment :: Console",
    "Intended Audience :: Developers",
    "Intended Audience :: Information Technology",
    "License :: OSI Approved :: Apache Software License",
    "Operating System :: OS Independent",
    "Programming Language :: Python",
]
requires-python = ">=3.9,<3.14"
dependencies = [
    "datasets>=2.19.0",
    "numpy>=1.0.0,<3.0.0",
    "requests>=2.26.0",
    "scikit-learn>=1.4.0",
    "scipy>=0.0.0",
    "sentence_transformers>=3.0.0",
    "typing-extensions>=4.5.0",
    "torch>1.0.0",
    "tqdm>1.0.0",
    "rich>=0.0.0",
    "pytrec-eval-terrier>=0.5.6",
    "pydantic>=2.0.0",
    "typing_extensions>=0.0.0",
    "eval_type_backport>=0.0.0",
    "polars>=0.20.22",
    "transformers<4.57.0; python_version == '3.9'",  # https://github.com/huggingface/transformers/issues/41339
]


[project.urls]
homepage = "https://github.com/embeddings-benchmark/mteb"
"Huggingface Organization" = "https://huggingface.co/mteb"
"Source Code" = "https://github.com/embeddings-benchmark/mteb"

[project.scripts]
mteb = "mteb.cli:main"

[project.optional-dependencies]
image = ["torchvision>0.2.1"]
codecarbon = ["codecarbon>=2.0.0,<3.0.0"]
leaderboard = [
    "gradio==5.35.0; python_version > '3.9'", # 3.10 is required for gradio
    "plotly>=5.24.0,<6.0.0",
    "cachetools>=5.2.0",
    "matplotlib>=3.9.4",
]

# model specific optional dependencies:
peft = ["peft>=0.11.0"]
flagembedding = ["FlagEmbedding==1.3.4"]
jina = ["einops>=0.8.0"]
jina-v4 = ["peft>=0.15.2", "transformers>=4.52.0", "torchvision>=0.22.1"]
flash_attention = ["flash-attn>=2.6.3"]
openai = ["openai>=1.41.0", "tiktoken>=0.8.0"]
model2vec = ["model2vec>=0.3.0"]
pylate = ["pylate>=1.3.1; python_version < '3.13'"]  # Required for sentence-transformers 5.0.0 compatibility (otherwise 1.1.6), pylate requires voyager, which in turn requires <=3.12
bm25s = ["bm25s>=0.2.6", "PyStemmer>=2.2.0.3"]
gritlm = ["gritlm>=1.0.2"]
xformers = ["xformers>=0.0.29"]
blip2 = ["salesforce-lavis>=1.0.2"]
voyageai = ["voyageai>0.3.0,<2.0.0"]
voyage_v = ["voyageai>0.3.0,<2.0.0", "tenacity>9.0.0"]
cohere = ["cohere==5.14.0"]
vertexai = ["vertexai==1.71.1"]
llm2vec = ["llm2vec>=0.2.3,<0.3.0"]
timm = ["timm>=1.0.15,<1.1.0"]
open_clip_torch = ["open_clip_torch==2.31.0"]
nomic = ["einops>=0.8.1"]
ark = ["volcengine-python-sdk[ark]==3.0.2", "tiktoken>=0.8.0"]
colpali_engine = ["colpali_engine>=0.3.12"]
xet = ["huggingface_hub>=0.32.0"]
youtu = ["tencentcloud-sdk-python-common>=3.0.1454", "tencentcloud-sdk-python-lkeap>=3.0.1451"]

[dependency-groups]
lint = [
    "ruff==0.11.13", # locked so we don't get PRs which fail only due to a lint update
    "pre-commit>=4.1.0",
    "bibtexparser>=1.4.3" # used for tests/test_citation_formatting.py
]
test = [
    "pytest>=8.3.4,<8.4.0",
    "pytest-xdist>=3.6.1,<3.7.0",
    "pytest-coverage>=0.0",
    "pytest-rerunfailures>=15.0,<16.0",
    "iso639>=0.1.4", # used for tests/scripts/test_generate_model_meta.py
    "GitPython>=3.0.0",
]
docs = [
    "mkdocs>=1.6.1",
    "mkdocs-material>=9.5.47",
    "mkdocstrings-python>=1.18.2",
    "mkdocs-bibtex>=2.16.2",
    "mkdocs-exclude>=1.0.2",
    "mkdocs-include-dir-to-nav>=1.2.0",
    "tabulate>=0.9.0",
]
typing = [
    "mypy>=1.18.1",
    "types-cachetools>=6.2.0.20250827",
    "types-pysocks>=1.7.1.20250828",
    "types-pyyaml>=6.0.12.20250822",
    "types-requests>=2.32.4.20250913",
    "types-simplejson>=3.20.0.20250822",
    "types-tqdm>=4.67.0.20250809",
    "types-tensorflow>=2.18.0.20250809",
    # stubs require python >=3.10
    # "pandas-stubs>=2.3.2.250827",
    # "scipy-stubs>=1.15.3.0",
]
dev = [
    {include-group = "lint"},
    {include-group = "test"},
    {include-group = "typing"},
]


[tool.coverage.report]
omit = ["tests/*", "mteb/tasks/**/*", "scripts"]

# Regexes for lines to exclude from consideration
exclude_also = [
    # Don't complain about missing debug-only code:
    "def __repr__",
    "if self\\.debug",

    # Don't complain if tests don't hit defensive assertion code:
    "raise AssertionError",
    "raise NotImplementedError",

    # Don't complain if non-runnable code isn't run:
    "if 0:",
    "if __name__ == .__main__.:",

    # Don't complain about abstract methods, they aren't run:
    "@(abc\\.)?abstractmethod",
    ]

[tool.setuptools.packages.find]
where = ["."]
include = ["mteb", "mteb.*"]
namespaces = false

[tool.setuptools.package-data]
"mteb" = [
    "languages/*.json",  # for languages
    "descriptive_stats/*/*.json",  # for descriptive_stats image
    "descriptive_stats/Image/*/*.json",  # for descriptive_stats image
]
"mteb.abstasks" = ["dataset_card_template.md"]
"mteb.tasks.Image.ZeroShotClassification.eng.templates" = ["*.txt"]

[tool.ruff]
target-version = "py310"


[tool.ruff.lint]
select = [
    "F",  # pyflakes rules,
    "I",  # sorting for imports
    "E",  # formatting for docs
    "D",  # formatting for docs
    "UP", # upgrade to latest syntax if possible
    "FA", # Future annotations
    "C4", # cleaner comprehensions
    "NPY", # numpy
    "N",       # PEP8 naming convention
    "RUF009",  # function-call-in-dataclass-default-argument
    "RUF008",  # mutable-dataclass-default
    "RUF013",  # implicit-optional
    "RUF012",  # mutable-class-default
    "RUF015",  # unnecessary-iterable-allocation-for-first-element
    "RUF016",  # invalid-index-type
    "RUF017",  # quadratic-list-summation
    "RUF018",  # assignment-in-assert
    "RUF019",  # unnecessary-key-check
    "RUF020",  # never-union
    "RUF021",  # parenthesize-chained-operators
    "RUF022",  # unsorted-dunder-all
    "RUF024",  # mutable-fromkeys-value
    "RUF026",  # default-factory-kwarg
    "RUF033",  # post-init-default
    "RUF034",  # useless-if-else
    "RUF041",  # unnecessary-nested-literal
    "RUF040",  # invalid-assert-message-literal-argument
    "RUF046",  # unnecessary-cast-to-int
    "RUF051",  # if-key-in-dict-del
    "RUF100",  # unused-noqa
    "RUF101",  # redirected-noqa
    "RUF200",  # invalid-pyproject-toml
    "PTH",     # use pathlib
    "TID",     # tidy-imports
]

ignore = [
    "E501",   # line too long
    "E741",     # ambiguous variable name
    "D100",     # Missing docstring in public module
    "D101",     # Missing docstring in public class
    "D102",     # Missing docstring in public method
    "D103",     # Missing docstring in public function
    "D105",     # Missing docstring in magic method
    "D104",     # Missing docstring in public package
    "D107",     # Missing docstring in __init__
    "D205",     # 1 blank line required between summary line and description
    "D415",     # First line should end with a period
    "C408",     # don't use unecc. collection call, e.g. dict over {}
]

[tool.ruff.lint.per-file-ignores]
"scripts/*" = ["PTH", "N"]
"tests/*" = ["RUF012"]
"mteb/tasks/*__init__.py" = ["F403"]  # undefined import `from .lang import *`

[tool.ruff.lint.flake8-implicit-str-concat]
allow-multiline = false

[tool.ruff.lint.pep8-naming]
ignore-names = [
    "F",  # torch.nn.functional
    "X_train",
    "X_test",
]

[tool.ruff.lint.pydocstyle]
convention = "google"

[tool.ruff.lint.flake8-annotations]
mypy-init-return = true
suppress-none-returning = true

[tool.semantic_release]
branch = "main"
version_toml = ["pyproject.toml:project.version"]
build_command = "python -m pip install build; python -m build"
tag_format = "{version}"

[tool.semantic_release.commit_parser_options]
major_tags = ["breaking"]
minor_tags = ["minor", "feat"]
patch_tags = [
    "patch",
    "fix",
    "perf",
    "model",
    "dataset",
]

[tool.pytest.ini_options]
addopts = """
            --reruns 3
            --only-rerun requests.exceptions.ReadTimeout
            --only-rerun huggingface_hub.errors.HfHubHTTPError
            --only-rerun huggingface_hub.errors.LocalEntryNotFoundError
            --only-rerun FileNotFoundError
            --durations=5
            --reruns-delay 10
        """
# --reruns 3 -> # Retry failed tests 3 times
# requests.exceptions.ReadTimeout -> # HF Read timed out -> https://github.com/embeddings-benchmark/mteb/actions/runs/13275350693/job/37093688544
# huggingface_hub.errors.HfHubHTTPError -> # HF is unavailable, e.g. seen here: https://github.com/embeddings-benchmark/mteb/actions/runs/13275350693/job/37093688544
# huggingface_hub.errors.LocalEntryNotFoundError -> # Gateway Time-out from HF, e.g. seen here: https://github.com/embeddings-benchmark/mteb/actions/runs/13275350693/job/37093688544
# FileNotFoundError -> HF Cache is broken:  https://github.com/embeddings-benchmark/mteb/actions/runs/13302915091/job/37147507251?pr=2029
# --durations=5 -> Show the 5 slowest tests
# --reruns-delay 10 -> Delay between reruns in seconds to avoid running into the same issue again

markers = [
    "test_datasets: marks tests that tests dataset availability",
]

[tool.uv]
override-dependencies = [
    "salesforce-lavis", # salesforce-lavis is not valid with sentence transformers >=3.0.0
]
conflicts = [
    [{ extra = "timm" }, { extra = "blip2" }],
    [{ extra = "llm2vec" }, { extra = "model2vec" }],
    # conflicting versions of transformers:
    [{ extra = "llm2vec" }, { extra = "pylate" }],
    [{ extra = "colpali-engine" }, { extra = "pylate" }],
    [{ extra = "colpali-engine" }, { extra = "llm2vec" }],
    [{ extra = "jina-v4" }, { extra = "llm2vec" }],
]

[tool.uv.extra-build-dependencies]
flash-attn = [{ requirement = "torch", match-runtime = true }]

[tool.mypy]
plugins = ['pydantic.mypy']

[[tool.mypy.overrides]]
# these modules not typed and don't have stubs
module = [
    "datasets",
    "sklearn",
    "sklearn.*",
]
ignore_missing_imports = true

[[tool.mypy.overrides]]
# don't typecheck these modules (too many issues)
module = [
    "mteb.models.model_implementations.*",
    "mteb.tasks.*",
    "mteb.leaderboard.*",
]
ignore_errors = true

[[tool.mypy.overrides]]
# mypy can't resolve dataset dict
module = ["mteb.abstasks.*"]
disable_error_code = ["index"]
