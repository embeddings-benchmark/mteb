model_name,status,file
AITeamVN/Vietnamese_Embedding,updated,vi_vn_models.py
Alibaba-NLP/gme-Qwen2-VL-2B-Instruct,updated,gme_v_models.py
Alibaba-NLP/gme-Qwen2-VL-7B-Instruct,updated,gme_v_models.py
Alibaba-NLP/gte-Qwen1.5-7B-instruct,updated,gte_models.py
Alibaba-NLP/gte-Qwen2-1.5B-instruct,updated,gte_models.py
Alibaba-NLP/gte-Qwen2-7B-instruct,updated,gte_models.py
Alibaba-NLP/gte-base-en-v1.5,updated,gte_models.py
Alibaba-NLP/gte-modernbert-base,updated,gte_models.py
Alibaba-NLP/gte-multilingual-base,updated,gte_models.py
ApsaraStackMaaS/EvoQwen2.5-VL-Retriever-3B-v1,updated,colqwen_models.py
ApsaraStackMaaS/EvoQwen2.5-VL-Retriever-7B-v1,updated,colqwen_models.py
BAAI/bge-base-en,updated,bge_models.py
BAAI/bge-base-en-v1.5,updated,bge_models.py
BAAI/bge-base-zh,updated,bge_models.py
BAAI/bge-base-zh-v1.5,updated,bge_models.py
BAAI/bge-en-icl,updated,bge_models.py
BAAI/bge-large-en,updated,bge_models.py
BAAI/bge-large-en-v1.5,updated,bge_models.py
BAAI/bge-large-zh,updated,bge_models.py
BAAI/bge-large-zh-v1.5,updated,bge_models.py
BAAI/bge-m3,updated,bge_models.py
BAAI/bge-m3-unsupervised,updated,bge_models.py
BAAI/bge-multilingual-gemma2,updated,bge_models.py
BAAI/bge-reranker-v2-m3,updated,rerankers_custom.py
BAAI/bge-small-en,updated,bge_models.py
BAAI/bge-small-en-v1.5,updated,bge_models.py
BAAI/bge-small-zh,updated,bge_models.py
BAAI/bge-small-zh-v1.5,updated,bge_models.py
BAAI/bge-visualized-base,updated,vista_models.py
BAAI/bge-visualized-m3,updated,vista_models.py
BMRetriever/BMRetriever-1B,updated,bmretriever_models.py
BMRetriever/BMRetriever-2B,updated,bmretriever_models.py
BMRetriever/BMRetriever-410M,updated,bmretriever_models.py
BMRetriever/BMRetriever-7B,updated,bmretriever_models.py
BeastyZ/e5-R-mistral-7b,updated,e5_instruct.py
ByteDance-Seed/Seed1.5-Embedding,updated,seed_models.py
ByteDance/ListConRanker,updated,listconranker.py
Bytedance/Seed1.6-embedding,updated,seed_1_6_embedding_models.py
Bytedance/Seed1.6-embedding-1215,updated,seed_1_6_embedding_models_1215.py
Classical/Yinka,updated,misc_models.py
Cohere/Cohere-embed-english-light-v3.0,updated,cohere_models.py
Cohere/Cohere-embed-english-v3.0,updated,cohere_models.py
Cohere/Cohere-embed-multilingual-light-v3.0,updated,cohere_models.py
Cohere/Cohere-embed-multilingual-v3.0,updated,cohere_models.py
Cohere/Cohere-embed-v4.0,updated,cohere_v.py
Cohere/Cohere-embed-v4.0 (output_dtype=binary),updated,cohere_v.py
Cohere/Cohere-embed-v4.0 (output_dtype=int8),updated,cohere_v.py
DMetaSoul/Dmeta-embedding-zh-small,updated,misc_models.py
DMetaSoul/sbert-chinese-general-v1,updated,misc_models.py
DeepPavlov/distilrubert-small-cased-conversational,updated,ru_sentence_models.py
DeepPavlov/rubert-base-cased,updated,ru_sentence_models.py
DeepPavlov/rubert-base-cased-sentence,updated,ru_sentence_models.py
FacebookAI/xlm-roberta-base,updated,facebookai.py
FacebookAI/xlm-roberta-large,updated,facebookai.py
Gameselo/STS-multilingual-mpnet-base-v2,updated,misc_models.py
GeoGPT-Research-Project/GeoEmbedding,updated,geogpt_models.py
GreenNode/GreenNode-Embedding-Large-VN-Mixed-V1,updated,vi_vn_models.py
GreenNode/GreenNode-Embedding-Large-VN-V1,updated,vi_vn_models.py
GritLM/GritLM-7B,updated,gritlm_models.py
GritLM/GritLM-8x7B,updated,gritlm_models.py
HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1,updated,kalm_models.py
HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1.5,updated,kalm_models.py
HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v2,updated,kalm_models.py
HIT-TMG/KaLM-embedding-multilingual-mini-v1,updated,kalm_models.py
Haon-Chen/speed-embedding-7b-instruct,updated,misc_models.py
HooshvareLab/bert-base-parsbert-uncased,updated,fa_models.py
Hum-Works/lodestone-base-4096-v1,updated,misc_models.py
Human,updated,human.py
IEITYuan/Yuan-embedding-2.0-en,updated,yuan_models_en.py
IEITYuan/Yuan-embedding-2.0-zh,updated,yuan_models.py
Jaume/gemma-2b-embeddings,updated,misc_models.py
KBLab/sentence-bert-swedish-cased,updated,kblab.py
KFST/XLMRoberta-en-da-sv-nb,updated,kfst.py
KaLM-Embedding/KaLM-embedding-multilingual-mini-instruct-v2.5,updated,kalm_models.py
KennethEnevoldsen/dfm-sentence-encoder-large,updated,kennethenevoldsen_models.py
KennethEnevoldsen/dfm-sentence-encoder-medium,updated,kennethenevoldsen_models.py
Kingsoft-LLM/QZhou-Embedding,updated,qzhou_models.py
Kingsoft-LLM/QZhou-Embedding-Zh,updated,qzhou_models.py
Kowshik24/bangla-sentence-transformer-ft-matryoshka-paraphrase-multilingual-mpnet-base-v2,updated,kowshik24_models.py
Lajavaness/bilingual-embedding-base,updated,misc_models.py
Lajavaness/bilingual-embedding-large,updated,misc_models.py
Lajavaness/bilingual-embedding-small,updated,misc_models.py
Linq-AI-Research/Linq-Embed-Mistral,updated,linq_models.py
MCINext/Hakim,updated,mcinext_models.py
MCINext/Hakim-small,updated,mcinext_models.py
MCINext/Hakim-unsup,updated,mcinext_models.py
McGill-NLP/LLM2Vec-Llama-2-7b-chat-hf-mntp-supervised,updated,llm2vec_models.py
McGill-NLP/LLM2Vec-Llama-2-7b-chat-hf-mntp-unsup-simcse,updated,llm2vec_models.py
McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-supervised,updated,llm2vec_models.py
McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-unsup-simcse,updated,llm2vec_models.py
McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp-supervised,updated,llm2vec_models.py
McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp-unsup-simcse,updated,llm2vec_models.py
McGill-NLP/LLM2Vec-Sheared-LLaMA-mntp-supervised,updated,llm2vec_models.py
McGill-NLP/LLM2Vec-Sheared-LLaMA-mntp-unsup-simcse,updated,llm2vec_models.py
Mihaiii/Bulbasaur,updated,misc_models.py
Mihaiii/Ivysaur,updated,misc_models.py
Mihaiii/Squirtle,updated,misc_models.py
Mihaiii/Venusaur,updated,misc_models.py
Mihaiii/Wartortle,updated,misc_models.py
Mihaiii/gte-micro,updated,misc_models.py
Mihaiii/gte-micro-v4,updated,misc_models.py
Mira190/Euler-Legal-Embedding-V1,updated,euler_models.py
MongoDB/mdbr-leaf-ir,updated,mdbr_models.py
MongoDB/mdbr-leaf-mt,updated,mdbr_models.py
NbAiLab/nb-bert-base,updated,nbailab.py
NbAiLab/nb-bert-large,updated,nbailab.py
NbAiLab/nb-sbert-base,updated,nbailab.py
NeuML/pubmedbert-base-embeddings-100K,updated,model2vec_models.py
NeuML/pubmedbert-base-embeddings-1M,updated,model2vec_models.py
NeuML/pubmedbert-base-embeddings-2M,updated,model2vec_models.py
NeuML/pubmedbert-base-embeddings-500K,updated,model2vec_models.py
NeuML/pubmedbert-base-embeddings-8M,updated,model2vec_models.py
NovaSearch/jasper_en_vision_language_v1,updated,jasper_models.py
NovaSearch/stella_en_1.5B_v5,updated,stella_models.py
NovaSearch/stella_en_400M_v5,updated,stella_models.py
Omartificial-Intelligence-Space/Arabert-all-nli-triplet-Matryoshka,updated,misc_models.py
Omartificial-Intelligence-Space/Arabic-MiniLM-L12-v2-all-nli-triplet,updated,misc_models.py
Omartificial-Intelligence-Space/Arabic-Triplet-Matryoshka-V2,updated,ara_models.py
Omartificial-Intelligence-Space/Arabic-all-nli-triplet-Matryoshka,updated,misc_models.py
Omartificial-Intelligence-Space/Arabic-labse-Matryoshka,updated,misc_models.py
Omartificial-Intelligence-Space/Arabic-mpnet-base-all-nli-triplet,updated,misc_models.py
Omartificial-Intelligence-Space/Marbert-all-nli-triplet-Matryoshka,updated,misc_models.py
OpenSearch-AI/Ops-MoA-Conan-embedding-v1,updated,ops_moa_models.py
OpenSearch-AI/Ops-MoA-Yuan-embedding-1.0,updated,ops_moa_models.py
OrdalieTech/Solon-embeddings-large-0.1,updated,misc_models.py
OrdalieTech/Solon-embeddings-mini-beta-1.1,updated,ordalietech_solon_embeddings_mini_beta_1_1.py
OrlikB/KartonBERT-USE-base-v1,updated,misc_models.py
OrlikB/st-polish-kartonberta-base-alpha-v1,updated,misc_models.py
PartAI/Tooka-SBERT,updated,fa_models.py
PartAI/Tooka-SBERT-V2-Large,updated,fa_models.py
PartAI/Tooka-SBERT-V2-Small,updated,fa_models.py
PartAI/TookaBERT-Base,updated,fa_models.py
Qodo/Qodo-Embed-1-1.5B,updated,qodo_models.py
Qodo/Qodo-Embed-1-7B,updated,qodo_models.py
QuanSun/EVA02-CLIP-B-16,updated,evaclip_models.py
QuanSun/EVA02-CLIP-L-14,updated,evaclip_models.py
QuanSun/EVA02-CLIP-bigE-14,updated,evaclip_models.py
QuanSun/EVA02-CLIP-bigE-14-plus,updated,evaclip_models.py
Qwen/Qwen3-Embedding-0.6B,updated,qwen3_models.py
Qwen/Qwen3-Embedding-4B,updated,qwen3_models.py
Qwen/Qwen3-Embedding-8B,updated,qwen3_models.py
ReasonIR/ReasonIR-8B,updated,reasonir_model.py
Sailesh97/Hinvec,updated,hinvec_models.py
Salesforce/SFR-Embedding-2_R,updated,salesforce_models.py
Salesforce/SFR-Embedding-Code-2B_R,updated,salesforce_models.py
Salesforce/SFR-Embedding-Mistral,updated,salesforce_models.py
Salesforce/blip-image-captioning-base,updated,blip_models.py
Salesforce/blip-image-captioning-large,updated,blip_models.py
Salesforce/blip-itm-base-coco,updated,blip_models.py
Salesforce/blip-itm-base-flickr,updated,blip_models.py
Salesforce/blip-itm-large-coco,updated,blip_models.py
Salesforce/blip-itm-large-flickr,updated,blip_models.py
Salesforce/blip-vqa-base,updated,blip_models.py
Salesforce/blip-vqa-capfilt-large,updated,blip_models.py
Salesforce/blip2-opt-2.7b,updated,blip2_models.py
Salesforce/blip2-opt-6.7b-coco,updated,blip2_models.py
SamilPwC-AXNode-GenAI/PwC-Embedding_expr,updated,samilpwc_models.py
Shuu12121/CodeSearch-ModernBERT-Crow-Plus,updated,shuu_model.py
Snowflake/snowflake-arctic-embed-l,updated,arctic_models.py
Snowflake/snowflake-arctic-embed-l-v2.0,updated,arctic_models.py
Snowflake/snowflake-arctic-embed-m,updated,arctic_models.py
Snowflake/snowflake-arctic-embed-m-long,updated,arctic_models.py
Snowflake/snowflake-arctic-embed-m-v1.5,updated,arctic_models.py
Snowflake/snowflake-arctic-embed-m-v2.0,updated,arctic_models.py
Snowflake/snowflake-arctic-embed-s,updated,arctic_models.py
Snowflake/snowflake-arctic-embed-xs,updated,arctic_models.py
TIGER-Lab/VLM2Vec-Full,updated,vlm2vec_models.py
TIGER-Lab/VLM2Vec-LoRA,updated,vlm2vec_models.py
Tarka-AIR/Tarka-Embedding-150M-V1,updated,tarka_models.py
Tarka-AIR/Tarka-Embedding-350M-V1,updated,tarka_models.py
TencentBAC/Conan-embedding-v1,updated,misc_models.py
TencentBAC/Conan-embedding-v2,updated,conan_models.py
TomoroAI/tomoro-colqwen3-embed-4b,updated,colqwen_models.py
TomoroAI/tomoro-colqwen3-embed-8b,updated,colqwen_models.py
VPLabs/SearchMap_Preview,updated,searchmap_models.py
VoVanPhuc/sup-SimCSE-VietNamese-phobert-base,updated,vi_vn_models.py
WhereIsAI/UAE-Large-V1,updated,uae_models.py
aari1995/German_Semantic_STS_V2,updated,misc_models.py
abhinand/MedEmbed-small-v0.1,updated,misc_models.py
ai-forever/FRIDA,updated,ru_sentence_models.py
ai-forever/ru-en-RoSBERTa,updated,ru_sentence_models.py
ai-forever/sbert_large_mt_nlu_ru,updated,ru_sentence_models.py
ai-forever/sbert_large_nlu_ru,updated,ru_sentence_models.py
ai-sage/Giga-Embeddings-instruct,updated,ru_sentence_models.py
amazon/Titan-text-embeddings-v2,updated,amazon_models.py
andersborges/model2vecdk,updated,andersborges.py
andersborges/model2vecdk-stem,updated,andersborges.py
annamodels/LGAI-Embedding-Preview,updated,lgai_embedding_models.py
avsolatorio/GIST-Embedding-v0,updated,misc_models.py
avsolatorio/GIST-all-MiniLM-L6-v2,updated,misc_models.py
avsolatorio/GIST-large-Embedding-v0,updated,misc_models.py
avsolatorio/GIST-small-Embedding-v0,updated,misc_models.py
avsolatorio/NoInstruct-small-Embedding-v0,updated,no_instruct_sentence_models.py
baseline/random-cross-encoder-baseline,unchanged_or_failed,random_baseline.py
baseline/random-encoder-baseline,unchanged_or_failed,random_baseline.py
bedrock/amazon-titan-embed-text-v1,updated,bedrock_models.py
bedrock/amazon-titan-embed-text-v2,updated,bedrock_models.py
bedrock/cohere-embed-english-v3,updated,bedrock_models.py
bedrock/cohere-embed-multilingual-v3,updated,bedrock_models.py
bflhc/MoD-Embedding,updated,mod_models.py
bflhc/Octen-Embedding-4B,updated,octen_models.py
bflhc/Octen-Embedding-8B,updated,octen_models.py
bigscience/sgpt-bloom-7b1-msmarco,updated,misc_models.py
bisectgroup/BiCA-base,updated,bica_model.py
bkai-foundation-models/vietnamese-bi-encoder,updated,vi_vn_models.py
bm25s,updated,bm25.py
brahmairesearch/slx-v0.1,updated,misc_models.py
castorini/monobert-large-msmarco,updated,rerankers_custom.py
castorini/monot5-3b-msmarco-10k,updated,rerankers_monot5_based.py
castorini/monot5-base-msmarco-10k,updated,rerankers_monot5_based.py
castorini/monot5-large-msmarco-10k,updated,rerankers_monot5_based.py
castorini/monot5-small-msmarco-10k,updated,rerankers_monot5_based.py
castorini/repllama-v1-7b-lora-passage,updated,repllama_models.py
cl-nagoya/ruri-base,updated,ruri_models.py
cl-nagoya/ruri-base-v2,updated,ruri_models.py
cl-nagoya/ruri-large,updated,ruri_models.py
cl-nagoya/ruri-large-v2,updated,ruri_models.py
cl-nagoya/ruri-small,updated,ruri_models.py
cl-nagoya/ruri-small-v2,updated,ruri_models.py
cl-nagoya/ruri-v3-130m,updated,ruri_models.py
cl-nagoya/ruri-v3-30m,updated,ruri_models.py
cl-nagoya/ruri-v3-310m,updated,ruri_models.py
cl-nagoya/ruri-v3-70m,updated,ruri_models.py
clips/e5-base-trm-nl,updated,clips_models.py
clips/e5-large-trm-nl,updated,clips_models.py
clips/e5-small-trm-nl,updated,clips_models.py
codefuse-ai/C2LLM-0.5B,updated,codefuse_models.py
codefuse-ai/C2LLM-7B,updated,codefuse_models.py
codefuse-ai/F2LLM-0.6B,updated,codefuse_models.py
codefuse-ai/F2LLM-1.7B,updated,codefuse_models.py
codefuse-ai/F2LLM-4B,updated,codefuse_models.py
codesage/codesage-base-v2,updated,codesage_models.py
codesage/codesage-large-v2,updated,codesage_models.py
codesage/codesage-small-v2,updated,codesage_models.py
cohere/embed-english-v3.0,updated,cohere_v.py
cohere/embed-multilingual-v3.0,updated,cohere_v.py
cointegrated/LaBSE-en-ru,updated,ru_sentence_models.py
cointegrated/rubert-tiny,updated,ru_sentence_models.py
cointegrated/rubert-tiny2,updated,ru_sentence_models.py
colbert-ir/colbertv2.0,updated,pylate_models.py
consciousAI/cai-lunaris-text-embeddings,updated,misc_models.py
consciousAI/cai-stellaris-text-embeddings,updated,misc_models.py
deepfile/embedder-100p,updated,misc_models.py
deepvk/USER-base,updated,ru_sentence_models.py
deepvk/USER-bge-m3,updated,ru_sentence_models.py
deepvk/USER2-base,updated,ru_sentence_models.py
deepvk/USER2-small,updated,ru_sentence_models.py
deepvk/deberta-v1-base,updated,ru_sentence_models.py
dmedhi/PawanEmbd-68M,updated,pawan_models.py
dunzhang/stella-large-zh-v3-1792d,updated,stella_models.py
dunzhang/stella-mrl-large-zh-v3.5-1792d,updated,stella_models.py
dwzhu/e5-base-4k,updated,misc_models.py
eagerworks/eager-embed-v1,updated,eagerworks_models.py
emillykkejensen/EmbeddingGemma-Scandi-300m,updated,emillykkejensen_models.py
emillykkejensen/Qwen3-Embedding-Scandi-0.6B,updated,emillykkejensen_models.py
emillykkejensen/mmBERTscandi-base-embedding,updated,emillykkejensen_models.py
facebook/SONAR,updated,sonar_models.py
facebook/contriever-msmarco,updated,sentence_transformers_models.py
facebook/dinov2-base,updated,dino_models.py
facebook/dinov2-giant,updated,dino_models.py
facebook/dinov2-large,updated,dino_models.py
facebook/dinov2-small,updated,dino_models.py
facebook/webssl-dino1b-full2b-224,updated,dino_models.py
facebook/webssl-dino2b-full2b-224,updated,dino_models.py
facebook/webssl-dino2b-heavy2b-224,updated,dino_models.py
facebook/webssl-dino2b-light2b-224,updated,dino_models.py
facebook/webssl-dino300m-full2b-224,updated,dino_models.py
facebook/webssl-dino3b-full2b-224,updated,dino_models.py
facebook/webssl-dino3b-heavy2b-224,updated,dino_models.py
facebook/webssl-dino3b-light2b-224,updated,dino_models.py
facebook/webssl-dino5b-full2b-224,updated,dino_models.py
facebook/webssl-dino7b-full8b-224,updated,dino_models.py
facebook/webssl-dino7b-full8b-378,updated,dino_models.py
facebook/webssl-dino7b-full8b-518,updated,dino_models.py
facebook/webssl-mae1b-full2b-224,updated,dino_models.py
facebook/webssl-mae300m-full2b-224,updated,dino_models.py
facebook/webssl-mae700m-full2b-224,updated,dino_models.py
fangxq/XYZ-embedding,updated,xyz_models.py
fyaronskiy/english_code_retriever,updated,en_code_retriever.py
google/embeddinggemma-300m,updated,google_models.py
google/flan-t5-base,updated,rerankers_monot5_based.py
google/flan-t5-large,updated,rerankers_monot5_based.py
google/flan-t5-xl,updated,rerankers_monot5_based.py
google/flan-t5-xxl,updated,rerankers_monot5_based.py
google/gemini-embedding-001,updated,google_models.py
google/siglip-base-patch16-224,updated,siglip_models.py
google/siglip-base-patch16-256,updated,siglip_models.py
google/siglip-base-patch16-256-multilingual,updated,siglip_models.py
google/siglip-base-patch16-384,updated,siglip_models.py
google/siglip-base-patch16-512,updated,siglip_models.py
google/siglip-large-patch16-256,updated,siglip_models.py
google/siglip-large-patch16-384,updated,siglip_models.py
google/siglip-so400m-patch14-224,updated,siglip_models.py
google/siglip-so400m-patch14-384,updated,siglip_models.py
google/siglip-so400m-patch16-256-i18n,updated,siglip_models.py
google/text-embedding-004,updated,google_models.py
google/text-embedding-005,updated,google_models.py
google/text-multilingual-embedding-002,updated,google_models.py
hiieu/halong_embedding,updated,vi_vn_models.py
iampanda/zpoint_large_embedding_zh,updated,stella_models.py
ibm-granite/granite-embedding-107m-multilingual,updated,ibm_granite_models.py
ibm-granite/granite-embedding-125m-english,updated,ibm_granite_models.py
ibm-granite/granite-embedding-278m-multilingual,updated,ibm_granite_models.py
ibm-granite/granite-embedding-30m-english,updated,ibm_granite_models.py
ibm-granite/granite-embedding-english-r2,updated,ibm_granite_models.py
ibm-granite/granite-embedding-small-english-r2,updated,ibm_granite_models.py
ibm-granite/granite-vision-3.3-2b-embedding,updated,granite_vision_embedding_models.py
infgrad/Jasper-Token-Compression-600M,updated,jasper_models.py
infgrad/stella-base-en-v2,updated,misc_models.py
infgrad/stella-base-zh-v3-1792d,updated,stella_models.py
infly/inf-retriever-v1,updated,inf_models.py
infly/inf-retriever-v1-1.5b,updated,inf_models.py
intfloat/e5-base,updated,e5_models.py
intfloat/e5-base-v2,updated,e5_models.py
intfloat/e5-large,updated,e5_models.py
intfloat/e5-large-v2,updated,e5_models.py
intfloat/e5-mistral-7b-instruct,updated,e5_instruct.py
intfloat/e5-small,updated,e5_models.py
intfloat/e5-small-v2,updated,e5_models.py
intfloat/mmE5-mllama-11b-instruct,updated,mme5_models.py
intfloat/multilingual-e5-base,updated,e5_models.py
intfloat/multilingual-e5-large,updated,e5_models.py
intfloat/multilingual-e5-large-instruct,updated,e5_instruct.py
intfloat/multilingual-e5-small,updated,e5_models.py
izhx/udever-bloom-1b1,updated,misc_models.py
izhx/udever-bloom-3b,updated,misc_models.py
izhx/udever-bloom-560m,updated,misc_models.py
izhx/udever-bloom-7b1,updated,misc_models.py
jhu-clsp/FollowIR-7B,updated,rerankers_monot5_based.py
jinaai/jina-clip-v1,updated,jina_clip.py
jinaai/jina-colbert-v2,updated,pylate_models.py
jinaai/jina-embedding-b-en-v1,updated,jina_models.py
jinaai/jina-embedding-s-en-v1,updated,jina_models.py
jinaai/jina-embeddings-v2-base-en,updated,jina_models.py
jinaai/jina-embeddings-v2-small-en,updated,jina_models.py
jinaai/jina-embeddings-v3,updated,jina_models.py
jinaai/jina-embeddings-v4,updated,jina_models.py
jinaai/jina-reranker-v2-base-multilingual,updated,rerankers_custom.py
jinaai/jina-reranker-v3,updated,jina_models.py
jxm/cde-small-v1,updated,cde_models.py
jxm/cde-small-v2,updated,cde_models.py
kakaobrain/align-base,updated,align_models.py
keeeeenw/MicroLlama-text-embedding,updated,sentence_transformers_models.py
laion/CLIP-ViT-B-16-DataComp.XL-s13B-b90K,updated,openclip_models.py
laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K,updated,openclip_models.py
laion/CLIP-ViT-B-32-laion2B-s34B-b79K,updated,openclip_models.py
laion/CLIP-ViT-H-14-laion2B-s32B-b79K,updated,openclip_models.py
laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K,updated,openclip_models.py
laion/CLIP-ViT-L-14-laion2B-s32B-b82K,updated,openclip_models.py
laion/CLIP-ViT-bigG-14-laion2B-39B-b160k,updated,openclip_models.py
laion/CLIP-ViT-g-14-laion2B-s34B-b88K,updated,openclip_models.py
lier007/xiaobu-embedding,updated,misc_models.py
lier007/xiaobu-embedding-v2,updated,misc_models.py
lightonai/GTE-ModernColBERT-v1,updated,pylate_models.py
llamaindex/vdr-2b-multi-v1,updated,vdr_models.py
llmrails/ember-v1,updated,misc_models.py
m3hrdadfi/bert-zwnj-wnli-mean-tokens,updated,fa_models.py
m3hrdadfi/roberta-zwnj-wnli-mean-tokens,updated,fa_models.py
malenia1/ternary-weight-embedding,updated,misc_models.py
manu/bge-m3-custom-fr,updated,bge_models.py
manu/sentence_croissant_alpha_v0.2,updated,misc_models.py
manu/sentence_croissant_alpha_v0.3,updated,misc_models.py
manu/sentence_croissant_alpha_v0.4,updated,misc_models.py
manveertamber/cadet-embed-base-v1,updated,cadet_models.py
meta-llama/Llama-2-7b-chat-hf,updated,rerankers_monot5_based.py
meta-llama/Llama-2-7b-hf,updated,rerankers_monot5_based.py
microsoft/LLM2CLIP-Openai-B-16,updated,llm2clip_models.py
microsoft/LLM2CLIP-Openai-L-14-224,updated,llm2clip_models.py
microsoft/LLM2CLIP-Openai-L-14-336,updated,llm2clip_models.py
minishlab/M2V_base_glove,updated,model2vec_models.py
minishlab/M2V_base_glove_subword,updated,model2vec_models.py
minishlab/M2V_base_output,updated,model2vec_models.py
minishlab/M2V_multilingual_output,updated,model2vec_models.py
minishlab/potion-base-2M,updated,model2vec_models.py
minishlab/potion-base-4M,updated,model2vec_models.py
minishlab/potion-base-8M,updated,model2vec_models.py
minishlab/potion-multilingual-128M,updated,model2vec_models.py
mistralai/Mistral-7B-Instruct-v0.2,updated,rerankers_monot5_based.py
mixedbread-ai/mxbai-embed-2d-large-v1,updated,mxbai_models.py
mixedbread-ai/mxbai-embed-large-v1,updated,mxbai_models.py
mixedbread-ai/mxbai-embed-xsmall-v1,updated,mxbai_models.py
moka-ai/m3e-base,updated,moka_models.py
moka-ai/m3e-large,updated,moka_models.py
moka-ai/m3e-small,updated,moka_models.py
myrkur/sentence-transformer-parsbert-fa,updated,fa_models.py
nomic-ai/colnomic-embed-multimodal-3b,updated,colqwen_models.py
nomic-ai/colnomic-embed-multimodal-7b,updated,colqwen_models.py
nomic-ai/modernbert-embed-base,updated,nomic_models.py
nomic-ai/nomic-embed-text-v1,updated,nomic_models.py
nomic-ai/nomic-embed-text-v1-ablated,updated,nomic_models.py
nomic-ai/nomic-embed-text-v1-unsupervised,updated,nomic_models.py
nomic-ai/nomic-embed-text-v1.5,updated,nomic_models.py
nomic-ai/nomic-embed-text-v2-moe,updated,nomic_models.py
nomic-ai/nomic-embed-vision-v1.5,updated,nomic_models_vision.py
nvidia/NV-Embed-v1,updated,nvidia_models.py
nvidia/NV-Embed-v2,updated,nvidia_models.py
nvidia/llama-embed-nemotron-8b,updated,nvidia_models.py
nvidia/llama-nemoretriever-colembed-1b-v1,updated,nvidia_llama_nemoretriever_colemb.py
nvidia/llama-nemoretriever-colembed-3b-v1,updated,nvidia_llama_nemoretriever_colemb.py
nyu-visionx/moco-v3-vit-b,updated,moco_models.py
nyu-visionx/moco-v3-vit-l,updated,moco_models.py
omarelshehy/arabic-english-sts-matryoshka,updated,misc_models.py
openai/clip-vit-base-patch16,updated,clip_models.py
openai/clip-vit-base-patch32,updated,clip_models.py
openai/clip-vit-large-patch14,updated,clip_models.py
openai/text-embedding-3-large,updated,openai_models.py
openai/text-embedding-3-large (embed_dim=512),updated,openai_models.py
openai/text-embedding-3-small,updated,openai_models.py
openai/text-embedding-3-small (embed_dim=512),updated,openai_models.py
openai/text-embedding-ada-002,updated,openai_models.py
openbmb/MiniCPM-Embedding,updated,misc_models.py
opensearch-project/opensearch-neural-sparse-encoding-doc-v1,updated,opensearch_neural_sparse_models.py
opensearch-project/opensearch-neural-sparse-encoding-doc-v2-distill,updated,opensearch_neural_sparse_models.py
opensearch-project/opensearch-neural-sparse-encoding-doc-v2-mini,updated,opensearch_neural_sparse_models.py
opensearch-project/opensearch-neural-sparse-encoding-doc-v3-distill,updated,opensearch_neural_sparse_models.py
opensearch-project/opensearch-neural-sparse-encoding-doc-v3-gte,updated,opensearch_neural_sparse_models.py
panalexeu/xlm-roberta-ua-distilled,updated,ua_sentence_models.py
prdev/mini-gte,updated,qtack_models.py
rasgaard/m2v-dfm-large,updated,rasgaard_models.py
richinfoai/ritrieve_zh_v1,updated,richinfoai_models.py
royokong/e5-v,updated,e5_v.py
samaya-ai/RepLLaMA-reproduced,updated,repllama_models.py
samaya-ai/promptriever-llama2-7b-v1,updated,promptriever_models.py
samaya-ai/promptriever-llama3.1-8b-instruct-v1,updated,promptriever_models.py
samaya-ai/promptriever-llama3.1-8b-v1,updated,promptriever_models.py
samaya-ai/promptriever-mistral-v0.1-7b-v1,updated,promptriever_models.py
sbintuitions/sarashina-embedding-v1-1b,updated,sarashina_embedding_models.py
sbintuitions/sarashina-embedding-v2-1b,updated,sarashina_embedding_models.py
sbunlp/fabert,updated,fa_models.py
sdadas/mmlw-e5-base,updated,misc_models.py
sdadas/mmlw-e5-large,updated,misc_models.py
sdadas/mmlw-e5-small,updated,misc_models.py
sdadas/mmlw-roberta-base,updated,misc_models.py
sdadas/mmlw-roberta-large,updated,misc_models.py
sensenova/piccolo-base-zh,updated,piccolo_models.py
sensenova/piccolo-large-zh-v2,updated,piccolo_models.py
sentence-transformers/LaBSE,updated,sentence_transformers_models.py
sentence-transformers/all-MiniLM-L12-v2,updated,sentence_transformers_models.py
sentence-transformers/all-MiniLM-L6-v2,updated,sentence_transformers_models.py
sentence-transformers/all-mpnet-base-v2,updated,sentence_transformers_models.py
sentence-transformers/gtr-t5-base,updated,sentence_transformers_models.py
sentence-transformers/gtr-t5-large,updated,sentence_transformers_models.py
sentence-transformers/gtr-t5-xl,updated,sentence_transformers_models.py
sentence-transformers/gtr-t5-xxl,updated,sentence_transformers_models.py
sentence-transformers/multi-qa-MiniLM-L6-cos-v1,updated,sentence_transformers_models.py
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,updated,sentence_transformers_models.py
sentence-transformers/paraphrase-multilingual-mpnet-base-v2,updated,sentence_transformers_models.py
sentence-transformers/sentence-t5-base,updated,sentence_transformers_models.py
sentence-transformers/sentence-t5-large,updated,sentence_transformers_models.py
sentence-transformers/sentence-t5-xl,updated,sentence_transformers_models.py
sentence-transformers/sentence-t5-xxl,updated,sentence_transformers_models.py
sentence-transformers/static-similarity-mrl-multilingual-v1,updated,sentence_transformers_models.py
sergeyzh/BERTA,updated,ru_sentence_models.py
sergeyzh/LaBSE-ru-turbo,updated,ru_sentence_models.py
sergeyzh/rubert-mini-frida,updated,ru_sentence_models.py
sergeyzh/rubert-tiny-turbo,updated,ru_sentence_models.py
shibing624/text2vec-base-chinese,updated,text2vec_models.py
shibing624/text2vec-base-chinese-paraphrase,updated,text2vec_models.py
shibing624/text2vec-base-multilingual,updated,text2vec_models.py
silma-ai/silma-embeddding-matryoshka-v0.1,updated,misc_models.py
spartan8806/atles-champion-embedding,updated,spartan8806_atles_champion.py
tencent/KaLM-Embedding-Gemma3-12B-2511,updated,kalm_models.py
tencent/Youtu-Embedding,updated,youtu_models.py
thenlper/gte-base,updated,misc_models.py
thenlper/gte-base-zh,updated,gte_models.py
thenlper/gte-large,updated,misc_models.py
thenlper/gte-large-zh,updated,gte_models.py
thenlper/gte-small,updated,misc_models.py
thenlper/gte-small-zh,updated,gte_models.py
unicamp-dl/mt5-13b-mmarco-100k,updated,rerankers_monot5_based.py
unicamp-dl/mt5-base-mmarco-v2,updated,rerankers_monot5_based.py
vidore/colSmol-256M,updated,colsmol_models.py
vidore/colSmol-500M,updated,colsmol_models.py
vidore/colpali-v1.1,updated,colpali_models.py
vidore/colpali-v1.2,updated,colpali_models.py
vidore/colpali-v1.3,updated,colpali_models.py
vidore/colqwen2-v1.0,updated,colqwen_models.py
vidore/colqwen2.5-v0.2,updated,colqwen_models.py
voyageai/voyage-2,updated,voyage_models.py
voyageai/voyage-3,updated,voyage_models.py
voyageai/voyage-3-large,updated,voyage_models.py
voyageai/voyage-3-lite,updated,voyage_models.py
voyageai/voyage-3-m-exp,updated,voyage_models.py
voyageai/voyage-3.5,updated,voyage_models.py
voyageai/voyage-3.5 (output_dtype=binary),updated,voyage_models.py
voyageai/voyage-3.5 (output_dtype=int8),updated,voyage_models.py
voyageai/voyage-code-2,updated,voyage_models.py
voyageai/voyage-code-3,updated,voyage_models.py
voyageai/voyage-finance-2,updated,voyage_models.py
voyageai/voyage-large-2,updated,voyage_models.py
voyageai/voyage-large-2-instruct,updated,voyage_models.py
voyageai/voyage-law-2,updated,voyage_models.py
voyageai/voyage-multilingual-2,updated,voyage_models.py
voyageai/voyage-multimodal-3,updated,voyage_v.py
w601sxs/b1ade-embed,updated,b1ade_models.py
yibinlei/LENS-d4000,updated,lens_models.py
yibinlei/LENS-d8000,updated,lens_models.py
zeta-alpha-ai/Zeta-Alpha-E5-Mistral,updated,e5_instruct.py
