{
  "dataset_revision": "416b34a802308eac30e4192afc0ff99bb8dcc7f2",
  "evaluation_time": 7.935570478439331,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.49",
  "scores": {
    "test": [
      {
        "accuracy": 0.20048828125,
        "f1": 0.09238285947405721,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "lrap": 0.29851345486110403,
        "main_score": 0.20048828125,
        "scores_per_experiment": [
          {
            "accuracy": 0.2236328125,
            "f1": 0.10770985716779645,
            "lrap": 0.3113064236111037
          },
          {
            "accuracy": 0.20361328125,
            "f1": 0.07619511009408148,
            "lrap": 0.2864990234374931
          },
          {
            "accuracy": 0.18505859375,
            "f1": 0.07834039752830026,
            "lrap": 0.2866482204861042
          },
          {
            "accuracy": 0.2021484375,
            "f1": 0.09596763705647932,
            "lrap": 0.299655490451382
          },
          {
            "accuracy": 0.1962890625,
            "f1": 0.09974118360602274,
            "lrap": 0.2988009982638816
          },
          {
            "accuracy": 0.19580078125,
            "f1": 0.08160497272285944,
            "lrap": 0.29306369357638185
          },
          {
            "accuracy": 0.18798828125,
            "f1": 0.09625660613639725,
            "lrap": 0.29935709635415975
          },
          {
            "accuracy": 0.21240234375,
            "f1": 0.09205838293412945,
            "lrap": 0.30396864149304836
          },
          {
            "accuracy": 0.19091796875,
            "f1": 0.09972073552643024,
            "lrap": 0.2977973090277707
          },
          {
            "accuracy": 0.20703125,
            "f1": 0.09623371196807555,
            "lrap": 0.30803765190971505
          }
        ]
      }
    ]
  },
  "task_name": "SensitiveTopicsClassification"
}