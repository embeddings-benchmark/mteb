{
  "dataset_revision": "18193f187b92da67168c655c9973a165ed9593dd",
  "mteb_dataset_name": "MasakhaNEWSClassification",
  "mteb_version": "1.7.62",
  "test": {
    "amh": {
      "accuracy": 0.6428191489361702,
      "accuracy_stderr": 0.03584115811128052,
      "f1": 0.6404915658210579,
      "f1_stderr": 0.03419183263729819,
      "main_score": 0.6428191489361702
    },
    "eng": {
      "accuracy": 0.7470464135021098,
      "accuracy_stderr": 0.017344543805119905,
      "f1": 0.7379623759807282,
      "f1_stderr": 0.01741902631045594,
      "main_score": 0.7470464135021098
    },
    "evaluation_time": 38.17,
    "fra": {
      "accuracy": 0.716824644549763,
      "accuracy_stderr": 0.035119890474591235,
      "f1": 0.6824332222759208,
      "f1_stderr": 0.0378263096372529,
      "main_score": 0.716824644549763
    },
    "hau": {
      "accuracy": 0.4795918367346939,
      "accuracy_stderr": 0.02173276477631405,
      "f1": 0.4640271397268439,
      "f1_stderr": 0.023651043454810852,
      "main_score": 0.4795918367346939
    },
    "ibo": {
      "accuracy": 0.4246153846153846,
      "accuracy_stderr": 0.026002579146845582,
      "f1": 0.4167451894492909,
      "f1_stderr": 0.03036164690580424,
      "main_score": 0.4246153846153846
    },
    "lin": {
      "accuracy": 0.5925714285714286,
      "accuracy_stderr": 0.03721312035466272,
      "f1": 0.5877993613069388,
      "f1_stderr": 0.027110902279942332,
      "main_score": 0.5925714285714286
    },
    "lug": {
      "accuracy": 0.4228699551569507,
      "accuracy_stderr": 0.0319646338783798,
      "f1": 0.3927777761725559,
      "f1_stderr": 0.03739858007613506,
      "main_score": 0.4228699551569507
    },
    "orm": {
      "accuracy": 0.3498461538461538,
      "accuracy_stderr": 0.04475944910321918,
      "f1": 0.3104695411445214,
      "f1_stderr": 0.03474874878272315,
      "main_score": 0.3498461538461538
    },
    "pcm": {
      "accuracy": 0.8954098360655738,
      "accuracy_stderr": 0.01417440414506051,
      "f1": 0.865374464331687,
      "f1_stderr": 0.01756999988202319,
      "main_score": 0.8954098360655738
    },
    "run": {
      "accuracy": 0.4720496894409938,
      "accuracy_stderr": 0.028429298115144865,
      "f1": 0.4103538158280077,
      "f1_stderr": 0.025344500206530486,
      "main_score": 0.4720496894409938
    },
    "sna": {
      "accuracy": 0.575609756097561,
      "accuracy_stderr": 0.03299562331755973,
      "f1": 0.5877518259775614,
      "f1_stderr": 0.031972158399916885,
      "main_score": 0.575609756097561
    },
    "som": {
      "accuracy": 0.3479591836734694,
      "accuracy_stderr": 0.046239742093797644,
      "f1": 0.31699824221892225,
      "f1_stderr": 0.02732313749949074,
      "main_score": 0.3479591836734694
    },
    "swa": {
      "accuracy": 0.46050420168067224,
      "accuracy_stderr": 0.038045516654083775,
      "f1": 0.40971775097634405,
      "f1_stderr": 0.035100246126147115,
      "main_score": 0.46050420168067224
    },
    "tir": {
      "accuracy": 0.27977941176470583,
      "accuracy_stderr": 0.028593866699045244,
      "f1": 0.24716772817996743,
      "f1_stderr": 0.026834369245200013,
      "main_score": 0.27977941176470583
    },
    "xho": {
      "accuracy": 0.4481481481481481,
      "accuracy_stderr": 0.03385303801825208,
      "f1": 0.3710008637876905,
      "f1_stderr": 0.032386483030034295,
      "main_score": 0.4481481481481481
    },
    "yor": {
      "accuracy": 0.5291970802919708,
      "accuracy_stderr": 0.04452288825106741,
      "f1": 0.532650030351643,
      "f1_stderr": 0.041121774908493496,
      "main_score": 0.5291970802919708
    }
  }
}