{
  "dataset_revision": "12ca3b695563788fead87a982ad1a068284413f4",
  "mteb_dataset_name": "LegalBenchPC",
  "mteb_version": "1.7.7",
  "test": {
    "cos_sim": {
      "accuracy": 0.5787671232876712,
      "accuracy_threshold": 0.5056948065757751,
      "ap": 0.5402065162027007,
      "f1": 0.6338028169014085,
      "f1_threshold": -0.04414784908294678,
      "precision": 0.46471600688468157,
      "recall": 0.996309963099631
    },
    "dot": {
      "accuracy": 0.5873287671232876,
      "accuracy_threshold": 9.095282554626465,
      "ap": 0.5542338305178248,
      "f1": 0.6330597889800704,
      "f1_threshold": -1.3291501998901367,
      "precision": 0.4639175257731959,
      "recall": 0.996309963099631
    },
    "euclidean": {
      "accuracy": 0.5616438356164384,
      "accuracy_threshold": 3.218596935272217,
      "ap": 0.5370663976538543,
      "f1": 0.6323185011709602,
      "f1_threshold": 6.803489685058594,
      "precision": 0.4631217838765009,
      "recall": 0.996309963099631
    },
    "evaluation_time": 32.4,
    "manhattan": {
      "accuracy": 0.559931506849315,
      "accuracy_threshold": 49.70074462890625,
      "ap": 0.534497153521956,
      "f1": 0.6323185011709602,
      "f1_threshold": 106.46473693847656,
      "precision": 0.4631217838765009,
      "recall": 0.996309963099631
    },
    "max": {
      "accuracy": 0.5873287671232876,
      "ap": 0.5542338305178248,
      "f1": 0.6338028169014085
    }
  }
}