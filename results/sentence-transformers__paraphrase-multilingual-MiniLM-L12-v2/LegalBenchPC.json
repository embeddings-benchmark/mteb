{
  "dataset_revision": "12ca3b695563788fead87a982ad1a068284413f4",
  "mteb_dataset_name": "LegalBenchPC",
  "mteb_version": "1.7.7",
  "test": {
    "cos_sim": {
      "accuracy": 0.5766961651917404,
      "accuracy_threshold": 0.5056948065757751,
      "ap": 0.5254706014726046,
      "f1": 0.6295546558704453,
      "f1_threshold": -0.07407242059707642,
      "precision": 0.46005917159763315,
      "recall": 0.9967948717948718
    },
    "dot": {
      "accuracy": 0.5825958702064897,
      "accuracy_threshold": 9.095282554626465,
      "ap": 0.5344458609718888,
      "f1": 0.6295546558704453,
      "f1_threshold": -1.500563144683838,
      "precision": 0.46005917159763315,
      "recall": 0.9967948717948718
    },
    "euclidean": {
      "accuracy": 0.5619469026548672,
      "accuracy_threshold": 3.218596935272217,
      "ap": 0.5271745863698191,
      "f1": 0.6309403437815976,
      "f1_threshold": 6.879115581512451,
      "precision": 0.4608567208271787,
      "recall": 1.0
    },
    "evaluation_time": 39.67,
    "manhattan": {
      "accuracy": 0.56047197640118,
      "accuracy_threshold": 49.70074462890625,
      "ap": 0.5252610979228741,
      "f1": 0.62891809908999,
      "f1_threshold": 106.47344970703125,
      "precision": 0.45937961595273263,
      "recall": 0.9967948717948718
    },
    "max": {
      "accuracy": 0.5825958702064897,
      "ap": 0.5344458609718888,
      "f1": 0.6309403437815976
    }
  }
}