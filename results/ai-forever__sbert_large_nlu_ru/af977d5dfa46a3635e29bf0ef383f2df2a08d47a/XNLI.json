{
  "dataset_revision": "09698e0180d87dc247ca447d3a1248b931ac0cdb",
  "evaluation_time": 5.730736017227173,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.25",
  "scores": {
    "test": [
      {
        "cos_sim": {
          "accuracy": 0.5897435897435898,
          "accuracy_threshold": 0.6617142558097839,
          "ap": 0.5982227062324497,
          "f1": 0.6711758584807493,
          "f1_threshold": 0.4916282296180725,
          "precision": 0.5201612903225806,
          "recall": 0.9457478005865103
        },
        "dot": {
          "accuracy": 0.5897435897435898,
          "accuracy_threshold": 0.6617142558097839,
          "ap": 0.5982220216998406,
          "f1": 0.6711758584807493,
          "f1_threshold": 0.4916282296180725,
          "precision": 0.5201612903225806,
          "recall": 0.9457478005865103
        },
        "euclidean": {
          "accuracy": 0.5897435897435898,
          "accuracy_threshold": 0.8225396871566772,
          "ap": 0.5982227062324497,
          "f1": 0.6711758584807493,
          "f1_threshold": 1.0083370208740234,
          "precision": 0.5201612903225806,
          "recall": 0.9457478005865103
        },
        "hf_subset": "ru",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.5982227062324497,
        "manhattan": {
          "accuracy": 0.5882783882783883,
          "accuracy_threshold": 20.289779663085938,
          "ap": 0.5979928188510247,
          "f1": 0.6694692590646347,
          "f1_threshold": 24.321449279785156,
          "precision": 0.5217035217035217,
          "recall": 0.9340175953079178
        },
        "max": {
          "accuracy": 0.5897435897435898,
          "ap": 0.5982227062324497,
          "f1": 0.6711758584807493
        }
      }
    ],
    "validation": [
      {
        "cos_sim": {
          "accuracy": 0.6065934065934065,
          "accuracy_threshold": 0.6902921199798584,
          "ap": 0.6135478418455651,
          "f1": 0.6696296296296296,
          "f1_threshold": 0.35159072279930115,
          "precision": 0.5048399106478034,
          "recall": 0.9941348973607038
        },
        "dot": {
          "accuracy": 0.6065934065934065,
          "accuracy_threshold": 0.6902921199798584,
          "ap": 0.6135478418455651,
          "f1": 0.6696296296296296,
          "f1_threshold": 0.351590633392334,
          "precision": 0.5048399106478034,
          "recall": 0.9941348973607038
        },
        "euclidean": {
          "accuracy": 0.6065934065934065,
          "accuracy_threshold": 0.7870296239852905,
          "ap": 0.6135478418455651,
          "f1": 0.6696296296296296,
          "f1_threshold": 1.138774037361145,
          "precision": 0.5048399106478034,
          "recall": 0.9941348973607038
        },
        "hf_subset": "ru",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.6135478418455651,
        "manhattan": {
          "accuracy": 0.6014652014652014,
          "accuracy_threshold": 19.375900268554688,
          "ap": 0.612412598185982,
          "f1": 0.6689655172413793,
          "f1_threshold": 28.38625717163086,
          "precision": 0.5037091988130564,
          "recall": 0.9956011730205279
        },
        "max": {
          "accuracy": 0.6065934065934065,
          "ap": 0.6135478418455651,
          "f1": 0.6696296296296296
        }
      }
    ]
  },
  "task_name": "XNLI"
}