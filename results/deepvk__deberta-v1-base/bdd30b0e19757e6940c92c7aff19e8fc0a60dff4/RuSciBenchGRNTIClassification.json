{
  "dataset_revision": "673a610d6d3dd91a547a0d57ae1b56f37ebbf6a1",
  "evaluation_time": 40.50701665878296,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.49",
  "scores": {
    "test": [
      {
        "accuracy": 0.53525390625,
        "f1": 0.5341330940901308,
        "f1_weighted": 0.5342250308982337,
        "hf_subset": "default",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.53525390625,
        "scores_per_experiment": [
          {
            "accuracy": 0.55908203125,
            "f1": 0.5548027646697411,
            "f1_weighted": 0.5548818941605839
          },
          {
            "accuracy": 0.548828125,
            "f1": 0.5475501225040655,
            "f1_weighted": 0.5476715171753379
          },
          {
            "accuracy": 0.5234375,
            "f1": 0.5233013000427874,
            "f1_weighted": 0.5234194631560196
          },
          {
            "accuracy": 0.5185546875,
            "f1": 0.5162020144282956,
            "f1_weighted": 0.5163044255777952
          },
          {
            "accuracy": 0.52490234375,
            "f1": 0.5272771767931309,
            "f1_weighted": 0.5272425423364556
          },
          {
            "accuracy": 0.54638671875,
            "f1": 0.5414941353237884,
            "f1_weighted": 0.5415997699650186
          },
          {
            "accuracy": 0.55712890625,
            "f1": 0.5564244145246192,
            "f1_weighted": 0.5565798527091881
          },
          {
            "accuracy": 0.53662109375,
            "f1": 0.5352123794741368,
            "f1_weighted": 0.5353073579963835
          },
          {
            "accuracy": 0.51806640625,
            "f1": 0.5181224818423842,
            "f1_weighted": 0.5182818675320902
          },
          {
            "accuracy": 0.51953125,
            "f1": 0.5209441512983577,
            "f1_weighted": 0.520961618373465
          }
        ]
      }
    ]
  },
  "task_name": "RuSciBenchGRNTIClassification"
}