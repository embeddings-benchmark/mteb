{
  "dataset_revision": "09698e0180d87dc247ca447d3a1248b931ac0cdb",
  "evaluation_time": 5.748415470123291,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.25",
  "scores": {
    "test": [
      {
        "cos_sim": {
          "accuracy": 0.6175824175824176,
          "accuracy_threshold": 0.656559944152832,
          "ap": 0.6427979721521064,
          "f1": 0.6789092932665554,
          "f1_threshold": 0.5138709545135498,
          "precision": 0.547085201793722,
          "recall": 0.8944281524926686
        },
        "dot": {
          "accuracy": 0.6175824175824176,
          "accuracy_threshold": 0.6565600633621216,
          "ap": 0.6427979721521064,
          "f1": 0.6789092932665554,
          "f1_threshold": 0.5138709545135498,
          "precision": 0.547085201793722,
          "recall": 0.8944281524926686
        },
        "euclidean": {
          "accuracy": 0.6175824175824176,
          "accuracy_threshold": 0.8287822008132935,
          "ap": 0.6427979721521064,
          "f1": 0.6789092932665554,
          "f1_threshold": 0.9860314130783081,
          "precision": 0.547085201793722,
          "recall": 0.8944281524926686
        },
        "hf_subset": "ru",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.6427979721521064,
        "manhattan": {
          "accuracy": 0.610989010989011,
          "accuracy_threshold": 20.587291717529297,
          "ap": 0.6400759377878474,
          "f1": 0.6814016172506738,
          "f1_threshold": 24.407180786132812,
          "precision": 0.5387894288150042,
          "recall": 0.9266862170087976
        },
        "max": {
          "accuracy": 0.6175824175824176,
          "ap": 0.6427979721521064,
          "f1": 0.6814016172506738
        }
      }
    ],
    "validation": [
      {
        "cos_sim": {
          "accuracy": 0.6212454212454213,
          "accuracy_threshold": 0.6916130185127258,
          "ap": 0.6502625368962802,
          "f1": 0.6737626397019691,
          "f1_threshold": 0.4545447528362274,
          "precision": 0.5288220551378446,
          "recall": 0.9281524926686217
        },
        "dot": {
          "accuracy": 0.6212454212454213,
          "accuracy_threshold": 0.6916130185127258,
          "ap": 0.6502625368962802,
          "f1": 0.6737626397019691,
          "f1_threshold": 0.4545448124408722,
          "precision": 0.5288220551378446,
          "recall": 0.9281524926686217
        },
        "euclidean": {
          "accuracy": 0.6212454212454213,
          "accuracy_threshold": 0.7853495478630066,
          "ap": 0.6502625368962802,
          "f1": 0.6737626397019691,
          "f1_threshold": 1.0444666147232056,
          "precision": 0.5288220551378446,
          "recall": 0.9281524926686217
        },
        "hf_subset": "ru",
        "languages": [
          "rus-Cyrl"
        ],
        "main_score": 0.6502625368962802,
        "manhattan": {
          "accuracy": 0.6153846153846154,
          "accuracy_threshold": 18.606258392333984,
          "ap": 0.6493888036487095,
          "f1": 0.6740389678778305,
          "f1_threshold": 25.23475456237793,
          "precision": 0.5258833196384552,
          "recall": 0.9384164222873901
        },
        "max": {
          "accuracy": 0.6212454212454213,
          "ap": 0.6502625368962802,
          "f1": 0.6740389678778305
        }
      }
    ]
  },
  "task_name": "XNLI"
}