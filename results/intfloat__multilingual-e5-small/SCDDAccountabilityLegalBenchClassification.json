{
  "dataset_revision": "12ca3b695563788fead87a982ad1a068284413f4",
  "mteb_dataset_name": "SCDDAccountabilityLegalBenchClassification",
  "mteb_version": "1.9.0",
  "test": {
    "accuracy": 0.6534391534391535,
    "ap": 0.956734424188619,
    "evaluation_time": 48.73,
    "f1": 0.46843432988030703,
    "main_score": 0.6534391534391535,
    "scores_per_experiment": [
      {
        "accuracy": 0.6534391534391535,
        "ap": 0.9567344241886189,
        "f1": 0.468434329880307
      },
      {
        "accuracy": 0.6534391534391535,
        "ap": 0.9567344241886189,
        "f1": 0.468434329880307
      },
      {
        "accuracy": 0.6534391534391535,
        "ap": 0.9567344241886189,
        "f1": 0.468434329880307
      },
      {
        "accuracy": 0.6534391534391535,
        "ap": 0.9567344241886189,
        "f1": 0.468434329880307
      },
      {
        "accuracy": 0.6534391534391535,
        "ap": 0.9567344241886189,
        "f1": 0.468434329880307
      },
      {
        "accuracy": 0.6534391534391535,
        "ap": 0.9567344241886189,
        "f1": 0.468434329880307
      },
      {
        "accuracy": 0.6534391534391535,
        "ap": 0.9567344241886189,
        "f1": 0.468434329880307
      },
      {
        "accuracy": 0.6534391534391535,
        "ap": 0.9567344241886189,
        "f1": 0.468434329880307
      },
      {
        "accuracy": 0.6534391534391535,
        "ap": 0.9567344241886189,
        "f1": 0.468434329880307
      },
      {
        "accuracy": 0.6534391534391535,
        "ap": 0.9567344241886189,
        "f1": 0.468434329880307
      }
    ]
  }
}