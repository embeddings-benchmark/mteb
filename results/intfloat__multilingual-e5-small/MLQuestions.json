{
  "dataset_revision": "83b690cb666c5a8869e7f213a877bbd24a642d7c",
  "evaluation_time": 7.949865818023682,
  "kg_co2_emissions": null,
  "mteb_version": "1.10.10",
  "scores": {
    "dev": [
      {
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.57787,
        "map_at_1": 0.36067,
        "map_at_10": 0.5039,
        "map_at_100": 0.51193,
        "map_at_1000": 0.51204,
        "map_at_20": 0.50955,
        "map_at_3": 0.46689,
        "map_at_5": 0.48952,
        "mrr_at_1": 0.36133,
        "mrr_at_10": 0.50556,
        "mrr_at_100": 0.51327,
        "mrr_at_1000": 0.51339,
        "mrr_at_20": 0.51085,
        "mrr_at_3": 0.46844,
        "mrr_at_5": 0.49131,
        "ndcg_at_1": 0.36067,
        "ndcg_at_10": 0.57787,
        "ndcg_at_100": 0.61361,
        "ndcg_at_1000": 0.6166,
        "ndcg_at_20": 0.59789,
        "ndcg_at_3": 0.50238,
        "ndcg_at_5": 0.54323,
        "precision_at_1": 0.36067,
        "precision_at_10": 0.08113,
        "precision_at_100": 0.00971,
        "precision_at_1000": 0.00099,
        "precision_at_20": 0.04447,
        "precision_at_3": 0.20178,
        "precision_at_5": 0.14093,
        "recall_at_1": 0.36067,
        "recall_at_10": 0.81133,
        "recall_at_100": 0.97133,
        "recall_at_1000": 0.99467,
        "recall_at_20": 0.88933,
        "recall_at_3": 0.60533,
        "recall_at_5": 0.70467
      }
    ],
    "test": [
      {
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.59682,
        "map_at_1": 0.39533,
        "map_at_10": 0.52594,
        "map_at_100": 0.53336,
        "map_at_1000": 0.53347,
        "map_at_20": 0.53103,
        "map_at_3": 0.48644,
        "map_at_5": 0.50911,
        "mrr_at_1": 0.39133,
        "mrr_at_10": 0.52207,
        "mrr_at_100": 0.52999,
        "mrr_at_1000": 0.53009,
        "mrr_at_20": 0.5277,
        "mrr_at_3": 0.48178,
        "mrr_at_5": 0.50588,
        "ndcg_at_1": 0.39533,
        "ndcg_at_10": 0.59682,
        "ndcg_at_100": 0.63039,
        "ndcg_at_1000": 0.63291,
        "ndcg_at_20": 0.61492,
        "ndcg_at_3": 0.51581,
        "ndcg_at_5": 0.55669,
        "precision_at_1": 0.39533,
        "precision_at_10": 0.08227,
        "precision_at_100": 0.00974,
        "precision_at_1000": 0.00099,
        "precision_at_20": 0.04467,
        "precision_at_3": 0.20022,
        "precision_at_5": 0.14,
        "recall_at_1": 0.39533,
        "recall_at_10": 0.82267,
        "recall_at_100": 0.974,
        "recall_at_1000": 0.99333,
        "recall_at_20": 0.89333,
        "recall_at_3": 0.60067,
        "recall_at_5": 0.7
      }
    ]
  },
  "task_name": "MLQuestions"
}