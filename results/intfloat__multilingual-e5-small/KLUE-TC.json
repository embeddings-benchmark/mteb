{
  "dataset_revision": "349481ec73fff722f88e0453ca05c77a447d967c",
  "mteb_dataset_name": "KLUE-TC",
  "mteb_version": "1.7.46",
  "validation": {
    "accuracy": 0.578759765625,
    "accuracy_stderr": 0.03893843212205992,
    "evaluation_time": 8.6,
    "f1": 0.5952239718354027,
    "f1_stderr": 0.028001030596815257,
    "main_score": 0.578759765625
  }
}