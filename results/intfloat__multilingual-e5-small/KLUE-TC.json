{
  "dataset_revision": "349481ec73fff722f88e0453ca05c77a447d967c",
  "mteb_dataset_name": "KLUE-TC",
  "mteb_version": "1.7.46",
  "validation": {
    "accuracy": 0.5745470517184584,
    "accuracy_stderr": 0.03705071536142237,
    "evaluation_time": 11.48,
    "f1": 0.5899855998019173,
    "f1_stderr": 0.025810551049404613,
    "main_score": 0.5745470517184584
  }
}