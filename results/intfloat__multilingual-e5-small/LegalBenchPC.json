{
  "dataset_revision": "12ca3b695563788fead87a982ad1a068284413f4",
  "mteb_dataset_name": "LegalBenchPC",
  "mteb_version": "1.7.7",
  "test": {
    "cos_sim": {
      "accuracy": 0.5722713864306784,
      "accuracy_threshold": 0.872885525226593,
      "ap": 0.5233200465732908,
      "f1": 0.6295546558704453,
      "f1_threshold": 0.7433135509490967,
      "precision": 0.46005917159763315,
      "recall": 0.9967948717948718
    },
    "dot": {
      "accuracy": 0.5722713864306784,
      "accuracy_threshold": 0.8728854656219482,
      "ap": 0.5233224857880587,
      "f1": 0.6295546558704453,
      "f1_threshold": 0.7433135509490967,
      "precision": 0.46005917159763315,
      "recall": 0.9967948717948718
    },
    "euclidean": {
      "accuracy": 0.5722713864306784,
      "accuracy_threshold": 0.5042111873626709,
      "ap": 0.5233200465732908,
      "f1": 0.6295546558704453,
      "f1_threshold": 0.7164959907531738,
      "precision": 0.46005917159763315,
      "recall": 0.9967948717948718
    },
    "evaluation_time": 85.28,
    "manhattan": {
      "accuracy": 0.5781710914454278,
      "accuracy_threshold": 8.489166259765625,
      "ap": 0.5241034805085035,
      "f1": 0.6309403437815976,
      "f1_threshold": 11.268424034118652,
      "precision": 0.4608567208271787,
      "recall": 1.0
    },
    "max": {
      "accuracy": 0.5781710914454278,
      "ap": 0.5241034805085035,
      "f1": 0.6309403437815976
    }
  }
}